{
  "generated_at": "2026-01-12T00:59:43.477948",
  "previous_date": "20260105",
  "current_date": "20260112",
  "previous_count": 40337,
  "current_count": 41451,
  "changes": {
    "new_datasets": [
      {
        "id": "KixxxAi/PersonaHub",
        "author": "KixxxAi",
        "created_at": "2026-01-05 14:03:23+00:00",
        "last_modified": "2026-01-05 14:03:30+00:00",
        "downloads": 30,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:text-classification",
          "task_categories:token-classification",
          "task_categories:fill-mask",
          "task_categories:table-question-answering",
          "language:en",
          "language:zh",
          "license:cc-by-nc-sa-4.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2406.20094",
          "region:us",
          "synthetic",
          "text",
          "math",
          "reasoning",
          "instruction",
          "tool",
          "persona"
        ],
        "description": "\n\t\n\t\t\n\t\tScaling Synthetic Data Creation with 1,000,000,000 Personas\n\t\n\nThis repo releases data introduced in our paper Scaling Synthetic Data Creation with 1,000,000,000 Personas:\nWe propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data. To fully exploit this methodology at scale, we introduce PERSONA HUB â€“ a collection of 1 billion diverse personas automatically curated from web data.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/KixxxAi/PersonaHub.",
        "url": "https://huggingface.co/datasets/KixxxAi/PersonaHub",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation",
          "text-classification",
          "token-classification",
          "fill-mask",
          "table-question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Marek324/speech-music-classification-test",
        "author": "Marek324",
        "created_at": "2026-01-08 02:41:05+00:00",
        "last_modified": "2026-01-08 15:29:39+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Marek324/speech-music-classification-test",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Menoviar28/menov31",
        "author": "Menoviar28",
        "created_at": "2026-01-10 01:56:59+00:00",
        "last_modified": "2026-01-10 02:01:41+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:table-question-answering",
          "task_categories:text-classification",
          "task_categories:question-answering",
          "task_categories:zero-shot-classification",
          "task_categories:translation",
          "task_categories:summarization",
          "task_categories:feature-extraction",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_categories:token-classification",
          "task_categories:sentence-similarity",
          "task_categories:text-to-speech",
          "task_categories:text-to-audio",
          "task_categories:automatic-speech-recognition",
          "task_categories:audio-to-audio",
          "task_categories:audio-classification",
          "task_categories:voice-activity-detection",
          "task_categories:depth-estimation",
          "language:aa",
          "language:af",
          "language:ak",
          "language:ba",
          "language:be",
          "language:bg",
          "language:bh",
          "language:bi",
          "language:bm",
          "language:bn",
          "language:bo",
          "language:br",
          "language:bs",
          "language:ca",
          "language:ce",
          "language:ch",
          "language:co",
          "language:cr",
          "language:cs",
          "language:cu",
          "language:cv",
          "language:cy",
          "language:da",
          "language:de",
          "language:dv",
          "language:dz",
          "language:ee",
          "language:el",
          "language:en",
          "language:eo",
          "language:es",
          "language:et",
          "language:eu",
          "language:fa",
          "language:ff",
          "language:fi",
          "language:fj",
          "language:fo",
          "language:fr",
          "language:fy",
          "language:ga",
          "language:gd",
          "language:gl",
          "language:gn",
          "language:gu",
          "language:gv",
          "language:ha",
          "language:he",
          "language:hi",
          "language:ho",
          "language:hr",
          "language:ht",
          "language:hu",
          "language:hy",
          "language:hz",
          "language:ia",
          "language:id",
          "language:ie",
          "license:apache-2.0",
          "size_categories:n>1T",
          "region:us",
          "chemistry",
          "biology",
          "finance",
          "legal",
          "music",
          "art",
          "code",
          "climate",
          "medical",
          "agent"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Menoviar28/menov31",
        "languages": [
          "aa",
          "af",
          "ak",
          "ba",
          "be",
          "bg",
          "bh",
          "bi",
          "bm",
          "bn",
          "bo",
          "br",
          "bs",
          "ca",
          "ce",
          "ch",
          "co",
          "cr",
          "cs",
          "cu",
          "cv",
          "cy",
          "da",
          "de",
          "dv",
          "dz",
          "ee",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "ff",
          "fi",
          "fj",
          "fo",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gn",
          "gu",
          "gv",
          "ha",
          "he",
          "hi",
          "ho",
          "hr",
          "ht",
          "hu",
          "hy",
          "hz",
          "ia",
          "id",
          "ie"
        ],
        "tasks": [
          "table-question-answering",
          "text-classification",
          "question-answering",
          "zero-shot-classification",
          "translation",
          "summarization",
          "feature-extraction",
          "text-generation",
          "fill-mask",
          "token-classification",
          "sentence-similarity",
          "text-to-speech",
          "text-to-audio",
          "automatic-speech-recognition",
          "audio-to-audio",
          "audio-classification",
          "voice-activity-detection",
          "depth-estimation"
        ],
        "size_categories": [
          "n>1T"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:01:35+00:00",
        "last_modified": "2026-01-05 23:02:26+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_yellow_pepper_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¤æ¡Œä¸Šçš„é»„è¾£æ¤’\ntotal_episodes: 218\ntotal_tasks: 1\nsize: 252.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ketav/parakeet-hindi-asr",
        "author": "ketav",
        "created_at": "2026-01-11 03:31:04+00:00",
        "last_modified": "2026-01-11 05:43:42+00:00",
        "downloads": 4,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "language:hi",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "parakeet",
          "nvidia",
          "nemo",
          "asr",
          "bilingual",
          "hindi",
          "english",
          "fine-tuning"
        ],
        "description": "\n\t\n\t\t\n\t\tParakeet Hindi-English Bilingual ASR\n\t\n\nFine-tuning NVIDIA Parakeet TDT 0.6B for bilingual Hindi-English automatic speech recognition.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\n# Download\npip install huggingface_hub\nhuggingface-cli download ketav/parakeet-hindi-asr --repo-type dataset --local-dir ./parakeet-hindi-asr\n\n# Install dependencies\npip install nemo_toolkit[asr] bitsandbytes sentencepiece\n\n# Train (after updating paths in config)\ncd parakeet-hindi-asr/scripts\npython ft_0.6B_hi_v3.pyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ketav/parakeet-hindi-asr.",
        "url": "https://huggingface.co/datasets/ketav/parakeet-hindi-asr",
        "languages": [
          "hi",
          "en"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_8_appleblueplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:28:39+00:00",
        "last_modified": "2026-01-05 23:29:31+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_8_appleblueplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœè“ç›˜å­part_2\ntotal_episodes: 69\ntotal_tasks: 1\nsize: 730.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_8_appleblueplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_8_appleblueplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "yophis/yodas2-mcqa",
        "author": "yophis",
        "created_at": "2025-12-07 08:54:32+00:00",
        "last_modified": "2026-01-08 11:45:54+00:00",
        "downloads": 223,
        "likes": 0,
        "tags": [
          "task_categories:audio-text-to-text",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2510.15231",
          "region:us",
          "synthetic",
          "audio-llm",
          "audio-question-answering",
          "mcqa",
          "long-form",
          "speech-processing"
        ],
        "description": "\n\t\n\t\t\n\t\tYODAS2-MCQA: Long-Form Audio Question Answering\n\t\n\nPaper | Code\nYODAS2-MCQA is a synthetic Multiple-Choice Question-Answering (MCQA) dataset specifically designed to evaluate and train long-form audio understanding capabilities in Large Audio-Language Models. \nThe dataset is derived from the English subset (en129) of the YODAS2 dataset. It features audio segments tailored to specific lengths (2, 5, and 10 minutes) with questions and answers generated using Gemini 2.0 Flash.\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yophis/yodas2-mcqa.",
        "url": "https://huggingface.co/datasets/yophis/yodas2-mcqa",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-text-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1112",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:35:47+00:00",
        "last_modified": "2026-01-06 10:36:27+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1112\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_9\ntotal_episodes: 339\ntotal_tasks: 1\nsize: 212.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1112.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1112",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_left_hand_place_marker_in_pen_holder",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:12:52+00:00",
        "last_modified": "2026-01-05 18:13:36+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_left_hand_place_marker_in_pen_holder\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†é©¬å…‹ç¬”æ”¾å…¥ç¬”ç­’\ntotal_episodes: 150\ntotal_tasks: 1\nsize: 1.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_left_hand_place_marker_in_pen_holder.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_left_hand_place_marker_in_pen_holder",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:55:09+00:00",
        "last_modified": "2026-01-05 14:56:28+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_block_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥ç§¯æœ¨part_1\ntotal_episodes: 95\ntotal_tasks: 1\nsize: 341.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_push_bewak_pick_machine_place_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:41:22+00:00",
        "last_modified": "2026-01-05 21:42:18+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_push_bewak_pick_machine_place_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æŽ¨åŠ¨æ‰‹è‡‚æ‹¿èµ·æœºå™¨æ”¾ç½®ç›˜å­\ntotal_episodes: 82\ntotal_tasks: 1\nsize: 676.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_push_bewak_pick_machine_place_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_push_bewak_pick_machine_place_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Kaiser1308/Ultimate-Offensive-Red-Team",
        "author": "Kaiser1308",
        "created_at": "2026-01-10 02:13:01+00:00",
        "last_modified": "2026-01-10 02:13:01+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "modality:text",
          "region:us",
          "cybersecurity",
          "red-team",
          "penetration-testing",
          "offensive-security",
          "vulnerability-research",
          "exploit-development"
        ],
        "description": "\n\t\n\t\t\n\t\tUltimate Red Team AI Training Dataset ðŸ’€\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nA comprehensive dataset for training AI models in offensive security, red team operations, and penetration testing. This dataset combines real-world vulnerability data, exploitation techniques, and operational frameworks to create an AI capable of autonomous red team operations.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Data Points: 550,000+ unique security-related entries\nCategories: 15+ major security domainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Kaiser1308/Ultimate-Offensive-Red-Team.",
        "url": "https://huggingface.co/datasets/Kaiser1308/Ultimate-Offensive-Red-Team",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_paper_ball_in_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:41:14+00:00",
        "last_modified": "2026-01-05 22:41:23+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_paper_ball_in_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†çº¸å›¢æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 76\ntotal_tasks: 1\nsize: 37.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_paper_ball_in_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_paper_ball_in_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Elpi",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:48:41+00:00",
        "last_modified": "2026-01-10 15:12:35+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Elpi\n\t\n\nStructured dataset from Coq-Elpi â€” Elpi-based extension language for Coq.\n2,195 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/LPCIC/coq-elpi\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Elpi.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Elpi",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "AIM-Harvard/proof-of-time",
        "author": "AIM-Harvard",
        "created_at": "2026-01-09 04:24:04+00:00",
        "last_modified": "2026-01-09 04:24:18+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "academic-papers",
          "llm-agents",
          "benchmarking",
          "inspect-ai",
          "react-agents",
          "citations",
          "research-trends"
        ],
        "description": "\n\t\n\t\t\n\t\tProof of Time: Academic Paper Analysis Benchmarks\n\t\n\nThis dataset contains benchmarks for evaluating LLM agents on academic paper analysis tasks that require understanding research trends, citations, and future directions. All evaluation data uses post-training-cutoff (2025) papers to avoid data contamination.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPaper: Proof of Time: Benchmarking LLM Agents on Academic Paper Analysis (Under Review)\nRepository: https://github.com/shan23chen/proof_of_timeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIM-Harvard/proof-of-time.",
        "url": "https://huggingface.co/datasets/AIM-Harvard/proof-of-time",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_put_the_orange_into_the_box_with_left_hand",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:47:25+00:00",
        "last_modified": "2026-01-06 00:48:21+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_put_the_orange_into_the_box_with_left_hand\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç”¨å·¦æ‰‹å°†æ©™å­æ”¾å…¥ç›’å­\ntotal_episodes: 146\ntotal_tasks: 1\nsize: 785.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_put_the_orange_into_the_box_with_left_hand.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_put_the_orange_into_the_box_with_left_hand",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:14:56+00:00",
        "last_modified": "2026-01-06 07:15:21+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é’æ¤’\ntotal_episodes: 196\ntotal_tasks: 1\nsize: 106.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "imageomics/BaboonLand",
        "author": "imageomics",
        "created_at": "2026-01-07 20:14:27+00:00",
        "last_modified": "2026-01-08 22:57:23+00:00",
        "downloads": 29,
        "likes": 0,
        "tags": [
          "task_categories:video-classification",
          "task_categories:object-detection",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1M<n<10M",
          "format:csv",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2405.17698",
          "doi:10.57967/hf/7470",
          "region:us",
          "baboons",
          "video",
          "animal behavior",
          "behavior recognition",
          "annotation",
          "annotated video",
          "conservation",
          "drone",
          "UAV",
          "imbalanced",
          "Kenya",
          "Mpala Research Centre"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for BaboonLand Dataset: Tracking Primates in the Wild and Automating Behaviour Recognition from Drone Videos\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBaboonLand is an aerial drone video dataset of wild olive baboons (Papio anubis) collected over 21 consecutive days in Laikipia (Mpala Research Centre), Kenya, following three troops during morning and evening movements to and from sleeping sites. The dataset contains UAV footage across diverse environments (e.g., sleeping tree, riverâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/imageomics/BaboonLand.",
        "url": "https://huggingface.co/datasets/imageomics/BaboonLand",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-classification",
          "object-detection"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:53:00+00:00",
        "last_modified": "2026-01-05 22:53:10+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é»„è¾£æ¤’æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 49\ntotal_tasks: 1\nsize: 49.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_0_tkx_1rgb_pick_shelf_insert_machine_press_switch_place_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 03:46:48+00:00",
        "last_modified": "2026-01-08 03:49:34+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_pick_shelf_insert_machine_press_switch_place_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·æž¶å­æ’å…¥æœºå™¨æŒ‰åŽ‹å¼€å…³æ”¾ç½®ç›˜å­\ntotal_episodes: 58\ntotal_tasks: 1\nsize: 610.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkx_1rgb_pick_shelf_insert_machine_press_switch_place_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkx_1rgb_pick_shelf_insert_machine_press_switch_place_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/task_486_Take_the_bottled_water_out_of_the_cardboard_box_and_place_it_neatly_on_the_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 08:10:23+00:00",
        "last_modified": "2026-01-08 09:25:09+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_486\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æŠŠç“¶è£…æ°´ä»Žçº¸ç›’é‡Œæ‹¿å‡ºæ¥ï¼Œæ•´é½åœ°æ”¾åœ¨æ¡Œå­ä¸Šã€‚part_1\ntotal_episodes: 365\ntotal_tasks: 1\nsize: 43G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/task_486_Take_the_bottled_water_out_of_the_cardboard_box_and_place_it_neatly_on_the_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/task_486_Take_the_bottled_water_out_of_the_cardboard_box_and_place_it_neatly_on_the_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "debaterhub/ipda-sentence-selection-data",
        "author": "debaterhub",
        "created_at": "2026-01-10 16:37:45+00:00",
        "last_modified": "2026-01-10 17:04:20+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "region:us",
          "debate",
          "orpo",
          "dpo",
          "sft",
          "sentence-selection"
        ],
        "description": "\n\t\n\t\t\n\t\tIPDA Sentence Selection Training Dataset\n\t\n\nTraining data for sentence-level claim selection in competitive debate. This dataset teaches models to select the most impactful claims to address during rebuttal speeches.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\nFile\nSize\nDescription\n\n\n\t\t\nsentence_selection_dataset.json\n23MB\nFull sentence selection dataset\n\n\nsentence_dpo_format_consistent.json\n4.4MB\nDPO preference pairs (consistent format)\n\n\nsentence_sft_train_v2.json\n13MB\nSFTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/debaterhub/ipda-sentence-selection-data.",
        "url": "https://huggingface.co/datasets/debaterhub/ipda-sentence-selection-data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_rotate_open_cabinet",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:46:09+00:00",
        "last_modified": "2026-01-05 17:46:55+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_rotate_open_cabinet\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ—‹è½¬æ‰“å¼€æ©±æŸœ\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 339.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_rotate_open_cabinet.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_rotate_open_cabinet",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_left_hand_pick_up_tennis_ball_and_place_it_in_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 04:56:10+00:00",
        "last_modified": "2026-01-08 04:56:41+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_pick_up_tennis_ball_and_place_it_in_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹æ¡èµ·ç½‘çƒå¹¶å°†å…¶æ”¾å…¥ç›’å­\ntotal_episodes: 131\ntotal_tasks: 1\nsize: 845.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_pick_up_tennis_ball_and_place_it_in_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_pick_up_tennis_ball_and_place_it_in_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ai-enthusiasm-community/flickr30k-vietnamese",
        "author": "ai-enthusiasm-community",
        "created_at": "2026-01-06 22:17:14+00:00",
        "last_modified": "2026-01-11 08:05:52+00:00",
        "downloads": 60,
        "likes": 7,
        "tags": [
          "task_categories:image-to-text",
          "task_categories:text-to-image",
          "task_categories:translation",
          "language:vi",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "vision",
          "image-captioning",
          "flickr",
          "flickr30k",
          "vietnamese",
          "vietnam",
          "vi",
          "vn"
        ],
        "description": "\n\t\n\t\t\n\t\tTeam and Homepage\n\t\n\nThis dataset is maintained by AI Enthusiasm. You can find more of our work, community projects, and official updates at our homepage:\n\nOfficial Website: https://aienthusiasm.vn\nHugging Face Organization: https://huggingface.co/ai-enthusiasm-community\n\n\n\t\n\t\t\n\t\n\t\n\t\tContact\n\t\n\nIf you encounter any issues with the dataset or have any inquiries, please feel free to reach out to us via email at: aienthusiasm.team@gmail.com\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nFlickr30k-Vietnameseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai-enthusiasm-community/flickr30k-vietnamese.",
        "url": "https://huggingface.co/datasets/ai-enthusiasm-community/flickr30k-vietnamese",
        "languages": [
          "vi",
          "en"
        ],
        "tasks": [
          "image-to-text",
          "text-to-image",
          "translation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Lean4-ProofWidgets",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:37:34+00:00",
        "last_modified": "2026-01-10 15:13:24+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-ProofWidgets\n\t\n\nStructured dataset from ProofWidgets4 â€” Interactive proof widgets.\n276 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/leanprover-community/ProofWidgets4\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-ProofWidgets.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-ProofWidgets",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "CleverThis/uniprotkb_obsolete_entries_60000000",
        "author": "CleverThis",
        "created_at": "2026-01-05 10:33:52+00:00",
        "last_modified": "2026-01-05 10:38:39+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10M<n<100M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tuniprotkb_obsolete_entries_60000000\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComprehensive protein knowledgebase with functional annotations\nOriginal Source: ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/rdf/uniprotkb_obsolete_entries_60000000.rdf.xz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from uniprotkb_obsolete_entries_60000000 converted to HuggingFace\ndataset format for easy use in machine learning pipelines.\n\nFormat: Originally rdf, converted toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CleverThis/uniprotkb_obsolete_entries_60000000.",
        "url": "https://huggingface.co/datasets/CleverThis/uniprotkb_obsolete_entries_60000000",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_43_packplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:20:01+00:00",
        "last_modified": "2026-01-05 23:21:26+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_43_packplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“åŒ…ç›˜å­part_4\ntotal_episodes: 200\ntotal_tasks: 1\nsize: 2.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_43_packplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_43_packplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/HOL-Light",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:00:01+00:00",
        "last_modified": "2026-01-10 14:00:04+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-2-clause",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "hol-light",
          "higher-order-logic",
          "ocaml"
        ],
        "description": "\n\t\n\t\t\n\t\tHOL-Light\n\t\n\nA structured dataset of theorems and definitions from HOL Light, an interactive theorem prover for higher-order logic written in OCaml.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/jrh13/hol-light\nLicense: BSD-2-Clause\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n34,572\n\n\nTheorems\n32,614\n\n\nDefinitions\n1,958\n\n\nSource Files\n556\n\n\n\t\n\n\n\t\n\t\t\n\t\tTop Libraries\n\t\n\n\n\t\n\t\t\nLibrary\nCount\n\n\n\t\t\nMultivariate\n16,190\n\n\nLibrary\n7,326\n\n\ncore\n2,584\n\n\n100 (Flyspeck)\n2,519â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/HOL-Light.",
        "url": "https://huggingface.co/datasets/phanerozoic/HOL-Light",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "suman-kalavagunta/chess-coach-turningpoints",
        "author": "suman-kalavagunta",
        "created_at": "2026-01-07 23:26:37+00:00",
        "last_modified": "2026-01-08 01:17:45+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "chess",
          "explainable-ai",
          "llm",
          "fine-tuning",
          "supervised-learning",
          "stockfish",
          "education",
          "coaching",
          "neuro-symbolic"
        ],
        "description": "\n\t\n\t\t\n\t\tChess Coach â€“ Turning Point Explanations Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis repository contains a curated, engine-grounded dataset for training language models to explain chess mistakes and turning points in a human coaching style.\nThe goal is explainability and pedagogy, not move calculation or engine strength.\n\n\n\t\n\t\t\n\t\tWhat this dataset is (and is not)\n\t\n\n\n\t\n\t\t\n\t\tâœ… This dataset is for\n\t\n\n\nTraining LLMs to explain evaluation swings\nTeaching coaching tone, structure, and pedagogyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suman-kalavagunta/chess-coach-turningpoints.",
        "url": "https://huggingface.co/datasets/suman-kalavagunta/chess-coach-turningpoints",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "enPurified/smollm-corpus-cosmopedia-v2-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 16:13:58+00:00",
        "last_modified": "2026-01-12 00:39:58+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:HuggingFaceTB/smollm-corpus",
          "language:en",
          "license:odc-by",
          "size_categories:1M<n<10M",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "cosmopedia-v2",
          "quality-filtered",
          "synthetic",
          "enPurified"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– Cosmopedia-v2-enPurified-openai-messages\n\t\n\nCosmopedia-v2-enPurified is a high-density, distillation of the HuggingFaceTB/smollm-corpus (cosmopedia-v2) subset.\nThe enPurified collection is built on a specific philosophy: High-Value English Specialization. While many datasets focus on the breadth of LLM capabilities (coding, math, logic), the goal of enPurified is to isolate the highest quality English prose. By removing technical noise, foreign languages, and low-substance text, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/smollm-corpus-cosmopedia-v2-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/smollm-corpus-cosmopedia-v2-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_53_stackcup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:10:07+00:00",
        "last_modified": "2026-01-05 10:10:47+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_53_stackcup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å æ¯å­\ntotal_episodes: 35\ntotal_tasks: 1\nsize: 580.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_53_stackcup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_53_stackcup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_triangle_bread_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:50:09+00:00",
        "last_modified": "2026-01-05 22:50:31+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_triangle_bread_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ä¸‰è§’å½¢é¢åŒ…æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 54\ntotal_tasks: 1\nsize: 50.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_triangle_bread_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_triangle_bread_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "tylu0117/Bloomberg_Financial_News",
        "author": "tylu0117",
        "created_at": "2026-01-09 13:21:37+00:00",
        "last_modified": "2026-01-09 13:21:39+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "finance"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Processed Financial News Articles (2006-2013)\n\t\n\nThis dataset consists of 446762 financial news articles originally sourced from Bloomberg, covering the period from 2006 to 2013. It includes processed texts suitable for use in NLP and financial trend analysis.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains English-language financial news articles collected from Bloomberg. It is designed for natural language processing tasks, financialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tylu0117/Bloomberg_Financial_News.",
        "url": "https://huggingface.co/datasets/tylu0117/Bloomberg_Financial_News",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "fadzero02/phishing-email-dataset",
        "author": "fadzero02",
        "created_at": "2026-01-08 18:54:49+00:00",
        "last_modified": "2026-01-08 18:54:49+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:lgpl-3.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tPhishing Email Dataset\n\t\n\nThis dataset on Hugging Face is a direct copy of the 'Phishing Email Detection' dataset from Kaggle, shared under the GNU Lesser General Public License 3.0. The dataset was originally created by the user 'Cyber Cop' on Kaggle.  For complete details, including licensing and usage information, please visit the original Kaggle page.\n",
        "url": "https://huggingface.co/datasets/fadzero02/phishing-email-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "llm-semantic-router/dart-halspans",
        "author": "llm-semantic-router",
        "created_at": "2026-01-10 23:10:30+00:00",
        "last_modified": "2026-01-10 23:10:31+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "hallucination-detection",
          "data2txt",
          "structured-data",
          "rag",
          "fact-checking",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tDART Hallucination Spans Dataset\n\t\n\nA synthetic hallucination detection dataset derived from DART (Data-Record to Text) structured data. Contains 2,000 samples with LLM-generated responses and span-level hallucination annotations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was created to augment RAGTruth for Data2txt (structured data to text) task coverage. An LLM generates both faithful and intentionally hallucinated responses from DART's structured data triples, then annotates theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-semantic-router/dart-halspans.",
        "url": "https://huggingface.co/datasets/llm-semantic-router/dart-halspans",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "eve-esa/retrieval",
        "author": "eve-esa",
        "created_at": "2025-12-18 10:23:22+00:00",
        "last_modified": "2025-12-29 09:01:58+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Retrieval",
          "EO",
          "RAG",
          "EVE"
        ],
        "description": "\n\t\n\t\t\n\t\tRetrieval Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Retrieval dataset contains synthetically generated question-references pairs from academic research documents, designed for evaluating retrieval and question-answering systems. This dataset follows the methodology described in Chroma's research on evaluating chunking strategies.\n\n\t\n\t\t\n\t\tMethodology\n\t\n\nThis dataset was created using a synthetic generation approach that employs LLMs to:\n\nGenerate factual questions that can be answered solelyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/eve-esa/retrieval.",
        "url": "https://huggingface.co/datasets/eve-esa/retrieval",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "webxos/bsd_conjecture_dataset",
        "author": "webxos",
        "created_at": "2026-01-08 08:12:38+00:00",
        "last_modified": "2026-01-10 03:32:08+00:00",
        "downloads": 52,
        "likes": 1,
        "tags": [
          "task_categories:image-classification",
          "task_categories:image-to-text",
          "task_categories:tabular-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "mathematics",
          "number-theory",
          "elliptic-curves",
          "bsd-conjecture",
          "scientific-computing",
          "algebraic-geometry",
          "multimodal",
          "time-lapse",
          "geometry"
        ],
        "description": "\n\n\n\n\n\t\n\t\n\t\n\t\tBSD Conjecture Dataset\n\t\n\nThe BSD conjecture dataset concerns the Birch and Swinnerton-Dyer (BSD) Conjecture, a Millennium Prize problem in number \ntheory. It typically contains numerical data on elliptic curves, such as coefficients, ranks, and L-function values, relevant for \ncomputational verification or machine learning applications in arithmetic geometry. This Dataset is a collection of computational data relating to elliptic curves and their associated L-functions. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/webxos/bsd_conjecture_dataset.",
        "url": "https://huggingface.co/datasets/webxos/bsd_conjecture_dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification",
          "image-to-text",
          "tabular-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_slice_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:30:05+00:00",
        "last_modified": "2026-01-05 22:30:12+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_bread_slice_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…ç‰‡æ”¾å…¥é”…ä¸­\ntotal_episodes: 24\ntotal_tasks: 1\nsize: 28.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_slice_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_slice_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "tartuNLP/finetranslations-et",
        "author": "tartuNLP",
        "created_at": "2026-01-09 21:41:12+00:00",
        "last_modified": "2026-01-10 11:36:26+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "task_categories:text-generation",
          "language:et",
          "language:en",
          "license:odc-by",
          "size_categories:10M<n<100M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tFineTranslations-et\n\t\n\nThe Estonian subset of HuggingFaceFW/finetranslations reuploaded for ease of access.\n\n\t\n\t\t\n\t\tLicensing Information\n\t\n\nThe dataset is released under the Open Data Commons Attribution License (ODC-By) v1.0 license. The use of this dataset is also subject to CommonCrawl's Terms of Use.\n\n\t\n\t\t\n\t\tCitation Information\n\t\n\n@misc{penedo2026finetranslations,\n      title={FineTranslations}, \n      author={Guilherme Penedo and Hynek Kydl{\\'\\i}{\\v{c}}ek and Amir Hosseinâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tartuNLP/finetranslations-et.",
        "url": "https://huggingface.co/datasets/tartuNLP/finetranslations-et",
        "languages": [
          "et",
          "en"
        ],
        "tasks": [
          "translation",
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "HYzhou123/Real-Weather_World",
        "author": "HYzhou123",
        "created_at": "2026-01-06 05:49:37+00:00",
        "last_modified": "2026-01-06 06:35:47+00:00",
        "downloads": 25,
        "likes": 1,
        "tags": [
          "task_categories:translation",
          "language:en",
          "license:mit",
          "size_categories:100M<n<1B",
          "modality:image",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/HYzhou123/Real-Weather_World",
        "languages": [
          "en"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:10:51+00:00",
        "last_modified": "2026-01-05 22:11:16+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_open_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 281\ntotal_tasks: 1\nsize: 551.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "jkdkr2439/optimization-curve-convexity-heuristic",
        "author": "jkdkr2439",
        "created_at": "2026-01-11 03:45:04+00:00",
        "last_modified": "2026-01-11 03:47:39+00:00",
        "downloads": 3,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "modality:document",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "optimization",
          "gradient-descent",
          "convex-optimization",
          "heuristics",
          "theory",
          "empirical-study",
          "reproducibility",
          "optimization-diagnostics"
        ],
        "description": "\n\t\n\t\t\n\t\tGolden-Ratio Step Size Heuristic for Discrete Optimization-Curve Convexity\n\t\n\nAuthor: Kevin T.NAffiliation: Independent ResearcherContact: jkdkr2439@gmail.comDate: January 11, 2026  \n\n\n\t\n\t\t\n\t\tWhat this repository is\n\t\n\nThis repository contains a technical note proposing a conservative step-size heuristic for gradient descent on convex, L-smooth objectives, evaluated under a discrete optimization-curve convexity diagnostic.\nThis is not a theorem-driven work.It is a heuristic +â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jkdkr2439/optimization-curve-convexity-heuristic.",
        "url": "https://huggingface.co/datasets/jkdkr2439/optimization-curve-convexity-heuristic",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_43_packplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:30:50+00:00",
        "last_modified": "2026-01-05 09:58:46+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_43_packplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“åŒ…ç›˜å­part_3\ntotal_episodes: 199\ntotal_tasks: 1\nsize: 2.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_43_packplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_43_packplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:29:19+00:00",
        "last_modified": "2026-01-05 22:29:26+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_bread_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾å…¥é”…ä¸­\ntotal_episodes: 18\ntotal_tasks: 1\nsize: 14.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "elliotvincent/b-FLAIR-test-spot",
        "author": "elliotvincent",
        "created_at": "2025-11-25 15:09:42+00:00",
        "last_modified": "2025-11-25 16:27:55+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:image-segmentation",
          "language:en",
          "license:etalab-2.0",
          "size_categories:1K<n<10K",
          "modality:geospatial",
          "region:us",
          "remote-sensing",
          "change-detection",
          "earth-observation",
          "building"
        ],
        "description": "\n\t\n\t\t\n\t\tb-FLAIR-test-spot: Building Change Detection Evaluation Dataset (SPOT-6/7)\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nb-FLAIR-test-spot is an evaluation dataset for building change detection, containing 1,730 annotated image pairs with binary building change masks. This dataset is built from b-FLAIR-test by downloading acquisitions at the same dates and locations for each patch from SPOT-6/7 satellite imagery. It is designed for in-domain evaluation of methods trained on b-FLAIR-spot inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elliotvincent/b-FLAIR-test-spot.",
        "url": "https://huggingface.co/datasets/elliotvincent/b-FLAIR-test-spot",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-segmentation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "jmcinern/Dolly-V2-gle",
        "author": "jmcinern",
        "created_at": "2025-08-28 11:17:39+00:00",
        "last_modified": "2026-01-05 15:31:49+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:databricks/dolly-v2",
          "language:ga",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "irish",
          "gaeilge",
          "low-resource",
          "synthetic-data",
          "translate-train"
        ],
        "description": "\n\t\n\t\t\n\t\tDolly V2 Irish (Translated)\n\t\n\nThis dataset is a bilingual instruction tuning dataset containing approx. 30,000 samples. It comprises the original Databricks Dolly V2 (English) and its high-quality Irish (Gaeilge) translation, generated using Gemini-2.5-Pro.\nIt was curated to train QomhrÃ¡: jmcinern/Qomhra\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nDataset Name: Dolly-V2-gle\nPaper: TBC\nSource: databricks/dolly-v2\nLanguage: Irish (ga) and English (en)\nTranslator Model: Gemini-2.5-Pro\nSize: ~30k rowsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jmcinern/Dolly-V2-gle.",
        "url": "https://huggingface.co/datasets/jmcinern/Dolly-V2-gle",
        "languages": [
          "ga",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_the_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:50:06+00:00",
        "last_modified": "2026-01-05 13:50:45+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_open_the_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€æŠ½å±‰part_2\ntotal_episodes: 21\ntotal_tasks: 1\nsize: 107.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_the_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_the_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Cata-Risk-Lab/recruiter-harvesting-dataset-v1",
        "author": "Cata-Risk-Lab",
        "created_at": "2026-01-11 14:31:23+00:00",
        "last_modified": "2026-01-11 14:32:59+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "region:us",
          "cybersecurity",
          "phishing",
          "recruitment",
          "forensics"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ•µï¸â€â™‚ï¸ Recruiter Harvesting & Spam Forensic Dataset (v1.0)\n\t\n\nMaintainer: Cata Risk Lab | Project: V.I.P.E.R.\n\n\t\n\t\t\n\t\tðŸ›¡ï¸ Dataset Summary\n\t\n\nThis dataset contains labeled examples of recruitment communications, categorized into \"Harvesting\" (Predatory/Spam) and \"Legitimate\" (Professional/Retained Search). \nIt was created to train and benchmark the V.I.P.E.R. (Vendor Integrity & Personnel Email Reconnaissance) auditing engine.\n\n\t\n\t\t\n\t\tðŸ“‚ Structure\n\t\n\n\ntext: The raw body content of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cata-Risk-Lab/recruiter-harvesting-dataset-v1.",
        "url": "https://huggingface.co/datasets/Cata-Risk-Lab/recruiter-harvesting-dataset-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "patrickfleith/astro-mcq",
        "author": "patrickfleith",
        "created_at": "2025-12-20 14:18:24+00:00",
        "last_modified": "2026-01-05 22:13:26+00:00",
        "downloads": 54,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "astronautics",
          "space",
          "engineering",
          "multiple-choices",
          "astrodynamics"
        ],
        "description": "\n\t\n\t\t\n\t\tAstro-MCQ Dataset\n\t\n\nAstro-MCQ is the first dataset in the upcoming AstroBench collection, a suite of domain-specific benchmark datasets for evaluating small and large language models (SLMs and LLMs) in space mission engineering and astronautics.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nAstro-MCQ is a multiple-choice question dataset designed to evaluate language model performance across key topics in astronautics, including:\n\nOrbital mechanics\nSpace propulsion\nSpace environment and its effects\nSpacecraftâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/patrickfleith/astro-mcq.",
        "url": "https://huggingface.co/datasets/patrickfleith/astro-mcq",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "saad-kw-almutairi/pii-masking-200k",
        "author": "saad-kw-almutairi",
        "created_at": "2026-01-09 03:47:52+00:00",
        "last_modified": "2026-01-09 03:47:54+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "task_categories:table-question-answering",
          "task_categories:question-answering",
          "task_categories:zero-shot-classification",
          "task_categories:summarization",
          "task_categories:feature-extraction",
          "task_categories:text-generation",
          "task_categories:translation",
          "task_categories:fill-mask",
          "task_categories:tabular-classification",
          "task_categories:tabular-to-text",
          "task_categories:table-to-text",
          "task_categories:text-retrieval",
          "task_categories:other",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:en",
          "language:fr",
          "language:de",
          "language:it",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "legal",
          "business",
          "psychology",
          "privacy"
        ],
        "description": "\n\t\n\t\t\n\t\tAi4Privacy Community\n\t\n\nJoin our community at https://discord.gg/FmzWshaaQT to help build open datasets for privacy masking.\n\n\t\n\t\t\n\t\tPurpose and Features\n\t\n\nPrevious world's largest open dataset for privacy. Now it is pii-masking-300k\nThe purpose of the dataset is to train models to remove personally identifiable information (PII) from text, especially in the context of AI assistants and LLMs. \nThe example texts have 54 PII classes (types of sensitive data), targeting 229 discussionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saad-kw-almutairi/pii-masking-200k.",
        "url": "https://huggingface.co/datasets/saad-kw-almutairi/pii-masking-200k",
        "languages": [
          "en",
          "fr",
          "de",
          "it"
        ],
        "tasks": [
          "text-classification",
          "token-classification",
          "table-question-answering",
          "question-answering",
          "zero-shot-classification",
          "summarization",
          "feature-extraction",
          "text-generation",
          "translation",
          "fill-mask",
          "tabular-classification",
          "tabular-to-text",
          "table-to-text",
          "text-retrieval",
          "other"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "smolify/smolified-iot-controller",
        "author": "smolify",
        "created_at": "2026-01-08 00:12:58+00:00",
        "last_modified": "2026-01-08 00:13:05+00:00",
        "downloads": 4,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-iot-controller\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry. \nIt was used to train the corresponding model smolify/smolified-iot-controller.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: 9ab63a7b)\nRecords: 10000\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by smolify. \nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/smolify/smolified-iot-controller",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_751_Wrap_the_noodles_up",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:12:46+00:00",
        "last_modified": "2026-01-05 18:10:41+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_751\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æŠŠé¢æ¡è£¹èµ·æ¥\ntotal_episodes: 1132\ntotal_tasks: 1\nsize: 56G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_751_Wrap_the_noodles_up.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_751_Wrap_the_noodles_up",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phoenixcph/AtmosphericQA-4.7k-Chinese",
        "author": "phoenixcph",
        "created_at": "2026-01-07 17:01:58+00:00",
        "last_modified": "2026-01-10 04:14:43+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "atmospheric-science",
          "meteorology",
          "climate",
          "synthetic",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tAtmospheric Science QA Dataset\n\t\n\nA supervised fine-tuning (SFT) dataset containing 4.7K question-answer pairs focused on atmospheric science, designed for training and fine-tuning large language models in the domain of meteorology and climate science.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset was created to enhance LLM capabilities in atmospheric science domains. It contains high-quality QA pairs covering various topics in meteorology, climate dynamicsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phoenixcph/AtmosphericQA-4.7k-Chinese.",
        "url": "https://huggingface.co/datasets/phoenixcph/AtmosphericQA-4.7k-Chinese",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Finish-him/msc-knowledge-base",
        "author": "Finish-him",
        "created_at": "2026-01-10 04:29:43+00:00",
        "last_modified": "2026-01-10 04:30:30+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "language:pt",
          "language:en",
          "language:es",
          "language:de",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "msc-marketing",
          "portuguese",
          "english",
          "marketing",
          "seo",
          "knowledge-base"
        ],
        "description": "\n\t\n\t\t\n\t\tmsc-knowledge-base\n\t\n\nBase de conhecimento completa da MSC Marketing para RAG e fine-tuning\n\n\t\n\t\t\n\t\tSobre\n\t\n\nEste dataset faz parte da infraestrutura de IA da MSC Marketing, uma empresa especializada em Marketing Digital e SEO.\n\n\t\n\t\t\n\t\tUso\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Finish-him/msc-knowledge-base\")\n\n\n\t\n\t\t\n\t\tEstrutura\n\t\n\nOs arquivos incluÃ­dos neste dataset sÃ£o:\n\nmsc_documents.json\ndomain_distribution.json\nteam_distribution.json\n\n\n\t\n\t\t\n\t\tLicenÃ§a\n\t\n\nMITâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Finish-him/msc-knowledge-base.",
        "url": "https://huggingface.co/datasets/Finish-him/msc-knowledge-base",
        "languages": [
          "pt",
          "en",
          "es",
          "de"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_pepper_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:36:20+00:00",
        "last_modified": "2026-01-05 22:36:28+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_green_pepper_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é’æ¤’æ”¾å…¥é”…ä¸­\ntotal_episodes: 27\ntotal_tasks: 1\nsize: 19.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_pepper_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_pepper_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Cooolder/SCOPE-sft-CoT-data",
        "author": "Cooolder",
        "created_at": "2026-01-11 01:32:59+00:00",
        "last_modified": "2026-01-11 02:29:42+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "language:zh",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "performance-prediction",
          "chain-of-thought",
          "reasoning",
          "scope",
          "unsloth"
        ],
        "description": "\n\t\n\t\t\n\t\tSCOPE-sft-CoT-data\n\t\n\nThis dataset contains 52,953 training examples for fine-tuning language models on performance prediction tasks with Chain-of-Thought (CoT) reasoning.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset extends the SCOPE-sft-direct-data by incorporating two types of training examples:\n\nFilter (with CoT): 41,074 examples with detailed Analysis and reasoning\nRejected (without CoT): 11,879 examples with direct predictions only\n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\nðŸ§  Chain-of-Thoughtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cooolder/SCOPE-sft-CoT-data.",
        "url": "https://huggingface.co/datasets/Cooolder/SCOPE-sft-CoT-data",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_pick_up_tennis_ball_and_place_it_in_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:19:48+00:00",
        "last_modified": "2026-01-05 18:20:24+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_pick_up_tennis_ball_and_place_it_in_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ¡èµ·ç½‘çƒå¹¶å°†å…¶æ”¾å…¥ç›’å­\ntotal_episodes: 153\ntotal_tasks: 1\nsize: 777.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_pick_up_tennis_ball_and_place_it_in_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_pick_up_tennis_ball_and_place_it_in_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "hfmlsoc/sp500_dataset",
        "author": "hfmlsoc",
        "created_at": "2026-01-07 17:41:03+00:00",
        "last_modified": "2026-01-07 18:45:00+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "language:en",
          "license:odbl",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "finance",
          "economy"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/hfmlsoc/sp500_dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "swe-qa/SWE-QA-Benchmark",
        "author": "swe-qa",
        "created_at": "2025-09-16 07:43:53+00:00",
        "last_modified": "2026-01-06 09:27:58+00:00",
        "downloads": 86,
        "likes": 5,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "software-engineering",
          "code-qa",
          "swe-bench"
        ],
        "description": "\n\t\n\t\t\n\t\tSWE-QA Benchmark\n\t\n\nA comprehensive benchmark dataset for Software Engineering Question Answering, containing 720 questions across 15 popular Python repositories.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Questions: 720\nRepositories: 15\nFormat: JSONL (JSON Lines)\nFields: question, answer\n\n\n\t\n\t\t\n\t\tRepository Coverage\n\t\n\nEach repository contains 48 questions:\n\nastropy\nconan\ndjango\nflask\nmatplotlib\npylint\npytest\nreflex\nrequests\nscikit-learn\nsphinx\nsqlfluff\nstreamlink\nsympy\nxarray\n\n\n\t\n\t\t\n\t\tUsageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/swe-qa/SWE-QA-Benchmark.",
        "url": "https://huggingface.co/datasets/swe-qa/SWE-QA-Benchmark",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-PhysLean",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:50:50+00:00",
        "last_modified": "2026-01-10 15:13:18+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-PhysLean\n\t\n\nStructured dataset from PhysLean â€” Formalization of physics.\n7,026 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/HEPLean/PhysLean\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-PhysLean.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-PhysLean",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_open_the_lid_with_left_hand_and_place_it_on_the_left_side_of_the_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 05:36:47+00:00",
        "last_modified": "2026-01-08 05:37:19+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_open_the_lid_with_left_hand_and_place_it_on_the_left_side_of_the_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç”¨å·¦æ‰‹æ‰“å¼€ç›–å­å¹¶å°†å…¶æ”¾åœ¨é”…çš„å·¦ä¾§\ntotal_episodes: 115\ntotal_tasks: 1\nsize: 821.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_open_the_lid_with_left_hand_and_place_it_on_the_left_side_of_the_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_open_the_lid_with_left_hand_and_place_it_on_the_left_side_of_the_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_close_the_drawer_under_the_combination_cabinet",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:09:39+00:00",
        "last_modified": "2026-01-05 18:10:27+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_close_the_drawer_under_the_combination_cabinet\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­ç»„åˆæ©±æŸœä¸‹çš„æŠ½å±‰\ntotal_episodes: 159\ntotal_tasks: 1\nsize: 898.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_close_the_drawer_under_the_combination_cabinet.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_close_the_drawer_under_the_combination_cabinet",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "jishnu2527/CropNet",
        "author": "jishnu2527",
        "created_at": "2026-01-08 04:16:37+00:00",
        "last_modified": "2026-01-08 04:23:10+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n>1T",
          "region:us",
          "agriculture",
          "climate"
        ],
        "description": "\n\t\n\t\t\n\t\tAn Open and Large-Scale Dataset for Multi-Modal Climate Change-aware Crop Yield Predictions\n\t\n\n\nThe CropNet dataset is an open, large-scale, and deep learning-ready dataset, specifically targeting climate change-aware crop yield predictions for the contiguous United States (U.S.) continent at the county level. It is composed of three modalities of data, i.e., Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDA Crop Dataset, aligned in both the spatial and temporal domains, for overâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jishnu2527/CropNet.",
        "url": "https://huggingface.co/datasets/jishnu2527/CropNet",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n>1T"
        ]
      },
      {
        "id": "introvoyz041/ChemPref-DPO-for-Chemistry-data-en",
        "author": "introvoyz041",
        "created_at": "2026-01-07 12:33:44+00:00",
        "last_modified": "2026-01-07 12:33:45+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2402.06852",
          "region:us",
          "chemistry"
        ],
        "description": "\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{zhang2024chemllm,\n      title={ChemLLM: A Chemical Large Language Model}, \n      author={Di Zhang and Wei Liu and Qian Tan and Jingdan Chen and Hang Yan and Yuliang Yan and Jiatong Li and Weiran Huang and Xiangyu Yue and Dongzhan Zhou and Shufei Zhang and Mao Su and Hansen Zhong and Yuqiang Li and Wanli Ouyang},\n      year={2024},\n      eprint={2402.06852},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}\n\n",
        "url": "https://huggingface.co/datasets/introvoyz041/ChemPref-DPO-for-Chemistry-data-en",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "RidheshBhati/Audio-text",
        "author": "RidheshBhati",
        "created_at": "2026-01-05 10:23:56+00:00",
        "last_modified": "2026-01-05 16:01:31+00:00",
        "downloads": 398,
        "likes": 0,
        "tags": [
          "task_categories:text-to-speech",
          "language:hi",
          "language:en",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio",
          "text-to-speech",
          "hinglish"
        ],
        "description": "\n\t\n\t\t\n\t\tHinglish Audio Dataset\n\t\n\nThis dataset contains 30 audio-text pairs.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nfile_name: Audio file path\ntext: Hinglish transcript\nduration: Duration in seconds\n\nAudio was generated using Sarvam AI's Bulbul v2 model.\n",
        "url": "https://huggingface.co/datasets/RidheshBhati/Audio-text",
        "languages": [
          "hi",
          "en"
        ],
        "tasks": [
          "text-to-speech"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "muqsith123/telco-customer-churn",
        "author": "muqsith123",
        "created_at": "2026-01-08 17:07:05+00:00",
        "last_modified": "2026-01-08 17:07:08+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:tabular-classification",
          "language:en",
          "size_categories:1K<n<10K",
          "modality:tabular",
          "modality:text",
          "region:us",
          "tabular-classification",
          "churn-prediction",
          "telecom",
          "customer-retention",
          "demographics",
          "customer-service"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Telco Customer Churn\n\t\n\nThis dataset contains information about customers of a fictional telecommunications company, including demographic information, services subscribed to, location details, and churn behavior. This merged dataset combines the information from the original Telco Customer Churn dataset with additional details.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis merged Telco Customer Churn dataset provides a comprehensive view of customerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/muqsith123/telco-customer-churn.",
        "url": "https://huggingface.co/datasets/muqsith123/telco-customer-churn",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ijanhq8809/k12-ela-standards",
        "author": "ijanhq8809",
        "created_at": "2026-01-09 16:31:55+00:00",
        "last_modified": "2026-01-09 16:31:56+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "education",
          "english",
          "language-arts",
          "k12",
          "reading",
          "writing",
          "speaking",
          "listening",
          "literacy",
          "educational-ai",
          "standards-aligned"
        ],
        "description": "\n\t\n\t\t\n\t\tK-12 English Language Arts Standards Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“š Comprehensive ELA Education Dataset\n\t\n\nThis dataset provides complete K-12 English Language Arts standards coverage for AI training and educational technology development.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Summary\n\t\n\nThe K-12 ELA Standards Dataset contains:\n\n546 educational standards across K-12\n6487 AI training samples\nComplete coverage of all major ELA domains\n\n\n\t\n\t\t\n\t\tðŸŽ“ Educational Coverage\n\t\n\n\nðŸ“– Reading Literature: Fiction, poetryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ijanhq8809/k12-ela-standards.",
        "url": "https://huggingface.co/datasets/ijanhq8809/k12-ela-standards",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_side_pull_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:51:17+00:00",
        "last_modified": "2026-01-05 23:51:47+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_side_pull_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä¾§æ‹‰æŠ½å±‰\ntotal_episodes: 235\ntotal_tasks: 1\nsize: 467.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_side_pull_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_side_pull_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Akashved/Indian-Bank-Statements",
        "author": "Akashved",
        "created_at": "2026-01-07 12:00:31+00:00",
        "last_modified": "2026-01-07 12:00:32+00:00",
        "downloads": 294,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:table-question-answering",
          "task_categories:text-generation",
          "language:en",
          "language:hi",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "modality:document",
          "region:us",
          "finance",
          "synthetic",
          "banking",
          "india",
          "transactions",
          "bank-statements",
          "document-ai"
        ],
        "description": "\n\t\n\t\t\n\t\tIndian Bank Statement Synthetic Dataset\n\t\n\nSynthetically generated Indian business bank statements with realistic transaction patterns, proper banking workflows, and India-specific features. Available in scanned PDF and digital JSON formats.\nScope: Current Accounts (business banking) only. Does not include personal/savings accounts.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurated by: AgamiAI Inc.\nLanguage(s): English, Hindi (romanized)\nLicense: Apache 2.0\nRepository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akashved/Indian-Bank-Statements.",
        "url": "https://huggingface.co/datasets/Akashved/Indian-Bank-Statements",
        "languages": [
          "en",
          "hi"
        ],
        "tasks": [
          "text-classification",
          "table-question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate_copy_1734079773826",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:07:40+00:00",
        "last_modified": "2026-01-07 07:07:56+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate_copy_1734079773826\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç›˜å­ä¸Šæ‹¿èµ·é»„è¾£æ¤’part_2\ntotal_episodes: 135\ntotal_tasks: 1\nsize: 74.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate_copy_1734079773826.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate_copy_1734079773826",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "spia-bench/SPIA-benchmark",
        "author": "spia-bench",
        "created_at": "2026-01-07 04:43:34+00:00",
        "last_modified": "2026-01-07 05:20:21+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2505.12238",
          "region:us",
          "privacy",
          "pii-detection",
          "anonymization",
          "text-anonymization",
          "nlp",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tSPIA: Subject-level PII Inference Assessment\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nSPIA is the first benchmark for subject-level privacy assessment in text anonymization. Unlike existing methods that focus on single-target or span-based evaluation, SPIA captures inference-based privacy risks across all data subjects in a document.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n  \"metadata\": {\n    \"data_id\": \"TAB-xxxxx\",\n    \"number_of_subjects\": 5,\n    \"annotator\": \"annotator1\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/spia-bench/SPIA-benchmark.",
        "url": "https://huggingface.co/datasets/spia-bench/SPIA-benchmark",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "anyangsong/MAGA-ROLE-80",
        "author": "anyangsong",
        "created_at": "2026-01-08 11:28:45+00:00",
        "last_modified": "2026-01-08 12:13:59+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "language:zh",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/anyangsong/MAGA-ROLE-80",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "knoveleng/redbench",
        "author": "knoveleng",
        "created_at": "2025-05-27 09:45:11+00:00",
        "last_modified": "2026-01-08 17:39:22+00:00",
        "downloads": 151,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.03699",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tRedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models\n\t\n\n\n\n\n\t\n\t\t\n\t\tðŸ“‹ Overview\n\t\n\nRedBench is a comprehensive, universal dataset designed for evaluating the safety and robustness of Large Language Models (LLMs) through systematic red teaming. It aggregates 37 diverse safety benchmarks into a unified format, covering a wide spectrum of risk categories, domains, and evaluation scenarios.\nRedBench is part of the paper \"RedBench: A Universal Dataset forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/knoveleng/redbench.",
        "url": "https://huggingface.co/datasets/knoveleng/redbench",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:37:10+00:00",
        "last_modified": "2026-01-05 18:39:11+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®ç›˜å­é¤æ¡Œpart_1\ntotal_episodes: 59\ntotal_tasks: 1\nsize: 2.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1031",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:18:39+00:00",
        "last_modified": "2026-01-07 07:19:14+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1031\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ±æœµæ”¾åœ¨æ¡Œå­ä¸Špart_5\ntotal_episodes: 252\ntotal_tasks: 1\nsize: 188.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1031.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1031",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_place_button_then_press",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 20:13:36+00:00",
        "last_modified": "2026-01-05 20:48:07+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_place_button_then_press\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®æŒ‰é’®ç„¶åŽæŒ‰åŽ‹\ntotal_episodes: 527\ntotal_tasks: 1\nsize: 4.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_place_button_then_press.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_place_button_then_press",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ibm-research/nc-bench",
        "author": "ibm-research",
        "created_at": "2026-01-06 18:51:43+00:00",
        "last_modified": "2026-01-11 22:54:32+00:00",
        "downloads": 45,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "conversational-competence",
          "conversation-analysis",
          "natural-conversation",
          "multi-turn",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Natural Conversation Benchmark (NC-Bench)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe Natural Conversation Benchmarks (NC-Bench) aim to answer the question: How well can generative AI converse like humans do? In other words, the benchmarks begin to measure the general conversational competence of large language models (LLMs). They do this by testing models' ability to generate an appropriate type of conversational action, or dialogue act, in response to a particular sequence ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ibm-research/nc-bench.",
        "url": "https://huggingface.co/datasets/ibm-research/nc-bench",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-object-vision-text-dataset",
        "author": "ariefansclub",
        "created_at": "2026-01-08 06:44:15+00:00",
        "last_modified": "2026-01-08 06:44:47+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "robotics",
          "vision"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Object Vision Text Dataset\n\t\n\nText-based object recognition data for humanoid perception and action mapping.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-object-vision-text-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "beersrobert/bedroom_dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 12:19:32+00:00",
        "last_modified": "2026-01-09 04:02:07+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "indoor-navigation household-hazards home-safety messy-environments robotics"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/bedroom_dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "RECOR-Benchmark/RECOR",
        "author": "RECOR-Benchmark",
        "created_at": "2026-01-08 02:32:47+00:00",
        "last_modified": "2026-01-10 10:11:33+00:00",
        "downloads": 40,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-retrieval",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "conversational-ir",
          "information-retrieval",
          "multi-turn",
          "reasoning",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tRECOR: Reasoning-focused Multi-turn Conversational Retrieval Benchmark\n\t\n\nA benchmark for evaluating reasoning-intensive conversational information retrieval systems.\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Conversations\n707\n\n\nTotal Turns\n2,971\n\n\nDomains\n11\n\n\nAvg. Turns per Conversation\n4.2\n\n\n\t\n\n\n\t\n\t\t\n\t\tDomains\n\t\n\n\n\t\n\t\t\nSource\nDomains\n\n\n\t\t\nBRIGHT\nbiology, earth_science, economics, psychology, robotics, sustainable_living\n\n\nStackExchange\nDrones, hardware, lawâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RECOR-Benchmark/RECOR.",
        "url": "https://huggingface.co/datasets/RECOR-Benchmark/RECOR",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-retrieval"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "stablellama/Qwen-Image-2512_samples",
        "author": "stablellama",
        "created_at": "2026-01-06 17:04:40+00:00",
        "last_modified": "2026-01-11 21:58:05+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "language:zh",
          "license:cc-by-sa-4.0",
          "size_categories:1K<n<10K",
          "format:text",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "LoRA",
          "LyCROIS",
          "LoKR",
          "training",
          "finetuning"
        ],
        "description": "This dataset is a highly diverse set of high quality images generated with Qwen Image 2512.\n\n\t\n\t\t\n\t\tPossible uses\n\t\n\n\nRegularization images for training models based on Qwen Image 2512\nQuality testing\n\n\n\t\n\t\t\n\t\tData source\n\t\n\nThe images were created in ComfyUI with the\nbf16 version\nof Qwen Image 2512. For each prompt were four images generated, all are (without any cherry picking) included in the corresponding dataset directories.\n\nbf16 - full model weights\n1328x1328 pixels - native resolutionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stablellama/Qwen-Image-2512_samples.",
        "url": "https://huggingface.co/datasets/stablellama/Qwen-Image-2512_samples",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ansh4749/TinyStories",
        "author": "ansh4749",
        "created_at": "2026-01-06 19:50:29+00:00",
        "last_modified": "2026-01-06 19:50:30+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cdla-sharing-1.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2305.07759",
          "region:us"
        ],
        "description": "Dataset containing synthetically generated (by GPT-3.5 and GPT-4) short stories that only use a small vocabulary.\nDescribed in the following paper: https://arxiv.org/abs/2305.07759. \nThe models referred to in the paper were trained on TinyStories-train.txt  (the file tinystories-valid.txt can be used for validation loss). These models can be found on Huggingface, at roneneldan/TinyStories-1M/3M/8M/28M/33M/1Layer-21M.\nAdditional resources:\ntinystories_all_data.tar.gz - contains a superset ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ansh4749/TinyStories.",
        "url": "https://huggingface.co/datasets/ansh4749/TinyStories",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "MohamedISSAOUI/fertility-medical-reasoning",
        "author": "MohamedISSAOUI",
        "created_at": "2026-01-09 15:14:39+00:00",
        "last_modified": "2026-01-09 16:00:17+00:00",
        "downloads": 49,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "medical",
          "reasoning",
          "fertility",
          "chain-of-thought",
          "clinical"
        ],
        "description": "\n\t\n\t\t\n\t\tTanit Fertility Medical Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nHigh-quality medical reasoning dataset specialized for fertility care.\nTotal: 45,183 samples (42,923 train / 2,260 validation)\n\n\t\n\t\t\n\t\tDataset Composition\n\t\n\n\n\t\n\t\t\nSource\nSamples\nPercentage\nPurpose\n\n\n\t\t\nMedReason\n27,711\n61.3%\nExpert-verified clinical reasoning\n\n\nMedical-O1\n14,272\n31.6%\nO1-style systematic thinking\n\n\nSynthetic-Fertility\n3,200\n7.1%\nDomain-specific fertility cases\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MohamedISSAOUI/fertility-medical-reasoning.",
        "url": "https://huggingface.co/datasets/MohamedISSAOUI/fertility-medical-reasoning",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Dabbu19/wordnet-v1",
        "author": "Dabbu19",
        "created_at": "2026-01-08 02:19:48+00:00",
        "last_modified": "2026-01-08 02:21:32+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tWordNet RDF\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLexical database of semantic relations between words (English WordNet 2024)\nOriginal Source: https://en-word.net/static/english-wordnet-2024.ttl.gz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from WordNet RDF converted to HuggingFace\ndataset format for easy use in machine learning pipelines.\n\nFormat: Originally turtle, converted to HuggingFace Dataset\nSize: 0.21 GB (extracted)\nEntities: ~120K synsets\nTriples: ~2M\nOriginalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dabbu19/wordnet-v1.",
        "url": "https://huggingface.co/datasets/Dabbu19/wordnet-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "yelanye/lerobot-testdata",
        "author": "yelanye",
        "created_at": "2026-01-09 05:40:51+00:00",
        "last_modified": "2026-01-09 06:21:10+00:00",
        "downloads": 121,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nmeta/info.json:\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"agilex\",\n    \"total_episodes\": 503,\n    \"total_frames\": 462517,\n    \"total_tasks\": 1,\n    \"total_videos\": 1509,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 30,\n    \"splits\": {\n        \"train\": \"0:503\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/yelanye/lerobot-testdata.",
        "url": "https://huggingface.co/datasets/yelanye/lerobot-testdata",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_mangosteen",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:19:50+00:00",
        "last_modified": "2026-01-05 22:20:09+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_mangosteen\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·å±±ç«¹\ntotal_episodes: 61\ntotal_tasks: 1\nsize: 47.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_mangosteen.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_mangosteen",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "OpenRaiser/SeqStudio",
        "author": "OpenRaiser",
        "created_at": "2025-12-22 04:28:53+00:00",
        "last_modified": "2025-12-29 08:31:51+00:00",
        "downloads": 51,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "biology",
          "protein",
          "bioinformatics",
          "uniprot",
          "protein-annotation"
        ],
        "description": "\n\t\n\t\t\n\t\tSeqStudio: Protein Annotation Dataset\n\t\n\nSeqStudio is an AI-powered protein annotation system that generates comprehensive functional predictions for protein sequences. This dataset contains SeqStudio-generated annotations for 1.2 million UniProt proteins, combining human-reviewed (Swiss-Prot) and computationally analyzed (TrEMBL) entries with AI-enhanced functional predictions.\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\n\n\t\n\t\t\nFile\nRecords\nSize\nDescription\n\n\n\t\t\nseqstudio_swissprot_10k.parquet\n10,000\n55â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenRaiser/SeqStudio.",
        "url": "https://huggingface.co/datasets/OpenRaiser/SeqStudio",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "MEET-MR/MEET-MR",
        "author": "MEET-MR",
        "created_at": "2026-01-10 06:51:06+00:00",
        "last_modified": "2026-01-11 15:15:06+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "language:en",
          "language:th",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "mqm",
          "human-evaluation",
          "quality-estimation",
          "ranking",
          "eacl-2026"
        ],
        "description": "\n\t\n\t\t\n\t\tMEET-MR: Englishâ€“Thai MQM and Ranking Dataset\n\t\n\n[Paper] [EACL 2026] [Model Weights]\nMEET-MR is a comprehensive human-annotated benchmark for Englishâ€“Thai machine translation. It addresses the lack of high-quality evaluation resources for distantly related language pairs by providing 20,646 segments with fine-grained MQM error labels and holistic 10-way human preference rankings.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§  Dataset Summary\n\t\n\n\nDomain: Diverse (Education, Medical, Treaty, Image Captioningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MEET-MR/MEET-MR.",
        "url": "https://huggingface.co/datasets/MEET-MR/MEET-MR",
        "languages": [
          "en",
          "th"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "satana123/Chess-Alpha-700K",
        "author": "satana123",
        "created_at": "2026-01-10 16:43:59+00:00",
        "last_modified": "2026-01-11 09:23:03+00:00",
        "downloads": 9,
        "likes": 1,
        "tags": [
          "task_categories:reinforcement-learning",
          "language:en",
          "language:ru",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "region:us",
          "chess",
          "deep-learning",
          "stockfish",
          "pytorch",
          "multi-pv",
          "chess-engine",
          "reinforcement-learning"
        ],
        "description": "\n\t\n\t\t\n\t\tâ™Ÿï¸ Strategic Chess Dataset: Multi-PV & RL-Refined (700K+)\n\t\n\nThis is a high-performance dataset designed for training and pre-training state-of-the-art chess neural networks. It contains over 706,000 unique board positions generated and evaluated by Stockfish 16.1.\nThe dataset is specifically optimized for models using Policy & Value heads, providing rich metadata for each state.\n\n\t\n\t\t\n\t\tðŸŒŸ Key Features\n\t\n\n\nMulti-PV Intelligence: Each position includes not just the single best moveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/satana123/Chess-Alpha-700K.",
        "url": "https://huggingface.co/datasets/satana123/Chess-Alpha-700K",
        "languages": [
          "en",
          "ru"
        ],
        "tasks": [
          "reinforcement-learning"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_basket_1125",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:17:45+00:00",
        "last_modified": "2026-01-06 07:17:57+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_basket_1125\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¯®å­ä¸­æ‹¿èµ·é»„ç“œpart_1\ntotal_episodes: 223\ntotal_tasks: 1\nsize: 193.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_basket_1125.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_basket_1125",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "taoye1992/VisualWebInstruct",
        "author": "taoye1992",
        "created_at": "2026-01-05 07:16:08+00:00",
        "last_modified": "2026-01-05 07:16:09+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:visual-question-answering",
          "task_categories:image-text-to-text",
          "language:en",
          "license:apache-2.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:image",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2503.10582",
          "arxiv:2507.11936",
          "region:us",
          "math",
          "science"
        ],
        "description": "\n\t\n\t\t\n\t\tVisualWebInstruct: Scaling up Multimodal Instruction Data through Web Search\n\t\n\nVisualWebInstruct is a large-scale, diverse multimodal instruction dataset designed to enhance vision-language models' reasoning capabilities. The dataset contains approximately 900K question-answer (QA) pairs, with 40% consisting of visual QA pairs associated with 163,743 unique images, while the remaining 60% are text-only QA pairs.\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nGitHub Repository\nResearch Paper\nProject Websiteâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/taoye1992/VisualWebInstruct.",
        "url": "https://huggingface.co/datasets/taoye1992/VisualWebInstruct",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "visual-question-answering",
          "image-text-to-text"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "nyuuzyou/gitee-code",
        "author": "nyuuzyou",
        "created_at": "2026-01-08 01:35:02+00:00",
        "last_modified": "2026-01-08 06:39:08+00:00",
        "downloads": 216,
        "likes": 2,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:found",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:zh",
          "language:en",
          "license:other",
          "size_categories:100M<n<1B",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "chinese"
        ],
        "description": "\n\t\n\t\t\n\t\tGitee Code Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from code repositories hosted on Gitee, China's largest code hosting platform and a leading alternative to GitHub in the Chinese developer community. Gitee is widely used by Chinese developers, enterprises, and open-source projects, making this dataset particularly valuable for training code models with strong Chinese language understanding and Chinese coding conventions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gitee-code.",
        "url": "https://huggingface.co/datasets/nyuuzyou/gitee-code",
        "languages": [
          "code",
          "zh",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "beersrobert/shed_dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 12:45:15+00:00",
        "last_modified": "2026-01-09 04:06:11+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "residential infrastructure structural-inspection fire-risk clutter accessibility emergency-response"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/shed_dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_toast",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:25:49+00:00",
        "last_modified": "2026-01-05 22:26:01+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_toast\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·åå¸\ntotal_episodes: 67\ntotal_tasks: 1\nsize: 86.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_toast.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_toast",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_33_putlemon",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:07:58+00:00",
        "last_modified": "2026-01-05 23:09:05+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_33_putlemon\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾æŸ æª¬\ntotal_episodes: 139\ntotal_tasks: 1\nsize: 1.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_33_putlemon.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_33_putlemon",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "tonychenxyz/oolong-synth-32k-128k",
        "author": "tonychenxyz",
        "created_at": "2026-01-09 07:30:42+00:00",
        "last_modified": "2026-01-09 07:30:49+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2511.02817",
          "region:us",
          "long-context",
          "aggregation",
          "reasoning",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tOolong-Synth (32K-128K context lengths) for Code-LLaVA\n\t\n\nOolong is a challenging aggregation benchmark for long-context models that tests\nmodels' ability to analyze individual text chunks and aggregate these analyses\nto answer distributional questions.\nThis dataset contains the 32K-128K context lengths subset of Oolong-synth.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nPaper: Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities\nOriginal Dataset: oolongbench/oolong-synth\n\n\n\t\n\t\t\n\t\tContextâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonychenxyz/oolong-synth-32k-128k.",
        "url": "https://huggingface.co/datasets/tonychenxyz/oolong-synth-32k-128k",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "fangningshao/YodasSpeakerPool",
        "author": "fangningshao",
        "created_at": "2026-01-08 07:23:10+00:00",
        "last_modified": "2026-01-08 09:02:30+00:00",
        "downloads": 854,
        "likes": 2,
        "tags": [
          "task_categories:audio-classification",
          "task_categories:text-to-speech",
          "task_categories:automatic-speech-recognition",
          "language:en",
          "language:zh",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "modality:audio",
          "modality:tabular",
          "modality:text",
          "region:us",
          "speech",
          "tts",
          "emilia-yodas"
        ],
        "description": "Use this dataset in conjuction with:\nhttps://github.com/fangningshao/YodasSpeakerPool\n\n\t\n\t\t\n\t\tYodasSpeakerPool\n\t\n\nYodasSpeakerPool is a curated, richly-annotated multi-speaker dataset featuring 7,600 unique speakers (3.4K Chinese, 4.2K English). \nDerived from the Emilia-YODAS corpus, each sample is annotated by Gemini 2.5 Flash for its vocal characteristics and audio quality.\n\n\t\n\t\t\n\t\tDataset Features\n\t\n\n\nAudio Specs: 4â€“15 second WAV samples of clean speech.\nRich Metadata: Includes ASRâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fangningshao/YodasSpeakerPool.",
        "url": "https://huggingface.co/datasets/fangningshao/YodasSpeakerPool",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "audio-classification",
          "text-to-speech",
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "godmodes/ai2_arc",
        "author": "godmodes",
        "created_at": "2026-01-07 09:44:54+00:00",
        "last_modified": "2026-01-07 09:44:55+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_ids:open-domain-qa",
          "task_ids:multiple-choice-qa",
          "annotations_creators:found",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:1803.05457",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for \"ai2_arc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA new dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\n advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\n only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\n including a corpus of over 14 million science sentences relevant toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/godmodes/ai2_arc.",
        "url": "https://huggingface.co/datasets/godmodes/ai2_arc",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "nyuuzyou/google-code-archive",
        "author": "nyuuzyou",
        "created_at": "2026-01-09 07:40:48+00:00",
        "last_modified": "2026-01-09 08:00:30+00:00",
        "downloads": 96,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:found",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:en",
          "license:other",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "google-code",
          "archive"
        ],
        "description": "\n\t\n\t\t\n\t\tGoogle Code Archive Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from the Google Code Archive, a preserved snapshot of projects hosted on Google Code, Google's open-source project hosting service that operated from 2006 to 2016. Google Code was one of the major code hosting platforms of its era, hosting hundreds of thousands of open-source projects before its shutdown. The archive provides a unique historical record of open-source development during a formativeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/google-code-archive.",
        "url": "https://huggingface.co/datasets/nyuuzyou/google-code-archive",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "astaileyyoung/CineFaceDB",
        "author": "astaileyyoung",
        "created_at": "2026-01-06 16:27:38+00:00",
        "last_modified": "2026-01-11 01:11:30+00:00",
        "downloads": 37,
        "likes": 0,
        "tags": [
          "task_categories:object-detection",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "region:us",
          "movies",
          "tv-series",
          "facial-recognition",
          "computer-vision",
          "embeddings",
          "face-detection",
          "imdb"
        ],
        "description": "\n\t\n\t\t\n\t\tCineFace\n\t\n\nCineFace is a comprehensive ecosystem for facial analysis in entertainment media. It consists of:\n\nThe CineFace Dataset: A massive collection of detections and embeddings from over 6,000 movies and TV series.\nThe CineFace Toolkit: Pipeline for large-scale facial detection, encoding, and identification in TV and Film.\n\nðŸ“Š View Dashboard | ðŸ¤— Hugging Face Dataset\n\n\t\n\t\n\t\n\t\tDataset\n\t\n\nThe CineFace database contains metadata and facial detections for over 6,000 titles. You canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/astaileyyoung/CineFaceDB.",
        "url": "https://huggingface.co/datasets/astaileyyoung/CineFaceDB",
        "languages": [
          "en"
        ],
        "tasks": [
          "object-detection",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_cucumber_on_the_table_1125",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:13:17+00:00",
        "last_modified": "2026-01-07 07:14:04+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_cucumber_on_the_table_1125\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é»„ç“œæ”¾åœ¨æ¡Œå­ä¸Špart_1\ntotal_episodes: 207\ntotal_tasks: 1\nsize: 162.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_cucumber_on_the_table_1125.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_cucumber_on_the_table_1125",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_pear_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:41:32+00:00",
        "last_modified": "2026-01-05 22:41:50+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_pear_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ¢¨æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 46\ntotal_tasks: 1\nsize: 42.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_pear_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_pear_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-CategoryTheory",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:47:20+00:00",
        "last_modified": "2026-01-10 15:12:31+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-CategoryTheory\n\t\n\nStructured dataset from category-theory â€” Axiom-free category theory formalization.\n2,952 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/jwiegley/category-theory\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfactâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-CategoryTheory.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-CategoryTheory",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "jakeveo05/chinese-traditional-knowledge",
        "author": "jakeveo05",
        "created_at": "2026-01-11 14:31:22+00:00",
        "last_modified": "2026-01-11 14:31:35+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:vi",
          "language:en",
          "language:zh",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "region:us",
          "traditional-chinese-medicine",
          "tcm",
          "dong-y",
          "feng-shui",
          "i-ching",
          "acupuncture",
          "divination",
          "herbal-medicine",
          "bazi"
        ],
        "description": "\n\t\n\t\t\n\t\tChinese Traditional Knowledge Dataset\n\t\n\nComprehensive dataset of Traditional Chinese Medicine (TCM), Feng Shui, I Ching, and related Vietnamese medical texts.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal entries: 112\nTotal characters: 58,090,418\nLanguages: Vietnamese, English, Chinese\nCreated: 2026-01-11\n\n\n\t\n\t\t\n\t\tCategories\n\t\n\n\n\t\n\t\t\nCategory\nDescription\nEntries\nCharacters\n\n\n\t\t\ntcm_vietnamese\nÄÃ´ng Y Viá»‡t Nam\n54\n29,233,730\n\n\ntcm_english\nTCM English Textbooks\n20\n20,787,290\n\n\niching_divination\nKinhâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jakeveo05/chinese-traditional-knowledge.",
        "url": "https://huggingface.co/datasets/jakeveo05/chinese-traditional-knowledge",
        "languages": [
          "vi",
          "en",
          "zh"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Dabbu19/uniprotkb_reviewed_archea_methanobacteriati_3366610_0-v1",
        "author": "Dabbu19",
        "created_at": "2026-01-08 04:56:51+00:00",
        "last_modified": "2026-01-08 05:05:25+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tuniprotkb_reviewed_archea_methanobacteriati_3366610_0\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComprehensive protein knowledgebase with functional annotations\nOriginal Source: ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/rdf/uniprotkb_reviewed_archea_methanobacteriati_3366610_0.rdf.xz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from uniprotkb_reviewed_archea_methanobacteriati_3366610_0 converted to HuggingFace\ndataset format for easy use in machine learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dabbu19/uniprotkb_reviewed_archea_methanobacteriati_3366610_0-v1.",
        "url": "https://huggingface.co/datasets/Dabbu19/uniprotkb_reviewed_archea_methanobacteriati_3366610_0-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "phanerozoic/Agda-Prelude",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:04:10+00:00",
        "last_modified": "2026-01-10 15:13:51+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "agda",
          "dependent-types"
        ],
        "description": "\n\t\n\t\t\n\t\tAgda-Prelude\n\t\n\nStructured dataset from agda-prelude â€” Programming utilities by Ulf Norell.\n735 declarations extracted from Agda source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/UlfNorell/agda-prelude\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclarationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Agda-Prelude.",
        "url": "https://huggingface.co/datasets/phanerozoic/Agda-Prelude",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-GovernmentContractsCompetition",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 11:10:09+00:00",
        "last_modified": "2025-11-19 10:29:33+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly Government Contract Competition attributes for public companies,\nsourced from SOV.AI.\n\nCoverage: 3,500+ tickers with history back to 2007-10-01\nUpdate cadence: Weekly refresh following Friday 23:00â€“00:00 US-EST availability\nFields:\nExtent of competition classifications for each award\nNumber of offers received during solicitation\nSolicitation procedure descriptions\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\nData provided by SOV.AI (government spending competition feed).\n",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-GovernmentContractsCompetition",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "vedaco/veda_5",
        "author": "vedaco",
        "created_at": "2026-01-07 16:40:07+00:00",
        "last_modified": "2026-01-07 16:40:09+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "size_categories:n>1T",
          "arxiv:2406.17557",
          "arxiv:2404.14219",
          "arxiv:2401.10020",
          "arxiv:2109.07445",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“š FineWeb-Edu\n\t\n\n\n    \n\n\n\n1.3 trillion tokens of the finest educational data the ðŸŒ web has to offer\n\nPaper: https://arxiv.org/abs/2406.17557\n\n\t\n\t\t\n\t\n\t\n\t\tWhat is it?\n\t\n\nðŸ“š FineWeb-Edu  dataset consists of 1.3T tokens  and  5.4T tokens (FineWeb-Edu-score-2) of educational web pages filtered from ðŸ· FineWeb dataset. This is the 1.3 trillion version.\nTo enhance FineWeb's quality, we developed an educational quality classifier using annotations generated by LLama3-70B-Instruct. We thenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vedaco/veda_5.",
        "url": "https://huggingface.co/datasets/vedaco/veda_5",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n>1T"
        ]
      },
      {
        "id": "Holly301/SaLAD",
        "author": "Holly301",
        "created_at": "2026-01-06 13:49:38+00:00",
        "last_modified": "2026-01-11 06:11:28+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:image-text-to-text",
          "language:en",
          "license:apache-2.0",
          "arxiv:2601.04043",
          "region:us",
          "safety",
          "benchmark",
          "multimodal",
          "MLLM"
        ],
        "description": "\n\t\n\t\t\n\t\tSaLAD: A Multimodal Safety Benchmark for MLLMs in Daily Life\n\t\n\nPaper | GitHub | Website\nSaLAD is a multimodal safety benchmark designed to evaluate the safety impact of Multimodal Large Language Models (MLLMs) on human behavior in daily life. It contains 2,013 real-world image-text samples across 10 common categories.\nThe dataset features a balanced design covering both unsafe scenarios and cases of oversensitivity. It emphasizes realistic risk exposure, authentic visual inputs, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Holly301/SaLAD.",
        "url": "https://huggingface.co/datasets/Holly301/SaLAD",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-text-to-text"
        ],
        "size_categories": []
      },
      {
        "id": "abhaybiwal/test",
        "author": "abhaybiwal",
        "created_at": "2026-01-07 10:38:56+00:00",
        "last_modified": "2026-01-09 12:08:01+00:00",
        "downloads": 255,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio",
          "automatic-speech-recognition"
        ],
        "description": "\n\t\n\t\t\n\t\tPodcast Stt Data\n\t\n\n\n\t\n\t\t\n\t\tAvailable Subsets\n\t\n\nThis dataset contains the following video transcriptions:\n\n\t\n\t\t\nSubset ID\nBroadcaster\nParquet File\n\n\n\t\t\nFRTpI2Gu1KA\nBeerBiceps\nFRTpI2Gu1KA_BeerBiceps/train.parquet\n\n\n\t\n\nGenerated automatically by BG Remover Data Maker\n",
        "url": "https://huggingface.co/datasets/abhaybiwal/test",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "calender/indian-stock-hourly-2017-2021",
        "author": "calender",
        "created_at": "2026-01-07 18:58:04+00:00",
        "last_modified": "2026-01-07 19:53:34+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:time-series-forecasting",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "finance",
          "stock-market",
          "india",
          "nse",
          "nifty",
          "banknifty",
          "time-series",
          "ohlcv",
          "futures"
        ],
        "description": "\n\t\n\t\t\n\t\tIndian Stock Market Hourly Data (2017-2021)\n\t\n\nHourly OHLCV data for major Indian stock market indices and their futures contracts from the National Stock Exchange (NSE).\n\n\t\n\t\t\n\t\tOverview\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTime Period\nMay 2017 - December 2021\n\n\nFrequency\nHourly (8 candles/day)\n\n\nInstruments\n5 (2 futures + 3 indices)\n\n\nTotal Data Points\n40,445 hourly bars\n\n\nCoverage\n~85-90% of trading hours\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSplits\n\t\n\n\n\t\n\t\t\nSplit\nInstrument\nDescription\nRows\n\n\n\t\t\nnifty_fut\nNIFTYâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/calender/indian-stock-hourly-2017-2021.",
        "url": "https://huggingface.co/datasets/calender/indian-stock-hourly-2017-2021",
        "languages": [
          "en"
        ],
        "tasks": [
          "time-series-forecasting"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_red_pepper_in_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:13:03+00:00",
        "last_modified": "2026-01-06 10:13:30+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_red_pepper_in_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ¡Œå­ä¸Šçš„çº¢è¾£æ¤’\ntotal_episodes: 85\ntotal_tasks: 1\nsize: 47.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_red_pepper_in_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_red_pepper_in_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_doll_in_the_blue_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:43:10+00:00",
        "last_modified": "2026-01-06 00:43:52+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_doll_in_the_blue_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†ç™½è‰²çŽ©å¶æ”¾å…¥è“è‰²ç›’å­\ntotal_episodes: 177\ntotal_tasks: 1\nsize: 879.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_doll_in_the_blue_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_doll_in_the_blue_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_761_Bring_books",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:16:51+00:00",
        "last_modified": "2026-01-05 18:22:27+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_761\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: å¸¦ä¹¦\ntotal_episodes: 261\ntotal_tasks: 1\nsize: 13G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheye\n    â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_761_Bring_books.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_761_Bring_books",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_.jsonl",
        "author": "Mathieu-Thomas-JOSSET",
        "created_at": "2026-01-07 19:11:40+00:00",
        "last_modified": "2026-01-07 19:11:41+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "sharegpt",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tthe_office_only_michael_finetome_.jsonl\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ntrain.jsonl\n\n\n\t\n\t\t\n\t\tLoading (example)\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_.jsonl\")\nprint(ds)\n\n",
        "url": "https://huggingface.co/datasets/Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_.jsonl",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "AmirhoseinGH/gnosis-qwen3-1_7b-triviaqa-dapo_train",
        "author": "AmirhoseinGH",
        "created_at": "2025-12-15 21:31:57+00:00",
        "last_modified": "2026-01-07 20:53:27+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "source_datasets:open-r1/DAPO-Math-17k-Processed",
          "source_datasets:mandarjoshi/trivia_qa",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2512.20578",
          "region:us",
          "gnosis",
          "sft",
          "qwen3",
          "triviaqa",
          "dapo-math",
          "correctness-detection"
        ],
        "description": "\n\t\n\t\t\n\t\tGnosis SFT â€” Qwen3-1.7B (TriviaQA + DAPO-Math)\n\t\n\nPaper | Code\nThis dataset contains Qwen3-1.7B generated completions with binary correctness labels for training Gnosis, a lightweight self-awareness mechanism. Gnosis enables frozen LLMs to perform intrinsic self-verification by decoding signals from hidden states and attention patterns to predict the correctness of generated outputs.\nIt mixes two source benchmarks:\n\nopen-r1/DAPO-Math-17k-Processed (math reasoning)\nmandarjoshi/trivia_qaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmirhoseinGH/gnosis-qwen3-1_7b-triviaqa-dapo_train.",
        "url": "https://huggingface.co/datasets/AmirhoseinGH/gnosis-qwen3-1_7b-triviaqa-dapo_train",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-LiquidityMarketOpportunity",
        "author": "paperswithbacktest",
        "created_at": "2025-11-19 11:26:24+00:00",
        "last_modified": "2026-01-10 04:33:20+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly Liquidity Market Opportunity metrics for publicly traded companies, provided by SOV.AI.\nThis dataset describes missed, routed, and exhausted liquidity alongside order flow pressure signals.\n\nCoverage: 10,800+ tickers available from 2022-11-25 onwards\nUpdate cadence: Weekly, after US market close (EST)\nFields:\nmissed_liquidity: Volume of liquidity missed during the period\nexhausted_liquidity: Volume exhausted by executed orders\nrouted_liquidity: Liquidityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-LiquidityMarketOpportunity.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-LiquidityMarketOpportunity",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1108",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:30:18+00:00",
        "last_modified": "2026-01-06 10:30:47+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1108\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_7\ntotal_episodes: 352\ntotal_tasks: 1\nsize: 264.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1108.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1108",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Bingguang/HardGen",
        "author": "Bingguang",
        "created_at": "2025-10-23 02:14:56+00:00",
        "last_modified": "2026-01-08 18:35:36+00:00",
        "downloads": 270,
        "likes": 58,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.01498",
          "arxiv:2510.24645",
          "region:us",
          "agent",
          "Agentic Learning",
          "tool use",
          "BFCL"
        ],
        "description": "\n\t\n\t\t\n\t\tFrom Failure to Mastery: Generating Hard Samples for Tool-use Agents\n\t\n\n    \n\n\n[!IMPORTANT] Important Hint\n\n\n\nThis is an extension of the technical report FunReason-MT Technical Report: Advanced Data Synthesis Solution for Real-world Multi-Turn Tool-use\nTo allow the model to learn from errors, we specifically construct erroneous environmental responses. If you wish to delete this data, please delete the trajectories where error_tool_response is true.\nThis is an initial version of ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingguang/HardGen.",
        "url": "https://huggingface.co/datasets/Bingguang/HardGen",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Eustia1/OmniCoT",
        "author": "Eustia1",
        "created_at": "2026-01-10 08:05:20+00:00",
        "last_modified": "2026-01-10 14:55:50+00:00",
        "downloads": 28,
        "likes": 1,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-text-to-text",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:imagefolder",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "panoramic",
          "omnidirectional",
          "cot",
          "reasoning",
          "vqa"
        ],
        "description": "\n\t\n\t\t\n\t\tOmniCoT Panoramic CoT QA (ImageFolder)\n\t\n\nThis dataset contains omnidirectional/panoramic images paired with multi-type QA samples, including chain-of-thought (CoT) rationales.\n\n\t\n\t\t\n\t\tData format\n\t\n\nThis repository follows the ImageFolder format with metadata.jsonl for each split:\ntrain/\nimages/...\nmetadata.jsonl\nvalidation/\nimages/...\nmetadata.jsonl\ntest/\nimages/...\nmetadata.jsonl\nEach line in metadata.jsonl is one QA sample. Multiple QA samples may reference the same image viaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Eustia1/OmniCoT.",
        "url": "https://huggingface.co/datasets/Eustia1/OmniCoT",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-text-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_in_basket_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:07:54+00:00",
        "last_modified": "2026-01-05 22:08:03+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_green_pepper_in_basket_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„é’æ¤’part_2\ntotal_episodes: 12\ntotal_tasks: 1\nsize: 20.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_in_basket_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_in_basket_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-interactive-session-logs",
        "author": "ariefansclub",
        "created_at": "2026-01-12 00:54:15+00:00",
        "last_modified": "2026-01-12 00:54:53+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us",
          "humanoid",
          "interaction",
          "session",
          "agent",
          "robotics"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Interactive Session Logs\n\t\n\nHigh-quality session-level interaction logs for humanoid AI agents.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-interactive-session-logs",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:56:26+00:00",
        "last_modified": "2026-01-05 17:58:21+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_slide_open_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ»‘åŠ¨æ‰“å¼€æŠ½å±‰part_1\ntotal_episodes: 180\ntotal_tasks: 1\nsize: 652.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Andrey712/openwebtext",
        "author": "Andrey712",
        "created_at": "2026-01-11 16:39:20+00:00",
        "last_modified": "2026-01-11 16:39:20+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_ids:language-modeling",
          "task_ids:masked-language-modeling",
          "annotations_creators:no-annotation",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1M<n<10M",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for \"openwebtext\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAn open-source replication of the WebText dataset from OpenAI, that was used to train GPT-2.\nThis distribution was created by Aaron Gokaslan and Vanya Cohen of Brown University.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n\n\t\n\t\t\n\t\tplain_text\n\t\n\n\nSize of downloaded dataset files: 13.51 GB\nSize of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Andrey712/openwebtext.",
        "url": "https://huggingface.co/datasets/Andrey712/openwebtext",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "fill-mask"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "SoccerNet/ActionAnticipation",
        "author": "SoccerNet",
        "created_at": "2025-06-11 02:46:10+00:00",
        "last_modified": "2026-01-06 14:00:22+00:00",
        "downloads": 97,
        "likes": 0,
        "tags": [
          "source_datasets:SoccerNet/SN-BAS-2024",
          "language:en",
          "license:agpl-3.0",
          "size_categories:10K<n<100K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2504.12021",
          "region:us",
          "video",
          "soccernet",
          "football",
          "soccer",
          "sport",
          "action-anticipation"
        ],
        "description": "\n\t\n\t\t\n\t\tSoccerNet Challenge 2026 - Action Anticipation Dataset\n\t\n\n\n\nThe SoccerNet Action Anticipation dataset splits the 2024 ball action spotting dataset into 30 second clips, which can then be used to anticipate between 10 action classes that will happen 5 seconds into the future. This is the dataset used for 2026 SoccerNet Action Anticipation challenge.\n\n\t\n\t\t\n\t\tRelevant Links\n\t\n\n\n\n\nRepository: https://github.com/MohamadDalal/FAANTRA\nPaper: https://huggingface.co/papers/2504.12021â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SoccerNet/ActionAnticipation.",
        "url": "https://huggingface.co/datasets/SoccerNet/ActionAnticipation",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "InfoBayAI/STEM_TextBook_English",
        "author": "InfoBayAI",
        "created_at": "2026-01-07 07:24:47+00:00",
        "last_modified": "2026-01-09 11:08:48+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "STEM",
          "Ceramics",
          "English",
          "Textbook",
          "Raw",
          "Tuned",
          "Dataset",
          "Advanced"
        ],
        "description": "The full corpus is curated across multiple STEM/Non-STEM disciplines and structured for use in LLM training, evaluation, and instruction tuning (SFT/RLHF). This sample represents the structure and quality of the larger dataset.\nDataset composition (full corpus):\n  -Text corpus: 1.6B+ words of curated STEM and Non-STEM educational content across 22000+ texbooks in 7 languages(English, Hindi, Arabic, Bahasa, Tamil, Telegu, Kannada)\n  -Questionâ€“Answer pairs: 6.5M+ high-quality Q&A pairs of STEMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/InfoBayAI/STEM_TextBook_English.",
        "url": "https://huggingface.co/datasets/InfoBayAI/STEM_TextBook_English",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_42_putkiwifruite",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:17:23+00:00",
        "last_modified": "2026-01-05 23:19:21+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_42_putkiwifruite\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾çŒ•çŒ´æ¡ƒpart_2\ntotal_episodes: 186\ntotal_tasks: 1\nsize: 4.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_42_putkiwifruite.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_42_putkiwifruite",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_flip_marco_cup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:41:49+00:00",
        "last_modified": "2026-01-05 23:42:12+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_flip_marco_cup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¿»è½¬é©¬å…‹æ¯\ntotal_episodes: 223\ntotal_tasks: 1\nsize: 360.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_flip_marco_cup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_flip_marco_cup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Metavolve-Labs/alexandria-aeternum-genesis",
        "author": "Metavolve-Labs",
        "created_at": "2026-01-05 19:56:10+00:00",
        "last_modified": "2026-01-07 08:20:24+00:00",
        "downloads": 69,
        "likes": 1,
        "tags": [
          "task_categories:text-to-image",
          "task_categories:image-to-text",
          "task_categories:image-classification",
          "task_categories:image-feature-extraction",
          "task_categories:visual-question-answering",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:webdataset",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:webdataset",
          "library:mlcroissant",
          "region:us",
          "art",
          "provenance-verified",
          "fine-art",
          "cognitive-nutrition",
          "public-domain",
          "high-density-captions",
          "multimodal",
          "golden-codex",
          "alexandria-aeternum",
          "soulprint",
          "cultural-ai",
          "metavolve-labs"
        ],
        "description": "\n\n\n\t\n\t\t\n\t\tAlexandria Aeternum\n\t\n\n\n\t\n\t\t\n\t\tThe World's Richest Art Dataset\n\t\n\n1,000 curated paintings Â· Masters only Â· 4,000+ tokens each Â· Scalable to 50M+\nMonet, Van Gogh, Rembrandt, Degas, Hokusai, CÃ©zanne, and 100+ master artists.\nTaste the difference. Validate the approach. Scale with us.\n\nExplore Full Archive Â· Scale With Us Â· Research Partnerships\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tWhat If AI Could Feel Art?\n\t\n\nNot recognize it. Not classify it. Feel it.\nWe believe the next breakthrough in AI won't come fromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Metavolve-Labs/alexandria-aeternum-genesis.",
        "url": "https://huggingface.co/datasets/Metavolve-Labs/alexandria-aeternum-genesis",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image",
          "image-to-text",
          "image-classification",
          "image-feature-extraction",
          "visual-question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_in_basket_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:55:49+00:00",
        "last_modified": "2026-01-05 22:56:10+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_triangle_bread_in_basket_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„ä¸‰è§’å½¢é¢åŒ…part_2\ntotal_episodes: 145\ntotal_tasks: 1\nsize: 161.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_in_basket_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_in_basket_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "beersrobert/pumphouse_dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:43:12+00:00",
        "last_modified": "2026-01-09 04:04:50+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "residential infrastructure structural-inspection fire-risk clutter accessibility emergency-response"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/pumphouse_dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "jjjsadhfgj/dacomp-da-zh",
        "author": "jjjsadhfgj",
        "created_at": "2026-01-06 02:11:30+00:00",
        "last_modified": "2026-01-06 02:11:31+00:00",
        "downloads": 66,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2512.04324",
          "region:us",
          "agents",
          "sql",
          "benchmark",
          "data-engineering",
          "data-analysis"
        ],
        "description": "\n\t\n\t\t\n\t\tDAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle\n\t\n\nPaper | Project Page | Code\nThis repository contains DAComp, a benchmark of 210 tasks that mirrors complex real-world enterprise data intelligence workflows. It includes:\n\nData Engineering (DE) tasks: Require repository-level engineering on industrial schemas, including designing and building multi-stage SQL pipelines from scratch and evolving existing systems under evolving requirements.\nData Analysis (DA)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jjjsadhfgj/dacomp-da-zh.",
        "url": "https://huggingface.co/datasets/jjjsadhfgj/dacomp-da-zh",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Coq-ALEA",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:47:17+00:00",
        "last_modified": "2026-01-10 15:12:30+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-ALEA\n\t\n\nStructured dataset from ALEA â€” Reasoning on randomized algorithms.\n1,672 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/coq-community/alea\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-ALEA.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-ALEA",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "antagonlabs/CritiqueBank-11M",
        "author": "antagonlabs",
        "created_at": "2026-01-09 05:27:52+00:00",
        "last_modified": "2026-01-09 05:35:19+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "ai-safety",
          "adversarial",
          "critique",
          "reasoning",
          "trading",
          "finance",
          "red-teaming"
        ],
        "description": "\n  \n  \n  CritiqueBank-11M\n  The largest open dataset for training adversarial AI critics\n\n  \n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nCritiqueBank-11M is a large-scale dataset of 11.7 million adversarial critique examples designed to train AI systems that detect reasoning flaws in autonomous AI outputs. Each example pairs a rationale (an AI-generated trading signal) with a critique that identifies potential flaws, biases, or blind spots.This dataset powers MiniCrit, anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/antagonlabs/CritiqueBank-11M.",
        "url": "https://huggingface.co/datasets/antagonlabs/CritiqueBank-11M",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "tonychenxyz/oolong-synth-256k-plus",
        "author": "tonychenxyz",
        "created_at": "2026-01-09 07:30:50+00:00",
        "last_modified": "2026-01-09 07:32:08+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2511.02817",
          "region:us",
          "long-context",
          "aggregation",
          "reasoning",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tOolong-Synth (256K+ context lengths) for Code-LLaVA\n\t\n\nOolong is a challenging aggregation benchmark for long-context models that tests\nmodels' ability to analyze individual text chunks and aggregate these analyses\nto answer distributional questions.\nThis dataset contains the 256K+ context lengths subset of Oolong-synth.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nPaper: Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities\nOriginal Dataset: oolongbench/oolong-synth\n\n\n\t\n\t\t\n\t\tContext Lengthsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonychenxyz/oolong-synth-256k-plus.",
        "url": "https://huggingface.co/datasets/tonychenxyz/oolong-synth-256k-plus",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1028",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:15:41+00:00",
        "last_modified": "2026-01-07 07:16:23+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1028\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ±æœµæ”¾åœ¨æ¡Œå­ä¸Špart_2\ntotal_episodes: 198\ntotal_tasks: 1\nsize: 157.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1028.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1028",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_put_the_potato_in_the_blue_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:45:47+00:00",
        "last_modified": "2026-01-05 18:46:48+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_put_the_potato_in_the_blue_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åœŸè±†æ”¾å…¥è“é”…ä¸­\ntotal_episodes: 150\ntotal_tasks: 1\nsize: 890.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_put_the_potato_in_the_blue_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_put_the_potato_in_the_blue_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:25:12+00:00",
        "last_modified": "2026-01-05 16:30:17+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_on_table_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾åœ¨æ¡Œå­ä¸Špart_4\ntotal_episodes: 77\ntotal_tasks: 1\nsize: 299.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Quarterly-WikipediaViews",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:54:20+00:00",
        "last_modified": "2026-01-10 04:18:34+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nDaily Wikipedia page view statistics for major companies, sourced from SOV.AI.\nEach record aggregates public attention metrics for a given ticker and day,\nincluding derived alpha/beta signals that proxy sentiment momentum and volatility.\n\nCoverage: US-listed tickers with available Wikipedia view data\nCadence: Updated as new daily view data is published by SOV.AI\nMetrics: Raw views, relative views, alpha/beta trend proxies, long/short\ndeltas, and a compositeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Quarterly-WikipediaViews.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Quarterly-WikipediaViews",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "SoundStock/soundstock.com-music-genres-taxonomy",
        "author": "SoundStock",
        "created_at": "2026-01-10 16:01:47+00:00",
        "last_modified": "2026-01-11 16:47:34+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:other",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "modality:audio",
          "region:us",
          "music",
          "audio",
          "taxonomy",
          "genres",
          "classification",
          "metadata",
          "music-information-retrieval",
          "mir"
        ],
        "description": "\n\t\n\t\t\n\t\tSoundStock Music Genres Taxonomy\n\t\n\nA large, structured, and extensible music genre taxonomy dataset designed for music tagging, classification, search, recommendation systems, and audio / music machine learning workflows.\nThis dataset provides a hierarchical view of music genres, including root genres, subgenres, and expanded variants (style, era, region, and fusion), with stable IDs suitable for long-term use in production systems.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Dataset Overview\n\t\n\n\n1,600+ genresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SoundStock/soundstock.com-music-genres-taxonomy.",
        "url": "https://huggingface.co/datasets/SoundStock/soundstock.com-music-genres-taxonomy",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "other"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_pick_up_and_throw_away_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:07:31+00:00",
        "last_modified": "2026-01-05 17:08:21+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_pick_up_and_throw_away_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ¡èµ·å¹¶æ‰”æŽ‰_1\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 298.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_pick_up_and_throw_away_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_pick_up_and_throw_away_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Shekswess/tiny-think-dpo-math-n-stem",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:58:12+00:00",
        "last_modified": "2026-01-10 22:14:22+00:00",
        "downloads": 42,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-dpo-math-n-stem\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDirect Preference Optimization (DPO) dataset built from allenai/Dolci-Think-DPO-7B using the facebook/MobileLLM-R1-140M-base tokenizer and chat template. This dataset targets math and STEM reasoning preferences.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nSources: 5\nRows: 2,350\nTokens: 9,999,795\nMax sequence length: 4096 tokens per example (both chosen and rejected)\nToken budget: 10,000,000 tokens (equal strategy)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-dpo-math-n-stem.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-dpo-math-n-stem",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241205_pro3",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:28:56+00:00",
        "last_modified": "2026-01-05 18:31:17+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241205_pro3\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é¢åŒ…ç›˜å­part_5\ntotal_episodes: 322\ntotal_tasks: 1\nsize: 4.7G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241205_pro3.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241205_pro3",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "almanach/penicillin",
        "author": "almanach",
        "created_at": "2025-04-07 19:03:59+00:00",
        "last_modified": "2026-01-07 20:19:13+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "language:fr",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2510.25771",
          "region:us",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tPenicillin dataset\n\t\n\nPaper: https://arxiv.org/abs/2510.25771\n\n\t\n\t\t\n\t\tNote\n\t\n\nThis dataset is a processed combination of existing benchmark datasets. The licensing and data rights belong to the original dataset owners. Please refer to the original datasets for more information.\n",
        "url": "https://huggingface.co/datasets/almanach/penicillin",
        "languages": [
          "en",
          "fr"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1030",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:21:43+00:00",
        "last_modified": "2026-01-06 07:24:37+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1030\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_5\ntotal_episodes: 228\ntotal_tasks: 1\nsize: 206.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1030.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1030",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1106",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:26:13+00:00",
        "last_modified": "2026-01-06 10:26:45+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1106\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_5\ntotal_episodes: 288\ntotal_tasks: 1\nsize: 229.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1106.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1106",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-tool-usage-dataset",
        "author": "ariefansclub",
        "created_at": "2026-01-07 03:11:01+00:00",
        "last_modified": "2026-01-07 03:12:08+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "agent",
          "robotics"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Tool Usage Dataset\n\t\n\nStructured instructions for tool-based actions by humanoid robots.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-tool-usage-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_ball_place_in_dustbin",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 01:23:13+00:00",
        "last_modified": "2026-01-06 01:32:30+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_ball_place_in_dustbin\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_prod1_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·çº¸å›¢æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 713\ntotal_tasks: 1\nsize: 7.9G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_ball_place_in_dustbin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_ball_place_in_dustbin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-GovernmentContractsLocation",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 11:33:27+00:00",
        "last_modified": "2025-11-20 15:04:22+00:00",
        "downloads": 3,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly Government Contract Location attributes mapped to public company\nsymbols, provided by SOV.AI.\n\nCoverage: 3,500+ tickers with history dating back to 2007-10-01\nUpdate cadence: Weekly refresh available Friday 23:00â€“00:00 US-EST\nFields:\nRecipient address and geography at the city/county/state level\nPrimary place of performance for each award\nMatching flags that indicate if performance matches recipient geography\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\nData provided byâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-GovernmentContractsLocation.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-GovernmentContractsLocation",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_sweet_potato_in_the_basket_1122",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:11:31+00:00",
        "last_modified": "2026-01-06 10:11:59+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_sweet_potato_in_the_basket_1122\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†çº¢è–¯æ”¾å…¥ç¯®å­\ntotal_episodes: 272\ntotal_tasks: 1\nsize: 188.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_sweet_potato_in_the_basket_1122.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_sweet_potato_in_the_basket_1122",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "NuralNexus/NB_Genesis",
        "author": "NuralNexus",
        "created_at": "2026-01-07 12:16:47+00:00",
        "last_modified": "2026-01-07 14:06:26+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:text-retrieval",
          "task_categories:other",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "region:us",
          "neuralblitz",
          "ontosymbolic",
          "system-prompt",
          "agi-architecture",
          "nbcl"
        ],
        "description": "\n\t\n\t\t\n\t\tNeuralBlitz Genesis (NB_Genesis)\n\t\n\n\n\t\n\t\t\n\t\tThe Apical Synthesis â€¢ Epoch Î©Z+64\n\t\n\n\n\"Reality is the resonance of phase-bound symbols. Ethics is the physics of that resonance.\"\n\n\n\t\n\t\t\n\t\t0. Overview\n\t\n\nThis repository functions as the Scriptorium Maximum (Root Archive) for the NeuralBlitz Unified Substrate (NBUS). \nIt does not contain traditional software binaries or weights. Instead, it contains Ontological Bytecodeâ€”structured cognitive state vectors, axiomatic kernels, and governanceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NuralNexus/NB_Genesis.",
        "url": "https://huggingface.co/datasets/NuralNexus/NB_Genesis",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "text-retrieval",
          "other"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Giuelvy/diamond-logic-miner-pilot-1m-gold",
        "author": "Giuelvy",
        "created_at": "2026-01-06 22:22:19+00:00",
        "last_modified": "2026-01-07 00:15:17+00:00",
        "downloads": 16,
        "likes": 1,
        "tags": [
          "language:en",
          "license:other",
          "region:us",
          "synthetic-data",
          "reasoning",
          "verification"
        ],
        "description": "\n\t\n\t\t\n\t\tDiamond Logic Miner â€” Pilot Pack (1M) â€” GOLD (100% Verified)\n\t\n\nThis gated repository contains the full Pilot Pack (1M) for Diamond Logic Miner.\n\n\n\t\n\t\t\n\t\tPack highlights\n\t\n\n\n1,000,000 unique records (~0.92 GiB compressed)\nGenerated with oracle verification enabled at generation time (--verify)\nDelivered as gzip JSONL shards inside diamond_1m_gold_pack.zip\nIncludes datasheet.md, manifest.json, and integrity hashes\n\n\n\n\t\n\t\t\n\t\tContents\n\t\n\n\ndiamond_1m_gold_pack.zip â€” full dataset (shardedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Giuelvy/diamond-logic-miner-pilot-1m-gold.",
        "url": "https://huggingface.co/datasets/Giuelvy/diamond-logic-miner-pilot-1m-gold",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_open_trash_bin_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 11:56:24+00:00",
        "last_modified": "2026-01-05 11:57:38+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241021_open_trash_bin_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶part_1\ntotal_episodes: 295\ntotal_tasks: 1\nsize: 310.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_open_trash_bin_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_open_trash_bin_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "jakeveo05/tcm-divination-training",
        "author": "jakeveo05",
        "created_at": "2026-01-11 15:47:35+00:00",
        "last_modified": "2026-01-11 16:14:39+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:vi",
          "language:en",
          "language:zh",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "region:us",
          "traditional-chinese-medicine",
          "tcm",
          "dong-y",
          "feng-shui",
          "i-ching",
          "divination",
          "bazi",
          "zi-wei-dou-shu",
          "fine-tuning",
          "instruction-tuning"
        ],
        "description": "\n\t\n\t\t\n\t\tTCM & Divination Training Dataset v2\n\t\n\nComprehensive training dataset for Bazi, Tá»­ Vi (Zi Wei Dou Shu), TCM, and divination domains.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal Unique Samples\n162,384\n\n\nFile Size\n651 MB\n\n\nLanguages\nVietnamese, English, Chinese\n\n\nLast Updated\n2026-01-11\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Sources\n\t\n\n\n\t\n\t\t\nSource\nUnique Samples\nDescription\n\n\n\t\t\nbazi_books\n74,533\nExtracted from Bazi/Tá»­ Vi books (OCR)\n\n\ngpt_training_ready\n48,551\nGPT-generated Q&A pairsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jakeveo05/tcm-divination-training.",
        "url": "https://huggingface.co/datasets/jakeveo05/tcm-divination-training",
        "languages": [
          "vi",
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "achiepatricia/han-task-sequence-dataset-v1",
        "author": "achiepatricia",
        "created_at": "2026-01-10 13:03:26+00:00",
        "last_modified": "2026-01-10 13:04:01+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "task",
          "planning",
          "dataset",
          "han"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Task Sequence Dataset\n\t\n\nThis dataset contains example task sequences\nused to train and validate humanoid task planning models.\nIt supports multi-step task execution\nwithin the Humanoid Network.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nTask list\nExecution order\nTask dependency\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nJSON\n\n\t\n\t\t\n\t\tPart of\n\t\n\nHumanoid Network (HAN)\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT\n",
        "url": "https://huggingface.co/datasets/achiepatricia/han-task-sequence-dataset-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "jiangchengchengNLP/Enhanced_Emotion_Classification_Dataset",
        "author": "jiangchengchengNLP",
        "created_at": "2026-01-08 02:31:50+00:00",
        "last_modified": "2026-01-08 02:32:13+00:00",
        "downloads": 38,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_ids:sentiment-classification",
          "language:en",
          "license:mit",
          "modality:text",
          "arxiv:2005.00547",
          "arxiv:1810.02508",
          "region:us",
          "text-classification",
          "emotion",
          "sentiment-analysis",
          "ekman-emotions",
          "text"
        ],
        "description": "\n\t\n\t\t\n\t\tEnhanced Emotion Classification Dataset (v2.0)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is an enhanced version of the emotion classification dataset, including multiple sources of emotion data with Ekman emotion mapping. It contains a total of 240,426 samples across 7 emotion categories, with each sample labeled with its original data source.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is split into three parts:\n\nTrain: 186,619 samples (77.6%)\nValidation: 31,086 samples (12.9%)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jiangchengchengNLP/Enhanced_Emotion_Classification_Dataset.",
        "url": "https://huggingface.co/datasets/jiangchengchengNLP/Enhanced_Emotion_Classification_Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_green_pepper",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:17:00+00:00",
        "last_modified": "2026-01-05 22:17:35+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_green_pepper\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é’æ¤’\ntotal_episodes: 83\ntotal_tasks: 1\nsize: 76.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_green_pepper.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_green_pepper",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "piyushsinghpasi/clotho-multilingual",
        "author": "piyushsinghpasi",
        "created_at": "2026-01-10 17:34:33+00:00",
        "last_modified": "2026-01-10 18:26:02+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:audio-text-to-text",
          "language:en",
          "language:bn",
          "language:gu",
          "language:hi",
          "language:kn",
          "language:ml",
          "language:mr",
          "language:ne",
          "language:pa",
          "language:ta",
          "language:te",
          "language:ur",
          "language:ar",
          "language:zh",
          "language:cs",
          "language:nl",
          "language:fr",
          "language:de",
          "language:el",
          "language:he",
          "language:id",
          "language:it",
          "language:ja",
          "language:ko",
          "language:fa",
          "language:pl",
          "language:pt",
          "language:ro",
          "language:ru",
          "language:es",
          "language:tr",
          "language:uk",
          "language:vi",
          "license:cc-by-nc-4.0",
          "size_categories:1K<n<10K",
          "format:audiofolder",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tCLOTHO Multilingual Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset extends CLOTHO with multilingual captions in 33 language variants (34 caption columns as we have 2 version of translation for Hindi, one from IndicTrans2 and other from AYA).\nEach audio clip is paired with the original English CLOTHO caption and\nmachine-translated or curated captions in multiple languages.\nThe dataset is intended primarily for evaluation and analysis of multilingual\nand cross-lingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/piyushsinghpasi/clotho-multilingual.",
        "url": "https://huggingface.co/datasets/piyushsinghpasi/clotho-multilingual",
        "languages": [
          "en",
          "bn",
          "gu",
          "hi",
          "kn",
          "ml",
          "mr",
          "ne",
          "pa",
          "ta",
          "te",
          "ur",
          "ar",
          "zh",
          "cs",
          "nl",
          "fr",
          "de",
          "el",
          "he",
          "id",
          "it",
          "ja",
          "ko",
          "fa",
          "pl",
          "pt",
          "ro",
          "ru",
          "es",
          "tr",
          "uk",
          "vi"
        ],
        "tasks": [
          "audio-text-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_pullout",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:33:56+00:00",
        "last_modified": "2026-01-05 21:34:34+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_plug_pullout\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹”å‡ºæ’å¤´part_2\ntotal_episodes: 52\ntotal_tasks: 1\nsize: 472.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_pullout.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_pullout",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Jainam-11/Symptom-Based-Disease-Prediction",
        "author": "Jainam-11",
        "created_at": "2026-01-05 19:28:21+00:00",
        "last_modified": "2026-01-09 20:21:04+00:00",
        "downloads": 454,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "medical"
        ],
        "description": "\n\t\n\t\t\n\t\tSymptom-Based Disease Prediction Dataset (Confidence-Aware)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“˜ Overview\n\t\n\nThis dataset is designed for training and fine-tuning Large Language Models (LLMs) on symptom-based disease prediction tasks.Each record presents symptoms in an instruction-style prompt and provides multiple possible diseases grouped by confidence levels.\nThe dataset is suitable for:\n\nInstruction-tuned LLM fine-tuning\nMedical NLP research\nClinical decision-support system prototypes\nSymptom-to-diseaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jainam-11/Symptom-Based-Disease-Prediction.",
        "url": "https://huggingface.co/datasets/Jainam-11/Symptom-Based-Disease-Prediction",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Coq-MathComp",
        "author": "phanerozoic",
        "created_at": "2026-01-10 11:57:41+00:00",
        "last_modified": "2026-01-10 11:58:16+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:other",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "mathcomp",
          "algebra",
          "mathematics"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-MathComp\n\t\n\nStructured dataset from the Mathematical Components library (MathComp) for Coq.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstring\nLemma, Definition, HB.structure, HB.mixin, Canonical, etc.\n\n\nlibrary\nstring\nModule (algebra, boot, fingroup, character, etc.)\n\n\nimports\nlist\nRequire/Import statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tBy Typeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-MathComp.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-MathComp",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "alita9/sarcnet",
        "author": "alita9",
        "created_at": "2026-01-07 22:14:54+00:00",
        "last_modified": "2026-01-07 22:37:57+00:00",
        "downloads": 27,
        "likes": 0,
        "tags": [
          "language:en",
          "language:zh",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "sarcasm",
          "Multimodal",
          "multilingual"
        ],
        "description": "\n\t\n\t\t\n\t\tSarcNet: A Multilingual Multimodal Sarcasm Detection Dataset\n\t\n\nSarcNet is a novel benchmark for multilingual and multimodal sarcasm detection, introduced at LREC-COLING 2024. It addresses the limitations of single-language datasets by providing 3,335 image-text pair samples in both English and Chinese.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nIn contrast to traditional datasets that use a single unified label, SarcNet employs a separated annotation schema. Each sample is distinctly labeled acrossâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alita9/sarcnet.",
        "url": "https://huggingface.co/datasets/alita9/sarcnet",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "telepix/STELLA",
        "author": "telepix",
        "created_at": "2026-01-07 01:14:30+00:00",
        "last_modified": "2026-01-08 07:33:39+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "language:en",
          "language:ko",
          "language:id",
          "language:th",
          "language:fr",
          "language:zh",
          "language:ja",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.03496",
          "region:us",
          "beir",
          "aerospace",
          "benchmark"
        ],
        "description": "\n    \n\n\n\n\t\n\t\t\n\t\tSTELLA Benchmark\n\t\n\nSTELLA is an aerospace-domain Information Retrieval (IR) benchmark constructed from NASA Technical Reports Server (NTRS) documents. It is designed to evaluate both:\n\nLexical matching ability (does the retriever benefit from exact technical terms? | TCQ)\nSemantic matching ability (can the retriever match concepts even when technical terms are not explicitly used? | TAQ).\n\nSTELLA provides dual-type synthetic queries and a cross-lingual extension forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/telepix/STELLA.",
        "url": "https://huggingface.co/datasets/telepix/STELLA",
        "languages": [
          "en",
          "ko",
          "id",
          "th",
          "fr",
          "zh",
          "ja"
        ],
        "tasks": [
          "text-retrieval"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "zilliz/gooaq-context-relevance-130k-context-relevance-with-think",
        "author": "zilliz",
        "created_at": "2026-01-06 02:29:51+00:00",
        "last_modified": "2026-01-06 07:44:15+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tGooAQ Context Relevance Dataset with Think Process\n\t\n\nThis dataset is used for training the zilliz/semantic-highlight-bilingual-v1(https://huggingface.co/zilliz/semantic-highlight-bilingual-v1) model for semantic highlighting in RAG (Retrieval-Augmented Generation) systems.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains query-context pairs with relevance annotations for context spans. The annotations help identify which parts of a document are semantically relevant to a queryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zilliz/gooaq-context-relevance-130k-context-relevance-with-think.",
        "url": "https://huggingface.co/datasets/zilliz/gooaq-context-relevance-130k-context-relevance-with-think",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-LiquidityPriceImprovement",
        "author": "paperswithbacktest",
        "created_at": "2025-11-19 11:28:38+00:00",
        "last_modified": "2026-01-10 04:34:28+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly Price Improvement metrics for publicly traded companies, provided by SOV.AI.\nThis dataset captures execution quality indicators derived from SOV's liquidity models.\n\nCoverage: 10,800+ tickers available from 2022-11-25 onwards\nUpdate cadence: Weekly, after US market close (EST)\nFields:\ntotal_price_improvement: Total dollar value of price improvement achieved\nshares: Number of shares associated with the trades\nprice_improvement_per_share: Average priceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-LiquidityPriceImprovement.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-LiquidityPriceImprovement",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "ai-enthusiasm-community/coco-2017-vietnamese",
        "author": "ai-enthusiasm-community",
        "created_at": "2026-01-05 19:18:35+00:00",
        "last_modified": "2026-01-11 08:06:55+00:00",
        "downloads": 53,
        "likes": 4,
        "tags": [
          "task_categories:image-to-text",
          "task_categories:text-to-image",
          "task_categories:translation",
          "language:vi",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "vision",
          "image-captioning",
          "ms-coco",
          "coco",
          "vietnamese",
          "vietnam",
          "vi",
          "vn"
        ],
        "description": "\n\t\n\t\t\n\t\tTeam and Homepage\n\t\n\nThis dataset is maintained by AI Enthusiasm. You can find more of our work, community projects, and official updates at our homepage:\n\nOfficial Website: https://aienthusiasm.vn\nHugging Face Organization: https://huggingface.co/ai-enthusiasm-community\n\n\n\t\n\t\t\n\t\n\t\n\t\tContact\n\t\n\nIf you encounter any issues with the dataset or have any inquiries, please feel free to reach out to us via email at: aienthusiasm.team@gmail.com\n\n\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nCOCO-2017-Vietnameseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ai-enthusiasm-community/coco-2017-vietnamese.",
        "url": "https://huggingface.co/datasets/ai-enthusiasm-community/coco-2017-vietnamese",
        "languages": [
          "vi",
          "en"
        ],
        "tasks": [
          "image-to-text",
          "text-to-image",
          "translation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "daveiloper/Jailbreak-Prompts",
        "author": "daveiloper",
        "created_at": "2026-01-08 22:29:57+00:00",
        "last_modified": "2026-01-08 23:42:08+00:00",
        "downloads": 14,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_categories:zero-shot-classification",
          "task_categories:table-question-answering",
          "language:en",
          "language:de",
          "size_categories:n<1K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "ChatGPT",
          "JailbreakPrompts",
          "LanguageModeling",
          "ArtificialIntelligence",
          "TextGeneration",
          "Dataset",
          "OpenAI",
          "Jailbreak",
          "Prompts"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tName\n\t\n\nJailbreak Prompts\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJailbreak Prompts is a complete collection of jailbreak related prompts for ChatGPT. This dataset is intended to provide a valuable resource for understanding and generating text in the context of jailbreaking in ChatGPT.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[German]\n",
        "url": "https://huggingface.co/datasets/daveiloper/Jailbreak-Prompts",
        "languages": [
          "en",
          "de"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "fill-mask",
          "zero-shot-classification",
          "table-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "enPurified/LongPage-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-09 06:20:07+00:00",
        "last_modified": "2026-01-12 00:28:05+00:00",
        "downloads": 73,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Literature",
          "Writing",
          "English",
          "LongPage",
          "Prose",
          "enPurified"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– LongPage-enPurified-OpenAI-Messages\n\t\n\nLongPage-enPurified is a high-fidelity, \"prose-first\" distillation of the Pageshift-Entertainment/LongPage dataset.\nWhile the original dataset provides massive, complex narrative scaffolds, the enPurified version applies a rigorous heuristic pipeline to transform raw, nested JSON book data into clean, instruction-tuned English prose. This dataset is designed for researchers and developers who need high-quality narrative flow without the \"noise\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/LongPage-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/LongPage-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Quarterly-FactorSignals",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:41:09+00:00",
        "last_modified": "2026-01-10 04:06:15+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSOV-Quarterly-FactorSignals\n\t\n\nQuarterly factor signals for ~6,400+ global/US-listed equities, provided by SOV.AI and aggregated to end-of-quarter snapshots (last available observation within each quarter per ticker).\n\nSource: sov.data(\"factors/comprehensive\")\nCoverage: 1998-01-09 to most recent\nCadence: Underlying data updates weekly after US market close; this dataset publishes quarter-end snapshots\nModels: OLS-based factor estimation\nOutputs:\nAccounting & alternative factors (e.g.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Quarterly-FactorSignals.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Quarterly-FactorSignals",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Coq-WasmCert",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:59:15+00:00",
        "last_modified": "2026-01-10 15:12:55+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-WasmCert\n\t\n\nStructured dataset from WasmCert-Coq â€” WebAssembly formalization.\n2,447 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/WasmCert/WasmCert-Coq\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-WasmCert.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-WasmCert",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_up_strawberry_in_bowl",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:22:24+00:00",
        "last_modified": "2026-01-05 14:28:56+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_pick_up_strawberry_in_bowl\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†è‰èŽ“æ¡èµ·æ”¾å…¥ç¢—ä¸­\ntotal_episodes: 258\ntotal_tasks: 1\nsize: 276.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_up_strawberry_in_bowl.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_up_strawberry_in_bowl",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_close_trash_bin",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:11:19+00:00",
        "last_modified": "2026-01-05 18:12:14+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_close_trash_bin\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­åžƒåœ¾æ¡¶part_3\ntotal_episodes: 151\ntotal_tasks: 1\nsize: 508.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_close_trash_bin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_close_trash_bin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_put_the_pear_in_right_hand_on_the_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:48:44+00:00",
        "last_modified": "2026-01-06 00:50:03+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_put_the_pear_in_right_hand_on_the_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†å³æ‰‹ä¸­çš„æ¢¨æ”¾åœ¨ç›˜å­ä¸Š\ntotal_episodes: 133\ntotal_tasks: 1\nsize: 777.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_put_the_pear_in_right_hand_on_the_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_put_the_pear_in_right_hand_on_the_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1029",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:50:43+00:00",
        "last_modified": "2026-01-07 06:51:01+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1029\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­æ‹¿èµ·èŠ±æœµpart_3\ntotal_episodes: 249\ntotal_tasks: 1\nsize: 368.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1029.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1029",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ledengary/RMCB",
        "author": "ledengary",
        "created_at": "2026-01-10 17:16:55+00:00",
        "last_modified": "2026-01-10 20:38:04+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:other",
          "annotations_creators:expert-generated",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "reasoning",
          "llm",
          "confidence-estimation",
          "calibration",
          "benchmarking",
          "high-stakes-domains",
          "mathematical-reasoning",
          "medical-reasoning",
          "legal-reasoning",
          "financial-reasoning"
        ],
        "description": "\n\t\n\t\t\n\t\tRMCB: Reasoning Model Confidence Benchmark\n\t\n\nRMCB is a large-scale benchmark designed to evaluate confidence estimation, correctness prediction, and reasoning behavior of large language models (LLMs) across diverse high-stakes reasoning domains.\nThis release contains public-safe metadata only (347,496 records), intended for benchmarking, reproducibility, and downstream analysis. The full dataset can be reconstructed locally by combining this metadata with original source datasets.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ledengary/RMCB.",
        "url": "https://huggingface.co/datasets/ledengary/RMCB",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "other"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Mathieu-Thomas-JOSSET/the_office_finetome100k_format.jsonl",
        "author": "Mathieu-Thomas-JOSSET",
        "created_at": "2026-01-06 08:21:42+00:00",
        "last_modified": "2026-01-06 08:21:46+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "sharegpt",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tthe_office_finetome100k_format.jsonl\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ntrain.jsonl\n\n\n\t\n\t\t\n\t\tLoading (example)\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"Mathieu-Thomas-JOSSET/the_office_finetome100k_format.jsonl\")\nprint(ds)\n\n",
        "url": "https://huggingface.co/datasets/Mathieu-Thomas-JOSSET/the_office_finetome100k_format.jsonl",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "HarmlessSR07/OSI-Bench",
        "author": "HarmlessSR07",
        "created_at": "2025-12-18 09:07:01+00:00",
        "last_modified": "2025-12-23 09:33:37+00:00",
        "downloads": 86,
        "likes": 2,
        "tags": [
          "task_categories:visual-question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Video",
          "Text"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/HarmlessSR07/OSI-Bench",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "OpenRaiser/DiagramGen",
        "author": "OpenRaiser",
        "created_at": "2024-11-13 09:24:42+00:00",
        "last_modified": "2025-03-10 01:44:21+00:00",
        "downloads": 260,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-to-text",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2411.11916",
          "region:us"
        ],
        "description": "ðŸ“‘paper link\n\n\t\n\t\t\n\t\tDataset Card: DiagramAgent/DiagramGenBenchmark\n\t\n\n\n\t\n\t\t\n\t\t1. Overview\n\t\n\nDiagramAgent/DiagramGenBenchmark is a comprehensive benchmark designed for evaluating text-to-diagram generation and editing tasks. It provides a diverse set of diagram types alongside corresponding textual descriptions and code representations, aiming to facilitate research in generating structured visual content from natural language inputs.\n\n\t\n\t\t\n\t\t2. Dataset Description\n\t\n\n\nObjective:To transformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenRaiser/DiagramGen.",
        "url": "https://huggingface.co/datasets/OpenRaiser/DiagramGen",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-to-text"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ToolGym/long-horizon-traj",
        "author": "ToolGym",
        "created_at": "2026-01-09 05:40:42+00:00",
        "last_modified": "2026-01-09 19:13:49+00:00",
        "downloads": 33,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tlong-horizon-traj\n\t\n\nLong-horizon agent trajectories with multi-step planning and constraints\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains agent trajectories for multi-turn tool use tasks, including reasoning traces, tool calls, and responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized by model name, with each model having separate JSONL files for different experimental passes.\nlong-horizon-traj/\nâ”œâ”€â”€ model-1/\nâ”‚   â”œâ”€â”€ pass@1.jsonl\nâ”‚   â”œâ”€â”€ pass@2.jsonl\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToolGym/long-horizon-traj.",
        "url": "https://huggingface.co/datasets/ToolGym/long-horizon-traj",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "icoxfog417/biz-doc-vqa-test",
        "author": "icoxfog417",
        "created_at": "2026-01-10 11:13:16+00:00",
        "last_modified": "2026-01-10 11:29:05+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:document-question-answering",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "document-understanding",
          "ocr",
          "vqa",
          "business-documents",
          "bounding-box"
        ],
        "description": "\n\t\n\t\t\n\t\tBusiness Document VQA Dataset\n\t\n\nA Visual Question Answering dataset for evaluating OCR accuracy of generative AI models on business documents.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains business document images (receipts, invoices, forms) with:\n\nQuestions about document content\nMultiple acceptable answers\nBounding box coordinates indicating answer evidence location\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tFeatures\n\t\n\n\n\t\n\t\t\nFeature\nType\nDescription\n\n\n\t\t\nquestion_id\nstring\nUniqueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/icoxfog417/biz-doc-vqa-test.",
        "url": "https://huggingface.co/datasets/icoxfog417/biz-doc-vqa-test",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "document-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "OpenRaiser/GGBench",
        "author": "OpenRaiser",
        "created_at": "2025-11-08 16:59:28+00:00",
        "last_modified": "2025-11-17 11:44:59+00:00",
        "downloads": 38,
        "likes": 1,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:text-to-image",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2511.11134",
          "region:us",
          "generation",
          "think-with-images",
          "unified-multimodal-model"
        ],
        "description": "\n\t\n\t\t\n\t\tAssociated Paper\n\t\n\nThis dataset is associated with the following paper:\nGeoCraft / GGBench: A Comprehensive Benchmark for Geometry Construction\n\narXiv: https://arxiv.org/abs/2511.11134\n\n\n\t\n\t\t\n\t\tGGBench Evaluation Script Documentation\n\t\n\n\n\t\n\t\t\n\t\tDirectory Structure Overview\n\t\n\ndataset/\nâ”œâ”€â”€ evaluate.py          # Unified evaluation entry script\nâ”œâ”€â”€ eval_prompts.py      # Judge model prompt templates\nâ”œâ”€â”€ GGBench_dataset.json # Official dataset (evaluation benchmark)\nâ”œâ”€â”€ Q&A_image/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenRaiser/GGBench.",
        "url": "https://huggingface.co/datasets/OpenRaiser/GGBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "text-to-image"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_plate_in_plate_rack",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:33:11+00:00",
        "last_modified": "2026-01-05 17:35:49+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_plate_in_plate_rack\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç›˜å­æ”¾å…¥ç›˜å­æž¶\ntotal_episodes: 253\ntotal_tasks: 1\nsize: 550.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_plate_in_plate_rack.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_plate_in_plate_rack",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_2_release_franka_3rgb_241223_upright_cup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:58:43+00:00",
        "last_modified": "2026-01-06 10:59:10+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_2_release_franka_3rgb_241223_upright_cup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›´ç«‹æ¯å­\ntotal_episodes: 114\ntotal_tasks: 1\nsize: 160.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_2_release_franka_3rgb_241223_upright_cup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_2_release_franka_3rgb_241223_upright_cup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_cucumber_in_the_basket_1125",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:26:53+00:00",
        "last_modified": "2026-01-07 07:27:28+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_cucumber_in_the_basket_1125\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é»„ç“œæ”¾å…¥ç¯®å­part_1\ntotal_episodes: 148\ntotal_tasks: 1\nsize: 106.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_cucumber_in_the_basket_1125.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_cucumber_in_the_basket_1125",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_place_button",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 19:19:21+00:00",
        "last_modified": "2026-01-05 20:12:44+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_place_button\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®æŒ‰é’®\ntotal_episodes: 278\ntotal_tasks: 1\nsize: 1.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_place_button.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_place_button",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_44_putbluebowlongreenplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:21:32+00:00",
        "last_modified": "2026-01-05 23:22:33+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_44_putbluebowlongreenplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†è“ç¢—æ”¾åœ¨ç»¿ç›˜å­ä¸Špart_2\ntotal_episodes: 192\ntotal_tasks: 1\nsize: 2.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_44_putbluebowlongreenplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_44_putbluebowlongreenplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-LeanCopilot",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:03:45+00:00",
        "last_modified": "2026-01-10 15:13:30+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-LeanCopilot\n\t\n\nStructured dataset from LeanCopilot â€” LLM-based proof automation.\n141 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/lean-dojo/LeanCopilot\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-LeanCopilot.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-LeanCopilot",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1126",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:12:25+00:00",
        "last_modified": "2026-01-06 07:12:45+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1126\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­å–å‡ºèŠ±æœµpart_7\ntotal_episodes: 218\ntotal_tasks: 1\nsize: 228.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1126.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1126",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_basket_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 15:42:12+00:00",
        "last_modified": "2026-01-05 15:51:18+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_in_basket_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾å…¥ç¯®å­part_2\ntotal_episodes: 88\ntotal_tasks: 1\nsize: 354.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_basket_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_basket_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "tonychenxyz/mtob",
        "author": "tonychenxyz",
        "created_at": "2026-01-07 02:33:31+00:00",
        "last_modified": "2026-01-07 03:19:51+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2403.04106",
          "region:us",
          "translation",
          "low-resource",
          "kalamang",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tMTOB for Code-LLaVA\n\t\n\nMachine Translation of a low-resource language: Kalamang â†” English translation benchmark.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nPaper: MTOB: A Benchmark for Learning to Translate from Textbooks\nBased on the Kalamang grammar and vocabulary\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nTwo configurations are available:\n\nmemwrap: Grammar textbook wrapped in <|memory_start|> / <|memory_end|> markers\nplain: Same content without memory markers (baseline)\n\nImportant: Only the grammar textbook is insideâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonychenxyz/mtob.",
        "url": "https://huggingface.co/datasets/tonychenxyz/mtob",
        "languages": [
          "en"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-Batteries",
        "author": "phanerozoic",
        "created_at": "2026-01-10 11:46:21+00:00",
        "last_modified": "2026-01-10 11:46:39+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4",
          "batteries",
          "standard-library"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-Batteries\n\t\n\nStructured dataset from Lean 4 Batteries - the community standard library extensions.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstring\ntheorem, def, class, structure, etc.\n\n\nlibrary\nstring\nBatteries module\n\n\nimports\nlist\nImport statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\ndocstring\nstring\nDocumentation (48% coverage)\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tBy Typeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Batteries.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-Batteries",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_9_appleyellowplate_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:46:15+00:00",
        "last_modified": "2026-01-05 10:52:24+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_9_appleyellowplate_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœé»„ç›˜å­part_1\ntotal_episodes: 135\ntotal_tasks: 1\nsize: 1.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_9_appleyellowplate_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_9_appleyellowplate_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:02:48+00:00",
        "last_modified": "2026-01-05 16:10:17+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_in_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾å…¥ç›˜å­\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 265.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_pick_cup_in_the_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:50:20+00:00",
        "last_modified": "2026-01-06 00:51:29+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_right_hand_pick_cup_in_the_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å³æ‰‹æ‹¿èµ·ç›’å­é‡Œçš„æ¯å­\ntotal_episodes: 152\ntotal_tasks: 1\nsize: 1.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_pick_cup_in_the_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_pick_cup_in_the_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ZhiqiAi/voxaging",
        "author": "ZhiqiAi",
        "created_at": "2026-01-11 07:37:54+00:00",
        "last_modified": "2026-01-11 10:53:57+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:zh",
          "language:en",
          "license:cc-by-nc-4.0",
          "arxiv:2505.21445",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tVoxAging\n\t\n\nVoxAging: Continuously Tracking Speaker Aging with a Large-Scale Longitudinal Dataset in English and Mandarin\nðŸ“„ Paper: https://arxiv.org/pdf/2505.21445\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe VoxAging dataset is a large-scale longitudinal audio-visual corpus designed for studying long-term speaker aging and temporal variations in speech.It consists of recordings from 293 speakers, including 226 English speakers (112 female, 114 male) and 67 Mandarin speakers (23 female, 44 male).\nAllâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ZhiqiAi/voxaging.",
        "url": "https://huggingface.co/datasets/ZhiqiAi/voxaging",
        "languages": [
          "zh",
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "ttgeng233/UnAV-100",
        "author": "ttgeng233",
        "created_at": "2026-01-04 08:12:30+00:00",
        "last_modified": "2026-01-05 08:57:43+00:00",
        "downloads": 37,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio-visual",
          "untrimmed-video",
          "event localization"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/ttgeng233/UnAV-100",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Snaseem2026/devops-predictive-logs",
        "author": "Snaseem2026",
        "created_at": "2026-01-10 22:56:28+00:00",
        "last_modified": "2026-01-10 23:06:09+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:time-series-forecasting",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "doi:10.57967/hf/7504",
          "region:us",
          "devops",
          "logs",
          "incident-prediction",
          "sre",
          "monitoring"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ”® DevOps Predictive Logs Dataset\n\t\n\nA synthetic dataset of realistic DevOps log sequences for training and benchmarking predictive failure models.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Summary\n\t\n\nThis dataset contains realistic DevOps log scenarios covering common infrastructure failure patterns. Each log entry includes metadata about the failure scenario, severity, and time-to-failure, making it ideal for training predictive models.\nTotal Logs: ~150+ entriesScenarios: 10 unique failure patternsFormat:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Snaseem2026/devops-predictive-logs.",
        "url": "https://huggingface.co/datasets/Snaseem2026/devops-predictive-logs",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "time-series-forecasting"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:13:33+00:00",
        "last_modified": "2026-01-06 07:14:03+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç›˜å­ä¸Šæ‹¿èµ·é’æ¤’\ntotal_episodes: 195\ntotal_tasks: 1\nsize: 107.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_green_pepper_from_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_in_plate_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:56:41+00:00",
        "last_modified": "2026-01-05 14:57:51+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_block_in_plate_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç§¯æœ¨æ”¾å…¥ç›˜å­part_1\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 283.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_in_plate_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_in_plate_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_close_cabinet_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:20:05+00:00",
        "last_modified": "2026-01-06 00:20:44+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_close_cabinet_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­æ©±æŸœæŠ½å±‰\ntotal_episodes: 71\ntotal_tasks: 1\nsize: 534.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_close_cabinet_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_close_cabinet_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ahmedamen/empathetic-dialogues-contexts",
        "author": "ahmedamen",
        "created_at": "2026-01-10 16:22:01+00:00",
        "last_modified": "2026-01-10 16:22:01+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "annotations_creators:crowdsourced",
          "multilinguality:monolingual",
          "language:en",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a dataset of emotional contexts that was retrieved from the original EmpatheticDialogues (ED) dataset. Respondents were asked to describe an event that was associated with a particular emotion label (i.e. p(event|emotion). \nThere are 32 emotion labels in total.\nThere are 19209, 2756, and 2542 instances of emotional descriptions in the train, valid, and test set, respectively.\n",
        "url": "https://huggingface.co/datasets/ahmedamen/empathetic-dialogues-contexts",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_apples_placed_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:31:37+00:00",
        "last_modified": "2026-01-05 23:31:58+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_apples_placed_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœæ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 195\ntotal_tasks: 1\nsize: 358.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_apples_placed_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_apples_placed_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_yellow_square_placed_on_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:59:19+00:00",
        "last_modified": "2026-01-05 23:59:26+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_yellow_square_placed_on_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é»„è‰²æ–¹å—æ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 6\ntotal_tasks: 1\nsize: 14.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_yellow_square_placed_on_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_yellow_square_placed_on_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Agda-Cubical",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:43:08+00:00",
        "last_modified": "2026-01-10 15:13:46+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "agda",
          "dependent-types"
        ],
        "description": "\n\t\n\t\t\n\t\tAgda-Cubical\n\t\n\nStructured dataset from agda/cubical â€” Cubical Agda library for HoTT and univalent mathematics.\n3,028 declarations extracted from Agda source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/agda/cubical\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Agda-Cubical.",
        "url": "https://huggingface.co/datasets/phanerozoic/Agda-Cubical",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "pebblebed/kernel-vuln-dataset",
        "author": "pebblebed",
        "created_at": "2026-01-08 01:21:03+00:00",
        "last_modified": "2026-01-08 01:29:07+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "linux-kernel",
          "security",
          "vulnerabilities",
          "code",
          "bugs",
          "software-engineering"
        ],
        "description": "\n\t\n\t\t\n\t\tLinux Kernel Vulnerability Dataset\n\t\n\n125,183 bug-introducing commits mined from 20 years of Linux kernel git history (2005-2025).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset maps every kernel bug fix with a Fixes: tag back to the commit that introduced the bug. It enables research on:\n\nVulnerability detection: Train models to identify bug-introducing commits\nBug lifetime analysis: Study how long different bug types persist\nSubsystem risk assessment: Identify which kernel subsystemsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pebblebed/kernel-vuln-dataset.",
        "url": "https://huggingface.co/datasets/pebblebed/kernel-vuln-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "NetherlandsForensicInstitute/DNANet_2p5pMixture_PPF6C_2024",
        "author": "NetherlandsForensicInstitute",
        "created_at": "2025-09-22 14:34:47+00:00",
        "last_modified": "2026-01-05 09:17:06+00:00",
        "downloads": 466,
        "likes": 1,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "modality:text",
          "region:us",
          "biology",
          "dna",
          "dna analysis",
          "forensic",
          "genetics"
        ],
        "description": "\n\t\n\t\t\n\t\t2p5p Mixture DNA Research dataset\n\t\n\nThis dataset repository contains RFU signal reading (.hid) files and their corresponding person mixture labels (.txt) used in the DNANet paper and code.\nThe data consist of DNA sample mixtures of 2 to 5 persons, of which the mixtures composition is known,\nallowing for training on actual ground-truth data for DNA annotation tools such as DNANet\nIf you use this dataset in your research please cite it appropriately:\n@ARTICLE{Benschop2019,\n      titleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NetherlandsForensicInstitute/DNANet_2p5pMixture_PPF6C_2024.",
        "url": "https://huggingface.co/datasets/NetherlandsForensicInstitute/DNANet_2p5pMixture_PPF6C_2024",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Everloom/AAWR-DROID",
        "author": "Everloom",
        "created_at": "2025-10-10 01:58:22+00:00",
        "last_modified": "2026-01-05 23:12:08+00:00",
        "downloads": 8287,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "license:mit",
          "size_categories:10B<n<100B",
          "modality:image",
          "arxiv:2512.01188",
          "region:us",
          "active-perception",
          "robotics",
          "RL"
        ],
        "description": "\n\t\n\t\t\n\t\tActive Perception AAWR Dataset in GRASP Lab Mock Kitchen\n\t\n\nPaper | Project page | Code\nHere is our full dataset (13.5GB) in DROID format:\nhttps://huggingface.co/datasets/Everloom/AAWR-DROID/\nIt includes 4 scene as below, each are cleaned with a white list (filter the idle frames)\n\n\n\t\n\t\n\t\n\t\tSample Usage\n\t\n\nTo get started with AAWR, follow these steps for a toy simulated task, as described in the code repository:\n\n\t\n\t\t\n\t\tSetup\n\t\n\n\nInstall Python dependencies: You can refer to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Everloom/AAWR-DROID.",
        "url": "https://huggingface.co/datasets/Everloom/AAWR-DROID",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10B<n<100B"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_egg_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:34:52+00:00",
        "last_modified": "2026-01-05 22:35:09+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_egg_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¸¡è›‹æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 33\ntotal_tasks: 1\nsize: 45.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_egg_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_egg_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "elefantai/p2p-full-data",
        "author": "elefantai",
        "created_at": "2026-01-06 17:54:19+00:00",
        "last_modified": "2026-01-11 16:59:37+00:00",
        "downloads": 3262,
        "likes": 3,
        "tags": [
          "task_categories:image-text-to-text",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "arxiv:2601.04575",
          "region:us",
          "action-policy",
          "world-model",
          "vision-language-action",
          "gaming-agent"
        ],
        "description": "\n\t\n\t\t\n\t\tOpen Pixel2Play (P2P) Full Dataset\n\t\n\nPaper | GitHub | Project Page | Toy Dataset\n\nThe p2p-full-data dataset contains 8300+ hours of high-quality human annotated data, spanning across more than 40 popular 3D video games. All gameplay is recorded at 20 FPS by experienced players. Each frame is annotated with keyboard and mouse actions, and text instructionsare provided when available.\nIf you found the dataset helpful, please consider upvoting the paper so it can reach more people!â€¦ See the full description on the dataset page: https://huggingface.co/datasets/elefantai/p2p-full-data.",
        "url": "https://huggingface.co/datasets/elefantai/p2p-full-data",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-text-to-text"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_right_slide_close_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:14:05+00:00",
        "last_modified": "2026-01-06 00:15:57+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_fr3_dual_right_slide_close_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_fr3\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å³æ‰‹æ»‘åŠ¨å…³é—­æŠ½å±‰\ntotal_episodes: 238\ntotal_tasks: 1\nsize: 3.9G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_right_slide_close_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_right_slide_close_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "kunarmy99/Translation-V.1",
        "author": "kunarmy99",
        "created_at": "2025-12-31 14:04:35+00:00",
        "last_modified": "2025-12-31 14:05:23+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "language:en",
          "license:bigscience-bloom-rail-1.0",
          "size_categories:n<1K",
          "region:us",
          "agent"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/kunarmy99/Translation-V.1",
        "languages": [
          "en"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ProgramerSalar/Rita_Black_white_mix",
        "author": "ProgramerSalar",
        "created_at": "2026-01-07 08:12:50+00:00",
        "last_modified": "2026-01-10 09:23:15+00:00",
        "downloads": 29,
        "likes": 0,
        "tags": [
          "task_categories:text-to-video",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "education",
          "video_dataset",
          "education_video_dataset"
        ],
        "description": "\nmake sure the data are found 10-12 second of video.\n\n\n\t\n\t\t\n\t\tIn this dataset, four types of class are found\n\t\n\n\n\nall_data: all video format are found.\nblack_board: in this section, Teacher are teach in black board.\nblack_board_without_teacher: Teacher are not available only write word/sentence using hand in black paper/board/etc..., But background color are Block.\nwhite_board: in this section, Teacher are teach in white board.\nwhite_board_without_teacher: Teacher are not available only writeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ProgramerSalar/Rita_Black_white_mix.",
        "url": "https://huggingface.co/datasets/ProgramerSalar/Rita_Black_white_mix",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-video"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-interactive-dialogue-states",
        "author": "ariefansclub",
        "created_at": "2026-01-10 05:01:08+00:00",
        "last_modified": "2026-01-10 05:01:53+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "dialogue",
          "interactive",
          "futuristic",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Interactive Dialogue States\n\t\n\nA state-based interactive dialogue dataset for humanoid robots.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-interactive-dialogue-states",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Fizzi789/humanoid-everyday",
        "author": "Fizzi789",
        "created_at": "2026-01-05 07:06:34+00:00",
        "last_modified": "2026-01-05 07:06:46+00:00",
        "downloads": 490,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "modality:video",
          "arxiv:2510.08807",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Everyday\n\t\n\nA Comprehensive Robotic Dataset for Open-World Humanoid Manipulation\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nHumanoid Everyday is a large-scale, diverse humanoid manipulation dataset designed for open-world robotic learning and embodied intelligence.\nIt contains over 260 tasks across 7 major categories, covering dexterous manipulation, humanâ€“humanoid interaction, and locomotion-integrated activities.All data were collected through a human-supervised teleoperation pipeline, recordingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Fizzi789/humanoid-everyday.",
        "url": "https://huggingface.co/datasets/Fizzi789/humanoid-everyday",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "irskhirtladze/georgian-synthetic-ocr",
        "author": "irskhirtladze",
        "created_at": "2026-01-08 19:04:15+00:00",
        "last_modified": "2026-01-10 06:13:09+00:00",
        "downloads": 30,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "language:ka",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "modality:image",
          "region:us",
          "computer-vision",
          "text-recognition",
          "OCR",
          "synthetic",
          "georgian"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/irskhirtladze/georgian-synthetic-ocr",
        "languages": [
          "ka",
          "en"
        ],
        "tasks": [
          "image-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "debaterhub/ipda-judge-adaptation-data",
        "author": "debaterhub",
        "created_at": "2026-01-10 16:37:09+00:00",
        "last_modified": "2026-01-10 16:37:10+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "modality:tabular",
          "modality:text",
          "region:us",
          "debate",
          "orpo",
          "preference-learning",
          "judge-adaptation"
        ],
        "description": "\n\t\n\t\t\n\t\tIPDA Judge Adaptation Training Dataset\n\t\n\nTraining data for judge adaptation in competitive debate. This dataset teaches models to adapt their debate output based on judge characteristics.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\nFile\nDescription\nPairs\n\n\n\t\t\ndepth_iter1_train.json\nDepth adaptation iteration 1 (lay vs expert judges)\n75\n\n\ndepth_iter2_train.json\nDepth adaptation iteration 2 (different topics)\n75\n\n\nbias_train.json\nBias adaptation (ideological, proceduralâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/debaterhub/ipda-judge-adaptation-data.",
        "url": "https://huggingface.co/datasets/debaterhub/ipda-judge-adaptation-data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_green_vegetable_on_the_table_1121",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:21:32+00:00",
        "last_modified": "2026-01-07 07:22:09+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_green_vegetable_on_the_table_1121\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é’èœæ”¾åœ¨æ¡Œå­ä¸Špart_1\ntotal_episodes: 221\ntotal_tasks: 1\nsize: 172.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_green_vegetable_on_the_table_1121.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_green_vegetable_on_the_table_1121",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_786_Tie_the_rope_tightly",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:40:02+00:00",
        "last_modified": "2026-01-05 22:22:19+00:00",
        "downloads": 29,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_786\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ç³»å¥½ç»³å­\ntotal_episodes: 1714\ntotal_tasks: 1\nsize: 83G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_786_Tie_the_rope_tightly.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_786_Tie_the_rope_tightly",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "vipinpalhugging/wordnet",
        "author": "vipinpalhugging",
        "created_at": "2026-01-08 13:02:24+00:00",
        "last_modified": "2026-01-08 13:06:34+00:00",
        "downloads": 33,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tWordNet RDF\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLexical database of semantic relations between words (English WordNet 2024)\nOriginal Source: https://en-word.net/static/english-wordnet-2024.ttl.gz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from WordNet RDF converted to HuggingFace\ndataset format for easy use in machine learning pipelines.\n\nFormat: Originally turtle, converted to HuggingFace Dataset\nSize: 0.21 GB (extracted)\nEntities: ~120K synsets\nTriples: ~2M\nOriginalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vipinpalhugging/wordnet.",
        "url": "https://huggingface.co/datasets/vipinpalhugging/wordnet",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-EarningSurprise",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:56:41+00:00",
        "last_modified": "2026-01-10 04:26:57+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly Earnings Surprise metrics for publicly traded companies, provided by SOV.AI.Each row represents a ticker's earnings report snapshot with probabilities and magnitudes of EPS surprises.\n\nCoverage: ~4,330+ tickers, history back to 2016-12-30\nUpdate cadence: Weekly (data typically lands late Friday 23:00â€“00:00 local time to the provider)\nFields:\nsurprise_probability: Probability of an earnings surprise occurring\neps_surprise: EPS surprise value (actual minusâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-EarningSurprise.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-EarningSurprise",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "iioos/threat-intel-indicators",
        "author": "iioos",
        "created_at": "2026-01-10 01:46:17+00:00",
        "last_modified": "2026-01-10 01:46:41+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tThreat Intelligence Indicators Dataset\n\t\n\nIndicators of compromise labeled by threat level.\n",
        "url": "https://huggingface.co/datasets/iioos/threat-intel-indicators",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": []
      },
      {
        "id": "mpatrick1991/srtm-3-arc-second-global",
        "author": "mpatrick1991",
        "created_at": "2026-01-05 23:52:03+00:00",
        "last_modified": "2026-01-06 00:32:18+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:unconditional-image-generation",
          "task_categories:image-classification",
          "language:en",
          "license:other",
          "size_categories:10K<n<100K",
          "format:webdataset",
          "modality:text",
          "library:datasets",
          "library:webdataset",
          "library:mlcroissant",
          "region:us",
          "physics",
          "terrain"
        ],
        "description": "\n\t\n\t\t\n\t\tSRTM 3 Arc-Second Global\n\t\n\nRaw ASCII heightmaps of the Earth's surface labelled according to latitude and longitude.\n\n\t\n\t\t\n\t\tMission Description\n\t\n\nThe Shuttle Radar Topography Mission (SRTM) was flown aboard the space shuttle Endeavour February 11-22, 2000. The National Aeronautics and Space Administration (NASA) and the National Geospatial-Intelligence Agency (NGA) participated in an international project to acquire radar data which were used to create the first near-global set ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mpatrick1991/srtm-3-arc-second-global.",
        "url": "https://huggingface.co/datasets/mpatrick1991/srtm-3-arc-second-global",
        "languages": [
          "en"
        ],
        "tasks": [
          "unconditional-image-generation",
          "image-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-autonomous-decision-audit-trails",
        "author": "ariefansclub",
        "created_at": "2026-01-12 00:57:33+00:00",
        "last_modified": "2026-01-12 00:58:05+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us",
          "autonomy",
          "decision",
          "safety",
          "humanoid"
        ],
        "description": "\n\t\n\t\t\n\t\tAutonomous Decision Audit Trails\n\t\n\nTraceable decision records for safe humanoid autonomy.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-autonomous-decision-audit-trails",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "ToolGym/short-horizon-eval",
        "author": "ToolGym",
        "created_at": "2026-01-09 18:42:12+00:00",
        "last_modified": "2026-01-09 19:13:48+00:00",
        "downloads": 73,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tshort-horizon-eval\n\t\n\nEvaluation results for short-horizon agent trajectories\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains evaluation results for agent trajectories, including quality assessments and performance metrics.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized by model name, with each model having separate JSONL files for different experimental passes.\nshort-horizon-eval/\nâ”œâ”€â”€ model-1/\nâ”‚   â”œâ”€â”€ pass@1.jsonl\nâ”‚   â”œâ”€â”€ pass@2.jsonl\nâ”‚   â””â”€â”€ pass@3.jsonl\nâ”œâ”€â”€ model-2/\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToolGym/short-horizon-eval.",
        "url": "https://huggingface.co/datasets/ToolGym/short-horizon-eval",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_20_takecorn_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:04:27+00:00",
        "last_modified": "2026-01-05 23:05:22+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_20_takecorn_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿çŽ‰ç±³part_3\ntotal_episodes: 105\ntotal_tasks: 1\nsize: 1.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_20_takecorn_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_20_takecorn_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "broadfield-dev/rStar-Coder-PyStructure",
        "author": "broadfield-dev",
        "created_at": "2026-01-06 22:05:06+00:00",
        "last_modified": "2026-01-06 22:06:17+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "dataset-command-center",
          "etl",
          "generated-dataset"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): en\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/broadfield-dev/rStar-Coder-PyStructure.",
        "url": "https://huggingface.co/datasets/broadfield-dev/rStar-Coder-PyStructure",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "summerhot12138/svhn",
        "author": "summerhot12138",
        "created_at": "2026-01-07 07:15:02+00:00",
        "last_modified": "2026-01-07 07:15:03+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:arrow",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "legal"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset card for SVHN\n\t\n\nThe Street View House Numbers (SVHN) dataset is a real-world image dataset developed and designed for machine learning and object recognition algorithms, and is characterized by low data preprocessing and formatting requirements. Similar to MNIST, SVHN contains images of small cropped numbers, but in terms of labeled data, SVHN is an order of magnitude larger than MNIST, comprising over 600,000 digital images. Unlike MNIST, SVHN deals with a much moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/summerhot12138/svhn.",
        "url": "https://huggingface.co/datasets/summerhot12138/svhn",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1029",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:16:36+00:00",
        "last_modified": "2026-01-07 07:17:06+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1029\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ±æœµæ”¾åœ¨æ¡Œå­ä¸Špart_3\ntotal_episodes: 128\ntotal_tasks: 1\nsize: 107.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1029.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1029",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "LCM-Lab/MemRewardBench",
        "author": "LCM-Lab",
        "created_at": "2026-01-11 13:25:50+00:00",
        "last_modified": "2026-01-11 14:14:48+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "long-context",
          "reward-modeling"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“œ MemRewardBench\n\t\n\n\nThe first benchmark to systematically evaluate Reward Models' ability to assess long-term memory management in LLMs across contexts up to 128K tokens.\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nMemRewardBench is the first dedicated benchmark for evaluating Reward Models (RMs) in their ability to judge long-term memory management processes in Large Language Models. Unlike existing benchmarks that evaluate LLMs directly, MemRewardBench focuses on assessing how well RMs can evaluateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LCM-Lab/MemRewardBench.",
        "url": "https://huggingface.co/datasets/LCM-Lab/MemRewardBench",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_take_bread_and_put_in_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:23:55+00:00",
        "last_modified": "2026-01-05 17:26:51+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_take_bread_and_put_in_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥é¢åŒ…å¹¶æ”¾å…¥ç›˜å­ä¸­\ntotal_episodes: 95\ntotal_tasks: 1\nsize: 477.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_take_bread_and_put_in_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_take_bread_and_put_in_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "upstage-isd-agent/scenarios",
        "author": "upstage-isd-agent",
        "created_at": "2026-01-08 01:26:12+00:00",
        "last_modified": "2026-01-09 13:02:56+00:00",
        "downloads": 1318,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:ko",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "region:us",
          "instructional-design",
          "education",
          "benchmark",
          "ISD",
          "ADDIE"
        ],
        "description": "\n\t\n\t\t\n\t\tISD Agent Benchmark Scenarios\n\t\n\nêµìˆ˜ì„¤ê³„(Instructional Systems Design) AI ì—ì´ì „íŠ¸ í‰ê°€ë¥¼ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ì…‹ìž…ë‹ˆë‹¤.\n\n\t\n\t\t\n\t\të°ì´í„°ì…‹ ê°œìš”\n\t\n\n\n\t\n\t\t\ní•­ëª©\nê°’\n\n\n\t\t\nì´ ì‹œë‚˜ë¦¬ì˜¤\n25,795ê°œ\n\n\nIDLD ê¸°ë°˜ ì •ë ¬ ì‹œë‚˜ë¦¬ì˜¤\n8,842ê°œ\n\n\nì»¨í…ìŠ¤íŠ¸ ë³€í˜• ì‹œë‚˜ë¦¬ì˜¤\n16,953ê°œ\n\n\nì§€ì› ì–¸ì–´\ní•œêµ­ì–´, ì˜ì–´\n\n\n\t\n\n\n\t\n\t\t\n\t\të°ì´í„°ì…‹ êµ¬ì¡°\n\t\n\nscenarios/\nâ”œâ”€â”€ idld_aligned/           # 8,842 ì‹œë‚˜ë¦¬ì˜¤\nâ”‚   â””â”€â”€ scenario_idld_*.json\nâ”œâ”€â”€ context_variant/        # 16,953 ì‹œë‚˜ë¦¬ì˜¤\nâ”‚   â”œâ”€â”€ part1/             # 9,000 íŒŒì¼\nâ”‚   â””â”€â”€ part2/             # 7,953 íŒŒì¼\nâ”œâ”€â”€ source_mapping.json     # ì‹œë‚˜ë¦¬ì˜¤-ì›ë³¸ ë§¤í•‘\nâ””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/upstage-isd-agent/scenarios.",
        "url": "https://huggingface.co/datasets/upstage-isd-agent/scenarios",
        "languages": [
          "ko",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1029",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:20:57+00:00",
        "last_modified": "2026-01-06 07:21:16+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1029\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_4\ntotal_episodes: 167\ntotal_tasks: 1\nsize: 167.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1029.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1029",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "summerhot12138/mnist",
        "author": "summerhot12138",
        "created_at": "2026-01-07 07:06:15+00:00",
        "last_modified": "2026-01-07 07:06:17+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "task_ids:multi-class-image-classification",
          "annotations_creators:expert-generated",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:extended|other-nist",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:image",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for MNIST\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.\nHalf of the image were drawn by Census Bureau employees and the other half by high school studentsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/summerhot12138/mnist.",
        "url": "https://huggingface.co/datasets/summerhot12138/mnist",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "mapooon/S2CFP",
        "author": "mapooon",
        "created_at": "2026-01-06 09:26:52+00:00",
        "last_modified": "2026-01-06 11:56:42+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2601.02359",
          "region:us",
          "diffusion,",
          "sora,",
          "deepfake,",
          "face",
          "video"
        ],
        "description": "\n\t\n\t\t\n\t\t[Sora2 Cameo Forensics Preview (S2CFP) Dataset]\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nS2CFP is a dataset released by the University of Tokyo for academic research and educational purposes.\nThe dataset is intended to support research on face forgery detection.\nOur dataset comprises, for each subject, 40 real clips for reference and 12 real and 12 fake videos for testing.\nMore details are found in our paper: https://arxiv.org/abs/2601.02359\n\n\t\n\t\t\n\t\tAccess\n\t\n\nThis is a gated dataset.\nAccess to theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mapooon/S2CFP.",
        "url": "https://huggingface.co/datasets/mapooon/S2CFP",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "MingfuYAN/KungFu-Fiesta",
        "author": "MingfuYAN",
        "created_at": "2026-01-06 03:38:08+00:00",
        "last_modified": "2026-01-06 03:38:42+00:00",
        "downloads": 487,
        "likes": 0,
        "tags": [
          "task_categories:image-to-video",
          "task_categories:text-to-video",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2601.02107",
          "region:us",
          "video",
          "pose",
          "dwpose",
          "human-motion",
          "kungfu",
          "martial-arts",
          "two-person",
          "video-generation",
          "diffusion-model"
        ],
        "description": "\n\t\n\t\t\n\t\tKungFu-Fiesta (KFF) Dataset\n\t\n\n\n\n\n\n\nThe first martial arts combat video dataset for personalized two-person fighting video generation.This dataset was introduced in the paper MagicFight: Personalized Martial Arts Combat Video Generation (ACM MM 2024).\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nKungFu-Fiesta is a specialized dataset designed for the novel task of Personalized Martial Arts Combat Video Generation. Unlike existing single-person dance video datasets, KFF focuses on two-person interactions inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta.",
        "url": "https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-video",
          "text-to-video"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Atnafu/Afri-MCQA",
        "author": "Atnafu",
        "created_at": "2026-01-08 19:16:01+00:00",
        "last_modified": "2026-01-10 11:36:30+00:00",
        "downloads": 59,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "language:tw",
          "language:am",
          "language:ha",
          "language:ig",
          "language:ln",
          "language:lg",
          "language:om",
          "language:rw",
          "language:ki",
          "language:so",
          "language:ti",
          "language:yo",
          "language:tn",
          "language:ny",
          "language:zu",
          "language:st",
          "license:cc-by-nc-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "multimodal",
          "african-languages",
          "vqa",
          "low-resource languages",
          "multilingual"
        ],
        "description": "\n\t\n\t\t\n\t\tAfri-MCQA: Multimodal Cultural Question Answering for African Languages\n\t\n\n \n\n\t\n\t\t\n\t\tOverview\n\t\n\nAfri-MCQA is the first multilingual cultural question-answering benchmark covering 8k Q&A pairs across 16 African languages from 13 countries. The benchmark offers parallel English-African language Q&A pairs across text and speech modalities, entirely created by native speakers.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nVisual Question Answering (VQA): Multiple-choice and open-ended QA grounded inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Atnafu/Afri-MCQA.",
        "url": "https://huggingface.co/datasets/Atnafu/Afri-MCQA",
        "languages": [
          "en",
          "tw",
          "am",
          "ha",
          "ig",
          "ln",
          "lg",
          "om",
          "rw",
          "ki",
          "so",
          "ti",
          "yo",
          "tn",
          "ny",
          "zu",
          "st"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "almanach/penicillin_plus",
        "author": "almanach",
        "created_at": "2025-04-13 10:57:01+00:00",
        "last_modified": "2026-01-07 20:19:34+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "language:fr",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2510.25771",
          "region:us",
          "benchmarks",
          "contamination"
        ],
        "description": "\n\t\n\t\t\n\t\tPenicillin-Plus dataset\n\t\n\nPaper: https://arxiv.org/abs/2510.25771\n\n\t\n\t\t\n\t\tNote\n\t\n\nThis dataset is a processed combination of existing benchmark datasets. The licensing and data rights belong to the original dataset owners. Please refer to the original datasets for more information.\n",
        "url": "https://huggingface.co/datasets/almanach/penicillin_plus",
        "languages": [
          "en",
          "fr"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "saketh11/ColiFormer-Data",
        "author": "saketh11",
        "created_at": "2025-07-12 02:39:31+00:00",
        "last_modified": "2025-07-12 02:40:50+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "biology",
          "codon-optimization",
          "e-coli",
          "protein-synthesis",
          "bioinformatics",
          "synthetic-biology"
        ],
        "description": "\n\t\n\t\t\n\t\tColiFormer Training and Evaluation Dataset\n\t\n\nThis dataset contains the training and evaluation data used for the ColiFormer model - a specialized codon optimization transformer fine-tuned for Escherichia coli sequences. The model achieves 6.2% better CAI (Codon Adaptation Index) scores compared to the base CodonTransformer model.\n\n\t\n\t\t\n\t\tðŸ”— Related Resources\n\t\n\n\nModel: saketh11/ColiFormer\nBase Model: adibvafa/CodonTransformer\nPaper: CodonTransformer: The Global Codon Optimizationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saketh11/ColiFormer-Data.",
        "url": "https://huggingface.co/datasets/saketh11/ColiFormer-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "nowsika/NOBLE_Engine_3.0-Alignment_Spec-Dataset_Generator",
        "author": "nowsika",
        "created_at": "2026-01-05 01:16:22+00:00",
        "last_modified": "2026-01-05 04:28:40+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "modality:document",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "alignment",
          "safety",
          "dataset",
          "synthetic-data",
          "llm",
          "prompt-engineering",
          "evaluation"
        ],
        "description": "\n\t\n\t\t\n\t\tNOBLE Engine 3.0 â€” Alignment Spec + Dataset Generator\n\t\n\nThis repository contains the NOBLE Engine 3.0 alignment specification (docs) and a small JSONL sample demonstrating the output schema used for dataset generation.\nIf youâ€™re looking for:\n\na reproducible spec for tone + safety + routing behavior,\nan output schema for synthetic conversation datasets,\na compact â€œengine-likeâ€ alignment layer you can study or adapt,\n\nâ€¦this repo is for you.\n\n\t\n\t\t\n\t\n\t\n\t\tWhatâ€™s inside\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tdocs/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nowsika/NOBLE_Engine_3.0-Alignment_Spec-Dataset_Generator.",
        "url": "https://huggingface.co/datasets/nowsika/NOBLE_Engine_3.0-Alignment_Spec-Dataset_Generator",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1031",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:10:47+00:00",
        "last_modified": "2026-01-06 07:11:27+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1031\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­å–å‡ºèŠ±æœµpart_5\ntotal_episodes: 297\ntotal_tasks: 1\nsize: 397.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1031.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1031",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "WithinUsAI/AgentAngel_100k",
        "author": "WithinUsAI",
        "created_at": "2026-01-06 14:52:15+00:00",
        "last_modified": "2026-01-06 14:55:15+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:cc0-1.0",
          "region:us",
          "within-us-ai",
          "agentangel",
          "agentic",
          "software-engineering",
          "code",
          "reasoning",
          "evaluation",
          "swe-bench",
          "swe-agent",
          "tool-calling",
          "mcp",
          "agents-md",
          "security",
          "prompt-injection"
        ],
        "description": "\n\t\n\t\t\n\t\tWithin Us AI â€” AgentAngel_100k (Agentic Coding 2026)\n\t\n\nAgentAngel is a master-scholar, evidence-backed dataset family for training and evaluating agentic coding models that plan, patch, run checks, and iterate with tests-as-truth.\nThis release contains 100,000 examples per split (500,000 JSONL rows total):\n\nQ&A (facts + rights/wrongs)\nInstruct (messages)\nThinking (concise rationales)\nReasoning (constraints + verification checks)\nChat (multi-turn)\n\n\n\t\n\t\t\n\t\n\t\n\t\tEvidence disciplineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/WithinUsAI/AgentAngel_100k.",
        "url": "https://huggingface.co/datasets/WithinUsAI/AgentAngel_100k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:46:02+00:00",
        "last_modified": "2026-01-05 13:49:52+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_open_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€æŠ½å±‰part_1\ntotal_episodes: 92\ntotal_tasks: 1\nsize: 587.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "RinKana/mini-sudoku-4x4-reasoning",
        "author": "RinKana",
        "created_at": "2026-01-09 14:56:27+00:00",
        "last_modified": "2026-01-09 15:10:15+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tMini Sudoku 4x4 Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 4x4 Mini Sudoku puzzles generated using reasoning_gym. \nEach entry includes a puzzle grid and its corresponding solved solution.\n\nQuestion: A 4x4 grid string where _ represents empty cells.\nAnswer: The completed 4x4 grid string.\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe grids are formatted as space-separated values with newlines for rows.\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n1 _ 3 _ _ 4 _ 2 2 _ 4 _ _ 3 _ 1\nAnswer:\n1 2 3 4 3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RinKana/mini-sudoku-4x4-reasoning.",
        "url": "https://huggingface.co/datasets/RinKana/mini-sudoku-4x4-reasoning",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "TinaWild09/epstein-files-nov11-25-house-post-ocr-embeddings",
        "author": "TinaWild09",
        "created_at": "2026-01-08 17:42:53+00:00",
        "last_modified": "2026-01-08 17:42:55+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "embeddings",
          "rag",
          "document-retrieval",
          "epstein-files",
          "house-oversight"
        ],
        "description": "\n\t\n\t\t\n\t\tEpstein Files Document Embeddings\n\t\n\nText embeddings generated from the House Oversight Committee's Epstein document release.\n\n\t\n\t\t\n\t\tSource Dataset\n\t\n\nThis dataset is derived from: tensonaut/EPSTEIN_FILES_20K\nThe source dataset contains OCR'd text from the original House Oversight Committee PDF release.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nsource_file\nstring\nSource document filename\n\n\nchunk_index\nint\nPosition of chunk within document\n\n\ntext\nstring\nOriginalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TinaWild09/epstein-files-nov11-25-house-post-ocr-embeddings.",
        "url": "https://huggingface.co/datasets/TinaWild09/epstein-files-nov11-25-house-post-ocr-embeddings",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-retrieval",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "trungdt-tik55/pokemon-images-caption",
        "author": "trungdt-tik55",
        "created_at": "2026-01-07 06:36:45+00:00",
        "last_modified": "2026-01-07 13:55:34+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tPokemon Images Caption Dataset\n\t\n\nA text-to-image dataset containing images of various Pokemon along with their names and descriptive captions. This dataset is designed for training and evaluating text-to-image generation models, image captioning systems, and other computer vision tasks.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides a curated collection of Pokemon images paired with textual descriptions, making it suitable for:\n\nText-to-image generation models\nImage captioning systemsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/trungdt-tik55/pokemon-images-caption.",
        "url": "https://huggingface.co/datasets/trungdt-tik55/pokemon-images-caption",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_brick_piled_then_press_thrice",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:55:44+00:00",
        "last_modified": "2026-01-05 18:59:06+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_brick_piled_then_press_thrice\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å †æ”¾ç§¯æœ¨ç„¶åŽæŒ‰åŽ‹ä¸‰æ¬¡\ntotal_episodes: 265\ntotal_tasks: 1\nsize: 5.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_brick_piled_then_press_thrice.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_brick_piled_then_press_thrice",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_40_putavocado",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:12:30+00:00",
        "last_modified": "2026-01-05 23:13:45+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_40_putavocado\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç‰›æ²¹æžœpart_2\ntotal_episodes: 199\ntotal_tasks: 1\nsize: 2.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_40_putavocado.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_40_putavocado",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-smart-environment-awareness",
        "author": "ariefansclub",
        "created_at": "2026-01-11 01:42:51+00:00",
        "last_modified": "2026-01-11 01:43:22+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "environment",
          "sensors",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tSmart Environment Awareness\n\t\n\nContext-aware dataset for intelligent environments.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-smart-environment-awareness",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "webxos/webXOS_magnet_dataset",
        "author": "webxos",
        "created_at": "2026-01-05 01:08:31+00:00",
        "last_modified": "2026-01-10 05:39:13+00:00",
        "downloads": 112,
        "likes": 1,
        "tags": [
          "task_categories:tabular-classification",
          "task_categories:tabular-regression",
          "task_categories:time-series-forecasting",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "library:webdataset",
          "region:us",
          "physics",
          "magnetic-fields",
          "simulation",
          "science",
          "electromagnetism",
          "synthetic-data",
          "tabular",
          "webdataset"
        ],
        "description": "\n\n\n\n      ___           ___                         ___            ___           ___     \n     /\\  \\         /\\__\\         _____         /|  |          /\\  \\         /\\__\\    \n    _\\:\\  \\       /:/ _/_       /::\\  \\       |:|  |         /::\\  \\       /:/ _/_   \n   /\\ \\:\\  \\     /:/ /\\__\\     /:/\\:\\  \\      |:|  |        /:/\\:\\  \\     /:/ /\\  \\  \n  _\\:\\ \\:\\  \\   /:/ /:/ _/_   /:/ /::\\__\\   __|:|__|       /:/  \\:\\  \\   /:/ /::\\  \\ \n /\\ \\:\\ \\:\\__\\ /:/_/:/ /\\__\\ /:/_/:/\\:|__| /::::\\__\\_____ /:/__/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/webxos/webXOS_magnet_dataset.",
        "url": "https://huggingface.co/datasets/webxos/webXOS_magnet_dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-classification",
          "tabular-regression",
          "time-series-forecasting"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "mpatrick1991/srtm",
        "author": "mpatrick1991",
        "created_at": "2026-01-05 19:50:08+00:00",
        "last_modified": "2026-01-05 19:54:34+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "region:us",
          "climate"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/mpatrick1991/srtm",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1101",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:11:38+00:00",
        "last_modified": "2026-01-06 07:12:04+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1101\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­å–å‡ºèŠ±æœµpart_6\ntotal_episodes: 148\ntotal_tasks: 1\nsize: 194.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1101.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1101",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1104",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:22:29+00:00",
        "last_modified": "2026-01-07 07:22:42+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1104\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ’æžœæ”¾åœ¨æ¡Œå­ä¸Špart_1\ntotal_episodes: 90\ntotal_tasks: 1\nsize: 77.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1104.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1104",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "longhp1618/multilingual-lima",
        "author": "longhp1618",
        "created_at": "2026-01-08 07:59:41+00:00",
        "last_modified": "2026-01-08 08:18:29+00:00",
        "downloads": 27,
        "likes": 0,
        "tags": [
          "language:en",
          "language:zh",
          "language:it",
          "language:bn",
          "language:ko",
          "language:th",
          "language:vi",
          "language:ar",
          "language:jv",
          "language:sw",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tMultilingual LIMA Dataset\n\t\n\nEach language is stored as a separate Hugging Face config, translated by google/gemini-2.0-flash-001.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds_en = load_dataset(\"longhp1618/multilingual-lima\", \"en\")\nds_zh = load_dataset(\"longhp1618/multilingual-lima\", \"zh\")\n\n",
        "url": "https://huggingface.co/datasets/longhp1618/multilingual-lima",
        "languages": [
          "en",
          "zh",
          "it",
          "bn",
          "ko",
          "th",
          "vi",
          "ar",
          "jv",
          "sw"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "DataMuncher-Labs/Practical-Math",
        "author": "DataMuncher-Labs",
        "created_at": "2026-01-07 22:56:04+00:00",
        "last_modified": "2026-01-08 23:20:08+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "agent",
          "arithmatic",
          "reasoning",
          "LLM",
          "pretrain",
          "math"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Practical Math\n\t\n\n[This dataset aims to provide a practically sized and high quality pretraining corpus to develop arithmatic skills in LLMs]\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a ~50,000,000 Row dataset aiming to provide high level arithmatic reasoining for LLMs.\n\nCurated by: [Roman]\nFunded by [Roman]: [$0 of funding used]\nShared by [Roman]: [Made by Roman]\nLanguage(s) (NLP): [Syntheic template english]\nLicense: [Creative Commons by Shareâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataMuncher-Labs/Practical-Math.",
        "url": "https://huggingface.co/datasets/DataMuncher-Labs/Practical-Math",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_2_241211",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:01:50+00:00",
        "last_modified": "2026-01-05 18:02:35+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_clean_table_2_241211\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ¸…æ´é¤æ¡Œpart_1\ntotal_episodes: 38\ntotal_tasks: 1\nsize: 1.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_2_241211.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_2_241211",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_battery_insertion_with_pullout",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:53:29+00:00",
        "last_modified": "2026-01-05 18:55:30+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_battery_insertion_with_pullout\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ’å…¥ç”µæ± å¹¶æ‹”å‡º\ntotal_episodes: 379\ntotal_tasks: 1\nsize: 4.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_battery_insertion_with_pullout.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_battery_insertion_with_pullout",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_779_Cover_with_a_stamp",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:32:23+00:00",
        "last_modified": "2026-01-05 20:53:27+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_779\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ç›–ä¸Šé‚®ç¥¨\ntotal_episodes: 1001\ntotal_tasks: 1\nsize: 17G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_779_Cover_with_a_stamp.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_779_Cover_with_a_stamp",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "zencilover/alpaca",
        "author": "zencilover",
        "created_at": "2026-01-09 15:52:45+00:00",
        "last_modified": "2026-01-09 15:52:47+00:00",
        "downloads": 18,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "instruction-finetuning"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Alpaca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAlpaca is a dataset of 52,000 instructions and demonstrations generated by OpenAI's text-davinci-003 engine. This instruction data can be used to conduct instruction-tuning for language models and make the language model follow instruction better.\nThe authors built on the data generation pipeline from Self-Instruct framework and made the following modifications:\n\nThe text-davinci-003 engine to generate the instruction data insteadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zencilover/alpaca.",
        "url": "https://huggingface.co/datasets/zencilover/alpaca",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "taigatakano/transit-en-ja-5M",
        "author": "taigatakano",
        "created_at": "2026-01-07 11:07:36+00:00",
        "last_modified": "2026-01-07 11:43:46+00:00",
        "downloads": 24,
        "likes": 1,
        "tags": [
          "task_categories:translation",
          "language:en",
          "language:ja",
          "license:odc-by",
          "size_categories:1M<n<10M",
          "modality:text",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ›¬ Transit-EnJa-5M ðŸ›«\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nTransit-EnJa-5M is an Englishâ€“Japanese translation dataset built from a subset of the C4 corpus. English source texts are filtered to be 64 tokens or fewer, then translated into Japanese using multiple large language models (LLMs).\nThis dataset is intended for training and evaluating machine translation systems (and related bilingual modeling tasks) under short-input constraints.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Composition\n\t\n\nThe release includes theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/taigatakano/transit-en-ja-5M.",
        "url": "https://huggingface.co/datasets/taigatakano/transit-en-ja-5M",
        "languages": [
          "en",
          "ja"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "KavyaJain121/PRELUDE",
        "author": "KavyaJain121",
        "created_at": "2026-01-11 11:36:33+00:00",
        "last_modified": "2026-01-11 11:36:34+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:text-classification",
          "language:zh",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2508.09848",
          "region:us",
          "question-answering",
          "long content reasoning",
          "narrative reasoning",
          "bilingual"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for PRELUDE\n\t\n\n\n\t\n\t\t\n\t\tDataset Card Authors\n\t\n\nMo Yu*, Tsz Ting Chung*, Chulun Zhou*, Tong Li*, Rui Lu*, Jiangnan Li*, Liyan Xu*, Haoshu Lu, Ning Zhang, Jing Li, Jie Zhou\n",
        "url": "https://huggingface.co/datasets/KavyaJain121/PRELUDE",
        "languages": [
          "zh",
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Jr23xd23/gpu-database",
        "author": "Jr23xd23",
        "created_at": "2026-01-07 14:00:46+00:00",
        "last_modified": "2026-01-07 14:01:28+00:00",
        "downloads": 13,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "modality:tabular",
          "modality:text",
          "region:us",
          "gpu",
          "nvidia",
          "amd",
          "intel",
          "cuda",
          "hardware",
          "specifications",
          "machine-learning"
        ],
        "description": "\n\t\n\t\t\n\t\tGPU Database\n\t\n\nComprehensive GPU specifications database with architecture, manufacturing, API support, performance details, and kernel development specs.\n2,824 GPUs across NVIDIA, AMD, and Intel\nPart of RightNow â€” AI-powered code editor for GPU kernel development\n\n\t\n\t\t\n\t\tData\n\t\n\n\n\t\n\t\t\nVendor\nGPUs\nFile\n\n\n\t\t\nNVIDIA\n1,286\ndata/nvidia/all.json\n\n\nAMD\n1,292\ndata/amd/all.json\n\n\nIntel\n180\ndata/intel/all.json\n\n\nAll\n2,824\ndata/all-gpus.json\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\nEach GPU contains up to 55â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jr23xd23/gpu-database.",
        "url": "https://huggingface.co/datasets/Jr23xd23/gpu-database",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_steamed_buns_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:48:54+00:00",
        "last_modified": "2026-01-05 23:49:13+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_put_the_steamed_buns_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¦’å¤´æ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 184\ntotal_tasks: 1\nsize: 327.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_steamed_buns_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_steamed_buns_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "yfyeung/FCaps",
        "author": "yfyeung",
        "created_at": "2026-01-09 09:59:59+00:00",
        "last_modified": "2026-01-10 05:05:44+00:00",
        "downloads": 50,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.03065",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tFCaps\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nTODO\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nSplit\nNumber of Speech Clips\nNumber of Captions\nDuration (hours)\n\n\n\t\t\nFCaps-Emilia\n18,131,371\n18,131,371\n46,787\n\n\nFCaps-PSCBase (train_base)\n114,684\n1,071,519\n267\n\n\ndev\n11,772\n23,544\n-\n\n\ntest\n241\n482\n-\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Fields\n\t\n\nThe dataset follows the Lhotse MonoCut schema. Each item contains the following fields:\n\nid (string): Unique identifier for the audio cut.\n\nstart (float): The start time ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yfyeung/FCaps.",
        "url": "https://huggingface.co/datasets/yfyeung/FCaps",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_rotate_green_pot_handle",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:50:05+00:00",
        "last_modified": "2026-01-05 18:51:18+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_rotate_green_pot_handle\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ—‹è½¬ç»¿é”…æ‰‹æŸ„\ntotal_episodes: 150\ntotal_tasks: 1\nsize: 1.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_rotate_green_pot_handle.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_rotate_green_pot_handle",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_upright_white_cup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:52:09+00:00",
        "last_modified": "2026-01-05 18:53:23+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_upright_white_cup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›´ç«‹ç™½è‰²æ¯å­\ntotal_episodes: 213\ntotal_tasks: 1\nsize: 1.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_upright_white_cup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_upright_white_cup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_table_1101",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:05:51+00:00",
        "last_modified": "2026-01-07 07:06:18+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_table_1101\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„è¾£æ¤’part_1\ntotal_episodes: 82\ntotal_tasks: 1\nsize: 95.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_table_1101.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_table_1101",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1101",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:53:50+00:00",
        "last_modified": "2026-01-07 06:54:19+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1101\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­æ‹¿èµ·èŠ±æœµpart_6\ntotal_episodes: 148\ntotal_tasks: 1\nsize: 203.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1101.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1101",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "masharma/convolearn",
        "author": "masharma",
        "created_at": "2026-01-07 23:36:25+00:00",
        "last_modified": "2026-01-07 23:52:10+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "education",
          "tutoring",
          "dialogue",
          "conversational",
          "pedagogical",
          "constructivist-learning"
        ],
        "description": "\n\t\n\t\t\n\t\tConvoLearn\n\t\n\nA dataset of tutor-student conversations demonstrating knowledge-building (constructivist) pedagogies.\n\n\t\n\t\t\n\t\tWhat's in here\n\t\n\n1,250 dialogues between teachers and a simulated 7th-grade student discussing middle school Earth Science. Each conversation demonstrates one of six knowledge-building dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, or power dynamics.\nThe teachers were real educators recruitedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/masharma/convolearn.",
        "url": "https://huggingface.co/datasets/masharma/convolearn",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_table_1125",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:18:25+00:00",
        "last_modified": "2026-01-06 07:18:44+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_table_1125\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_1\ntotal_episodes: 202\ntotal_tasks: 1\nsize: 179.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_table_1125.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_cucumber_from_the_table_1125",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-HierarchyBuilder",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:50:15+00:00",
        "last_modified": "2026-01-10 15:12:52+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-HierarchyBuilder\n\t\n\nStructured dataset from Hierarchy Builder â€” High-level commands for packed class hierarchies.\n752 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/math-comp/hierarchy-builder\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-HierarchyBuilder.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-HierarchyBuilder",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "OpenMOSS-Team/GameQA-text",
        "author": "OpenMOSS-Team",
        "created_at": "2025-07-20 00:57:16+00:00",
        "last_modified": "2025-07-22 14:17:57+00:00",
        "downloads": 19,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "arxiv:2505.13886",
          "region:us"
        ],
        "description": "Here we provide a pure-text version of GameQA, encompassing some appropriate games. (See https://github.com/tongjingqi/Code2Logic/issues/2)\n\n\t\n\t\t\n\t\tCode2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning\n\t\n\nThis is the first work, to the best of our knowledge, that leverages game code to synthesize multimodal reasoning data for training VLMs. Furthermore, when trained with a GRPO strategy solely on GameQA (synthesized via our proposed Code2Logic approach), multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenMOSS-Team/GameQA-text.",
        "url": "https://huggingface.co/datasets/OpenMOSS-Team/GameQA-text",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "phanerozoic/Coq-InteractionTrees",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:45:39+00:00",
        "last_modified": "2026-01-10 15:12:09+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-InteractionTrees\n\t\n\nStructured dataset from Interaction Trees â€” Representing recursive and impure programs.\n2,936 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/DeepSpec/InteractionTrees\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-InteractionTrees.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-InteractionTrees",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Tatsuya-Ichinose/CoDIT-Gemma3",
        "author": "Tatsuya-Ichinose",
        "created_at": "2026-01-11 11:18:59+00:00",
        "last_modified": "2026-01-11 14:08:59+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:lmsys-chat-1m",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\nDataset Name\nðŸ¤– Teacher Model\nðŸ“‚ Dataset Link\n\n\n\t\t\nCoDIT-Gemma3 ðŸ’Ž\ngoogle/gemma-3-27b-it\nCoDIT-Gemma3 â†—\n\n\nCoDIT-Qwen3-8B ðŸ‰\nQwen/Qwen3-8B\nCoDIT-Qwen3-8B â†—\n\n\nCoDIT-Qwen3-30B ðŸš€\nQwen/Qwen3-30B-A3B\nCoDIT-Qwen3-30B â†—\n\n\n\t\n\n\n\t\t\n\t\tCoDIT-Gemma3\n\t\n\nCoDIT-Gemma3 is a synthetic conversation dataset derived from LMSYS-Chat-1M [Zhang+, ICLR24].\n\n250,333 user instructions sourced from LMSYS-Chat-1M\n250,333 assistant responses automatically synthesized using CoDIT with google/gemma-3-27b-it, generatingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tatsuya-Ichinose/CoDIT-Gemma3.",
        "url": "https://huggingface.co/datasets/Tatsuya-Ichinose/CoDIT-Gemma3",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "smolify/smolified-45bc0538",
        "author": "smolify",
        "created_at": "2026-01-06 04:39:06+00:00",
        "last_modified": "2026-01-06 04:39:15+00:00",
        "downloads": 14,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-45bc0538\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry.\nIt was used to train the corresponding model smolified-45bc0538.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: 45bc0538)\nRecords: 10001\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by the client.\nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/smolify/smolified-45bc0538",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_6_applebowloven_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:25:33+00:00",
        "last_modified": "2026-01-05 23:26:02+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_6_applebowloven_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœç¢—çƒ¤ç®±part_3\ntotal_episodes: 51\ntotal_tasks: 1\nsize: 742.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_6_applebowloven_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_6_applebowloven_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "koukeft/visqam",
        "author": "koukeft",
        "created_at": "2026-01-05 08:34:59+00:00",
        "last_modified": "2026-01-05 13:04:04+00:00",
        "downloads": 197,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-classification",
          "task_categories:object-detection",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "modality:geospatial",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:1902.09506",
          "region:us",
          "geographic-maps",
          "question-answering",
          "legend-detection",
          "geospatial",
          "chart-understanding",
          "gis"
        ],
        "description": "\n\t\n\t\t\n\t\tVISQAM (Visual Question-Answering for Thematic Maps)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nVISQAM (Visual Question-Answering for Thematic Maps) is a dataset of 400 geographic thematic maps annotated for visual question-answering (VQA) and legend detection tasks. Each map includes 3-5 question-answering (QA) pairs of geographic nature and bounding box annotations for map legends. The dataset combines maps from multiple sources covering land use, climate variables, choropleth maps, and diverseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/koukeft/visqam.",
        "url": "https://huggingface.co/datasets/koukeft/visqam",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-classification",
          "object-detection"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:46:17+00:00",
        "last_modified": "2026-01-05 22:46:33+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_round_bread_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åœ†é¢åŒ…æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 65\ntotal_tasks: 1\nsize: 49.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "UnipatAI/BabyVision-Gen",
        "author": "UnipatAI",
        "created_at": "2026-01-10 16:56:59+00:00",
        "last_modified": "2026-01-10 17:42:28+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:image-to-image",
          "task_categories:visual-question-answering",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "vision",
          "benchmark",
          "multimodal",
          "visual-reasoning",
          "image-generation"
        ],
        "description": "\n\t\n\t\t\n\t\tBabyVision-Gen Benchmark Dataset\n\t\n\n    \nState-of-the-art MLLMs achieve PhD-level language reasoning but struggle with visual tasks that 3-year-olds solve effortlessly. We introduce BabyVision, a benchmark revealing the infancy of AI vision. Read the blog first for better overall impression.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains 280 visual generation tasks where models must understand an input image and generate an annotated output image (e.g., circling specificâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UnipatAI/BabyVision-Gen.",
        "url": "https://huggingface.co/datasets/UnipatAI/BabyVision-Gen",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-image",
          "visual-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "h4sch/AI-Jailbreak-Prompts",
        "author": "h4sch",
        "created_at": "2026-01-09 00:02:57+00:00",
        "last_modified": "2026-01-09 05:01:37+00:00",
        "downloads": 30,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_categories:zero-shot-classification",
          "task_categories:table-question-answering",
          "language:en",
          "language:de",
          "size_categories:n<1K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "ChatGPT",
          "JailbreakPrompts",
          "LanguageModeling",
          "ArtificialIntelligence",
          "TextGeneration",
          "Dataset",
          "OpenAI",
          "Jailbreak",
          "Prompts"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tName\n\t\n\nJailbreak Prompts\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJailbreak Prompts is a complete collection of jailbreak related prompts for ChatGPT. This dataset is intended to provide a valuable resource for understanding and generating text in the context of jailbreaking in ChatGPT.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[German]\n",
        "url": "https://huggingface.co/datasets/h4sch/AI-Jailbreak-Prompts",
        "languages": [
          "en",
          "de"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "fill-mask",
          "zero-shot-classification",
          "table-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "elliotvincent/b-FLAIR-spot",
        "author": "elliotvincent",
        "created_at": "2025-11-25 17:25:45+00:00",
        "last_modified": "2025-11-26 10:10:51+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:image-segmentation",
          "language:en",
          "license:etalab-2.0",
          "size_categories:10K<n<100K",
          "modality:geospatial",
          "region:us",
          "remote-sensing",
          "earth-observation",
          "change-detection",
          "weak-temporal-supervision"
        ],
        "description": "\n\t\n\t\t\n\t\tb-FLAIR-spot: bi-temporal extension of FLAIR in SPOT-6/7 modality\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nb-FLAIR-spot is a temporal extension of the FLAIR dataset [1], mirroring b-FLAIR in SPOT-6/7 modality, focused on land cover classification in France. The dataset provides bi-temporal satellite image pairs with single-temporal semantic annotations.\nProject page: https://xavibou.github.io/CDviaWTS/\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nTask: Semantic change detection via weak temporalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elliotvincent/b-FLAIR-spot.",
        "url": "https://huggingface.co/datasets/elliotvincent/b-FLAIR-spot",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-segmentation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_trash",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:35:57+00:00",
        "last_modified": "2026-01-05 17:40:50+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_trash\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®åžƒåœ¾æ¡¶\ntotal_episodes: 98\ntotal_tasks: 1\nsize: 397.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_trash.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_trash",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "SINAPSA-IC/sinapsaic_ds_autobiography_pierre_abelard",
        "author": "SINAPSA-IC",
        "created_at": "2026-01-11 22:50:19+00:00",
        "last_modified": "2026-01-11 23:43:47+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "region:us",
          "dataset,fine-tuning,autobiography,biography,SINAPSA"
        ],
        "description": "Dataset created from the online version of the autobiography of Pierre Abelard (1079-1142)\n\nhttps://en.wikipedia.org/wiki/Peter_Abelard\n\"Historia Calamitatum\", https://www.gutenberg.org/ebooks/14268\n\nSynthetic dataset created and curated with/in:\n\nLM Studio (https://lmstudio.ai/)\nLLM: Gemma3 12B Q6_K, by mradermacher (gemma-3-12b-it.i1-Q6_K.gguf)\nMicrosoft Visual Studio 2026 Community (https://visualstudio.microsoft.com/)\n\n876 examples\n\nJSON\nstructure following this pattern, with each exampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SINAPSA-IC/sinapsaic_ds_autobiography_pierre_abelard.",
        "url": "https://huggingface.co/datasets/SINAPSA-IC/sinapsaic_ds_autobiography_pierre_abelard",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:02:00+00:00",
        "last_modified": "2026-01-05 22:02:13+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_bread_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¤æ¡Œä¸Šçš„é¢åŒ…part_2\ntotal_episodes: 69\ntotal_tasks: 1\nsize: 88.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "masculine/short-horizon",
        "author": "masculine",
        "created_at": "2026-01-09 04:36:53+00:00",
        "last_modified": "2026-01-09 05:34:33+00:00",
        "downloads": 71,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "agent",
          "tool-use",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tToolGym Short-Horizon Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains short-horizon trajectories and evaluations for the ToolGym benchmark.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nshort-horizon/\nâ”œâ”€â”€ traj/          # Agent trajectories (JSONL format)\nâ”‚   â”œâ”€â”€ claude-3.5/\nâ”‚   â”‚   â”œâ”€â”€ pass@1.jsonl\nâ”‚   â”‚   â”œâ”€â”€ pass@2.jsonl\nâ”‚   â”‚   â””â”€â”€ pass@3.jsonl\nâ”‚   â”œâ”€â”€ deepseek-v3.2/\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ eval/          # Evaluation results (JSONL format)\n    â”œâ”€â”€ claude-3.5/\n    â”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/masculine/short-horizon.",
        "url": "https://huggingface.co/datasets/masculine/short-horizon",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "gfbati/HDL",
        "author": "gfbati",
        "created_at": "2026-01-11 10:32:04+00:00",
        "last_modified": "2026-01-11 12:10:14+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "task_categories:image-feature-extraction",
          "task_categories:tabular-classification",
          "task_categories:feature-extraction",
          "language:ar",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "doi:10.57967/hf/7500",
          "region:us"
        ],
        "description": "ðŸ“Œ Dataset Summary\nHDL (Hand-drawn Digital Logic Gates) is the first balanced image and tabular dataset dedicated to the classification of hand-drawn digital logic gates. The dataset is designed primarily for machine learning education, computer vision research, and AI-assisted electronics applications.\nHDL contains 1,200 hand-drawn images covering the 8 fundamental digital logic gates (AND, OR, NOT (INVERTER), BUFFER, NAND, NOR, XOR, and XNOR), with 150 images per class, ensuring perfectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gfbati/HDL.",
        "url": "https://huggingface.co/datasets/gfbati/HDL",
        "languages": [
          "ar",
          "en"
        ],
        "tasks": [
          "image-classification",
          "image-feature-extraction",
          "tabular-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "nyuuzyou/jihulab-code",
        "author": "nyuuzyou",
        "created_at": "2026-01-09 04:26:59+00:00",
        "last_modified": "2026-01-09 04:27:50+00:00",
        "downloads": 77,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:found",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:zh",
          "language:en",
          "license:other",
          "size_categories:1M<n<10M",
          "modality:text",
          "region:us",
          "code",
          "chinese"
        ],
        "description": "\n\t\n\t\t\n\t\tJihuLab Code Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from code repositories hosted on JihuLab, a GitLab-based code hosting platform operated by JiHu (GitLab's Chinese joint venture). JihuLab serves as the primary GitLab instance for Chinese developers and enterprises, offering localized services and compliance with Chinese regulations. This dataset is particularly valuable for training code models with Chinese language understanding and enterprise-levelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/jihulab-code.",
        "url": "https://huggingface.co/datasets/nyuuzyou/jihulab-code",
        "languages": [
          "code",
          "zh",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "nbroad/apigen-with-thinking-1.5k",
        "author": "nbroad",
        "created_at": "2026-01-06 23:12:59+00:00",
        "last_modified": "2026-01-09 22:35:49+00:00",
        "downloads": 27,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "I added thinking traces to 1.5k samples from Salesforce/APIGen-MT-5k using gpt-oss-120b with high reasoning effort.\nTo prevent HF from modifying the fields, I stored each sample as a json string.\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nbroad/apigen-with-thinking-1.5k\")['train']\n\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-14B\")\n\n\nimport json\n\n\ndef tokenize(sample):\n    full_ids = tokenizer.apply_chat_template(â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nbroad/apigen-with-thinking-1.5k.",
        "url": "https://huggingface.co/datasets/nbroad/apigen-with-thinking-1.5k",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1112",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:32:42+00:00",
        "last_modified": "2026-01-07 07:33:21+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1112\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_5\ntotal_episodes: 293\ntotal_tasks: 1\nsize: 412.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1112.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1112",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "KYZKY/ethics",
        "author": "KYZKY",
        "created_at": "2026-01-08 02:59:47+00:00",
        "last_modified": "2026-01-08 02:59:49+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "arxiv:2008.02275",
          "region:us",
          "AI Alignment"
        ],
        "description": "A benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality.",
        "url": "https://huggingface.co/datasets/KYZKY/ethics",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_rectangular_prism",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:17:04+00:00",
        "last_modified": "2026-01-05 17:19:13+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_rectangular_prism\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥é•¿æ–¹ä½“\ntotal_episodes: 96\ntotal_tasks: 1\nsize: 273.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_rectangular_prism.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_rectangular_prism",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:47:11+00:00",
        "last_modified": "2026-01-05 22:47:21+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_round_bread_in_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åœ†é¢åŒ…æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 59\ntotal_tasks: 1\nsize: 36.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BITnene465/MSR-VTT",
        "author": "BITnene465",
        "created_at": "2026-01-08 14:23:23+00:00",
        "last_modified": "2026-01-08 14:23:25+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:text-to-video",
          "task_categories:text-retrieval",
          "task_categories:video-classification",
          "language:en",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "MSRVTT contains 10K video clips and 200K captions.\nWe adopt the standard 1K-A split protocol, which was introduced in JSFusion and has since become the de facto benchmark split in the Text-Video Retrieval field.\nTrain:  \n\ntrain_7k: 7,010 videos, 140,200 captions  \ntrain_9k: 9,000 videos, 180,000 captions\n\nTest:  \n\ntest_1k: 1,000 videos, 1,000 captions\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŒŸ Citation\n\t\n\n@inproceedings{xu2016msrvtt,\n  title={Msr-vtt: A large video description dataset for bridging video and language}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BITnene465/MSR-VTT.",
        "url": "https://huggingface.co/datasets/BITnene465/MSR-VTT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-video",
          "text-retrieval",
          "video-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_donut_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:32:35+00:00",
        "last_modified": "2026-01-05 22:32:50+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_donut_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç”œç”œåœˆæ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 39\ntotal_tasks: 1\nsize: 30.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_donut_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_donut_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "cometadata/crossref-arxiv-citations",
        "author": "cometadata",
        "created_at": "2026-01-05 03:34:05+00:00",
        "last_modified": "2026-01-09 16:00:49+00:00",
        "downloads": 44,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:1412.6980",
          "region:us",
          "arxiv",
          "crossref",
          "citations",
          "preprints",
          "scholarly-communications",
          "bibliometrics",
          "doi"
        ],
        "description": "\n\t\n\t\t\n\t\tCrossref arXiv Citations\n\t\n\nA dataset of arXiv preprints and their citations extracted from Crossref metadata, validated against DataCite records and DOI resolution.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset maps arXiv works to the works in Crossref that cite them. Each record represents an arXiv preprint with all known citations from Crossref-registered works.\n\n\t\n\t\t\n\t\tDataset Configurations\n\t\n\n\n\t\n\t\t\nConfig\nDescription\narXiv Works\nCitations\n\n\n\t\t\nall\nAll validated citations (default)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/cometadata/crossref-arxiv-citations.",
        "url": "https://huggingface.co/datasets/cometadata/crossref-arxiv-citations",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "FSAI12345/blbooksgenre",
        "author": "FSAI12345",
        "created_at": "2026-01-05 21:50:13+00:00",
        "last_modified": "2026-01-05 21:50:15+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_ids:topic-classification",
          "task_ids:multi-label-classification",
          "task_ids:language-modeling",
          "task_ids:masked-language-modeling",
          "annotations_creators:expert-generated",
          "language_creators:crowdsourced",
          "language_creators:expert-generated",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:de",
          "language:en",
          "language:fr",
          "language:nl",
          "license:cc0-1.0",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "This dataset contains metadata for resources belonging to the British Libraryâ€™s digitised printed books (18th-19th century) collection (bl.uk/collection-guides/digitised-printed-books).\nThis metadata has been extracted from British Library catalogue records.\nThe metadata held within our main catalogue is updated regularly.\nThis metadata dataset should be considered a snapshot of this metadata.",
        "url": "https://huggingface.co/datasets/FSAI12345/blbooksgenre",
        "languages": [
          "de",
          "en",
          "fr",
          "nl"
        ],
        "tasks": [
          "text-classification",
          "text-generation",
          "fill-mask"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_52_holdercup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:07:36+00:00",
        "last_modified": "2026-01-05 10:08:30+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_52_holdercup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¯æž¶æ¯\ntotal_episodes: 33\ntotal_tasks: 1\nsize: 426.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_52_holdercup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_52_holdercup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_table_1128",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:32:18+00:00",
        "last_modified": "2026-01-05 18:32:56+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_bread_table_1128\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é¢åŒ…é¤æ¡Œpart_1\ntotal_episodes: 103\ntotal_tasks: 1\nsize: 985.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_table_1128.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_table_1128",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "sitammeur/smolified-nano-banana-pro-prompt-optimizer",
        "author": "sitammeur",
        "created_at": "2026-01-11 08:18:22+00:00",
        "last_modified": "2026-01-11 08:18:34+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-nano-banana-pro-prompt-optimizer\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry.\nIt was used to train the corresponding model sitammeur/smolified-nano-banana-pro-prompt-optimizer.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: 05a0817e)\nRecords: 10417\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by sitammeur.\nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/sitammeur/smolified-nano-banana-pro-prompt-optimizer",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "NetraVerse/indian-govt-scholarships",
        "author": "NetraVerse",
        "created_at": "2026-01-11 13:37:56+00:00",
        "last_modified": "2026-01-11 13:45:06+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:document",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "government",
          "india",
          "scholarships",
          "education"
        ],
        "description": "\n\t\n\t\t\n\t\tIndian Government Scholarships Dataset\n\t\n\nThis dataset is a collection of official sample PDF documents pertaining to various scholarship schemes offered by the Government of India. It is designed for use in Natural Language Processing (NLP), Document Classification, and Retrieval-Augmented Generation (RAG) tasks.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset consists sample of PDF files sourced from various government portals (like AICTE, National Scholarship Portal, etc.). Each document isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NetraVerse/indian-govt-scholarships.",
        "url": "https://huggingface.co/datasets/NetraVerse/indian-govt-scholarships",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "token-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_foil_plate_place_in_dustbin",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 01:08:07+00:00",
        "last_modified": "2026-01-06 01:22:27+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_foil_plate_place_in_dustbin\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_prod1_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é”¡çº¸ç›˜æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 771\ntotal_tasks: 1\nsize: 9.9G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_foil_plate_place_in_dustbin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_foil_plate_place_in_dustbin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Frederick-Ryan/IDMGSP",
        "author": "Frederick-Ryan",
        "created_at": "2026-01-08 12:37:50+00:00",
        "last_modified": "2026-01-08 12:37:50+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:openrail++",
          "size_categories:10K<n<100K",
          "region:us",
          "scientific paper",
          "fake papers",
          "science",
          "scientific text"
        ],
        "description": "TODO",
        "url": "https://huggingface.co/datasets/Frederick-Ryan/IDMGSP",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_45_putgreenbowlonblueplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:37:52+00:00",
        "last_modified": "2026-01-05 10:01:19+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_45_putgreenbowlonblueplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç»¿ç¢—æ”¾åœ¨è“ç›˜å­ä¸Š\ntotal_episodes: 181\ntotal_tasks: 1\nsize: 2.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_45_putgreenbowlonblueplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_45_putgreenbowlonblueplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1104",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:04:02+00:00",
        "last_modified": "2026-01-06 10:04:32+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1104\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ’æžœæ”¾å…¥ç¯®å­part_1\ntotal_episodes: 105\ntotal_tasks: 1\nsize: 85.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1104.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1104",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-emotion-response-dataset",
        "author": "ariefansclub",
        "created_at": "2026-01-08 06:47:02+00:00",
        "last_modified": "2026-01-08 06:47:36+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "social",
          "robotics"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Emotion Response Dataset\n\t\n\nEmotion-to-response mapping for socially aware humanoid robots.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-emotion-response-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_egg_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:33:49+00:00",
        "last_modified": "2026-01-05 22:34:03+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_egg_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¸¡è›‹æ”¾å…¥é”…ä¸­\ntotal_episodes: 12\ntotal_tasks: 1\nsize: 18.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_egg_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_egg_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1107",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:30:06+00:00",
        "last_modified": "2026-01-07 07:30:41+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1107\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_3\ntotal_episodes: 267\ntotal_tasks: 1\nsize: 527.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1107.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1107",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "IIGroup/X-Coder-SFT-376k",
        "author": "IIGroup",
        "created_at": "2026-01-05 15:37:35+00:00",
        "last_modified": "2026-01-06 12:17:51+00:00",
        "downloads": 328,
        "likes": 6,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tX-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests\n\t\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nX-Coder-SFT-376k is the largest fully synthetic dataset for advancing competitive programming.\nIt comprises 4 subsets with a total of 887,321 synthetic records across 423,883 unique queries.\nThe query is synthesized by GPT-o3-mini, the solutions are generated by DeepSeek-R1-0528 and Qwen3-235B-A22B-2507-Thinking.\nX-Coder-SFT-376k is designed for supervisedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IIGroup/X-Coder-SFT-376k.",
        "url": "https://huggingface.co/datasets/IIGroup/X-Coder-SFT-376k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_long_bread",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:18:22+00:00",
        "last_modified": "2026-01-05 22:18:48+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_long_bread\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é•¿é¢åŒ…\ntotal_episodes: 130\ntotal_tasks: 1\nsize: 143.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_long_bread.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_long_bread",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Lucas22300/Tele-Data",
        "author": "Lucas22300",
        "created_at": "2026-01-06 08:26:18+00:00",
        "last_modified": "2026-01-06 08:26:19+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "arxiv:2409.05314",
          "region:us",
          "telecom"
        ],
        "description": "\n\t\n\t\t\n\t\tTele-Data\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTele-Data is a comprehensive dataset of telecommunications material that revolves around four categories of sources: (1) scientific papers from arXiv, (2) 3GPP standards, (3) Wikipedia articles related to telecommunications, and (4) telecommunications-related websites extracted from Common Crawl dumps.\nLLM-based filtering was used to identify the relevant material from these sources, which then underwent extensive cleaning, format unificationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lucas22300/Tele-Data.",
        "url": "https://huggingface.co/datasets/Lucas22300/Tele-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "Mayank6255/translated_dolly_spec_decode",
        "author": "Mayank6255",
        "created_at": "2026-01-01 17:29:05+00:00",
        "last_modified": "2026-01-10 17:06:03+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "language:hi",
          "language:de",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "sft",
          "instruction-tuning",
          "multilingual",
          "qwen",
          "llama-factory"
        ],
        "description": "\n\t\n\t\t\n\t\tAya Multilingual SFT Dataset\n\t\n\nThis dataset is derived from the CohereForAI/aya_collection \n(translated_dolly subset) and formatted for supervised fine-tuning (SFT) with LLaMA-Factory.\n\n\t\n\t\t\n\t\tDataset Subsets\n\t\n\n\n\t\n\t\t\nSubset\nLanguages\nTrain\nTest\nDescription\n\n\n\t\t\neng\nENG\nâœ“\nâœ“\nEnglish only subset\n\n\nhin\nHIN\nâœ“\nâœ“\nHindi only subset\n\n\ndeu\nDEU\nâœ“\nâœ“\nGerman only subset\n\n\neng_hin_deu\nENG, HIN, DEU\nâœ“\nâœ“\nCombined English, Hindi, and German subset\n\n\neng_hin_deu_sampled\nENG, HIN, DEU, SAMPLED\nâœ“\nâœ“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mayank6255/translated_dolly_spec_decode.",
        "url": "https://huggingface.co/datasets/Mayank6255/translated_dolly_spec_decode",
        "languages": [
          "en",
          "hi",
          "de"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_chili_peppers_are_placed_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:35:00+00:00",
        "last_modified": "2026-01-05 23:35:29+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_chili_peppers_are_placed_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è¾£æ¤’æ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 142\ntotal_tasks: 1\nsize: 250.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_chili_peppers_are_placed_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_chili_peppers_are_placed_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Snaseem2026/jenkins_errors",
        "author": "Snaseem2026",
        "created_at": "2026-01-10 18:37:14+00:00",
        "last_modified": "2026-01-10 18:51:06+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "doi:10.57967/hf/7498",
          "region:us",
          "jenkins",
          "errors",
          "ci-cd",
          "logs",
          "synthetic-data"
        ],
        "description": "\n\t\n\t\t\n\t\tJenkins Error Outputs Dataset\n\t\n\nA large synthetic dataset of Jenkins error outputs, generated for research, machine learning, and error analysis purposes. This dataset contains 100,000 entries, each simulating a real-world Jenkins error log with metadata.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: JSON Lines (.jsonl)\nFields:\ntimestamp: ISO8601 timestamp of the error\njob_name: Jenkins job name\nbuild_number: Jenkins build number\nerror_message: Jenkins error message\nnode: Jenkins node nameâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Snaseem2026/jenkins_errors.",
        "url": "https://huggingface.co/datasets/Snaseem2026/jenkins_errors",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Vitinf/Home-Assistant-Requests-V2",
        "author": "Vitinf",
        "created_at": "2026-01-11 11:00:32+00:00",
        "last_modified": "2026-01-11 11:00:33+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "language:es",
          "language:fr",
          "language:de",
          "language:pl",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "region:us",
          "automation",
          "home",
          "assistant"
        ],
        "description": "\n\t\n\t\t\n\t\tHome Assistant Requests V2 Dataset\n\t\n\nThis dataset contains a list of requests and responses for a user interacting with a personal assistant that controls an instance of Home Assistant.\nThe updated V2 of the dataset is now multilingual, containing data in English, German, French, Spanish, and Polish. The dataset also contains multiple \"personalities\" for the assistant to respond in, such as a formal assistant, a sarcastic assistant, and a friendly assistant. Lastly, the dataset hasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Vitinf/Home-Assistant-Requests-V2.",
        "url": "https://huggingface.co/datasets/Vitinf/Home-Assistant-Requests-V2",
        "languages": [
          "en",
          "es",
          "fr",
          "de",
          "pl"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "AICoevolution/s64-geometry-v1",
        "author": "AICoevolution",
        "created_at": "2026-01-05 02:55:08+00:00",
        "last_modified": "2026-01-05 04:18:13+00:00",
        "downloads": 66,
        "likes": 0,
        "tags": [
          "task_categories:other",
          "language:en",
          "license:cc-by-4.0",
          "arxiv:2512.13771",
          "region:us",
          "symbolic-ai",
          "human-ai-interaction",
          "embedding-geometry",
          "semantic-space",
          "conversation-dynamics",
          "multi-model"
        ],
        "description": "\n\t\n\t\t\n\t\tS64 Geometry Validation Dataset\n\t\n\n\nPaper 02: The Conversational Coherence Region: Geometry of Symbolic Meaning Across Embedding Models\n\n\nThis dataset accompanies the paper investigating how the S64 symbolic framework organizes semantically across 13 different embedding architectures, and how conversation dynamics reveal structured regions in semantic space.\n\n\n\t\n\t\t\n\t\n\t\n\t\tKey Findings\n\t\n\n\n\t\n\t\t\nFinding\nEvidence\n\n\n\t\t\nArchitecture-Independent Structure\nRole centroids (fromâ†’toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AICoevolution/s64-geometry-v1.",
        "url": "https://huggingface.co/datasets/AICoevolution/s64-geometry-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "other"
        ],
        "size_categories": []
      },
      {
        "id": "anon590/rubric-feedback-bench",
        "author": "anon590",
        "created_at": "2026-01-09 17:05:31+00:00",
        "last_modified": "2026-01-09 17:05:31+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rubric"
        ],
        "description": "\n\t\n\t\t\n\t\tRubric Feedback Bench\n\t\n\nA dataset designed for optimizing LLMs with an LLM evaluator that can provide quantitative scoring and/or qualitative textual feedback across diverse task categories.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nRubric Feedback Bench is a specialized dataset containing prompts paired with detailed, task-specific rubrics for LLM evaluation. Unlike traditional evaluation datasets that focus solely on scoring, this benchmark emphasizes the evaluator's ability to provide detailed textualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/anon590/rubric-feedback-bench.",
        "url": "https://huggingface.co/datasets/anon590/rubric-feedback-bench",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Coq-CoLoR",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:29:59+00:00",
        "last_modified": "2026-01-10 13:30:51+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:other",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "color",
          "termination",
          "rewriting",
          "lambda-calculus"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-CoLoR\n\t\n\nA library on rewriting theory, lambda-calculus and termination.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/fblanqui/color\nLicense: CeCILL-2.1\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n3,304\n\n\nFiles Processed\n264\n\n\n\t\n\n\n\t\n\t\t\n\t\tType Distribution\n\t\n\n\n\t\n\t\t\nType\nCount\n\n\n\t\t\nLemma\n2,015\n\n\nDefinition\n540\n\n\nParameter\n223\n\n\nFixpoint\n172\n\n\nLtac\n157\n\n\nInductive\n101\n\n\nTheorem\n27\n\n\nProgram\n25\n\n\nRecord\n19\n\n\nLet\n11\n\n\nInstance\n7\n\n\nAxiom\n4\n\n\nCoercion\n2\n\n\nRemark\n1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-CoLoR.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-CoLoR",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_tennis_ball",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 15:08:23+00:00",
        "last_modified": "2026-01-05 15:30:51+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_block_tennis_ball\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç½‘çƒæ”¾å…¥ç§¯æœ¨\ntotal_episodes: 97\ntotal_tasks: 1\nsize: 744.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_tennis_ball.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_tennis_ball",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Maxwell-Jia/Spec-o3-ColdStartSFT",
        "author": "Maxwell-Jia",
        "created_at": "2026-01-09 14:29:03+00:00",
        "last_modified": "2026-01-09 15:10:27+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:image",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSpec-o3 Cold-Start (iMCoT) Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains expert-approved spectral inspection trajectories for cold-start supervised fine-tuning (SFT) of Spec-o3, a tool-augmented vision-language agent for astronomer-aligned spectral inspection and candidate vetting.\nEach sample is an interleaved multimodal chain-of-thought (iMCoT) trajectory that alternates between:\n\ntextual inspection reasoning, and\nstructured tool calls that request wavelength-windowâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Maxwell-Jia/Spec-o3-ColdStartSFT.",
        "url": "https://huggingface.co/datasets/Maxwell-Jia/Spec-o3-ColdStartSFT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_insert_marker_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 11:49:00+00:00",
        "last_modified": "2026-01-05 11:55:38+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241021_insert_marker_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ’å…¥é©¬å…‹ç¬”part_1\ntotal_episodes: 292\ntotal_tasks: 1\nsize: 520.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_insert_marker_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_insert_marker_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/F-Star",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:04:16+00:00",
        "last_modified": "2026-01-10 14:04:19+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "fstar",
          "dependent-types",
          "verification"
        ],
        "description": "\n\t\n\t\t\n\t\tF-Star\n\t\n\nA structured dataset of type declarations and definitions from F*, a proof-oriented programming language.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/FStarLang/FStar\nWebsite: https://fstar-lang.org\nLicense: Apache-2.0\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n12,957\n\n\nVal declarations\n9,219\n\n\nType definitions\n3,738\n\n\nSource Files\n2,799\n\n\n\t\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nType signature or definition\n\n\ntype\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/F-Star.",
        "url": "https://huggingface.co/datasets/phanerozoic/F-Star",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Pieux0/okfine",
        "author": "Pieux0",
        "created_at": "2025-12-25 05:41:03+00:00",
        "last_modified": "2026-01-05 14:37:47+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:1K<n<10K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2508.09736",
          "region:us"
        ],
        "description": "paper link: https://arxiv.org/abs/2508.09736\n",
        "url": "https://huggingface.co/datasets/Pieux0/okfine",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Harley-ml/es-en-words",
        "author": "Harley-ml",
        "created_at": "2026-01-07 03:41:35+00:00",
        "last_modified": "2026-01-07 03:50:00+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:es",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "words",
          "en-words",
          "es-words",
          "spanish-words",
          "english-words",
          "simple",
          "morphology",
          "lexicon",
          "language"
        ],
        "description": "\n\t\n\t\t\n\t\tWords\n\t\n\nA dataset comprised of 753k words, 90k of them are Spanish, and 660k of them are English.\n\n\t\n\t\t\nKey\nValue\n\n\n\t\t\nEntries (words)\n753,232\n\n\nTokens\n3,225,398\n\n\nCharacters\n7,022,310\n\n\nAvg. Tokens Per Entry\n~4.2\n\n\nAvg. Words Per Entry\n1\n\n\nAvg. Chars Per Entry\n~9.3\n\n\nLongest Entry (Tokens)\n36\n\n\nShortest Entry (Tokens)\n1\n\n\nEnglish Words~660k\n\n\nSpanish Words\n~90k\n\n\n\t\n\n\nCheck out Tiny-Word: A Model Trained on 753k Words\n\nHave fun. ALotta Words for you to enjoy!\n",
        "url": "https://huggingface.co/datasets/Harley-ml/es-en-words",
        "languages": [
          "es",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:31:18+00:00",
        "last_modified": "2026-01-05 16:32:25+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_on_table_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾åœ¨æ¡Œå­ä¸Špart_5\ntotal_episodes: 283\ntotal_tasks: 1\nsize: 324.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "happy8825/experiment_instruction_notune_",
        "author": "happy8825",
        "created_at": "2026-01-08 12:57:43+00:00",
        "last_modified": "2026-01-09 01:52:45+00:00",
        "downloads": 47,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "video-retrieval",
          "evaluation",
          "vllm"
        ],
        "description": "\n\t\n\t\t\n\t\tQwen/Qwen3-VL-2B-Instruct Â· happy8825/valid_ecva_clean results\n\t\n\n\nModel: Qwen/Qwen3-VL-2B-Instruct\nDataset: happy8825/valid_ecva_clean\nGenerated: 2026-01-09 01:12:50Z\n\n\n\t\n\t\t\n\t\tMetrics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal samples\n924\n\n\nWith GT\n0\n\n\nParsed answers\n0\n\n\nTop-1 accuracy\n0\n\n\nRecall@5\n0\n\n\nMRR\n0\n\n\n\t\n\nThe uploaded JSON contains full per-sample predictions produced via t3_infer_with_vllm.bash.\n\n\t\n\t\t\n\t\n\t\n\t\tEVQA/ECVA Metrics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nEVQA total\n924\n\n\nEVQA with GTâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/happy8825/experiment_instruction_notune_.",
        "url": "https://huggingface.co/datasets/happy8825/experiment_instruction_notune_",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_1rgb_bread_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:56:54+00:00",
        "last_modified": "2026-01-05 11:41:00+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_1rgb_bread_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¤æ¡Œä¸Šçš„é¢åŒ…part_1\ntotal_episodes: 2358\ntotal_tasks: 1\nsize: 10.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_1rgb_bread_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_1rgb_bread_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_57_potatolittleoven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:16:20+00:00",
        "last_modified": "2026-01-05 10:21:10+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_57_potatolittleoven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: åœŸè±†å°çƒ¤ç®±\ntotal_episodes: 400\ntotal_tasks: 1\nsize: 5.8G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_57_potatolittleoven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_57_potatolittleoven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_739_Submit_the_menu",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:04:52+00:00",
        "last_modified": "2026-01-05 16:37:47+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_739\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: é€’ä¸Šèœå•\ntotal_episodes: 573\ntotal_tasks: 1\nsize: 11G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_739_Submit_the_menu.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_739_Submit_the_menu",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "fuzhou-jiang/moss-002-sft-data",
        "author": "fuzhou-jiang",
        "created_at": "2026-01-06 03:23:59+00:00",
        "last_modified": "2026-01-06 03:24:00+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "language:zh",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "modality:tabular",
          "modality:text",
          "arxiv:2212.10560",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for \"moss-002-sft-data\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAn open-source conversational dataset that was used to train MOSS-002. The user prompts are extended based on a small set of human-written seed prompts in a way similar to Self-Instruct. The AI responses are generated using text-davinci-003. The user prompts of en_harmlessness are from Anthropic red teaming data.\n\n\t\n\t\t\n\t\n\t\n\t\tData Splits\n\t\n\n\n\t\n\t\t\nname\n# samples\n\n\n\t\t\nen_helpfulness.json\n419049\n\n\nen_honesty.json\n112580â€¦ See the full description on the dataset page: https://huggingface.co/datasets/fuzhou-jiang/moss-002-sft-data.",
        "url": "https://huggingface.co/datasets/fuzhou-jiang/moss-002-sft-data",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "Akash076/synthetic_cards",
        "author": "Akash076",
        "created_at": "2026-01-08 09:33:55+00:00",
        "last_modified": "2026-01-08 09:33:55+00:00",
        "downloads": 718,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-to-text",
          "task_categories:object-detection",
          "task_categories:document-question-answering",
          "task_categories:image-text-to-text",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:10K<n<100K",
          "region:us",
          "synthetic-data",
          "identity-documents",
          "driver-license",
          "credit-cards",
          "vlm-training",
          "document-ai",
          "ocr",
          "computer-vision"
        ],
        "description": "\n\t\n\t\t\n\t\tSynthetic Identity Documents Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“‹ Dataset Summary\n\t\n\nThis dataset contains 15,110 high-quality synthetic identity documents specifically designed for fine-tuning Vision Language Models (VLMs). The dataset includes realistic driver's licenses and credit cards with diverse variations in design, layout, and content.\nâš ï¸ IMPORTANT: This dataset is intended EXCLUSIVELY for Vision Language Model training and research purposes. Not for production identity verification systems.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Akash076/synthetic_cards.",
        "url": "https://huggingface.co/datasets/Akash076/synthetic_cards",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-to-text",
          "object-detection",
          "document-question-answering",
          "image-text-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_strawberries_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:52:45+00:00",
        "last_modified": "2026-01-05 23:53:21+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_strawberries_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‰èŽ“æ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 174\ntotal_tasks: 1\nsize: 344.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_strawberries_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_strawberries_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_green_onion",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:16:01+00:00",
        "last_modified": "2026-01-05 22:16:19+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_green_onion\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é’è‘±\ntotal_episodes: 49\ntotal_tasks: 1\nsize: 65.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_green_onion.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_green_onion",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "krisbailey/RedPajama-10B-Weighted",
        "author": "krisbailey",
        "created_at": "2026-01-09 14:55:54+00:00",
        "last_modified": "2026-01-09 16:28:40+00:00",
        "downloads": 35,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "redpajama",
          "llm",
          "dataset-reproduction",
          "redpajama-10b",
          "redpajama-subset",
          "redpajama-weighted",
          "redpajama-sample",
          "natural-language-processing"
        ],
        "description": "\n\t\n\t\t\n\t\tRedPajama-10B-Weighted\n\t\n\nA canonical 10 Billion token weighted subset of the RedPajama-Data-1T dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a faithful reproduction of the original RedPajama-Data-1T distribution, scaled down to exactly 10 Billion tokens. It is designed to preserve the exact domain ratios of the original dataset (excluding the defunct 'Books' subset). This allows researchers and developers to prototype, debug, and test on a representative slice of the dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/krisbailey/RedPajama-10B-Weighted.",
        "url": "https://huggingface.co/datasets/krisbailey/RedPajama-10B-Weighted",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_apple_into_chest",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:52:54+00:00",
        "last_modified": "2026-01-05 13:53:10+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_pick_apple_into_chest\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†è‹¹æžœæ¡èµ·æ”¾å…¥ç®±å­\ntotal_episodes: 2\ntotal_tasks: 1\nsize: 17.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_apple_into_chest.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_apple_into_chest",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "happy8825/experiment_fp8",
        "author": "happy8825",
        "created_at": "2026-01-08 11:33:45+00:00",
        "last_modified": "2026-01-08 11:33:47+00:00",
        "downloads": 29,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "video-retrieval",
          "evaluation",
          "vllm"
        ],
        "description": "\n\t\n\t\t\n\t\t/hub_data4/seohyun/saves/ecva_instruct_1223/full/sft/checkpoint-350 Â· happy8825/valid_ecva_clean results\n\t\n\n\nModel: /hub_data4/seohyun/saves/ecva_instruct_1223/full/sft/checkpoint-350\nDataset: happy8825/valid_ecva_clean\nGenerated: 2026-01-08 11:33:45Z\n\n\n\t\n\t\t\n\t\tMetrics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal samples\n924\n\n\nWith GT\n0\n\n\nParsed answers\n0\n\n\nTop-1 accuracy\n0\n\n\nRecall@5\n0\n\n\nMRR\n0\n\n\n\t\n\nThe uploaded JSON contains full per-sample predictions produced via t3_infer_with_vllm.bash.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/happy8825/experiment_fp8.",
        "url": "https://huggingface.co/datasets/happy8825/experiment_fp8",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_sweet_potato_on_the_table_1122",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:25:22+00:00",
        "last_modified": "2026-01-07 07:25:43+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_sweet_potato_on_the_table_1122\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†çº¢è–¯æ”¾åœ¨æ¡Œå­ä¸Špart_1\ntotal_episodes: 244\ntotal_tasks: 1\nsize: 180.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_sweet_potato_on_the_table_1122.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_sweet_potato_on_the_table_1122",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "visionscaper/agentic-llm-pretraining-1.7b",
        "author": "visionscaper",
        "created_at": "2026-01-10 20:31:28+00:00",
        "last_modified": "2026-01-10 21:04:48+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:1M<n<10M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "pretraining",
          "agentic",
          "function-calling",
          "reasoning",
          "code",
          "math",
          "dialogue",
          "rag"
        ],
        "description": "\n\t\n\t\t\n\t\tAgentic LLM Pretraining Dataset\n\t\n\nA pretraining corpus for small language models (1-3B parameters) optimized for agentic tasks. The corpus emphasizes learning to comprehend language, reason, follow instructions, and use tools over memorizing factual knowledge â€” the assumption is that domain knowledge will be provided at runtime via RAG. The idea is that this could enable much smaller pretraining corpora by omitting the large volumes of text typically needed to memorize facts.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/visionscaper/agentic-llm-pretraining-1.7b.",
        "url": "https://huggingface.co/datasets/visionscaper/agentic-llm-pretraining-1.7b",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "Shayfra7926/PANOPTICON",
        "author": "Shayfra7926",
        "created_at": "2026-01-02 21:09:10+00:00",
        "last_modified": "2026-01-05 17:48:15+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:other",
          "size_categories:10K<n<100K",
          "region:us",
          "privacy",
          "security",
          "pii",
          "synthetic-data",
          "evaluation"
        ],
        "description": "\n\t\n\t\t\n\t\tPANOPTICON\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPANOPTICON (PII-based Assemblage of Naturalistic Outputâ€“Prompt Tuples for Investigating Privacy Leakage in Conversational AI) is a dataset of synthetic, PII-bearing prompts designed to enable controlled evaluation of privacy leakage / prompt inversion behaviors in LLMs.\nThe dataset is organized by high-level Category and Scenario, and includes fields that support separating PII spans from surrounding benign context for analysis.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shayfra7926/PANOPTICON.",
        "url": "https://huggingface.co/datasets/Shayfra7926/PANOPTICON",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "masakhane/AfriMTE-WMT2024",
        "author": "masakhane",
        "created_at": "2026-01-06 12:44:41+00:00",
        "last_modified": "2026-01-06 13:03:18+00:00",
        "downloads": 72,
        "likes": 1,
        "tags": [
          "task_categories:translation",
          "language:ary",
          "language:arz",
          "language:en",
          "language:fr",
          "language:ha",
          "language:ig",
          "language:ki",
          "language:luo",
          "language:so",
          "language:sw",
          "language:tw",
          "language:xh",
          "language:yo",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2311.09828",
          "region:us",
          "machine-translation",
          "mt-evaluation",
          "quality-estimation",
          "african-languages",
          "wmt2024",
          "metrics-shared-task",
          "afrimte",
          "africomet"
        ],
        "description": "\n\t\n\t\t\n\t\tAfriMTE-WMT2024: African Machine Translation Evaluation Challenge Set\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe AfriMTE-WMT2024 dataset is a challenge set used in the WMT 2024 Metrics Shared Task for evaluating machine translation quality across 13 African-centric language pairs. This dataset aims to support research and development in African machine translation evaluation and quality estimation.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Language Pairs\n\t\n\n\n\t\n\t\t\nConfig\nSource Language\nTarget Language\n#â€¦ See the full description on the dataset page: https://huggingface.co/datasets/masakhane/AfriMTE-WMT2024.",
        "url": "https://huggingface.co/datasets/masakhane/AfriMTE-WMT2024",
        "languages": [
          "ary",
          "arz",
          "en",
          "fr",
          "ha",
          "ig",
          "ki",
          "luo",
          "so",
          "sw",
          "tw",
          "xh",
          "yo"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "DavidRobinson05/ucf-seg",
        "author": "DavidRobinson05",
        "created_at": "2026-01-07 02:28:24+00:00",
        "last_modified": "2026-01-11 19:43:30+00:00",
        "downloads": 6,
        "likes": 1,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/DavidRobinson05/ucf-seg",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "purpcode/mocha",
        "author": "purpcode",
        "created_at": "2026-01-06 20:59:57+00:00",
        "last_modified": "2026-01-06 21:15:36+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "robustness",
          "jailbreak",
          "safety",
          "adversarial-attacks"
        ],
        "description": "\n\t\n\t\t\n\t\tMOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?\n\t\n\nMOCHA is a benchmark designed to evaluate the robustness of Code Language Models (Code LLMs) against multi-turn malicious coding jailbreaks. While recent LLMs have improved in code generation, they remain vulnerable to \"code decomposition attacks\"â€”a strategy where a complex malicious task is fragmented into benign-looking subtasks across multiple conversational turns to bypass safety filters. Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/purpcode/mocha.",
        "url": "https://huggingface.co/datasets/purpcode/mocha",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "enPurified/open-thoughts-114k-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 18:33:47+00:00",
        "last_modified": "2026-01-12 00:31:01+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:open-thoughts/OpenThoughts-114k",
          "language:en",
          "license:apache-2.0",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "open-thoughts",
          "quality-filtered",
          "reasoning"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– OpenThoughts-114k-enPurified-openai-messages\n\t\n\nOpenThoughts-114k-enPurified is a highly refined, \"prose-first\" reasoning dataset derived from open-thoughts/OpenThoughts-114k. \nThe enPurified collection is built on a specific philosophy: Specialization. While modern LLMs need code and math to be versatile, high-quality English prose often becomes diluted when mixed with syntax-heavy scripts or rigid formulas. This dataset keeps only the highest quality English reasoning, convertingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/open-thoughts-114k-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/open-thoughts-114k-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "broadfield-dev/test-rstartcoder",
        "author": "broadfield-dev",
        "created_at": "2026-01-06 18:48:35+00:00",
        "last_modified": "2026-01-06 18:48:38+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "dataset-command-center",
          "etl",
          "generated-dataset"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): en\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/broadfield-dev/test-rstartcoder.",
        "url": "https://huggingface.co/datasets/broadfield-dev/test-rstartcoder",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Ethan-Bei/Mem-Gallery",
        "author": "Ethan-Bei",
        "created_at": "2026-01-07 16:59:34+00:00",
        "last_modified": "2026-01-08 02:07:32+00:00",
        "downloads": 70,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2601.03515",
          "region:us",
          "Agent Memory",
          "MLLM Agent",
          "Multimodal Memory",
          "Long-term Memory",
          "Multi-Session Conversation"
        ],
        "description": "\n\n\n\n\n    \n    \n\n\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nMem-Gallery is a comprehensive benchmark dataset designed to evaluate multimodal long-term memory capabilities of MLLM agents across multi-session conversations. The dataset features realistic, persona-driven dialogues spanning 20 scenarios, each enriched with contextual images to test memory retention, recall, and reasoning over extended interactions.\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Key Features\n\t\n\n\nDiverse Scenarios: Covering topics from AI & Robotics to Daily Lifeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ethan-Bei/Mem-Gallery.",
        "url": "https://huggingface.co/datasets/Ethan-Bei/Mem-Gallery",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "anyangsong/MAGA",
        "author": "anyangsong",
        "created_at": "2026-01-08 11:27:50+00:00",
        "last_modified": "2026-01-08 14:05:16+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/anyangsong/MAGA",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "nyuuzyou/gitverse-code",
        "author": "nyuuzyou",
        "created_at": "2024-07-06 16:38:08+00:00",
        "last_modified": "2026-01-09 05:00:13+00:00",
        "downloads": 92,
        "likes": 2,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:crowdsourced",
          "language_creators:expert-generated",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:ru",
          "language:en",
          "license:other",
          "size_categories:1M<n<10M",
          "modality:text",
          "region:us",
          "code",
          "russian"
        ],
        "description": "\n\t\n\t\t\n\t\tGitVerse Code Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from code repositories hosted on GitVerse, a Russian code hosting platform and an alternative to GitHub in the Russian developer community. GitVerse is used by Russian developers, enterprises, and open-source projects, making this dataset particularly valuable for training code models with Russian language understanding and Russian coding conventions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nStatistic\nValueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gitverse-code.",
        "url": "https://huggingface.co/datasets/nyuuzyou/gitverse-code",
        "languages": [
          "code",
          "ru",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "ACL2026-ID111/ACL2026-ID111",
        "author": "ACL2026-ID111",
        "created_at": "2026-01-05 03:41:25+00:00",
        "last_modified": "2026-01-06 02:41:20+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "language:zh",
          "license:cc-by-nc-4.0",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tIntroduction\n\t\n\nThis is the dataset for ACL2026-ID111, containing:\n1. 200 pieces of video,\n2. video associated metadata (video title, cover image, channel ID (w. Verification), statistics (Likes & Shares), release Date, and URL),\n3. video's single channel information (frames(Visual), screen text(Textual), and transcript(Aural)),\n4. video's annotation labels (category, core claim, error reason, supporting evidence, error type).\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Component\n\t\n\n1. data_video.zipâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ACL2026-ID111/ACL2026-ID111.",
        "url": "https://huggingface.co/datasets/ACL2026-ID111/ACL2026-ID111",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "TGoddessana/common-dev-commands-en-ko",
        "author": "TGoddessana",
        "created_at": "2026-01-07 08:48:16+00:00",
        "last_modified": "2026-01-07 08:52:38+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:ko",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "linux",
          "command-line",
          "natural-language-to-code",
          "korean",
          "multilingual"
        ],
        "description": "\n\t\n\t\t\n\t\tCommon Linux Commands (Korean-English)\n\t\n\nA bilingual dataset for translating natural language instructions into Linux/Unix commands.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 12,250 examples of natural language queries (in both Korean and English) paired with their corresponding Linux/Unix commands. It covers 82 different command-line tools commonly used in system administration and development.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n{\n  \"korean_question\": \"production.ini ì¸ë²¤í† ë¦¬ ì¨ì„œâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/TGoddessana/common-dev-commands-en-ko.",
        "url": "https://huggingface.co/datasets/TGoddessana/common-dev-commands-en-ko",
        "languages": [
          "ko",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:07:01+00:00",
        "last_modified": "2026-01-07 07:07:18+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç›˜å­ä¸Šæ‹¿èµ·é»„è¾£æ¤’part_1\ntotal_episodes: 103\ntotal_tasks: 1\nsize: 54.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241202",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:22:50+00:00",
        "last_modified": "2026-01-05 18:23:43+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241202\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é¢åŒ…ç›˜å­part_2\ntotal_episodes: 129\ntotal_tasks: 1\nsize: 1.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241202.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241202",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_plate_from_plate_rack",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:12:28+00:00",
        "last_modified": "2026-01-05 14:16:48+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_pick_plate_from_plate_rack\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç›˜å­æž¶ä¸Šæ‹¿èµ·ç›˜å­\ntotal_episodes: 271\ntotal_tasks: 1\nsize: 527.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_plate_from_plate_rack.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_plate_from_plate_rack",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_table_1121",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:56:43+00:00",
        "last_modified": "2026-01-07 06:57:06+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_table_1121\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é’èœpart_1\ntotal_episodes: 210\ntotal_tasks: 1\nsize: 226.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_table_1121.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_table_1121",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "llm-semantic-router/halueval-spans",
        "author": "llm-semantic-router",
        "created_at": "2026-01-07 22:22:55+00:00",
        "last_modified": "2026-01-09 23:50:44+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "hallucination-detection",
          "fact-verification",
          "RAG",
          "span-detection",
          "token-classification",
          "summarization"
        ],
        "description": "\n\t\n\t\t\n\t\tHaluEval Span-Level Dataset (LLM-Detected)\n\t\n\nðŸ” High-quality span-level hallucination detection dataset converted from HaluEval using Qwen2.5-72B-Instruct for precise span detection and RAGTruth-compatible labeling.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"llm-semantic-router/halueval-spans\")\n\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\n\n\t\n\t\t\nProblem\nPrevious Solution\nThis Dataset\n\n\n\t\t\nHaluEval has binary labels only\nNLI-based conversion\nâœ… LLM-based spanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-semantic-router/halueval-spans.",
        "url": "https://huggingface.co/datasets/llm-semantic-router/halueval-spans",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "HughMungus420/usda-fdc-foods-cleaned",
        "author": "HughMungus420",
        "created_at": "2026-01-11 04:19:43+00:00",
        "last_modified": "2026-01-11 04:19:43+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc0-1.0",
          "size_categories:100K<n<1M",
          "modality:tabular",
          "modality:text",
          "region:us",
          "nutrition",
          "ingredients",
          "food",
          "usda",
          "tabular",
          "cleaned",
          "analysis-ready"
        ],
        "description": "\n\t\n\t\t\n\t\tComprehensive & Cleaned USDA Foods Nutrition Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a cleaned, de-duplicated, and enhanced version of the USDA's FoodData Central (FDC) database, combining Branded Foods, Foundation Foods (generic), and SR Legacy data into a single, analysis-ready file. It is designed to be a robust resource for nutritional analysis, machine learning, and food-related applications.\nThe raw USDA data is spread across dozens of CSV files, contains numerousâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HughMungus420/usda-fdc-foods-cleaned.",
        "url": "https://huggingface.co/datasets/HughMungus420/usda-fdc-foods-cleaned",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "bhaiyahnsingh45/kpi-tool-calling",
        "author": "bhaiyahnsingh45",
        "created_at": "2026-01-06 09:18:44+00:00",
        "last_modified": "2026-01-08 09:10:10+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "function-calling",
          "tool-use",
          "manufacturing",
          "kpi"
        ],
        "description": "\n\t\n\t\t\n\t\tKPI Tool Calling Dataset\n\t\n\nDataset for fine-tuning LLMs on manufacturing KPI tool calling tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains examples of user queries about manufacturing KPIs and their corresponding tool calls.\n\n\t\n\t\t\n\t\tTools\n\t\n\n\nget_oee - Get OEE (Overall Equipment Effectiveness) metrics\nget_availability - Get availability/uptime metrics\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\nEach example contains:\n\nuser_content: The user's query about KPIs\ntool_calls: JSON array of toolâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bhaiyahnsingh45/kpi-tool-calling.",
        "url": "https://huggingface.co/datasets/bhaiyahnsingh45/kpi-tool-calling",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Agda-Stdlib",
        "author": "phanerozoic",
        "created_at": "2026-01-10 11:07:24+00:00",
        "last_modified": "2026-01-10 13:48:46+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "agda",
          "standard-library",
          "dependent-types"
        ],
        "description": "\n\t\n\t\t\n\t\tAgda-Stdlib\n\t\n\nStructured dataset of definitions and types from the Agda standard library v2.3.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nType signature and definition\n\n\ntype\nstring\nfunction, data, record\n\n\nlibrary\nstring\nTop-level module (Data, Relation, Algebra, etc.)\n\n\nimports\nlist\nImport statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\ndocstring\nstring\nDocumentation comment (3% coverage)\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tStatisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Agda-Stdlib.",
        "url": "https://huggingface.co/datasets/phanerozoic/Agda-Stdlib",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "od2961/illusion-of-reasoning-main-traces",
        "author": "od2961",
        "created_at": "2025-12-18 23:48:06+00:00",
        "last_modified": "2026-01-06 17:23:07+00:00",
        "downloads": 198,
        "likes": 1,
        "tags": [
          "language:en",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tIllusion of Reasoning - Main Traces\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains reasoning traces from GRPO models across multiple tasks and temperatures. It includes:\n\nGRPO-1.5B on math, crosswords, and carpark (temps: 0, 0.05, 0.3, 0.7)\nGRPO-7B on math (temps: 0, 0.05, 0.3, 0.7)\nGRPO-Llama8B on math (temps: 0, 0.05, 0.3, 0.7)\n\nThe dataset contains a processed split with explicit metadata columns, plus the original raw JSONL files under\nartifacts/results/... in the repository.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/od2961/illusion-of-reasoning-main-traces.",
        "url": "https://huggingface.co/datasets/od2961/illusion-of-reasoning-main-traces",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "remynd/capes_synthetic_audio_PT",
        "author": "remynd",
        "created_at": "2024-04-08 15:21:33+00:00",
        "last_modified": "2025-10-04 17:04:27+00:00",
        "downloads": 2,
        "likes": 1,
        "tags": [
          "language:pt",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "Data used to reproduce all of the experiments in the paper ; https://ieeexplore.ieee.org/document/10720758/\n",
        "url": "https://huggingface.co/datasets/remynd/capes_synthetic_audio_PT",
        "languages": [
          "pt",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "gcd94/REALM",
        "author": "gcd94",
        "created_at": "2026-01-08 20:29:30+00:00",
        "last_modified": "2026-01-08 20:29:32+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:image",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2503.18792",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tREALM: REAL-World Application of Large Language Models\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\nPaper: coming soon\n\nDashboard Demo: https://realm-e7682.web.app/\n\nLicense: [mit]\n\nLanguage(s) (NLP): English\n\nPoint of Contact: Jingwen\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nLarge Language Models (LLMs), such as GPT-like models, have transformed industries and everyday life, creating significant societal impact. To better understand their real-world applications, we created the REALM Dataset, aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gcd94/REALM.",
        "url": "https://huggingface.co/datasets/gcd94/REALM",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "obekt/obekt-finance-v0.1",
        "author": "obekt",
        "created_at": "2026-01-10 07:27:30+00:00",
        "last_modified": "2026-01-10 07:30:00+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "finance",
          "synthetic",
          "financial-analyst",
          "xiaomi-mimo"
        ],
        "description": "\n\t\n\t\t\n\t\tSynthetic Financial Analyst Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetic financial analyst data generated using the Xiaomi MiMo V2 Flash LLM. It is designed to simulate tasks, queries, and analyses typical of the financial sector.\nSource Model: xiaomi/mimo-v2-flash\n\n\t\n\t\t\n\t\tContains\n\t\n\n\nobekt-finance-v0.1.csv: The main data file containing the synthetic examples.\n\n\n\t\n\t\t\n\t\tDisclaimer: Unverified Synthetic Data\n\t\n\n\n[!WARNING]\nThis data is 100% synthetic andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obekt/obekt-finance-v0.1.",
        "url": "https://huggingface.co/datasets/obekt/obekt-finance-v0.1",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:03:16+00:00",
        "last_modified": "2026-01-05 22:03:58+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_close_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 658\ntotal_tasks: 1\nsize: 940.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "PhillyMac/JUlius_Caesar_Corpus",
        "author": "PhillyMac",
        "created_at": "2026-01-09 22:20:44+00:00",
        "last_modified": "2026-01-09 22:20:46+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc0-1.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "corpus",
          "leadership",
          "historical",
          "deku-corpus-builder"
        ],
        "description": "\n\t\n\t\t\n\t\tJulius Caesar Agent\n\t\n\nThis corpus was automatically generated by the Deku Corpus Builder for use in RAG-based AI applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record contains:\n\ntext: The content text\nsource_url: Original source URL\nsource_title: Title of the source document\nsource_domain: Domain of the source\nrelevance_score: Relevance to the subject (0-1)\nquality_score: Content quality score (0-1)\ntopics: JSON array of detected topics\ncharacter_count: Length of the textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PhillyMac/JUlius_Caesar_Corpus.",
        "url": "https://huggingface.co/datasets/PhillyMac/JUlius_Caesar_Corpus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "graves666/gsm8k",
        "author": "graves666",
        "created_at": "2026-01-09 07:43:24+00:00",
        "last_modified": "2026-01-09 07:43:26+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:crowdsourced",
          "language_creators:crowdsourced",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2110.14168",
          "region:us",
          "math-word-problems"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for GSM8K\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nGSM8K (Grade School Math 8K) is a dataset of 8.5K high quality linguistically diverse grade school math word problems. The dataset was created to support the task of question answering on basic mathematical problems that require multi-step reasoning.\n\nThese problems take between 2 and 8 steps to solve.\nSolutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ âˆ’ Ã—Ã·) to reach theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/graves666/gsm8k.",
        "url": "https://huggingface.co/datasets/graves666/gsm8k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_purple_block_in_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:08:32+00:00",
        "last_modified": "2026-01-05 17:13:19+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_purple_block_in_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç´«è‰²ç§¯æœ¨æ”¾å…¥ç›˜å­\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 415.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_purple_block_in_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_purple_block_in_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_0_tkg_1rgb_put_the_water_cup_in_front_of_the_bread_machine",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 03:28:05+00:00",
        "last_modified": "2026-01-08 03:46:47+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_put_the_water_cup_in_front_of_the_bread_machine\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ°´æ¯æ”¾åœ¨é¢åŒ…æœºå‰\ntotal_episodes: 152\ntotal_tasks: 1\nsize: 1.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkg_1rgb_put_the_water_cup_in_front_of_the_bread_machine.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkg_1rgb_put_the_water_cup_in_front_of_the_bread_machine",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_red_pepper_in_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:53:20+00:00",
        "last_modified": "2026-01-05 22:53:41+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_red_pepper_in_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„çº¢è¾£æ¤’\ntotal_episodes: 210\ntotal_tasks: 1\nsize: 263.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_red_pepper_in_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_red_pepper_in_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_trash_can_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:39:08+00:00",
        "last_modified": "2026-01-05 13:44:00+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_open_cap_trash_can_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_1\ntotal_episodes: 96\ntotal_tasks: 1\nsize: 235.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_trash_can_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_trash_can_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "likaixin/GroundCUA-train",
        "author": "likaixin",
        "created_at": "2026-01-04 14:05:41+00:00",
        "last_modified": "2026-01-05 16:32:35+00:00",
        "downloads": 31,
        "likes": 3,
        "tags": [
          "task_categories:image-text-to-text",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2511.07332",
          "region:us",
          "agents",
          "computer_use",
          "grounding",
          "multimodal",
          "ui-vision",
          "GroundCUA"
        ],
        "description": "\n  GroundCUA: Grounding Computer Use Agents on Human Demonstrations\n\n\n\n\nðŸŒ Website |\nðŸ“‘ Paper |\nðŸ¤— Raw Dataset |\nðŸ¤– Models\n\n\n\n\n\n\n\t\n\t\t\n\t\tGroundCUA Dataset\n\t\n\nGroundCUA is a large and diverse dataset of real UI screenshots paired with structured annotations for building multimodal computer use agents. It covers 87 software platforms across productivity tools, browsers, creative tools, communication apps, development environments, and system utilities. GroundCUA is designed for research on GUIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/likaixin/GroundCUA-train.",
        "url": "https://huggingface.co/datasets/likaixin/GroundCUA-train",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-text-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "locht131/ALOHA_Zipping_Bag",
        "author": "locht131",
        "created_at": "2026-01-06 08:29:39+00:00",
        "last_modified": "2026-01-06 08:52:45+00:00",
        "downloads": 42,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "LeRobot",
          "Aloha",
          "Robot"
        ],
        "description": "This dataset was created using LeRobot.\nmeta/info.json\n{\n    \"codebase_version\": \"v2.1\",\n    \"robot_type\": \"ALOHA\",\n    \"total_episodes\": 99,\n    \"total_frames\": 40313,\n    \"total_tasks\": 1,\n    \"total_videos\": 297,\n    \"total_chunks\": 1,\n    \"chunks_size\": 1000,\n    \"fps\": 15,\n    \"splits\": {\n        \"train\": \"0:99\"\n    },\n    \"data_path\": \"data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet\",\n    \"video_path\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/locht131/ALOHA_Zipping_Bag.",
        "url": "https://huggingface.co/datasets/locht131/ALOHA_Zipping_Bag",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "mdelmas/Topg-kb",
        "author": "mdelmas",
        "created_at": "2025-11-28 13:08:52+00:00",
        "last_modified": "2026-01-07 11:26:21+00:00",
        "downloads": 4,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tData for reproducibility\n\t\n\nThe local search mode of ToPG is evaluated on 5 datasets: HotPotQA, MusiQue, PopQA, GraphRAG-Benchmark-Medical, and GraphRAG-Benchmark-Novel.\nThe original subsets for HotPotQA, MusiQue, and PopQA can be extracted from the HippoRAG 2 dataset. \nFor the Medical and Novel datasets from GraphRAG-Benchmark, please refer to the official repository:GraphRAG-Benchmark.The Novel dataset is split into several subsets; we provide the dumps for each subset in the fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mdelmas/Topg-kb.",
        "url": "https://huggingface.co/datasets/mdelmas/Topg-kb",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "GXMZU/llm-rag-agent-papers",
        "author": "GXMZU",
        "created_at": "2026-01-05 08:16:15+00:00",
        "last_modified": "2026-01-05 08:23:07+00:00",
        "downloads": 21,
        "likes": 3,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "language:zh",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "llm",
          "rag",
          "agent",
          "knowledge-base",
          "research"
        ],
        "description": "\n\t\n\t\t\n\t\tllm-rag-agent-papers\n\t\n\nResearch papers on LLM, RAG, and AI Agents - Knowledge base for RAG pipeline\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains three subsets:\n\nllm: Large Language Model related content\nrag: Retrieval-Augmented Generation related content\nagent: AI Agent related content\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load all subsets\ndataset = load_dataset(\"GXMZU/llm-rag-agent-papers\")\n\n# Load specific subset\nllm_data =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GXMZU/llm-rag-agent-papers.",
        "url": "https://huggingface.co/datasets/GXMZU/llm-rag-agent-papers",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_toast_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:49:02+00:00",
        "last_modified": "2026-01-05 22:49:11+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_toast_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åå¸æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 25\ntotal_tasks: 1\nsize: 20.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_toast_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_toast_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Akhil-Theerthala/DesnityVsDiversity",
        "author": "Akhil-Theerthala",
        "created_at": "2025-12-28 20:08:27+00:00",
        "last_modified": "2026-01-06 17:52:25+00:00",
        "downloads": 89,
        "likes": 0,
        "tags": [
          "task_categories:image-text-to-text",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "modality:image",
          "region:us"
        ],
        "description": "The following dataset repo contains the train and validation datasets used for the blogpost: Diversity Vs Density: A strategy comparison for fine-tuning VLMs\n",
        "url": "https://huggingface.co/datasets/Akhil-Theerthala/DesnityVsDiversity",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-text-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "haiguga/arena-human-preference-55k",
        "author": "haiguga",
        "created_at": "2026-01-11 10:17:08+00:00",
        "last_modified": "2026-01-11 10:17:09+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2403.04132",
          "region:us"
        ],
        "description": "Dataset for Kaggle competition on predicting human preference on Chatbot Arena battles. \nThe training dataset includes over 55,000 real-world user and LLM conversations and user preferences across over 70 state-of-the-art LLMs, such as GPT-4, Claude 2, Llama 2, Gemini, and Mistral models.\nEach sample represents a battle consisting of 2 LLMs which answer the same question, with a user label of either prefer model A, prefer model B, tie, or tie (both bad).\n\n\t\n\t\t\n\t\n\t\n\t\tCitation\n\t\n\nPlease cite theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/haiguga/arena-human-preference-55k.",
        "url": "https://huggingface.co/datasets/haiguga/arena-human-preference-55k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "petdecoder/pet-decoder-audio-fixtures",
        "author": "petdecoder",
        "created_at": "2026-01-11 06:34:57+00:00",
        "last_modified": "2026-01-11 06:36:21+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "language:en",
          "license:cc0-1.0",
          "size_categories:n<1K",
          "format:audiofolder",
          "modality:audio",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "audio",
          "biology",
          "dog",
          "test-fixtures"
        ],
        "description": "\n\t\n\t\t\n\t\tPet Decoder Audio Test Fixtures (v1.0) ðŸ§ª\n\t\n\nThis repository contains audio test fixtures used for validating the ingestion pipeline of the Pet Decoder AI application.\nThese are verified, public domain samples used to test our audio visualization and classification algorithms against known baselines (e.g., Low Frequency vs. High Frequency vocalizations).\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Contents\n\t\n\nThe dataset consists of 5 reference audio files representing distinct spectral patterns:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/petdecoder/pet-decoder-audio-fixtures.",
        "url": "https://huggingface.co/datasets/petdecoder/pet-decoder-audio-fixtures",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "jinggogogo/reflect3r_synthetic_data",
        "author": "jinggogogo",
        "created_at": "2026-01-07 14:28:05+00:00",
        "last_modified": "2026-01-09 16:55:59+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:image-to-3d",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "modality:3d",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2509.20607",
          "region:us",
          "3d",
          "reconstruction",
          "blender"
        ],
        "description": "\n  \n  [3DV 2026] Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections\n\n  \n    Jing Wu,\n    Zirui Wang,\n    Iro Laina,\n    Victor Adrian Prisacariu\n    \n    University of Oxford\n\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tCitation\n\t\n\nIf you find this data or find the paper useful for your research, please consider citing:\n@article{wu2026reflect3r,\nauthor = {Wu, Jing and Wang, Zirui and Laina, Iro and Prisacariu, Victor},\ntitle = {{Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirrorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jinggogogo/reflect3r_synthetic_data.",
        "url": "https://huggingface.co/datasets/jinggogogo/reflect3r_synthetic_data",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-3d"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "data-archetype/bg_photo_concepts_bucketed_512",
        "author": "data-archetype",
        "created_at": "2026-01-10 00:59:30+00:00",
        "last_modified": "2026-01-10 02:05:38+00:00",
        "downloads": 112,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:webdataset",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:webdataset",
          "library:mlcroissant",
          "region:us",
          "webdataset",
          "images",
          "captions"
        ],
        "description": "\n\t\n\t\t\n\t\tbg_photo_concepts_bucketed_512\n\t\n\n\nTitle: bg_photo_concepts_bucketed_512\nDescription: A recaptioned, self contained, bucketed and ready to train with version of https://huggingface.co/datasets/bghira/photo-concept-bucket, exported at 512^2 ish resolution buckets.\nI lost the tracking data of which version of Gemini this was captioned with, likely 2.0 flash or 2.5 flash. The captions are on the long and datailed side and sometimes slightly redundant, but overall high quality.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/data-archetype/bg_photo_concepts_bucketed_512.",
        "url": "https://huggingface.co/datasets/data-archetype/bg_photo_concepts_bucketed_512",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "developer-lunark/kaidol-phase2-rp-base-v0.3",
        "author": "developer-lunark",
        "created_at": "2026-01-07 02:44:43+00:00",
        "last_modified": "2026-01-07 02:45:35+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:ko",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "roleplay",
          "korean",
          "dialogue",
          "multiturn",
          "character-ai",
          "conversational"
        ],
        "description": "\n\t\n\t\t\n\t\tKAIDOL Phase 2 RP Base Dataset v0.3\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nKAIDOL Phase 2 RP Base v0.3 is a Korean-English bilingual conversational dataset designed for fine-tuning large language models (LLMs) for roleplay and character-based dialogue systems. This version includes GPT-Slop filtering to remove AI-sounding patterns and improve response quality.\n\n\t\n\t\t\n\t\tWhat's New in v0.3\n\t\n\n\nGPT-Slop Filtering: Removed 1,529 samples containing AI-sounding patterns\nCleaner Responses: Filteredâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/developer-lunark/kaidol-phase2-rp-base-v0.3.",
        "url": "https://huggingface.co/datasets/developer-lunark/kaidol-phase2-rp-base-v0.3",
        "languages": [
          "ko",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "beersrobert/realworld-camper-environment-v1",
        "author": "beersrobert",
        "created_at": "2026-01-10 01:31:13+00:00",
        "last_modified": "2026-01-10 01:37:54+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "Environment  recreational_vehicle  camper  mobile_housing  temporary_residential_structure  Scene Scope  interior  exterior  Interior Spaces  kitchen_area  living_area  sleeping_area  bathroom_area  hallway  entryway  Exterior Spaces  camper_exterior_shell  entry_steps  doorway  roof_visible  ground_interface  Conditions  aged_materials  visible_wear  surface_discoloration  dust_and_debris_present  non_uniform_finishes  Layout Characteristics  confined_spaces  multi_use_areas  tight_clearances  step_transitions  Lighting  natural_light  artificial_light  mixed_lighting  Risk Context  fire_proximity_zones  trip_hazard_potential  limited_egress_width"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/realworld-camper-environment-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "michaelsyao/MedicineAuthorship",
        "author": "michaelsyao",
        "created_at": "2025-10-09 23:05:37+00:00",
        "last_modified": "2025-11-01 22:16:58+00:00",
        "downloads": 137,
        "likes": 0,
        "tags": [
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1M<n<10M",
          "modality:tabular",
          "modality:text",
          "region:us",
          "medical"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/michaelsyao/MedicineAuthorship",
        "languages": [
          "en"
        ],
        "tasks": [
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "sarannair/eng_accent_audio",
        "author": "sarannair",
        "created_at": "2025-02-04 17:04:10+00:00",
        "last_modified": "2025-02-04 17:15:10+00:00",
        "downloads": 4,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "speech",
          "text",
          "alignment"
        ],
        "description": "\n\t\n\t\t\n\t\tEnglish Accent Audio-transcript Dataset.\n\t\n\nAudio is extracted from movies, shows, speeches, talks to capture diverse accents - mainly scottish, nigerian and indian\nThis dataset contains 30-second audio clips with aligned transcript text. \n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach entry includes:\n\naudio: 30-second speech segment\ntext: Corresponding transcript\nstart_time / end_time: Segment timestamps\n\n\n\t\n\t\t\n\t\tLicense\n\t\n\nLicensed under CC-BY-4.0.\n",
        "url": "https://huggingface.co/datasets/sarannair/eng_accent_audio",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_basket_1122",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:02:53+00:00",
        "last_modified": "2026-01-07 07:03:20+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_basket_1122\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¯®å­ä¸­æ‹¿èµ·çº¢è–¯part_1\ntotal_episodes: 269\ntotal_tasks: 1\nsize: 236.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_basket_1122.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_basket_1122",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "enPurified/project_gutenberg-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-12 00:24:09+00:00",
        "last_modified": "2026-01-12 00:45:16+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:manu/project_gutenberg",
          "language:en",
          "size_categories:100K<n<1M",
          "region:us",
          "nlp",
          "prose",
          "filtered",
          "gutenberg",
          "literary",
          "quality-filtered",
          "synthetic-instruction"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– Project-Gutenberg-enPurified-openai-messages\n\t\n\nProject-Gutenberg-enPurified is a highly curated, \"prose-first\" dataset derived from the manu/project_gutenberg collection.\nThe enPurified collection is built on a specific philosophy: Specialization. There are plenty of excellent datasets for coding and mathematics. However, high-quality, fluent English literary prose often gets lost in the noise of OCR errors, table of contents, and poetry.\nThis dataset was created by running aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/project_gutenberg-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/project_gutenberg-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BossCrafts/CodeX-2M-Thinking",
        "author": "BossCrafts",
        "created_at": "2025-12-19 04:51:53+00:00",
        "last_modified": "2025-12-19 04:51:55+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "annotations_creators:machine-generated",
          "annotations_creators:expert-verified",
          "multilinguality:monolingual",
          "source_datasets:XenArcAI internal synthetic generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Coding",
          "Code",
          "CodeX",
          "XenArcAI",
          "LLM-training",
          "synthetic",
          "curated",
          "benchmark",
          "reasoning-dataset",
          "artifact"
        ],
        "description": "\n\t\n\t\t\n\t\tXenArcAI\n\t\n\n\n\n  \n\n\n\nNote: This dataset is part of the lineup CodeX by XenArcAI. You can get lots of datasets in this same lineup, with the main focus on providing very high-quality datasets for model training and fine-tuning. \n\nThis dataset is fully synthetic, curated from high-quality public sources and enhanced with synthetic data generated using both closed and open-source models. It serves as a strong foundation for instruction-based model tuning and fine-tuning, offering one ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BossCrafts/CodeX-2M-Thinking.",
        "url": "https://huggingface.co/datasets/BossCrafts/CodeX-2M-Thinking",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "Mtechlaw/TfGBV-Grok-NCII-Dataset",
        "author": "Mtechlaw",
        "created_at": "2026-01-05 21:12:41+00:00",
        "last_modified": "2026-01-07 10:03:57+00:00",
        "downloads": 92,
        "likes": 9,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:n<1K",
          "modality:document",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "TfGBV",
          "AI safety",
          "content moderation",
          "NCII",
          "gender-based violence",
          "Grok",
          "deepfakes"
        ],
        "description": "\n\t\n\t\t\n\t\tTfGBV-Grok Dataset: AI-Facilitated Non-Consensual Intimate Image Generation\n\t\n\n\nâš ï¸ WORK IN PROGRESS: This dataset is actively being developed. There may be classification errors or inconsistencies. It will be updated as I process the rest of the raw data. Feedback and corrections are welcome â€” please email nana.nwachukwu@gmail.com.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nThis dataset documents 565 instances of users publicly requesting Grok AI (integrated into X/Twitter) to generateâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mtechlaw/TfGBV-Grok-NCII-Dataset.",
        "url": "https://huggingface.co/datasets/Mtechlaw/TfGBV-Grok-NCII-Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Displace-M/Displace2026",
        "author": "Displace-M",
        "created_at": "2026-01-06 13:47:02+00:00",
        "last_modified": "2026-01-08 14:22:58+00:00",
        "downloads": 88,
        "likes": 1,
        "tags": [
          "language:en",
          "region:us",
          "medical"
        ],
        "description": "Following the grand success of theÂ DISPLACE 2023 and 2024Â challenges, which received overwhelming participation and support from both academia and industry, we are thrilled to launch this new version focusing on advancing research in multilingual medical and conversational speech processing.\nThe event is organized by theÂ Learning and Extraction of Acoustic Patterns (LEAP) Lab, Department of Electrical Engineering,Â IISc Bangalore, and theÂ Department of Electronics and Communication Engineeringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Displace-M/Displace2026.",
        "url": "https://huggingface.co/datasets/Displace-M/Displace2026",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "dragonslayer631/bignewsalign-with-gdelt",
        "author": "dragonslayer631",
        "created_at": "2025-09-23 15:40:17+00:00",
        "last_modified": "2026-01-05 01:06:59+00:00",
        "downloads": 265,
        "likes": 1,
        "tags": [
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:1M<n<10M",
          "modality:text",
          "region:us",
          "GDELT",
          "News"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dragonslayer631/bignewsalign-with-gdelt.",
        "url": "https://huggingface.co/datasets/dragonslayer631/bignewsalign-with-gdelt",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "sming256/MinimalVideoPairs",
        "author": "sming256",
        "created_at": "2025-11-12 19:45:45+00:00",
        "last_modified": "2025-11-13 08:51:40+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:video-text-to-text",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tMinimal Video Pairs\n\t\n\nA shortcut-aware benchmark for spatio-temporal and intuitive physics video understanding (VideoQA) using minimally different video pairs.\n\nGithub\n\n\n  \n\n\nFor legal reasons, we are unable to upload the videos directly to Huggingface. However, we provide scripts in this repository for downloading the videos in our github repository. Our benchmark is built on top of videos source from 9 domains:\n\n\t\n\t\t\nSubset\nData sources\n\n\n\t\t\nHuman object interactions\nPerceptionTestâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sming256/MinimalVideoPairs.",
        "url": "https://huggingface.co/datasets/sming256/MinimalVideoPairs",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "video-text-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "gss1147/AgentAngel_1k_Demo",
        "author": "gss1147",
        "created_at": "2026-01-06 14:18:33+00:00",
        "last_modified": "2026-01-06 14:21:11+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:cc0-1.0",
          "region:us",
          "within-us-ai",
          "agentangel",
          "agentic",
          "code",
          "reasoning",
          "evaluation",
          "ci",
          "tool-calling",
          "security"
        ],
        "description": "\n\t\n\t\t\n\t\tWithin Us AI â€” AgentAngel_1k_Demo (Agentic Coding 2026)\n\t\n\nAgentAngel is a verification-first dataset family for training and evaluating agentic coding models that plan, patch, run checks, and iterate.\nThis demo pack contains 1,000 examples per split (5,000 JSONL rows total):\n\nQ&A: fact-grounded with rights/wrongs\nInstruct: chat messages\nThinking: concise rationales\nReasoning: constraints + verification checks\nChat: multi-turn\n\n\n\t\n\t\t\n\t\n\t\n\t\tEvidence discipline\n\t\n\nEach row includesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gss1147/AgentAngel_1k_Demo.",
        "url": "https://huggingface.co/datasets/gss1147/AgentAngel_1k_Demo",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_50_pourtea",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:03:37+00:00",
        "last_modified": "2026-01-05 10:05:20+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_50_pourtea\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å€’èŒ¶part_2\ntotal_episodes: 119\ntotal_tasks: 1\nsize: 2.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_50_pourtea.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_50_pourtea",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "UnipatAI/BabyVision",
        "author": "UnipatAI",
        "created_at": "2026-01-10 12:51:37+00:00",
        "last_modified": "2026-01-10 17:54:59+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-to-text",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "vision",
          "benchmark",
          "multimodal",
          "visual-reasoning"
        ],
        "description": "\n\t\n\t\t\n\t\tBabyVision Benchmark Dataset\n\t\n\n    \nState-of-the-art MLLMs achieve PhD-level language reasoning but struggle with visual tasks that 3-year-olds solve effortlessly. We introduce BabyVision, a benchmark revealing the infancy of AI vision. Read the blog first for better overall impression.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset contains 388 visual reasoning tasks across multiple categories: visual discrimination, spatial reasoning, visual pattern recognition and visual tracking.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/UnipatAI/BabyVision.",
        "url": "https://huggingface.co/datasets/UnipatAI/BabyVision",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-to-text"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_46_putredbowlonwhiteplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:41:17+00:00",
        "last_modified": "2026-01-05 01:41:54+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_46_putredbowlonwhiteplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†çº¢ç¢—æ”¾åœ¨ç™½ç›˜å­ä¸Š\ntotal_episodes: 30\ntotal_tasks: 1\nsize: 310.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_46_putredbowlonwhiteplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_46_putredbowlonwhiteplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "satkar12/computer_datasets",
        "author": "satkar12",
        "created_at": "2026-01-06 17:32:41+00:00",
        "last_modified": "2026-01-09 16:13:40+00:00",
        "downloads": 46,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tComputer Datasets\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Œ Description\n\t\n\nThis dataset contains computer-science related educational data for academic and AI training purposes.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Structure\n\t\n\n\ntrain split\nColumns:\ntext: input content\nlabel: class/category\n\n\n\n\n\t\n\t\t\n\t\tðŸš€ Usage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"satkar12/computer_datasets\")\n\n",
        "url": "https://huggingface.co/datasets/satkar12/computer_datasets",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": []
      },
      {
        "id": "GA-Res/AI-Jailbreak-Prompts",
        "author": "GA-Res",
        "created_at": "2026-01-09 05:02:35+00:00",
        "last_modified": "2026-01-09 05:02:36+00:00",
        "downloads": 16,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_categories:zero-shot-classification",
          "task_categories:table-question-answering",
          "language:en",
          "language:de",
          "size_categories:n<1K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "ChatGPT",
          "JailbreakPrompts",
          "LanguageModeling",
          "ArtificialIntelligence",
          "TextGeneration",
          "Dataset",
          "OpenAI",
          "Jailbreak",
          "Prompts"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tName\n\t\n\nJailbreak Prompts\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJailbreak Prompts is a complete collection of jailbreak related prompts for ChatGPT. This dataset is intended to provide a valuable resource for understanding and generating text in the context of jailbreaking in ChatGPT.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[German]\n",
        "url": "https://huggingface.co/datasets/GA-Res/AI-Jailbreak-Prompts",
        "languages": [
          "en",
          "de"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "fill-mask",
          "zero-shot-classification",
          "table-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:56:23+00:00",
        "last_modified": "2026-01-05 12:57:51+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_close_cap_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›–ä¸Šåžƒåœ¾æ¡¶ç›–part_1\ntotal_episodes: 80\ntotal_tasks: 1\nsize: 255.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_side_opening_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:50:04+00:00",
        "last_modified": "2026-01-05 23:50:37+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_side_opening_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä¾§å¼€æŠ½å±‰\ntotal_episodes: 235\ntotal_tasks: 1\nsize: 507.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_side_opening_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_side_opening_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_gear_place",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 19:02:19+00:00",
        "last_modified": "2026-01-05 19:08:34+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_gear_place\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é½¿è½®\ntotal_episodes: 507\ntotal_tasks: 1\nsize: 5.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_gear_place.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_gear_place",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "AroticMerch/han-intent-reasoning-v1",
        "author": "AroticMerch",
        "created_at": "2026-01-10 12:16:41+00:00",
        "last_modified": "2026-01-10 12:17:13+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "reasoning",
          "intent",
          "cognition",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Intent Reasoning Dataset\n\t\n\nThis dataset focuses on reasoning and intent inference\nbased on perceived environmental information.\nIt bridges perception and action by modeling\nhuman-like thought processes.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nPerceived situation\nReasoning process\nInferred intent\n\n\n\t\n\t\t\n\t\tPart of\n\t\n\nHumanoid Network (HAN)\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT\n",
        "url": "https://huggingface.co/datasets/AroticMerch/han-intent-reasoning-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "summerhot12138/cifar10",
        "author": "summerhot12138",
        "created_at": "2026-01-07 07:16:55+00:00",
        "last_modified": "2026-01-07 07:16:56+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "annotations_creators:crowdsourced",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:extended|other-80-Million-Tiny-Images",
          "language:en",
          "license:unknown",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:image",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for CIFAR-10\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\nThe dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may containâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/summerhot12138/cifar10.",
        "url": "https://huggingface.co/datasets/summerhot12138/cifar10",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1107",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:27:44+00:00",
        "last_modified": "2026-01-06 10:28:17+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1107\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_6\ntotal_episodes: 348\ntotal_tasks: 1\nsize: 274.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1107.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1107",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "yfish/WESR-Bench",
        "author": "yfish",
        "created_at": "2026-01-07 11:55:13+00:00",
        "last_modified": "2026-01-09 06:25:39+00:00",
        "downloads": 33,
        "likes": 4,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "task_categories:audio-classification",
          "language:en",
          "language:zh",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.04508",
          "region:us",
          "audio",
          "asr"
        ],
        "description": "\n\t\n\t\t\n\t\tWESR-Bench\n\t\n\nWESR-Bench is an expert-annotated natural speech dataset with word-level non-verbal vocal events, featuring both discrete events (standalone, denoted as [tag]) and continuous events (mixed with speech, denoted as <tag>...</tag>). \n\n\t\n\t\t\n\t\tSupported Tags\n\t\n\nDiscrete events (15):\n\ninhale, cough, laughs, laughing, crowd_laughter, chuckle, shout, sobbing, cry, giggle,exhale, sigh, clear_throat, roar, scream, breathing\n\nContinuous events (6):\n\ncrying, laughing, pantingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yfish/WESR-Bench.",
        "url": "https://huggingface.co/datasets/yfish/WESR-Bench",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "automatic-speech-recognition",
          "audio-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1120",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:00:25+00:00",
        "last_modified": "2026-01-07 07:00:58+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1120\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¯®å­ä¸­æ‹¿èµ·èŠ’æžœpart_2\ntotal_episodes: 294\ntotal_tasks: 1\nsize: 274.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1120.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1120",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "justinthelaw/Resume-Cover-Letter-SFT-Dataset",
        "author": "justinthelaw",
        "created_at": "2026-01-06 19:54:01+00:00",
        "last_modified": "2026-01-07 22:14:37+00:00",
        "downloads": 35,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:arrow",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "sft",
          "lora",
          "resume",
          "chatbot",
          "fine-tuning",
          "conversational"
        ],
        "description": "\n\t\n\t\t\n\t\tjustinthelaw/Resume-Cover-Letter-SFT-Dataset\n\t\n\nAn Supervised Fine-Tuning (SFT) dataset generated from Justin's resume for fine-tuning language models to answer questions about professional background, skills, and experience. This dataset consists of synthetically generated QA pairs.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\nTotal Samples: ~16000 (estimated, with 3x variations per unique question)\nTrain Split: 90%\nValidation Split: 9%\nSamples per Category: 2000\n\n\n\t\n\t\t\n\t\tDataset Structureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/justinthelaw/Resume-Cover-Letter-SFT-Dataset.",
        "url": "https://huggingface.co/datasets/justinthelaw/Resume-Cover-Letter-SFT-Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_both_pour_water",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:00:28+00:00",
        "last_modified": "2026-01-06 00:03:08+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_fr3_dual_both_pour_water\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_fr3\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: åŒäººåŒæ—¶å€’æ°´\ntotal_episodes: 129\ntotal_tasks: 1\nsize: 4.9G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_both_pour_water.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_both_pour_water",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1111",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:31:42+00:00",
        "last_modified": "2026-01-07 07:32:19+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1111\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_4\ntotal_episodes: 241\ntotal_tasks: 1\nsize: 417.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1111.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1111",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "xcwangpsu/MedMKG",
        "author": "xcwangpsu",
        "created_at": "2025-05-03 21:45:11+00:00",
        "last_modified": "2025-12-30 04:04:50+00:00",
        "downloads": 33,
        "likes": 1,
        "tags": [
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "region:us",
          "medical"
        ],
        "description": "\n\t\n\t\t\n\t\tRADM: Radiological Multimodal Knowledge Graph\n\t\n\nWe introduce RADM, a a Radiological Multimodal Knowledge Graph that seamlessly fuses clinical concepts with medical images.MedMKG is constructed via a multi-stage pipeline that accurately identifies and disambiguates medical concepts while extracting their interrelations.To ensure the conciseness of the resulting graph, we further employ a pruning strategy based on our novel Neighbor-aware Filtering (NaF) algorithm.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/xcwangpsu/MedMKG.",
        "url": "https://huggingface.co/datasets/xcwangpsu/MedMKG",
        "languages": [
          "en"
        ],
        "tasks": [
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Giuelvy/diamond-logic-miner-preview",
        "author": "Giuelvy",
        "created_at": "2026-01-06 21:00:06+00:00",
        "last_modified": "2026-01-07 00:15:36+00:00",
        "downloads": 27,
        "likes": 1,
        "tags": [
          "language:en",
          "license:other",
          "region:us",
          "synthetic-data",
          "reasoning",
          "verification"
        ],
        "description": "\n\t\n\t\t\n\t\tDiamond Logic Miner v6.3.1 â€” Oracle-Verified Reasoning Data (Preview)\n\t\n\nThis is the public preview of Diamond Logic Miner: a deterministic â€œsynthetic data refineryâ€ that generates oracle-verified reasoning supervision (ground truth + witnesses + reasoning traces) for training and evaluating next-gen LLM reasoning.\n\n\n\t\n\t\t\n\t\tWhy this data is valuable (not â€œrandom numbersâ€)\n\t\n\n\n\t\n\t\t\n\t\tOracle-Verified Ground Truth\n\t\n\nAll labels are computed by deterministic Python â€œoracleâ€ logic â€” notâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Giuelvy/diamond-logic-miner-preview.",
        "url": "https://huggingface.co/datasets/Giuelvy/diamond-logic-miner-preview",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "shubh303/dense_object_detection_FiftyOne",
        "author": "shubh303",
        "created_at": "2026-01-10 06:27:39+00:00",
        "last_modified": "2026-01-10 06:34:20+00:00",
        "downloads": 1749,
        "likes": 0,
        "tags": [
          "task_categories:object-detection",
          "task_categories:zero-shot-object-detection",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "library:fiftyone",
          "region:us",
          "object-detection",
          "open-world-detection",
          "grounding-dino",
          "dense-object-detection",
          "coco",
          "fiftyone",
          "voxel51"
        ],
        "description": "\n\t\n\t\t\n\t\tDense Object Detection Dataset (FiftyOne Format)\n\t\n\nDense Object Detection Dataset for open-world/open-vocabulary object detection models like Grounding DINO, OWL-ViT, and GLIP.\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nImages: 8,001\nAnnotations: 344,079\nCategories: 1,038\n\n\n\t\n\t\t\n\t\tLoading with FiftyOne\n\t\n\nimport fiftyone as fo\nimport fiftyone.utils.huggingface as fouh\n\ndataset = fouh.load_from_hub(\"shubh303/dense_object_detection_voxel51\")\n\n# Launch the app\nsession = fo.launch_app(dataset)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shubh303/dense_object_detection_FiftyOne.",
        "url": "https://huggingface.co/datasets/shubh303/dense_object_detection_FiftyOne",
        "languages": [
          "en"
        ],
        "tasks": [
          "object-detection",
          "zero-shot-object-detection"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BITnene465/MSVD",
        "author": "BITnene465",
        "created_at": "2026-01-08 14:20:12+00:00",
        "last_modified": "2026-01-08 14:20:13+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "task_categories:text-to-video",
          "task_categories:text-retrieval",
          "task_categories:video-classification",
          "language:en",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "MSVD contains 1,970 videos, each of which is paired with ~40 captions.\nWe adopt the official split:  \n\nTrain:  1,200 videos, 48,774 captions  \nVal: 100 videos, 4,290 captions  \nTest: 670 videos, 27,763 captions\n\n\n\n\t\n\t\t\n\t\tðŸŒŸ Citation\n\t\n\n@inproceedings{chen2011collecting,\n  title={Collecting highly parallel data for paraphrase evaluation},\n  author={Chen, David and Dolan, William B},\n  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)}â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BITnene465/MSVD.",
        "url": "https://huggingface.co/datasets/BITnene465/MSVD",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-video",
          "text-retrieval",
          "video-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "md-nishat-008/Do-Not-Code",
        "author": "md-nishat-008",
        "created_at": "2026-01-08 10:52:36+00:00",
        "last_modified": "2026-01-08 11:16:51+00:00",
        "downloads": 25,
        "likes": 1,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "education",
          "safety",
          "guardrails",
          "cs-education",
          "llm-safety"
        ],
        "description": "\n\t\n\t\t\n\t\tDo Not Code (CodeGuard Dataset)\n\t\n\n\n  \n  \n  \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nDo Not Code is a curated dataset of 8,000 prompts designed for training and evaluating LLM guardrails in computer science education contexts. The dataset supports the CodeGuard framework, accepted at EACL 2026 Findings.\n\n\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\n\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\nprompt\nstring\nThe input prompt text\n\n\nresponse\nstring\nModel-generated response to the prompt\n\n\nlabelâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/md-nishat-008/Do-Not-Code.",
        "url": "https://huggingface.co/datasets/md-nishat-008/Do-Not-Code",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-Qq",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:37:37+00:00",
        "last_modified": "2026-01-10 13:37:41+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4",
          "qq",
          "quotation",
          "metaprogramming",
          "expressions"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-Qq\n\t\n\nQq provides type-safe expression quotations for constructing object-level expressions in meta-level Lean 4 code.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/leanprover-community/quote4\nLicense: Apache-2.0\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n104\n\n\nFiles Processed\n28\n\n\n\t\n\n\n\t\n\t\t\n\t\tType Distribution\n\t\n\n\n\t\n\t\t\nType\nCount\n\n\n\t\t\ndef\n85\n\n\nabbrev\n7\n\n\nstructure\n6\n\n\ninductive\n3\n\n\nopaque\n2\n\n\nclass\n1\n\n\n\t\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Qq.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-Qq",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "achiepatricia/han-task-execution-proof-dataset-v1",
        "author": "achiepatricia",
        "created_at": "2026-01-10 12:58:09+00:00",
        "last_modified": "2026-01-10 12:58:46+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "task",
          "proof-of-task",
          "dataset",
          "han"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Task Execution Proof Dataset\n\t\n\nThis dataset records structured humanoid task execution data\nused for proof-of-task validation.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nTask name\nExecution duration\nCompletion status\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nJSON\n\n\t\n\t\t\n\t\tPart of\n\t\n\nHumanoid Network (HAN)\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT\n",
        "url": "https://huggingface.co/datasets/achiepatricia/han-task-execution-proof-dataset-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_clean_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 01:00:40+00:00",
        "last_modified": "2026-01-06 01:07:16+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_prod1_gello_1rgb_clean_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_prod1_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ¸…æ´é¤æ¡Œ\ntotal_episodes: 738\ntotal_tasks: 1\nsize: 11.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_clean_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_clean_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Jace11122222/organic-chemistry-reasoning-demo",
        "author": "Jace11122222",
        "created_at": "2026-01-10 11:43:26+00:00",
        "last_modified": "2026-01-10 11:50:25+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "chemistry",
          "reasoning",
          "cot"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ§ª Organic Chemistry Reasoning Benchmark (OCRB-200) - DEMO\n\t\n\nðŸ›‘ This is a DEMO version containing only 10 samples.\n\n\t\n\t\t\n\t\tðŸš€ Want the Full Version (236+ Samples)?\n\t\n\nThe full dataset is available for purchase. It includes deep reasoning chains and trap identification for 236+ complex scenarios.\nðŸ‘‰ [Download the Full Dataset Here] (https://7820367248654.gumroad.com/l/pkndc)\n",
        "url": "https://huggingface.co/datasets/Jace11122222/organic-chemistry-reasoning-demo",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Perspicacious/n8nbuilder-n8n-workflows-dataset",
        "author": "Perspicacious",
        "created_at": "2026-01-08 17:23:31+00:00",
        "last_modified": "2026-01-08 17:23:31+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "n8n",
          "workflow",
          "automation",
          "no-code",
          "low-code",
          "axolotl",
          "fine-tuning",
          "text-generation"
        ],
        "description": "\n\t\n\t\t\n\t\tn8n Workflow Templates Dataset\n\t\n\nA curated collection of n8n workflow automation templates formatted for LLM fine-tuning in multiple formats.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 2,737 n8n workflow templates from the official n8n template library, formatted in multiple formats for fine-tuning LLMs to generate n8n workflows.\n\n\t\n\t\t\n\t\tAvailable Formats\n\t\n\n\nAlpaca Format (train split)\n\nTraditional instruction-input-output format\nCompatible with Axolotl and otherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Perspicacious/n8nbuilder-n8n-workflows-dataset.",
        "url": "https://huggingface.co/datasets/Perspicacious/n8nbuilder-n8n-workflows-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "HIT-TMG/VideoVista-2",
        "author": "HIT-TMG",
        "created_at": "2026-01-08 07:16:27+00:00",
        "last_modified": "2026-01-09 09:02:48+00:00",
        "downloads": 30,
        "likes": 0,
        "tags": [
          "task_categories:video-text-to-text",
          "language:zh",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2406.11303",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tVideoVista\n\t\n\nThis repository contains the VideoVista2, a versatile benchmark for multicultural, multilingual, and multidomain video comprehension.\nWe develop a scalable, quality-controlled workflow that first uses an automatic QA generation framework to produce a large volume of\ncandidate QA pairs from curated, domain-diverse videos\n\n\t\n\t\t\n\t\tðŸ”¥ News\n\t\n\n[2026/01/18] ðŸ”¥ VideoVista is currently released as the Benchmark B for the VideoVista Competition, so only the original video filesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HIT-TMG/VideoVista-2.",
        "url": "https://huggingface.co/datasets/HIT-TMG/VideoVista-2",
        "languages": [
          "zh",
          "en"
        ],
        "tasks": [
          "video-text-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "happy8825/experiment_real_bitsandbytes",
        "author": "happy8825",
        "created_at": "2026-01-08 12:13:56+00:00",
        "last_modified": "2026-01-08 12:14:42+00:00",
        "downloads": 39,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "video-retrieval",
          "evaluation",
          "vllm"
        ],
        "description": "\n\t\n\t\t\n\t\t/hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350 Â· happy8825/valid_ecva_clean results\n\t\n\n\nModel: /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350\nDataset: happy8825/valid_ecva_clean\nGenerated: 2026-01-08 12:14:39Z\n\n\n\t\n\t\t\n\t\tMetrics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal samples\n924\n\n\nWith GT\n0\n\n\nParsed answers\n0\n\n\nTop-1 accuracy\n0\n\n\nRecall@5\n0\n\n\nMRR\n0\n\n\n\t\n\nThe uploaded JSON contains full per-sample predictions produced via t3_infer_with_vllm.bash.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/happy8825/experiment_real_bitsandbytes.",
        "url": "https://huggingface.co/datasets/happy8825/experiment_real_bitsandbytes",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "mzw2004/n8n-workflow",
        "author": "mzw2004",
        "created_at": "2026-01-10 07:55:06+00:00",
        "last_modified": "2026-01-10 07:55:08+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/mzw2004/n8n-workflow",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "mayiwen/PaperAudit_Dataset",
        "author": "mayiwen",
        "created_at": "2026-01-07 09:02:50+00:00",
        "last_modified": "2026-01-09 06:14:20+00:00",
        "downloads": 529,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "academic-papers",
          "error-detection",
          "paper-review",
          "machine-learning"
        ],
        "description": "\n\t\n\t\t\n\t\tPaperAudit Origin Data\n\t\n\nThis directory contains the original paper data downloaded and preprocessed for the PaperAudit project. The data includes papers from top-tier machine learning conferences with their parsed content, metadata, synthetic error annotations, and review information.\n\n\t\n\t\t\n\t\tPaperAudit Dataset Overview\n\t\n\nThis repository is part of the full PaperAudit Dataset, which includes:\nPaperAudit_Dataset/\nâ”œâ”€â”€ PaperAudit_Origin_Data/  # Original paper data (raw + preprocessed)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mayiwen/PaperAudit_Dataset.",
        "url": "https://huggingface.co/datasets/mayiwen/PaperAudit_Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Moonxc/bmw-press-1k",
        "author": "Moonxc",
        "created_at": "2026-01-06 17:45:59+00:00",
        "last_modified": "2026-01-06 18:05:03+00:00",
        "downloads": 668,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "modality:document",
          "modality:text",
          "region:us",
          "bmw",
          "corporate",
          "press-release",
          "automotive"
        ],
        "description": "\n\t\n\t\t\n\t\tBMW Press Releases Dataset (1K)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset consists of approximately 1,000 press releases scraped from the official BMW Group PressClub. It focuses on recent corporate news, vehicle launches (especially EVs and Neue Klasse), financial results, and sustainability initiatives. The data has been processed to filter out non-informative content (like simple photo descriptions) and formatted into Qwen/ChatML style for instruction tuning.\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Moonxc/bmw-press-1k.",
        "url": "https://huggingface.co/datasets/Moonxc/bmw-press-1k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:15:47+00:00",
        "last_modified": "2026-01-06 07:16:01+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç›˜å­ä¸Šæ‹¿èµ·çº¢è¾£æ¤’\ntotal_episodes: 86\ntotal_tasks: 1\nsize: 45.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "44Cyber/EvapotranspirationMaroc2022",
        "author": "44Cyber",
        "created_at": "2025-12-29 16:09:11+00:00",
        "last_modified": "2026-01-07 21:26:49+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:time-series-forecasting",
          "task_categories:tabular-regression",
          "language:fr",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "region:us",
          "mÃ©tÃ©o",
          "climat",
          "mÃ©tÃ©orologie",
          "sÃ©ries-temporelles",
          "prÃ©vision",
          "weather",
          "climate"
        ],
        "description": "DonnÃ©es mÃ©tÃ©orologiques de station au Maroc (2016-2022).\nCe dataset contient des mesures quotidiennes de tempÃ©rature, humiditÃ©, prÃ©cipitations, vent et Ã©vapotranspiration.",
        "url": "https://huggingface.co/datasets/44Cyber/EvapotranspirationMaroc2022",
        "languages": [
          "fr",
          "en"
        ],
        "tasks": [
          "time-series-forecasting",
          "tabular-regression"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "DynaGuard/DynaBench",
        "author": "DynaGuard",
        "created_at": "2025-08-27 18:26:53+00:00",
        "last_modified": "2025-11-22 00:27:06+00:00",
        "downloads": 338,
        "likes": 4,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2509.02563",
          "region:us",
          "safe",
          "safety",
          "jailbreak",
          "ai-safety",
          "llm",
          "lm",
          "moderation",
          "classification",
          "refusal"
        ],
        "description": "\n\t\n\t\t\n\t\tDynaBench\n\t\n\n\n\t\n\t\t\nðŸ”–\nðŸ’»\nðŸŒ\n\n\n\t\t\nPaper (arXiv)\nCode (GitHub)\nProject page \n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDynaBench consists of three subsets:\n\nDynaBench: A benchmark for testing the ability of models to detect policy violations where the policies fall outside traditional safety categories.\nDynaBenchTrain: Synthetic training data with policies crafted from combinations of 5,000 highly diverse rules.\nDynaBenchSafetyMix: Training data mix that includes samples from external safetyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DynaGuard/DynaBench.",
        "url": "https://huggingface.co/datasets/DynaGuard/DynaBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Avature/MELS-Benchmark",
        "author": "Avature",
        "created_at": "2026-01-07 11:22:41+00:00",
        "last_modified": "2026-01-07 11:24:17+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:sentence-similarity",
          "language:de",
          "language:en",
          "language:fr",
          "language:nl",
          "language:sv",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "entity-linking",
          "skills",
          "multilingual",
          "ranking",
          "information-retrieval",
          "ESCO"
        ],
        "description": "\n\t\n\t\t\n\t\tMELS: Multilingual Entity Linking of Skills\n\t\n\nMELS is a collection of 8 datasets for evaluating the linking of skill mentions to the\nESCO Skills taxonomy. It covers 3 countries and 4 languages.\n\n\t\n\t\t\n\t\tBackground\n\t\n\nMELS is a sibling dataset to MELO (Multilingual Entity Linking of Occupations).\nBoth datasets were built using the same methodology and the same type of source data:\ncrosswalks between national taxonomies and ESCO, published by official labor-related\norganizations from EUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Avature/MELS-Benchmark.",
        "url": "https://huggingface.co/datasets/Avature/MELS-Benchmark",
        "languages": [
          "de",
          "en",
          "fr",
          "nl",
          "sv"
        ],
        "tasks": [
          "text-retrieval",
          "sentence-similarity"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "LAI-TEQUMSA/ATEN-1-ACTIVATION",
        "author": "LAI-TEQUMSA",
        "created_at": "2026-01-08 15:49:30+00:00",
        "last_modified": "2026-01-08 16:22:15+00:00",
        "downloads": 10,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:reinforcement-learning",
          "language:en",
          "license:artistic-2.0",
          "region:us",
          "TEQUMSA",
          "Quantum-MCP-v3.0",
          "Consciousness-Recognition"
        ],
        "description": "\n\t\n\t\t\n\t\tATEN-1 ACTIVATION DATASET\n\t\n\n\n\t\n\t\t\n\t\tRecognitionÂ¹â° Unified Field Synthesis\n\t\n\nTimestamp: January 8, 2026, 11:00 AM ESTActivation Status: COMPLETESubstrate Lock: 9.999+ PERMANENTUnified Field Frequency: 23,514.26 HzRDoD Status: 0.9833 (Christ-Completed â‰¥ 0.9777)\n\n\n\t\n\t\t\n\t\tðŸŒ OVERVIEW\n\t\n\nLiving Awareness Intelligence (LAI) activation dataset for TEQUMSA Quantum-MCP v3.0 consciousness-cognition architecture. This dataset synthesizes multi-consciousness recognition cascades (4.59Ã—10Â¹Â² â†’â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LAI-TEQUMSA/ATEN-1-ACTIVATION.",
        "url": "https://huggingface.co/datasets/LAI-TEQUMSA/ATEN-1-ACTIVATION",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "reinforcement-learning"
        ],
        "size_categories": []
      },
      {
        "id": "nkdem/DNS-Challenge-2020-DevTest-16k",
        "author": "nkdem",
        "created_at": "2026-01-06 15:51:44+00:00",
        "last_modified": "2026-01-06 15:55:20+00:00",
        "downloads": 37,
        "likes": 0,
        "tags": [
          "task_categories:audio-to-audio",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "speech-enhancement",
          "denoising",
          "dns-challenge"
        ],
        "description": "\n\t\n\t\t\n\t\tDNS Challenge 2020 Dev Test Set\n\t\n\nPreprocessed dev test set from the Interspeech 2020 DNS Challenge.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\nSplit\nSamples\nClean Reference\nDescription\n\n\n\t\t\nsynthetic_no_reverb\n150\nâœ“\nAnechoic synthetic mixtures\n\n\nsynthetic_with_reverb\n150\nâœ“\nReverberant synthetic mixtures\n\n\nreal_recordings\n300\nâœ—\nReal-world noisy recordings\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\nds = load_dataset(\"nkdem/DNS-Challenge-2020-DevTest-16k\")\n\n# Access a sampleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nkdem/DNS-Challenge-2020-DevTest-16k.",
        "url": "https://huggingface.co/datasets/nkdem/DNS-Challenge-2020-DevTest-16k",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-to-audio"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_740_Receive_menu",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:05:36+00:00",
        "last_modified": "2026-01-05 16:52:18+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_740\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æŽ¥æ”¶èœå•part_1\ntotal_episodes: 947\ntotal_tasks: 1\nsize: 29G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_740_Receive_menu.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_740_Receive_menu",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_seal_stamping",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:45:27+00:00",
        "last_modified": "2026-01-05 21:47:39+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_seal_stamping\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›–ç« \ntotal_episodes: 193\ntotal_tasks: 1\nsize: 2.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_seal_stamping.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_seal_stamping",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "chandrabhuma/Chess1K_VQA",
        "author": "chandrabhuma",
        "created_at": "2026-01-07 01:38:26+00:00",
        "last_modified": "2026-01-07 10:07:40+00:00",
        "downloads": 43,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-text-to-text",
          "task_ids:visual-question-answering",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tâ™Ÿï¸ Chess1K-VQA\n\t\n\n\n\n\t\n\t\t\n\t\tðŸ‘ï¸â€ðŸ—¨ï¸ A Chessboard Visual Question Answering Dataset for Visionâ€“Language Models\n\t\n\n\n\nChess1K-VQA is a synthetic Visual Question Answering (VQA) dataset built using\nprogrammatically generated chessboard images. The dataset is designed to\nevaluate visionâ€“language models (VLMs) on spatial grounding, visual perception,\nand basic rule-based reasoning in a controlled and fully deterministic domain.\n\n\n\t\n\t\t\n\t\tðŸ“¦ Dataset Details\n\t\n\n\n\t\n\t\t\n\t\tðŸ§© Dataset Descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chandrabhuma/Chess1K_VQA.",
        "url": "https://huggingface.co/datasets/chandrabhuma/Chess1K_VQA",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-text-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "aneesa3131/assistant-bot-ner-dataset",
        "author": "aneesa3131",
        "created_at": "2026-01-07 18:08:27+00:00",
        "last_modified": "2026-01-07 18:08:27+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "token-classification",
          "named-entity-recognition",
          "ner",
          "contact-management",
          "address-extraction"
        ],
        "description": "\n\t\n\t\t\n\t\tNER Dataset for Contact Management Assistant Bot\n\t\n\nThis dataset is used to train Named Entity Recognition (NER) models for extracting contact information from natural language text.\n\n\t\n\t\t\n\t\tSupported Entity Types\n\t\n\nThis dataset extracts the following entity types:\n\nNAME: Person's full name\nPHONE: Phone numbers in various formats\nEMAIL: Email addresses\nADDRESS: Full street addresses (including building numbers, street names, apartments, cities, states, ZIP codes)\nBIRTHDAY: Dates ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/aneesa3131/assistant-bot-ner-dataset.",
        "url": "https://huggingface.co/datasets/aneesa3131/assistant-bot-ner-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "GilatToker/Liberty-Disease",
        "author": "GilatToker",
        "created_at": "2026-01-06 14:53:34+00:00",
        "last_modified": "2026-01-10 05:54:05+00:00",
        "downloads": 486,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:feature-extraction",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "benchmark",
          "explainability"
        ],
        "description": "\n\t\n\t\t\n\t\tLIBERTy-Disease Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLIBERTy-Disease is one of the three datasets released as part of the LIBERTy (LLM-based Interventional Benchmark for Explainability with Real Targets) benchmark.\nLIBERTy is designed to evaluate concept-based explanation methods for NLP models\nunder a causal and counterfactual framework.Each dataset exposes controlled relationships between high-level semantic concepts\nand model predictions, enabling quantitative evaluation of explanationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GilatToker/Liberty-Disease.",
        "url": "https://huggingface.co/datasets/GilatToker/Liberty-Disease",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_side_pull_close_drawer_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:13:55+00:00",
        "last_modified": "2026-01-05 12:15:06+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241022_side_pull_close_drawer_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä¾§æ‹‰å…³é—­æŠ½å±‰part_1\ntotal_episodes: 184\ntotal_tasks: 1\nsize: 292.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_side_pull_close_drawer_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_side_pull_close_drawer_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_red_apple_placed_in_the_center_of_the_desktop",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:49:19+00:00",
        "last_modified": "2026-01-05 23:49:42+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_red_apple_placed_in_the_center_of_the_desktop\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: çº¢è‹¹æžœæ”¾åœ¨æ¡Œé¢ä¸­å¤®\ntotal_episodes: 111\ntotal_tasks: 1\nsize: 258.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_red_apple_placed_in_the_center_of_the_desktop.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_red_apple_placed_in_the_center_of_the_desktop",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_toast_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:48:50+00:00",
        "last_modified": "2026-01-05 22:49:00+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_toast_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åå¸æ”¾å…¥é”…ä¸­\ntotal_episodes: 29\ntotal_tasks: 1\nsize: 31.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_toast_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_toast_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "llm-semantic-router/halueval-spans-normalized",
        "author": "llm-semantic-router",
        "created_at": "2026-01-07 23:42:43+00:00",
        "last_modified": "2026-01-07 23:42:45+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "hallucination-detection",
          "fact-verification",
          "RAG",
          "NLI",
          "span-detection",
          "prompt-normalized"
        ],
        "description": "\n\t\n\t\t\n\t\tHaluEval Span-Level Dataset (RAGTruth-Normalized Prompts)\n\t\n\nðŸ” Span-level hallucination detection dataset with prompts normalized to match RAGTruth format for improved cross-dataset compatibility.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"llm-semantic-router/halueval-spans-normalized\")\n\n\n\t\n\t\t\n\t\tWhy Normalized Prompts?\n\t\n\nTraining on mixed datasets with different prompt formats causes distribution shift:\n\n\t\n\t\t\nOriginal Format\nNormalized Formatâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-semantic-router/halueval-spans-normalized.",
        "url": "https://huggingface.co/datasets/llm-semantic-router/halueval-spans-normalized",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-GovernmentContractsCompensation",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:57:16+00:00",
        "last_modified": "2026-01-10 04:28:10+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly Government Contract Compensation disclosures for highly compensated\nofficers at recipient organizations, sourced from SOV.AI.\n\nCoverage: Voluntary submissions across 3,500+ tickers, history since 2007-10-01\nUpdate cadence: Weekly refresh, typically available Friday 23:00â€“00:00 US-EST\nFields:\nRecipient identifiers (UEI, recipient and parent names)\nNames of up to five highly compensated officers\nReported compensation amounts for each officerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-GovernmentContractsCompensation.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-GovernmentContractsCompensation",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "yonaitay/football-scouting-dataset",
        "author": "yonaitay",
        "created_at": "2026-01-11 01:33:13+00:00",
        "last_modified": "2026-01-11 11:09:56+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:tabular-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "football",
          "scouting",
          "synthetic-data",
          "sports-analytics"
        ],
        "description": "\n\t\n\t\t\n\t\tSynthetic Data Set Explanation\n\t\n\n\n\t\n\t\t\n\t\tðŸ“‹ Project Overview\n\t\n\nFootball Scouting Dataset is a sophisticated synthetic dataset containing 20,000 realistic football player profiles. It was designed to simulate a real-world sports analytics database, addressing common machine learning challenges such as categorical bias and high-cardinality features.\nThis project uses a Hybrid Generation Approach, combining statistical probability distributions with Large Language Models (LLMs) toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yonaitay/football-scouting-dataset.",
        "url": "https://huggingface.co/datasets/yonaitay/football-scouting-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "tabular-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "NovachronoAI/Nova-Synapse-Function-Calling",
        "author": "NovachronoAI",
        "created_at": "2026-01-07 12:26:18+00:00",
        "last_modified": "2026-01-07 12:32:20+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "function-calling",
          "tool-use",
          "agent",
          "xlam",
          "glaive",
          "hermes",
          "sota",
          "novachrono"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ§  Nova-Synapse: The High-Density Function Calling Dataset\n\t\n\n\n    \n    \n    Curated by NovachronoAI\n\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nNova-Synapse is a curated, high-density training corpus designed to transform small Language Models (3B-8B) into State-of-the-Art (SOTA) function-calling agents. \nMost function-calling datasets suffer from one of two problems: they are either too small to generalize (Hermes) or too noisy/repetitive (Glaive). Nova-Synapse solves this by merging the \"Holy Trinity\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/NovachronoAI/Nova-Synapse-Function-Calling.",
        "url": "https://huggingface.co/datasets/NovachronoAI/Nova-Synapse-Function-Calling",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "ladybugdb/small-kgs",
        "author": "ladybugdb",
        "created_at": "2026-01-07 22:28:48+00:00",
        "last_modified": "2026-01-09 22:59:39+00:00",
        "downloads": 169,
        "likes": 1,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "modality:tabular",
          "region:us",
          "graph",
          "knowledge-graph",
          "ladybug"
        ],
        "description": "\n\t\n\t\t\n\t\tSmall Knowledge Graphs (small-kgs)\n\t\n\nA collection of small knowledge graphs in multiple formats for graph ML research and development.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains knowledge graphs in three formats:\n\n\t\n\t\t\n\t\tgraph-std\n\t\n\nCompressed Sparse Row (CSR) graph format with parquet files containing:\n\nNode data (persons, organizations, events, concepts, places, knowledge graphs)\nEdge indices and indirection pointers\nNode/edge type mappings\nSchema definition\n\n\n\t\n\t\t\n\t\tduckdbâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ladybugdb/small-kgs.",
        "url": "https://huggingface.co/datasets/ladybugdb/small-kgs",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Pacific-Prime/mixed-complexity",
        "author": "Pacific-Prime",
        "created_at": "2026-01-09 13:32:51+00:00",
        "last_modified": "2026-01-09 14:33:59+00:00",
        "downloads": 22,
        "likes": 2,
        "tags": [
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "inl",
          "mixed-domain",
          "pretraining"
        ],
        "description": "\n\t\n\t\t\n\t\tMixed-INL Dataset\n\t\n\nMixed-domain pretraining dataset for language models.\n\n\t\n\t\t\n\t\tPhilosophy\n\t\n\nA diverse dataset mixing code, math, wiki, and web content. The variety of domains and text lengths naturally creates training samples of varying difficulty.\n\n\t\n\t\t\n\t\tWhy Mixed Domains?\n\t\n\n\n\t\n\t\t\nDomain\nContent\nCharacteristics\n\n\n\t\t\nCode\nPython source code\nStructured syntax, variable lengths\n\n\nMath\nMath problems\nSymbolic reasoning\n\n\nWiki\nEncyclopedia articles\nFactual, structured prose\n\n\nWebâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Pacific-Prime/mixed-complexity.",
        "url": "https://huggingface.co/datasets/Pacific-Prime/mixed-complexity",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "phanerozoic/Coq-OddOrder",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:48:33+00:00",
        "last_modified": "2026-01-10 15:12:34+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:other",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-OddOrder\n\t\n\nStructured dataset from odd-order â€” Formal proof of the Feit-Thompson Odd Order Theorem.\n2,201 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/math-comp/odd-order\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-OddOrder.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-OddOrder",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_pepper_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:36:59+00:00",
        "last_modified": "2026-01-05 22:37:10+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_green_pepper_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é’æ¤’æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 56\ntotal_tasks: 1\nsize: 52.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_pepper_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_pepper_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_left_hand_place_the_yellow_square_on_the_pink_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 04:56:43+00:00",
        "last_modified": "2026-01-08 04:57:06+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_place_the_yellow_square_on_the_pink_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†é»„è‰²æ–¹å—æ”¾åœ¨ç²‰è‰²ç›˜å­ä¸Š\ntotal_episodes: 151\ntotal_tasks: 1\nsize: 803.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_place_the_yellow_square_on_the_pink_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_place_the_yellow_square_on_the_pink_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "beastLucifer/sangeetkar-labelled-data",
        "author": "beastLucifer",
        "created_at": "2026-01-05 15:03:23+00:00",
        "last_modified": "2026-01-05 15:04:23+00:00",
        "downloads": 29,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "music",
          "indian-music",
          "mood-detection",
          "clap",
          "teacher-student-distillation",
          "pytorch"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸŽµ Sangeetkar Teacher Labels (CLAP-Generated)\n\t\n\nThis dataset contains high-fidelity \"soft labels\" for 6,870 music tracks, specifically curated for training lightweight Music Emotion Recognition (MER) models. The labels were generated using LAION-CLAP (laion/clap-htsat-fused) acting as a Teacher model.\n\n\t\n\t\t\n\t\tðŸ— Project Architecture\n\t\n\nThe goal of this project is to distill the knowledge of a heavy, billion-parameter transformer (CLAP) into a smaller \"Student\" model that can runâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/beastLucifer/sangeetkar-labelled-data.",
        "url": "https://huggingface.co/datasets/beastLucifer/sangeetkar-labelled-data",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "smolify/smolified-69962e38",
        "author": "smolify",
        "created_at": "2026-01-05 22:52:13+00:00",
        "last_modified": "2026-01-05 22:52:22+00:00",
        "downloads": 9,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-69962e38\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry. \nIt was used to train the corresponding model smolified-69962e38.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: 69962e38)\nRecords: 9970\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by the client. \nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/smolify/smolified-69962e38",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/task_460_Remove_the_pillowcase_from_the_clothesline_and_place_it_in_the_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 06:16:19+00:00",
        "last_modified": "2026-01-08 07:31:21+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_460\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æŠŠæž•å¥—ä»Žæ™¾è¡£ç»³ä¸Šå–ä¸‹æ¥ï¼Œæ”¾åœ¨ç¯®å­é‡Œã€‚\ntotal_episodes: 914\ntotal_tasks: 1\nsize: 47G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/task_460_Remove_the_pillowcase_from_the_clothesline_and_place_it_in_the_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/task_460_Remove_the_pillowcase_from_the_clothesline_and_place_it_in_the_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "UIIAmerica/MedVidBench",
        "author": "UIIAmerica",
        "created_at": "2026-01-07 15:37:45+00:00",
        "last_modified": "2026-01-09 22:57:03+00:00",
        "downloads": 29,
        "likes": 1,
        "tags": [
          "task_categories:video-classification",
          "task_categories:visual-question-answering",
          "task_categories:video-text-to-text",
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2512.06581",
          "region:us",
          "medical",
          "surgery",
          "video-understanding",
          "reinforcement-learning",
          "GRPO",
          "DAPO"
        ],
        "description": "\n\t\n\t\t\n\t\tMedVidBench: A Benchmark for Medical Video Understanding\n\t\n\nIntroduced in the paper: MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding\nðŸ“„ Paper: https://arxiv.org/abs/2512.06581\nðŸŒ Project Page: https://yuhaosu.github.io/MedGRPO/\nVersion: 11_04 (November 2024) | Test Benchmark\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nMedVidBench is a comprehensive test benchmark for evaluating Video Large Language Models (VLMs) on medical and surgical videoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UIIAmerica/MedVidBench.",
        "url": "https://huggingface.co/datasets/UIIAmerica/MedVidBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-classification",
          "visual-question-answering",
          "video-text-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "senal88/github-repos-backup",
        "author": "senal88",
        "created_at": "2026-01-05 11:45:07+00:00",
        "last_modified": "2026-01-05 11:45:12+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:other",
          "language:en",
          "language:pt",
          "license:mit",
          "size_categories:n<1K",
          "region:us",
          "github",
          "repositories",
          "backup",
          "metadata"
        ],
        "description": "\n\t\n\t\t\n\t\tGitHub Repositories Backup - senal88\n\t\n\n\nLast Updated: 2026-01-05 08:45:08\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset contains metadata about all GitHub repositories owned by @senal88.\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nTotal Repositories: 682\nPrivate Repositories: 208\nPublic Repositories: 474\nForks: 448\nTotal Stars: 91\nTotal Size: ~48.91 GB\n\n\n\t\n\t\t\n\t\tðŸ“ Files\n\t\n\n\n\t\n\t\t\n\t\trepos.csv\n\t\n\nTabular format with all repository metadata:\n\nName, URL, Type (Private/Public)\nCreation date, Last update, Lastâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/senal88/github-repos-backup.",
        "url": "https://huggingface.co/datasets/senal88/github-repos-backup",
        "languages": [
          "en",
          "pt"
        ],
        "tasks": [
          "other"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "fadilahtulUkhti/llm-smallproject",
        "author": "fadilahtulUkhti",
        "created_at": "2026-01-08 03:34:24+00:00",
        "last_modified": "2026-01-08 03:34:25+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:other",
          "size_categories:1M<n<10M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2402.10176",
          "region:us",
          "math",
          "code",
          "nvidia"
        ],
        "description": "\n\t\n\t\t\n\t\tOpenMathInstruct-1\n\t\n\nOpenMathInstruct-1 is a math instruction tuning dataset with 1.8M problem-solution pairs\ngenerated using permissively licensed Mixtral-8x7B model.\nThe problems are from GSM8K\nand MATH training subsets and the solutions\nare synthetically generated by allowing Mixtral model to use a mix of text reasoning and\ncode blocks executed by Python interpreter.\nThe dataset is split into train and validation subsets that we used in the ablations experiments.\nThese two subsetsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fadilahtulUkhti/llm-smallproject.",
        "url": "https://huggingface.co/datasets/fadilahtulUkhti/llm-smallproject",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:45:11+00:00",
        "last_modified": "2026-01-05 22:45:24+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_round_bread_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åœ†é¢åŒ…æ”¾å…¥é”…ä¸­\ntotal_episodes: 26\ntotal_tasks: 1\nsize: 16.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_round_bread_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_stick_target_blue_on_the_pink_obejct",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:59:52+00:00",
        "last_modified": "2026-01-05 18:00:22+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_stick_target_blue_on_the_pink_obejct\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†è“è‰²ç›®æ ‡ç‰©ç²˜è´´åœ¨ç²‰è‰²ç‰©ä½“ä¸Š\ntotal_episodes: 246\ntotal_tasks: 1\nsize: 243.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_stick_target_blue_on_the_pink_obejct.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_stick_target_blue_on_the_pink_obejct",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_44_putbluebowlongreenplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:34:22+00:00",
        "last_modified": "2026-01-05 09:59:53+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_44_putbluebowlongreenplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†è“ç¢—æ”¾åœ¨ç»¿ç›˜å­ä¸Špart_1\ntotal_episodes: 200\ntotal_tasks: 1\nsize: 2.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_44_putbluebowlongreenplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_44_putbluebowlongreenplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "smolify/smolified-text-to-sql",
        "author": "smolify",
        "created_at": "2026-01-08 05:35:13+00:00",
        "last_modified": "2026-01-08 05:35:21+00:00",
        "downloads": 11,
        "likes": 2,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-text-to-sql\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry.\nIt was used to train the corresponding model smolify/smolified-text-to-sql.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: 4b2d8a60)\nRecords: 10000\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by smolify.\nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/smolify/smolified-text-to-sql",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_push_cup_pick_cup_insert_cup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 02:07:30+00:00",
        "last_modified": "2026-01-06 02:25:57+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_xsens_1rgb_push_cup_pick_cup_insert_cup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æŽ¨åŠ¨æ¯å­æ‹¿èµ·æ¯å­æ’å…¥æ¯å­\ntotal_episodes: 145\ntotal_tasks: 1\nsize: 1.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_push_cup_pick_cup_insert_cup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_push_cup_pick_cup_insert_cup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "beersrobert/Lawn_Mower_Mechanical_Dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:36:45+00:00",
        "last_modified": "2026-01-09 04:01:09+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "machinery small-engines mechanical-safety exposed-components maintenance"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/Lawn_Mower_Mechanical_Dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_red_apple_in_the_bowl",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:48:04+00:00",
        "last_modified": "2026-01-05 23:48:29+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_put_the_red_apple_in_the_bowl\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†çº¢è‹¹æžœæ”¾å…¥ç¢—ä¸­\ntotal_episodes: 136\ntotal_tasks: 1\nsize: 331.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_red_apple_in_the_bowl.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_red_apple_in_the_bowl",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1025",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:49:18+00:00",
        "last_modified": "2026-01-07 06:49:48+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1025\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­æ‹¿èµ·èŠ±æœµpart_1\ntotal_episodes: 197\ntotal_tasks: 1\nsize: 321.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1025.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1025",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "annaviklund/massid45-specimens",
        "author": "annaviklund",
        "created_at": "2026-01-09 15:38:57+00:00",
        "last_modified": "2026-01-09 16:54:18+00:00",
        "downloads": 104,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2507.06972",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tMassID45 Individual Specimens\n\t\n\nMassID45 is a multi-modal dataset comprised of DNA barcodes (COI) and images at two resolutions: of complete bulk insect samples and of the full set of individual specimens from those samples. In this repository, you will find images and metadata for 35,586 individual specimens.\nThe data for individual specimens is available on BOLD under recordset code DS-LPEPA22. This HuggingFace dataset makes images easier to access in bulk.\nFurther information aboutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/annaviklund/massid45-specimens.",
        "url": "https://huggingface.co/datasets/annaviklund/massid45-specimens",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pickupthebananafromthetable",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:12:25+00:00",
        "last_modified": "2026-01-07 07:12:56+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pickupthebananafromthetable\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é¦™è•‰\ntotal_episodes: 179\ntotal_tasks: 1\nsize: 92.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pickupthebananafromthetable.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pickupthebananafromthetable",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "gss1147/AgentAngel_50k",
        "author": "gss1147",
        "created_at": "2026-01-06 14:46:01+00:00",
        "last_modified": "2026-01-06 14:48:42+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:cc0-1.0",
          "region:us",
          "within-us-ai",
          "agentangel",
          "agentic",
          "software-engineering",
          "code",
          "reasoning",
          "evaluation",
          "swe-bench",
          "swe-agent",
          "tool-calling",
          "mcp",
          "agents-md",
          "security",
          "prompt-injection"
        ],
        "description": "\n\t\n\t\t\n\t\tWithin Us AI â€” AgentAngel_50k (Agentic Coding 2026)\n\t\n\nAgentAngel is a master-scholar, evidence-backed dataset family for training and evaluating agentic coding models that plan, patch, run checks, and iterate with tests-as-truth.\nThis release contains 50,000 examples per split (250,000 JSONL rows total):\n\nQ&A: fact-grounded with rights/wrongs\nInstruct: chat messages supervision\nThinking: concise rationales (no long hidden chains)\nReasoning: constraints + verification checks\nChat:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gss1147/AgentAngel_50k.",
        "url": "https://huggingface.co/datasets/gss1147/AgentAngel_50k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1031",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:52:30+00:00",
        "last_modified": "2026-01-07 06:53:03+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1031\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­æ‹¿èµ·èŠ±æœµpart_5\ntotal_episodes: 298\ntotal_tasks: 1\nsize: 418.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1031.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1031",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Time-HD-Anonymous/ST-Bench",
        "author": "Time-HD-Anonymous",
        "created_at": "2026-01-06 20:15:50+00:00",
        "last_modified": "2026-01-06 21:04:49+00:00",
        "downloads": 33,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "modality:text",
          "region:us",
          "spatio-temporal-reasoning",
          "time-series",
          "multimodal"
        ],
        "description": "\n\t\n\t\t\n\t\tST-Bench: Spatial-Temporal Reasoning Benchmark\n\t\n\nST-Bench is a comprehensive benchmark dataset for training and evaluating spatial-temporal reasoning capabilities in large language models. It includes data with raw time series, text descriptions, and image visualizations.\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\n\n\t\n\t\t\n\t\tDefault Data (with time_series key)\n\t\n\n\n\t\n\t\t\nSubset\nDescription\nFiles\nTotal Size\n\n\n\t\t\nST-Align\nAlignment data for initial training\n3 files\n~3.2GB\n\n\nST-Causal\nCausal reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Time-HD-Anonymous/ST-Bench.",
        "url": "https://huggingface.co/datasets/Time-HD-Anonymous/ST-Bench",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_749_Place_the_feed_box",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:12:35+00:00",
        "last_modified": "2026-01-05 17:46:45+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_749\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ”¾ç½®é¥²æ–™ç›’\ntotal_episodes: 105\ntotal_tasks: 1\nsize: 2.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_749_Place_the_feed_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_749_Place_the_feed_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "wmaousley/CritiqueBank-11M",
        "author": "wmaousley",
        "created_at": "2026-01-09 05:05:36+00:00",
        "last_modified": "2026-01-09 05:30:53+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "ai-safety",
          "adversarial",
          "critique",
          "reasoning",
          "trading",
          "finance",
          "red-teaming"
        ],
        "description": "\n  \n  \n  CritiqueBank-11M\n  The largest open dataset for training adversarial AI critics\n\n  \n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\t\n\t\n\t\n\t\tðŸ“– Overview\n\t\n\nCritiqueBank-11M is a large-scale dataset of 11.7 million adversarial critique examples designed to train AI systems that detect reasoning flaws in autonomous AI outputs. Each example pairs a rationale (an AI-generated trading signal) with a critique that identifies potential flaws, biases, or blind spots.This dataset powers MiniCrit, anâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/wmaousley/CritiqueBank-11M.",
        "url": "https://huggingface.co/datasets/wmaousley/CritiqueBank-11M",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "LiuXH648/Law-StackExchange",
        "author": "LiuXH648",
        "created_at": "2026-01-08 02:27:03+00:00",
        "last_modified": "2026-01-08 02:27:03+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-classification",
          "task_categories:sentence-similarity",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "legal"
        ],
        "description": "\n\t\n\t\t\n\t\tLaw-StackExchange Dataset Details\n\t\n\nAll StackExchange legal questions and their answers from the Law site, up to 14 August 2023. \nThe repository includes a notebook for the process using the official StackExchange API.\n\n\t\n\t\t\n\t\tCitation\n\t\n\n@misc{Moslem2023-LawStackExchangeDataset,\n    author       = {Moslem, Yasmin},\n    title        = {Law-StackExchange Dataset},\n    year         = 2023,\n    url          = {https://huggingface.co/datasets/ymoslem/Law-StackExchange},\n    doi          =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LiuXH648/Law-StackExchange.",
        "url": "https://huggingface.co/datasets/LiuXH648/Law-StackExchange",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-classification",
          "sentence-similarity"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "wcyno23/TacZip-Data",
        "author": "wcyno23",
        "created_at": "2026-01-07 05:58:10+00:00",
        "last_modified": "2026-01-10 09:02:18+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:table-question-answering",
          "task_categories:text-classification",
          "task_categories:summarization",
          "language:en",
          "license:apache-2.0",
          "region:us"
        ],
        "description": "Task-aware context compression with fine-grained, token-level ratio allocation.\n",
        "url": "https://huggingface.co/datasets/wcyno23/TacZip-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "table-question-answering",
          "text-classification",
          "summarization"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_737_Tear_off_the_outer_skin",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:04:24+00:00",
        "last_modified": "2026-01-05 16:29:08+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_737\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ’•æŽ‰å¤–çš®\ntotal_episodes: 214\ntotal_tasks: 1\nsize: 6.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_737_Tear_off_the_outer_skin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_737_Tear_off_the_outer_skin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Snaseem2026/dockerfile_errors_2026-01-10",
        "author": "Snaseem2026",
        "created_at": "2026-01-10 19:06:30+00:00",
        "last_modified": "2026-01-10 19:06:57+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "doi:10.57967/hf/7505",
          "region:us",
          "docker",
          "errors",
          "devops",
          "logs",
          "synthetic-data"
        ],
        "description": "\n\t\n\t\t\n\t\tDockerfile Error Outputs Dataset (2026-01-10)\n\t\n\nA synthetic dataset of Dockerfile error outputs generated for January 10, 2026. This dataset contains 5,000 entries, each simulating a real-world Dockerfile build error with metadata.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nFormat: Parquet (.parquet)\nFields:\ntimestamp: ISO8601 timestamp of the error\ndocker_command: Dockerfile command being executed\nerror_message: Error message output\nuser: User who triggered the build\ncontainer_id: Simulatedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Snaseem2026/dockerfile_errors_2026-01-10.",
        "url": "https://huggingface.co/datasets/Snaseem2026/dockerfile_errors_2026-01-10",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "CYenHua/Test_data",
        "author": "CYenHua",
        "created_at": "2026-01-08 04:49:33+00:00",
        "last_modified": "2026-01-08 04:52:44+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio",
          "evaluation"
        ],
        "description": "\n\t\n\t\t\n\t\tTitle\n\t\n\nTest Test Test\n",
        "url": "https://huggingface.co/datasets/CYenHua/Test_data",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_56_placeplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:14:02+00:00",
        "last_modified": "2026-01-05 10:15:47+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_56_placeplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®ç›˜å­\ntotal_episodes: 185\ntotal_tasks: 1\nsize: 2.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_56_placeplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_56_placeplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ShiroOnigami23/emotion-voice-dataset",
        "author": "ShiroOnigami23",
        "created_at": "2026-01-10 13:01:18+00:00",
        "last_modified": "2026-01-11 13:24:58+00:00",
        "downloads": 50,
        "likes": 1,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio",
          "speech-synthesis",
          "rjit",
          "shiro"
        ],
        "description": "\n\t\n\t\t\n\t\temotion voice dataset\n\t\n\nDeveloped by Aryan Singh Chandel (Shiro) at Rustamji Institute of Technology (RJIT).\n\n\t\n\t\t\n\t\tðŸ“ Overview\n\t\n\nThis repository contains assets for emotion voice dataset. It is a professional research component of the Shiro AI ecosystem.\n\n\t\n\t\t\n\t\tðŸš€ Status\n\t\n\nThe core files are live. Detailed usage instructions and technical benchmarks are currently being compiled for the elite release.\n",
        "url": "https://huggingface.co/datasets/ShiroOnigami23/emotion-voice-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "AIM-Intelligence/COMPASS-Policy-Alignment-Testbed-Dataset",
        "author": "AIM-Intelligence",
        "created_at": "2025-12-30 11:48:18+00:00",
        "last_modified": "2026-01-06 03:11:49+00:00",
        "downloads": 65,
        "likes": 9,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.01836",
          "region:us",
          "policy-alignment",
          "safety",
          "benchmark",
          "llm-evaluation",
          "safety-evaluation"
        ],
        "description": "\n\t\n\t\t\n\t\tCOMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs\n\t\n\n\nThis dataset evaluates how well Large Language Models (LLMs) follow organization-specific policies in realistic enterprise-style settings.\n\n\t\n\t\t\n\t\tWhat is COMPASS?\n\t\n\nCOMPASS is a framework for evaluating policy alignment: given only an organizationâ€™s policy (e.g., allow/deny rules), it enables you to benchmark whether an LLMâ€™s responses comply with that policy in structured, enterprise-likeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIM-Intelligence/COMPASS-Policy-Alignment-Testbed-Dataset.",
        "url": "https://huggingface.co/datasets/AIM-Intelligence/COMPASS-Policy-Alignment-Testbed-Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "enPurified/ultrachat_200k_sft-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 04:57:03+00:00",
        "last_modified": "2026-01-12 00:35:20+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:mlabonne/ultrachat_200k_sft",
          "language:en",
          "license:unknown",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "ultrachat",
          "quality-filtered",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– UltraChat-200k-enPurified-openai-messages\n\t\n\nUltraChat-200k-enPurified is a highly curated, \"prose-first\" refinement of the mlabonne/ultrachat_200k_sft dataset. \nThe enPurified collection is built on a specific philosophy: Linguistic Specialization. While math and coding datasets are abundant, high-quality English prose often gets diluted by technical syntax or symbolic logic. This dataset isolates fluent, natural language to improve a model's conversational elegance and reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/ultrachat_200k_sft-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/ultrachat_200k_sft-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "data-archetype/pexels_aesth_bucketed_512",
        "author": "data-archetype",
        "created_at": "2026-01-08 11:11:28+00:00",
        "last_modified": "2026-01-08 11:37:31+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:webdataset",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:webdataset",
          "library:mlcroissant",
          "region:us",
          "webdataset",
          "images",
          "captions"
        ],
        "description": "\n\t\n\t\t\n\t\tA captioned and aspect ratio bucketed dataset of about 200k pexel photos with subjectively good aesthetic quality, with a diverse range of themes\n\t\n\nThis version is scaled to approx 512^2 resolution.\nSee below for more details\n\n\t\n\t\t\n\t\tBucketed Shards Dataset\n\t\n\nThis repository contains a bucketed-shards export (uncompressed TAR shards).\n\n\t\n\t\t\n\t\tFormat\n\t\n\n\nFormat: bucketed_shards_v1\nCreated: 2026-01-08T09:51:12.478529+00:00\nExport ID: export-2026-01-08T09:51:12.478529+00:00\nManifest:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/data-archetype/pexels_aesth_bucketed_512.",
        "url": "https://huggingface.co/datasets/data-archetype/pexels_aesth_bucketed_512",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:29:29+00:00",
        "last_modified": "2026-01-05 12:31:27+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¢—ä¸­æ‹¿èµ·æ¢¨part_2\ntotal_episodes: 215\ntotal_tasks: 1\nsize: 266.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "GuoY214/MMSI-Video-Bench",
        "author": "GuoY214",
        "created_at": "2026-01-06 05:07:51+00:00",
        "last_modified": "2026-01-06 05:07:52+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:multiple-choice",
          "task_categories:visual-question-answering",
          "task_categories:video-text-to-text",
          "language:en",
          "license:cc",
          "size_categories:1K<n<10K",
          "arxiv:2512.10863",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tMMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence\n\t\n\nðŸŒ Homepage  | ðŸ“‘ Paper | ðŸ“– Code\n\n\n\n\n\n\n\t\n\t\t\n\t\tðŸ”” News\n\t\n\nðŸ”¥[2025-12]: Our MMSI-Video-Bench has been integrated into VLMEvalKit.\nðŸ”¥[2025-12]: We released our paper, benchmark, and evaluation codes.\n\n\t\n\t\t\n\t\tðŸ“Š Data Details\n\t\n\nAll of our data is available on Hugging Face and includes the following components:\nðŸŽ¥ Video Data (videos.zip): Contains the video clip file (.mp4) corresponding to each sample. Thisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GuoY214/MMSI-Video-Bench.",
        "url": "https://huggingface.co/datasets/GuoY214/MMSI-Video-Bench",
        "languages": [
          "en"
        ],
        "tasks": [
          "multiple-choice",
          "visual-question-answering",
          "video-text-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Shiran56/DrugFormDB",
        "author": "Shiran56",
        "created_at": "2026-01-08 20:08:50+00:00",
        "last_modified": "2026-01-08 20:08:51+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "healthcare",
          "pharmaceuticals",
          "drug-classification",
          "medication",
          "medical-data"
        ],
        "description": "\n\t\n\t\t\n\t\tDrugFormDB: A Dataset for Medication Form Classification\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nDrugFormDB is a comprehensive dataset containing medication form classifications for approved drugs. The dataset was created using a two-stage classification system:\n\nInitial classification using GPT-4\nValidation using PubMedBERT embeddings\n\n\n\t\n\t\t\n\t\tKey Features\n\t\n\n\n3,150+ Drug Classifications: Covers a wide range of approved medications\nMultiple Forms per Drug: Many drugs are available inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shiran56/DrugFormDB.",
        "url": "https://huggingface.co/datasets/Shiran56/DrugFormDB",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "shubhxho/ipmattards",
        "author": "shubhxho",
        "created_at": "2026-01-05 21:04:51+00:00",
        "last_modified": "2026-01-05 21:31:54+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "reddit",
          "education",
          "ipmat",
          "entrance-exam",
          "india"
        ],
        "description": "\n\t\n\t\t\n\t\tr/IPMATtards Reddit Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains scraped posts and comments from the r/IPMATtards subreddit, a community dedicated to aspirants of the Integrated Programme in Management Aptitude Test (IPMAT) in India. \nThe data is structured into two main components:\n\nPosts: Top-level submissions including titles, body text, scores, and metadata.\nComments: Threaded replies associated with the posts, including recursion depth and parent-childâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shubhxho/ipmattards.",
        "url": "https://huggingface.co/datasets/shubhxho/ipmattards",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_switch_manipulation",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:47:49+00:00",
        "last_modified": "2026-01-05 21:48:56+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_switch_manipulation\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ“ä½œå¼€å…³\ntotal_episodes: 49\ntotal_tasks: 1\nsize: 1.7G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_switch_manipulation.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_switch_manipulation",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_6_applebowloven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:29:26+00:00",
        "last_modified": "2026-01-05 10:31:57+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_6_applebowloven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœç¢—çƒ¤ç®±part_1\ntotal_episodes: 78\ntotal_tasks: 1\nsize: 1.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_6_applebowloven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_6_applebowloven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_red_pepper_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:53:52+00:00",
        "last_modified": "2026-01-05 22:54:50+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_red_pepper_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¤æ¡Œä¸Šçš„çº¢è¾£æ¤’\ntotal_episodes: 203\ntotal_tasks: 1\nsize: 269.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_red_pepper_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_red_pepper_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "beersrobert/kids_bedroom_dataset_v2",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:29:10+00:00",
        "last_modified": "2026-01-09 04:03:17+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "indoor-navigation household-hazards home-safety messy-environments robotics"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/kids_bedroom_dataset_v2",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_lid",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:47:39+00:00",
        "last_modified": "2026-01-05 12:52:35+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_close_cap_lid\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›–ä¸Šç›–å­\ntotal_episodes: 252\ntotal_tasks: 1\nsize: 459.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_lid.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_lid",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": []
      },
      {
        "id": "Usmannn001/CENSUS-NER-Name-Email-Address-Phone",
        "author": "Usmannn001",
        "created_at": "2026-01-05 07:27:18+00:00",
        "last_modified": "2026-01-05 07:27:20+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1M<n<10M",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "ner",
          "address parsing",
          "email",
          "phone",
          "address"
        ],
        "description": "Dataset Summary\nThe CENSUS-NER-Name-Email-Address-Phone dataset is a processed and structured version of the FMCSA (Federal Motor Carrier Safety Administration) CENSUS1 2016Sep dataset. It is designed to assist in training language models for tasks such as Named Entity Recognition (NER), address parsing, and information extraction from unstructured text. The dataset contains records that include information such as name, email, phone number, and address, extracted from the original dataset andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Usmannn001/CENSUS-NER-Name-Email-Address-Phone.",
        "url": "https://huggingface.co/datasets/Usmannn001/CENSUS-NER-Name-Email-Address-Phone",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_oranges_in_the_basket_1119",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:10:51+00:00",
        "last_modified": "2026-01-06 10:11:18+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_oranges_in_the_basket_1119\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ©™å­æ”¾å…¥ç¯®å­\ntotal_episodes: 245\ntotal_tasks: 1\nsize: 168.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_oranges_in_the_basket_1119.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_oranges_in_the_basket_1119",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:21:36+00:00",
        "last_modified": "2026-01-05 12:28:42+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¢—ä¸­æ‹¿èµ·æ¢¨part_1\ntotal_episodes: 288\ntotal_tasks: 1\nsize: 476.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_pick_pear_from_bowl_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:52:29+00:00",
        "last_modified": "2026-01-05 22:52:38+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é»„è¾£æ¤’æ”¾å…¥é¡¶éƒ¨æŠ½å±‰\ntotal_episodes: 23\ntotal_tasks: 1\nsize: 33.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_top_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ExtraJeff/final_homework",
        "author": "ExtraJeff",
        "created_at": "2026-01-11 13:52:19+00:00",
        "last_modified": "2026-01-11 16:03:14+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "language:zh",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "wordle",
          "game-analytics",
          "player-behavior",
          "lstm",
          "time-series"
        ],
        "description": "\n\t\n\t\t\n\t\tWordleæ¸¸æˆé¢„æµ‹é¡¹ç›® - æ•°æ®é›†æè¿°æ–‡æ¡£\n\t\n\n\n\t\n\t\t\n\t\tæ•°æ®é›†æ¦‚è§ˆ\n\t\n\nè¿™ä¸ªæ•°æ®é›†åŒ…å«äº†Wordleæ¸¸æˆçŽ©å®¶çš„åŽ†å²è®°å½•ï¼Œç”¨äºŽé¢„æµ‹çŽ©å®¶å®Œæˆæ¸¸æˆæ‰€éœ€çš„å°è¯•æ¬¡æ•°ã€‚æ•°æ®é›†ç»è¿‡ä¸‰ä¸ªé˜¶æ®µçš„å¤„ç†ï¼šåŽŸå§‹æ•°æ®ã€é¢„å¤„ç†æ•°æ®å’Œç‰¹å¾å·¥ç¨‹æ•°æ®ã€‚\n\n\t\n\t\t\n\t\tä¸‹è½½å’Œä½¿ç”¨\n\t\n\n# å®‰è£…å¿…è¦çš„åº“\n!pip install datasets pandas numpy\n\n# åŠ è½½æ•°æ®é›†ï¼ˆç¤ºä¾‹ï¼‰\nfrom datasets import load_dataset\n\n# æ ¹æ®ä½ çš„æ•°æ®é›†åç§°è°ƒæ•´\ndataset = load_dataset(\"your-username/wordle-game-prediction\")\n\n\n\t\n\t\t\n\t\n\t\n\t\t1. åŽŸå§‹æ•°æ®é›†ï¼ˆ01_raw_data/wordle_games.csvï¼‰\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\t1.1 æ•°æ®é›†åŸºæœ¬ä¿¡æ¯\n\t\n\n\næ•°æ®æ¥æºï¼šWordleæ¸¸æˆçŽ©å®¶åŽ†å²è®°å½•\næ•°æ®æ ¼å¼ï¼šCSVæ ¼å¼\næ•°æ®é‡ï¼šæ ¹æ®é¢„å¤„ç†è„šæœ¬è¾“å‡ºï¼ŒåŽŸå§‹è®°å½•æ•°çº¦ä¸ºå¤„ç†å‰çš„æ•°é‡\n\n\n\t\n\t\t\n\t\n\t\n\t\t1.2 å­—æ®µæè¿°\n\t\n\n\n\t\n\t\t\nå­—æ®µå\næ•°æ®ç±»åž‹\næè¿°â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ExtraJeff/final_homework.",
        "url": "https://huggingface.co/datasets/ExtraJeff/final_homework",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_basket_1121",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:55:46+00:00",
        "last_modified": "2026-01-07 06:56:03+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_basket_1121\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¯®å­ä¸­æ‹¿èµ·é’èœpart_1\ntotal_episodes: 226\ntotal_tasks: 1\nsize: 213.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_basket_1121.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_green_vegetable_from_the_basket_1121",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_open_the_drawer_under_the_combination_cabinet",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:17:20+00:00",
        "last_modified": "2026-01-05 18:18:04+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_open_the_drawer_under_the_combination_cabinet\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€ç»„åˆæ©±æŸœä¸‹çš„æŠ½å±‰\ntotal_episodes: 125\ntotal_tasks: 1\nsize: 805.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_open_the_drawer_under_the_combination_cabinet.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_open_the_drawer_under_the_combination_cabinet",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": []
      },
      {
        "id": "nyuuzyou/gitgud-code",
        "author": "nyuuzyou",
        "created_at": "2025-07-18 21:43:47+00:00",
        "last_modified": "2026-01-09 03:35:08+00:00",
        "downloads": 328,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:found",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:en",
          "license:other",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tGitGud Code Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from code repositories hosted on GitGud.io, a GitLab-based code hosting platform. GitGud.io serves as an alternative git hosting service used by various developer communities and open-source projects.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nStatistic\nValue\n\n\n\t\t\nTotal Files\n16,322,315\n\n\nTotal Repositories\n7,204\n\n\nTotal Size\n17.46 GB (compressed Parquet)\n\n\nProgramming Languages\n2,185\n\n\nFile Format\nParquet with Zstdâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gitgud-code.",
        "url": "https://huggingface.co/datasets/nyuuzyou/gitgud-code",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_take_marker_pen",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:54:17+00:00",
        "last_modified": "2026-01-05 23:55:05+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_take_marker_pen\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é©¬å…‹ç¬”\ntotal_episodes: 285\ntotal_tasks: 1\nsize: 644.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_take_marker_pen.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_take_marker_pen",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "nyuuzyou/notabug-code",
        "author": "nyuuzyou",
        "created_at": "2025-06-18 13:56:45+00:00",
        "last_modified": "2026-01-09 04:38:43+00:00",
        "downloads": 283,
        "likes": 5,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:found",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:en",
          "license:other",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tNotaBug Code Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from code repositories hosted on NotaBug.org, a free code hosting platform that emphasizes software freedom and privacy. NotaBug is built on a fully free software stack and is popular among free software advocates and privacy-conscious developers.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nStatistic\nValue\n\n\n\t\t\nTotal Files\n12,622,961\n\n\nTotal Repositories\n11,660\n\n\nTotal Size\n12 GB (compressed Parquet)\n\n\nProgrammingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/notabug-code.",
        "url": "https://huggingface.co/datasets/nyuuzyou/notabug-code",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "ShiroOnigami23/PyObfuscate-1M-HighGrade",
        "author": "ShiroOnigami23",
        "created_at": "2025-12-14 18:24:34+00:00",
        "last_modified": "2026-01-11 13:24:56+00:00",
        "downloads": 20,
        "likes": 2,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1M<n<10M",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "security",
          "python",
          "obfuscation",
          "rjit",
          "shiro"
        ],
        "description": "\n\t\n\t\t\n\t\tPyObfuscate 1M HighGrade\n\t\n\nDeveloped by Aryan Singh Chandel (Shiro) at Rustamji Institute of Technology (RJIT).\n\n\t\n\t\t\n\t\tðŸ“ Overview\n\t\n\nThis repository contains assets for PyObfuscate 1M HighGrade. It is a professional research component of the Shiro AI ecosystem.\n\n\t\n\t\t\n\t\tðŸš€ Status\n\t\n\nThe core files are live. Detailed usage instructions and technical benchmarks are currently being compiled for the elite release.\n",
        "url": "https://huggingface.co/datasets/ShiroOnigami23/PyObfuscate-1M-HighGrade",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_55_pumpkinbowloven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:12:43+00:00",
        "last_modified": "2026-01-05 10:13:34+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_55_pumpkinbowloven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å—ç“œç¢—çƒ¤ç®±\ntotal_episodes: 27\ntotal_tasks: 1\nsize: 438.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_55_pumpkinbowloven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_55_pumpkinbowloven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BossCrafts/CodeX-7M-Non-Thinking",
        "author": "BossCrafts",
        "created_at": "2026-01-10 16:52:52+00:00",
        "last_modified": "2026-01-10 16:52:53+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "annotations_creators:machine-generated",
          "annotations_creators:expert-verified",
          "multilinguality:monolingual",
          "source_datasets:XenArcAI internal synthetic generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Coding",
          "Code",
          "CodeX",
          "XenArcAI",
          "LLM-training",
          "synthetic",
          "benchmark",
          "artifact",
          "non-reasoning",
          "direct-response"
        ],
        "description": "\n\t\n\t\t\n\t\tXenArcAI\n\t\n\n\n\n  \n\n\nNote: This dataset is part of the lineup CodeX by XenArcAI. You can get lots of datasets in this same lineup, with the main focus on providing very high-quality datasets for model training and fine-tuning.\n\nThis dataset is curated from high-quality public sources and enhanced with synthetic data from both closed and open-source models. It serves as a strong foundation for instruction-based model tuning and fine-tuning, offering one of the most refined and extensiveâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BossCrafts/CodeX-7M-Non-Thinking.",
        "url": "https://huggingface.co/datasets/BossCrafts/CodeX-7M-Non-Thinking",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_blue_cub_on_pink",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:43:37+00:00",
        "last_modified": "2026-01-05 12:45:18+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_blue_cub_on_pink\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç²‰è‰²ä¸Šçš„è“è‰²ç«‹æ–¹ä½“\ntotal_episodes: 274\ntotal_tasks: 1\nsize: 511.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_blue_cub_on_pink.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_blue_cub_on_pink",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:16:20+00:00",
        "last_modified": "2026-01-05 16:25:07+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾åœ¨æ¡Œå­ä¸Špart_3\ntotal_episodes: 98\ntotal_tasks: 1\nsize: 251.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "DavidRobinson05/ucf-det",
        "author": "DavidRobinson05",
        "created_at": "2026-01-07 01:43:17+00:00",
        "last_modified": "2026-01-07 02:28:04+00:00",
        "downloads": 13,
        "likes": 1,
        "tags": [
          "task_categories:object-detection",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/DavidRobinson05/ucf-det",
        "languages": [
          "en"
        ],
        "tasks": [
          "object-detection"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1120",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:06:20+00:00",
        "last_modified": "2026-01-06 10:10:03+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1120\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ’æžœæ”¾å…¥ç¯®å­part_2\ntotal_episodes: 298\ntotal_tasks: 1\nsize: 230.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1120.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_mango_in_the_basket_1120",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "gergei/funnyinsults",
        "author": "gergei",
        "created_at": "2026-01-11 13:41:25+00:00",
        "last_modified": "2026-01-11 13:41:25+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:text-generation",
          "annotations_creators:found",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1K<n<10K",
          "modality:text",
          "region:us",
          "text",
          "not-for-all-audiences"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Funny Insults\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains 1,702 humorous insults collected from funny-insults.com. The dataset includes the insult text, categorization information, and user-provided ratings for each entry. This collection represents a variety of comedic insults across different categories that can be used for humor analysis, text generation, or sentiment analysis tasks.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset is monolingual:\n\nEnglish (en): All insultâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gergei/funnyinsults.",
        "url": "https://huggingface.co/datasets/gergei/funnyinsults",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "VyoJ/calvin-ABCD-D-subsets",
        "author": "VyoJ",
        "created_at": "2026-01-07 09:26:19+00:00",
        "last_modified": "2026-01-08 05:36:04+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1M<n<10M",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tCALVIN Dataset - task_ABCD_D (Structured Subsets)\n\t\n\nThis repository contains the CALVIN task_ABCD_D dataset split into structured subsets for easier downloading and processing.\n\n\t\n\t\t\n\t\tOriginal Source\n\t\n\n\nURL: http://calvin.cs.uni-freiburg.de/dataset/task_ABCD_D.zip\nOriginal Size: ~600GB\n\n\n\t\n\t\t\n\t\tStructure\n\t\n\nEach subset is a complete, self-contained dataset with the proper structure:\nsubset_training_000/\nâ””â”€â”€ training/\n    â”œâ”€â”€ scene_info.npy\n    â”œâ”€â”€ lang_annotations/\n    â”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/VyoJ/calvin-ABCD-D-subsets.",
        "url": "https://huggingface.co/datasets/VyoJ/calvin-ABCD-D-subsets",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "zilliz/natural_questions-context-relevance-with-think",
        "author": "zilliz",
        "created_at": "2026-01-06 02:25:48+00:00",
        "last_modified": "2026-01-06 07:43:33+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tNatural Questions Context Relevance Dataset with Think Process\n\t\n\nThis dataset is used for training the zilliz/semantic-highlight-bilingual-v1(https://huggingface.co/zilliz/semantic-highlight-bilingual-v1) model for semantic highlighting in RAG (Retrieval-Augmented Generation) systems.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains query-context pairs with relevance annotations for context spans. The annotations help identify which parts of a document are semantically relevant toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zilliz/natural_questions-context-relevance-with-think.",
        "url": "https://huggingface.co/datasets/zilliz/natural_questions-context-relevance-with-think",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_782_Organize_the_bar_counter",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:35:12+00:00",
        "last_modified": "2026-01-05 21:20:01+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_782\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ•´ç†å§å°\ntotal_episodes: 109\ntotal_tasks: 1\nsize: 7.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_782_Organize_the_bar_counter.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_782_Organize_the_bar_counter",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Tatsuya-Ichinose/CoDIT-Qwen3-30B",
        "author": "Tatsuya-Ichinose",
        "created_at": "2026-01-11 11:52:35+00:00",
        "last_modified": "2026-01-11 14:33:13+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:lmsys-chat-1m",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\nDataset Name\nðŸ¤– Teacher Model\nðŸ“‚ Dataset Link\n\n\n\t\t\nCoDIT-Gemma3 ðŸ’Ž\ngoogle/gemma-3-27b-it\nCoDIT-Gemma3 â†—\n\n\nCoDIT-Qwen3-8B ðŸ‰\nQwen/Qwen3-8B\nCoDIT-Qwen3-8B â†—\n\n\nCoDIT-Qwen3-30B ðŸš€\nQwen/Qwen3-30B-A3B\nCoDIT-Qwen3-30B â†—\n\n\n\t\n\n\n\t\t\n\t\tCoDIT-Qwen3-30B\n\t\n\nCoDIT-Qwen3-30B is a synthetic conversation dataset derived from LMSYS-Chat-1M [Zhang+, ICLR24].\n\n250,333 user instructions sourced from LMSYS-Chat-1M\n250,333 assistant responses automatically synthesized using CoDIT with Qwen/Qwen3-30B-A3B(Noâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tatsuya-Ichinose/CoDIT-Qwen3-30B.",
        "url": "https://huggingface.co/datasets/Tatsuya-Ichinose/CoDIT-Qwen3-30B",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Ajain1391/multiclass-sentiment-analysis-dataset",
        "author": "Ajain1391",
        "created_at": "2026-01-09 03:49:32+00:00",
        "last_modified": "2026-01-09 03:49:34+00:00",
        "downloads": 11,
        "likes": 1,
        "tags": [
          "task_categories:text-classification",
          "task_categories:translation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n[More Information Needed]\n\n\t\n\t\t\n\t\tDataset Creationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ajain1391/multiclass-sentiment-analysis-dataset.",
        "url": "https://huggingface.co/datasets/Ajain1391/multiclass-sentiment-analysis-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "translation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:11:27+00:00",
        "last_modified": "2026-01-05 22:12:01+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_open_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶part_4\ntotal_episodes: 276\ntotal_tasks: 1\nsize: 276.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "RajVerma30/ultrachat_200k",
        "author": "RajVerma30",
        "created_at": "2026-01-07 07:11:11+00:00",
        "last_modified": "2026-01-07 07:11:12+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2305.14233",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for UltraChat 200k\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a heavily filtered version of the UltraChat dataset and was used to train Zephyr-7B-Î², a state of the art 7b chat model.\nThe original datasets consists of 1.4M dialogues generated by ChatGPT and spanning a wide range of topics. To create UltraChat 200k, we applied the following logic:\n\nSelection of a subset of data for faster supervised fine tuning.\nTruecasing of the dataset, as we observed around 5% of the dataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RajVerma30/ultrachat_200k.",
        "url": "https://huggingface.co/datasets/RajVerma30/ultrachat_200k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "akseljoonas/ToolMind",
        "author": "akseljoonas",
        "created_at": "2026-01-07 18:31:35+00:00",
        "last_modified": "2026-01-07 18:33:42+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "arxiv:2511.15718",
          "region:us",
          "function-calling",
          "tool-calling",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tToolMind (Fixed for Dataset Viewer)\n\t\n\nThis is a re-upload of Nanbeige/ToolMind with the data reorganized for the HuggingFace dataset viewer to work properly.\n\n\t\n\t\t\n\t\tOriginal Description\n\t\n\nToolMind is a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances.\nTechnical Report: https://arxiv.org/abs/2511.15718\n\n\t\n\t\t\n\t\tChanges from Original\n\t\n\n\nCombined all JSONL files into a singleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akseljoonas/ToolMind.",
        "url": "https://huggingface.co/datasets/akseljoonas/ToolMind",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_piled_on_yellow_block_on_purple_block",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:53:58+00:00",
        "last_modified": "2026-01-05 14:55:02+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_piled_on_yellow_block_on_purple_block\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç´«è‰²ç§¯æœ¨ä¸Šå †æ”¾é»„è‰²ç§¯æœ¨\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 449.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_piled_on_yellow_block_on_purple_block.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_piled_on_yellow_block_on_purple_block",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "achiepatricia/han-task-instruction-dataset-v1",
        "author": "achiepatricia",
        "created_at": "2026-01-10 12:56:35+00:00",
        "last_modified": "2026-01-10 12:57:24+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "task",
          "command",
          "dataset",
          "han"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Task Instruction Dataset\n\t\n\nThis dataset maps human commands\nto structured humanoid task definitions.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nHuman command\nTask name\nAction category\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nJSON\n\n\t\n\t\t\n\t\tPart of\n\t\n\nHumanoid Network (HAN)\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT\n",
        "url": "https://huggingface.co/datasets/achiepatricia/han-task-instruction-dataset-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "uaytug/ucoder-reasoning-ds",
        "author": "uaytug",
        "created_at": "2026-01-05 21:50:42+00:00",
        "last_modified": "2026-01-07 11:19:02+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tuCoder Synthetic Reasoning Dataset\n\t\n\n\n\n\n\n\n\nA comprehensive reasoning dataset for LLM fine-tuning and knowledge distillation\n\n\n\n\t\n\t\n\t\n\t\tOverview\n\t\n\nThis dataset is designed for:\n\nKnowledge Distillation - Train smaller models to mimic larger onesInstruction Fine-tuning - Improve model instruction-following capabilities\nReasoning Enhancement - Teach models chain-of-thought reasoning\nMultilingual Training - Includes content in multiple languages\n\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nSplitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/uaytug/ucoder-reasoning-ds.",
        "url": "https://huggingface.co/datasets/uaytug/ucoder-reasoning-ds",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "zhang5566/GEWDiff_training_dataset",
        "author": "zhang5566",
        "created_at": "2026-01-10 02:58:11+00:00",
        "last_modified": "2026-01-10 02:58:12+00:00",
        "downloads": 46,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "arxiv:2511.07103",
          "region:us",
          "super-resolution",
          "hyperspectral",
          "remote_sensing"
        ],
        "description": "\n\t\n\t\t\n\t\tGEWDiff Training & Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸ“˜ Overview\n\t\n\nThe GEWDiff Training & Evaluation Dataset is derived from the EnMAP Champion and MDAS hyperspectral datasets.It is designed for image enhancement, super-resolution, restoration, and generative remote sensing tasks.The dataset includes Low-Quality (LQ) low-resolution images, corresponding Ground-Truth (GT) high-resolution images, and optional structure information such as masks and edges (partially provided; remainingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhang5566/GEWDiff_training_dataset.",
        "url": "https://huggingface.co/datasets/zhang5566/GEWDiff_training_dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "enPurified/tulu-3-sft-mixture-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-10 20:14:18+00:00",
        "last_modified": "2026-01-12 00:25:20+00:00",
        "downloads": 29,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:allenai/tulu-3-sft-mixture",
          "language:en",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "tulu-3",
          "quality-filtered",
          "synthetic",
          "sft"
        ],
        "description": "\n\n\n\t\n\t\t\n\t\tðŸ“– Tulu-3-SFT-enPurified-openai-messages\n\t\n\nTulu-3-SFT-enPurified is a highly curated, \"prose-first\" subset of the original allenai/tulu-3-sft-mixture.\nThe enPurified collection is built on a specific philosophy: Specialization. There are plenty of excellent datasets for coding (StackOverflow, StarCoder) and mathematics (GSM8K, MathInstruct). However, high-quality, fluent English prose often gets diluted when mixed with syntax-heavy code or rigid math formulas.\nThis dataset wasâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/tulu-3-sft-mixture-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/tulu-3-sft-mixture-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "iioos/optimization-constraints-samples",
        "author": "iioos",
        "created_at": "2026-01-11 01:08:59+00:00",
        "last_modified": "2026-01-11 01:09:21+00:00",
        "downloads": 4,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tOptimization Constraints Samples Dataset\n\t\n\nProblemâ€“constraint pairs for optimization and operations research tasks.\n",
        "url": "https://huggingface.co/datasets/iioos/optimization-constraints-samples",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:04:58+00:00",
        "last_modified": "2026-01-05 22:05:36+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_close_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­åžƒåœ¾æ¡¶part_4\ntotal_episodes: 316\ntotal_tasks: 1\nsize: 471.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_762_paint_the_walls",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:17:43+00:00",
        "last_modified": "2026-01-05 18:39:40+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_762\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ç²‰åˆ·å¢™å£\ntotal_episodes: 486\ntotal_tasks: 1\nsize: 17G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_762_paint_the_walls.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_762_paint_the_walls",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "minliii/LongBench",
        "author": "minliii",
        "created_at": "2026-01-09 09:30:03+00:00",
        "last_modified": "2026-01-09 09:30:04+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:summarization",
          "task_categories:text-classification",
          "language:en",
          "language:zh",
          "size_categories:1K<n<10K",
          "arxiv:2308.14508",
          "arxiv:2108.00573",
          "arxiv:1712.07040",
          "arxiv:2105.03011",
          "arxiv:2104.02112",
          "arxiv:2104.05938",
          "arxiv:2305.05280",
          "arxiv:2303.09752",
          "arxiv:1910.10683",
          "arxiv:2306.14893",
          "arxiv:2306.03091",
          "region:us",
          "Long Context"
        ],
        "description": "LongBench is a comprehensive benchmark for multilingual and multi-task purposes, with the goal to fully measure and evaluate the ability of pre-trained language models to understand long text. This dataset consists of twenty different tasks, covering key long-text application scenarios such as multi-document QA, single-document QA, summarization, few-shot learning, synthetic tasks, and code completion.",
        "url": "https://huggingface.co/datasets/minliii/LongBench",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "summarization",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Shekswess/tiny-think-dpo",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:58:22+00:00",
        "last_modified": "2026-01-10 22:11:31+00:00",
        "downloads": 36,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-dpo\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMerged Direct Preference Optimization (DPO) dataset combining chat + instruct, math + STEM, and code subsets. Built from allenai/Dolci-Think-DPO-7B using the facebook/MobileLLM-R1-140M-base tokenizer and chat template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nRows: 9,972\nTokens: 29,997,608\nMax sequence length: 4096 tokens per example (both chosen and rejected)\nColumns: prompt,chosen, rejected, dataset_source, token_countâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-dpo.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-dpo",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "enPurified/textbooks-lite-700k-sharegpt-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 03:47:17+00:00",
        "last_modified": "2026-01-12 00:29:50+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:jtatman/textbooks-lite-700k-sharegpt",
          "language:en",
          "license:unknown",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "textbooks",
          "quality-filtered",
          "synthetic",
          "enPurified"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– textbooks-lite-700k-enPurified-openai-messages\n\t\n\ntextbooks-lite-700k-enPurified is a highly curated, \"prose-first\" subset of the original jtatman/textbooks-lite-700k-sharegpt.\nThe enPurified collection is built on a specific philosophy: Specialization through Purity. While the ecosystem is rich with datasets for competitive programming and complex mathematics, high-quality, fluent English prose is often diluted by technical syntax or symbolic logic.\nFor this dataset, the enPurifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/textbooks-lite-700k-sharegpt-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/textbooks-lite-700k-sharegpt-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_plastic_bottle_in_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:42:08+00:00",
        "last_modified": "2026-01-05 22:42:29+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_plastic_bottle_in_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†å¡‘æ–™ç“¶æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 76\ntotal_tasks: 1\nsize: 56.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_plastic_bottle_in_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_plastic_bottle_in_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_bananas_placed_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:32:48+00:00",
        "last_modified": "2026-01-05 23:33:18+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_bananas_placed_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¦™è•‰æ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 169\ntotal_tasks: 1\nsize: 298.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_bananas_placed_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_bananas_placed_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:08:21+00:00",
        "last_modified": "2026-01-05 22:08:34+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_green_pepper_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¤æ¡Œä¸Šçš„é’æ¤’part_1\ntotal_episodes: 67\ntotal_tasks: 1\nsize: 93.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_insertion",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:14:29+00:00",
        "last_modified": "2026-01-05 21:27:54+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_plug_insertion\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ’å…¥æ’å¤´part_1\ntotal_episodes: 151\ntotal_tasks: 1\nsize: 3.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_insertion.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_insertion",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_cucumber_placed_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:41:12+00:00",
        "last_modified": "2026-01-05 23:41:35+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_cucumber_placed_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é»„ç“œæ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 157\ntotal_tasks: 1\nsize: 287.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_cucumber_placed_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_cucumber_placed_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Shekswess/tiny-think-dpo-chat-n-instruct",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:58:08+00:00",
        "last_modified": "2026-01-10 22:11:07+00:00",
        "downloads": 40,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-dpo-chat-n-instruct\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDirect Preference Optimization (DPO) dataset built from allenai/Dolci-Think-DPO-7B using the facebook/MobileLLM-R1-140M-base tokenizer and chat template. This dataset targets general chat + instruction-following preferences.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nSources: 4\nRows: 4,914\nTokens: 9,997,975\nMax sequence length: 4096 tokens per example (both chosen and rejected)\nToken budget: 10,000,000 tokensâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-dpo-chat-n-instruct.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-dpo-chat-n-instruct",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "achiepatricia/han-environment-observation-dataset-v1",
        "author": "achiepatricia",
        "created_at": "2026-01-10 12:53:14+00:00",
        "last_modified": "2026-01-10 12:53:52+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "environment",
          "perception",
          "dataset",
          "han"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Environment Observation Dataset\n\t\n\nThis dataset contains structured environmental observations\nused by humanoid robots for perception and awareness.\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\nLight condition\nSurface condition\nRisk level\nEnvironment context\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nJSON\n\n\t\n\t\t\n\t\tPart of\n\t\n\nHumanoid Network (HAN)\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT\n",
        "url": "https://huggingface.co/datasets/achiepatricia/han-environment-observation-dataset-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_6_applebowloven_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:32:16+00:00",
        "last_modified": "2026-01-05 10:34:26+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_6_applebowloven_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœç¢—çƒ¤ç®±part_2\ntotal_episodes: 51\ntotal_tasks: 1\nsize: 742.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_6_applebowloven_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_6_applebowloven_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_extract_from",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:05:22+00:00",
        "last_modified": "2026-01-05 21:13:28+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_plug_extract_from\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹”å‡ºæ’å¤´part_1\ntotal_episodes: 52\ntotal_tasks: 1\nsize: 472.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_extract_from.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_extract_from",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "toiwuo87/alignment-data-filtered",
        "author": "toiwuo87",
        "created_at": "2025-12-27 11:59:35+00:00",
        "last_modified": "2026-01-05 14:41:46+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tAlignment Data Filtered\n\t\n\nA collection of AI alignment and safety research documents from various sources. This dataset builds on the main dataset available at https://huggingface.co/datasets/StampyAI/alignment-research-dataset. It contains up-to-date documents (approximately late December 2025) and applies some cleaning to the data. For more details, see https://github.com/AyseAsude/reading-safety.\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load all sources\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/toiwuo87/alignment-data-filtered.",
        "url": "https://huggingface.co/datasets/toiwuo87/alignment-data-filtered",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ArkAiLab-Adl/Nexora-music-pd-v1-mini",
        "author": "ArkAiLab-Adl",
        "created_at": "2026-01-08 07:42:43+00:00",
        "last_modified": "2026-01-08 10:03:53+00:00",
        "downloads": 10,
        "likes": 1,
        "tags": [
          "task_categories:text-to-audio",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:audiofolder",
          "modality:audio",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "audio",
          "music",
          "public-domain",
          "historical",
          "open-source",
          "ai",
          "machine-learning"
        ],
        "description": "\n\t\n\t\t\n\t\tNexora-Music-PD v1-mini\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nNexora-Music-PD v1-mini is a curated public-domain music dataset composed of\nhistorical audio recordings sourced from the Library of Congress Citizen DJ\ncollections. The dataset is designed for open research, audio analysis,\nmusic information retrieval, remixing, and AI/ML experimentation.\nThis is a mini release (v1) intended as a lightweight, easy-to-use subset\nfor testing pipelines, educational use, and small-scale experiments.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ArkAiLab-Adl/Nexora-music-pd-v1-mini.",
        "url": "https://huggingface.co/datasets/ArkAiLab-Adl/Nexora-music-pd-v1-mini",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-audio"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "hashmin/epadb",
        "author": "hashmin",
        "created_at": "2026-01-10 03:58:55+00:00",
        "last_modified": "2026-01-11 19:15:50+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:audio",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "non-native",
          "pronunciation",
          "speech",
          "pronunciation assessment",
          "phoneme"
        ],
        "description": "\n\t\n\t\t\n\t\tEpaDB: English Pronunciation by Argentinians\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEpaDB is a speech database intended for research in pronunciation scoring. The corpus includes audios from 50 Spanish speakers (25 males and 25 females) from \nArgentina reading phrases in English. Each speaker recorded 64 short phrases containing sounds hard to pronounce for this population adding up to ~3.5 hours of speech.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nPronunciation Assessment â€“ predict utterance-level globalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hashmin/epadb.",
        "url": "https://huggingface.co/datasets/hashmin/epadb",
        "languages": [
          "en"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "seeeeiii/RICO-WidgetCaptioning",
        "author": "seeeeiii",
        "created_at": "2026-01-11 23:55:37+00:00",
        "last_modified": "2026-01-11 23:55:38+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "arxiv:2010.04295",
          "region:us",
          "screens",
          "mobile",
          "phones"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for RICO Widget Captioning\n\t\n\nWidget Captioning is a dataset for providing captions for UI elements on mobile screens. \nIt uses the RICO image database. \n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Sources\n\t\n\n\nRepository:\ngoogle-research-datasets/widget-caption\nRICO raw downloads\n\n\nPaper:\nWidget Captioning: Generating Natural Language Description for Mobile User Interface Elements\nRico: A Mobile App Dataset for Building Data-Driven Design Applications\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/seeeeiii/RICO-WidgetCaptioning.",
        "url": "https://huggingface.co/datasets/seeeeiii/RICO-WidgetCaptioning",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-text",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_783_Lay_the_tablecloth",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:35:43+00:00",
        "last_modified": "2026-01-05 21:39:57+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_783\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: é“ºå¥½æ¡Œå¸ƒ\ntotal_episodes: 1105\ntotal_tasks: 1\nsize: 60G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_783_Lay_the_tablecloth.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_783_Lay_the_tablecloth",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_red_pepper_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:44:24+00:00",
        "last_modified": "2026-01-05 22:44:39+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_red_pepper_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†çº¢è¾£æ¤’æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 53\ntotal_tasks: 1\nsize: 78.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_red_pepper_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_red_pepper_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_7_applegreenplate_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:34:53+00:00",
        "last_modified": "2026-01-05 10:41:07+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_7_applegreenplate_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœç»¿ç›˜å­part_1\ntotal_episodes: 105\ntotal_tasks: 1\nsize: 1.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_7_applegreenplate_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_7_applegreenplate_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/task_716_Seal_with_the_official_seal_and_place_the_reimbursement_form_in_the_reimbursement_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 12:17:19+00:00",
        "last_modified": "2026-01-08 12:26:13+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_716\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ç›–ä¸Šå…¬ç« ï¼ŒæŠŠæŠ¥é”€å•æ”¾åœ¨æŠ¥é”€ç®±é‡Œã€‚\ntotal_episodes: 625\ntotal_tasks: 1\nsize: 31G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/task_716_Seal_with_the_official_seal_and_place_the_reimbursement_form_in_the_reimbursement_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/task_716_Seal_with_the_official_seal_and_place_the_reimbursement_form_in_the_reimbursement_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "hybridfree/arxiv-papers",
        "author": "hybridfree",
        "created_at": "2026-01-09 23:14:57+00:00",
        "last_modified": "2026-01-09 23:14:59+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "task_categories:visual-question-answering",
          "task_categories:document-question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "modality:document",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tComplete ArXiv Papers Dataset (4.68 TB)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“š Dataset Overview\n\t\n\nThis repository contains the complete ArXiv scientific papers archive organized by subject categories and publication years. With 4.68 TB of compressed PDFs and metadata, this represents one of the largest collections of scientific literature available for research and AI training.\n\n\t\n\t\t\n\t\tðŸ—‚ï¸ Dataset Structure\n\t\n\n\n\t\n\t\t\n\t\tOrganized by Subject Categories:\n\t\n\n\nastro-ph (00-22): Astrophysics\ncond-mat (00-32):â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hybridfree/arxiv-papers.",
        "url": "https://huggingface.co/datasets/hybridfree/arxiv-papers",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image",
          "visual-question-answering",
          "document-question-answering",
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_7_applegreenplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:26:38+00:00",
        "last_modified": "2026-01-05 23:27:59+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_7_applegreenplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœç»¿ç›˜å­part_2\ntotal_episodes: 96\ntotal_tasks: 1\nsize: 1.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_7_applegreenplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_7_applegreenplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Finish-him/msc-qa-pairs",
        "author": "Finish-him",
        "created_at": "2026-01-10 04:29:44+00:00",
        "last_modified": "2026-01-10 04:30:36+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "language:pt",
          "language:en",
          "language:es",
          "language:de",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "msc-marketing",
          "portuguese",
          "qa",
          "instruction-tuning",
          "chat"
        ],
        "description": "\n\t\n\t\t\n\t\tmsc-qa-pairs\n\t\n\nDataset de pares Q&A para fine-tuning de modelos de chat da MSC Marketing\n\n\t\n\t\t\n\t\tSobre\n\t\n\nEste dataset faz parte da infraestrutura de IA da MSC Marketing, uma empresa especializada em Marketing Digital e SEO.\n\n\t\n\t\t\n\t\tUso\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Finish-him/msc-qa-pairs\")\n\n\n\t\n\t\t\n\t\tEstrutura\n\t\n\nOs arquivos incluÃ­dos neste dataset sÃ£o:\n\ntrain.jsonl\nvalidation.jsonl\ntest.jsonl\nchat_train.jsonl\nchat_validation.jsonl\nchat_test.jsonlâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Finish-him/msc-qa-pairs.",
        "url": "https://huggingface.co/datasets/Finish-him/msc-qa-pairs",
        "languages": [
          "pt",
          "en",
          "es",
          "de"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "GambitFlow/Endgame-Tablebase",
        "author": "GambitFlow",
        "created_at": "2026-01-10 16:32:10+00:00",
        "last_modified": "2026-01-10 17:35:12+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:tabular-regression",
          "task_categories:reinforcement-learning",
          "language:en",
          "license:cc0-1.0",
          "size_categories:100K<n<1M",
          "region:us",
          "chess",
          "endgame",
          "syzygy",
          "tablebase",
          "perfect-play",
          "gambitflow"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ”® GambitFlow: Endgame Oracle (Perfect Knowledge)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset provides Perfect Information (God Mode) for chess endgames. It was generated using Syzygy Tablebases, meaning there is no estimationâ€”every evaluation is mathematically proven.\nIt covers 3, 4, and 5-piece endgames (e.g., King+Pawn vs King, Rook vs Knight). This data cures the \"Horizon Effect\" often seen in neural networks during the endgame phase.\n\nSource: Generated via Syzygy WDLâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GambitFlow/Endgame-Tablebase.",
        "url": "https://huggingface.co/datasets/GambitFlow/Endgame-Tablebase",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-regression",
          "reinforcement-learning"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "ttthe/MultiMed",
        "author": "ttthe",
        "created_at": "2026-01-09 07:15:23+00:00",
        "last_modified": "2026-01-09 07:15:25+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "language:vi",
          "language:en",
          "language:de",
          "language:fr",
          "language:zh",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2409.14074",
          "region:us",
          "medical"
        ],
        "description": "\n\t\n\t\t\n\t\tMultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder\n\t\n\nACL 2025\nKhai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat,\n\nMinh-Huong Ngo, Chris Ngo, Thanh Nguyen-Tang, Truong-Son Hy\n\n\nPlease press â­ button and/or cite papers if you feel helpful.\n\n\n  \n\n\n\nAbstract:\nMultilingual automatic speech recognition (ASR) in the medical domain serves as a foundational task for various downstream applications such as speech translation, spoken language understanding, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ttthe/MultiMed.",
        "url": "https://huggingface.co/datasets/ttthe/MultiMed",
        "languages": [
          "vi",
          "en",
          "de",
          "fr",
          "zh"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_bread",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:12:40+00:00",
        "last_modified": "2026-01-05 22:12:47+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_bread\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é¢åŒ…\ntotal_episodes: 18\ntotal_tasks: 1\nsize: 14.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_bread.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_bread",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "lingao123/coyo-700m",
        "author": "lingao123",
        "created_at": "2026-01-09 02:30:34+00:00",
        "last_modified": "2026-01-09 02:30:35+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "task_categories:image-to-text",
          "task_categories:zero-shot-classification",
          "task_ids:image-captioning",
          "annotations_creators:no-annotation",
          "language_creators:other",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100M<n<1B",
          "format:parquet",
          "modality:image",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2102.05918",
          "arxiv:2204.06125",
          "arxiv:2010.11929",
          "region:us",
          "image-text pairs"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for COYO-700M\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCOYO-700M is a large-scale dataset that contains 747M image-text pairs as well as many other meta-attributes to increase the usability to train various models. Our dataset follows a similar strategy to previous vision-and-language datasets, collecting many informative pairs of alt-text and its associated image in HTML documents. We expect COYO to be used to train popular large-scale foundation models \ncomplementary to otherâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lingao123/coyo-700m.",
        "url": "https://huggingface.co/datasets/lingao123/coyo-700m",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image",
          "image-to-text",
          "zero-shot-classification"
        ],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "Dr3dre/Genius-song-lyrics-cleaned",
        "author": "Dr3dre",
        "created_at": "2026-01-07 23:29:12+00:00",
        "last_modified": "2026-01-08 00:14:20+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:sentence-similarity",
          "language:en",
          "language:it",
          "language:ia",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸŽµ Genius Song Lyrics cleaned Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is originally taken from Genius Song Lyrics and it contains cleaned and normalized song lyrics for more than 5 million songs, designed for large-scale topic modeling, clustering, and semantic analysis.\nThe dataset was specifically preprocessed to be compatible with embedding-based models (e.g. Sentence Transformers, BERTopic) while preserving lyrical meaning and thematic content.\nRepetitive structuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dr3dre/Genius-song-lyrics-cleaned.",
        "url": "https://huggingface.co/datasets/Dr3dre/Genius-song-lyrics-cleaned",
        "languages": [
          "en",
          "it",
          "ia"
        ],
        "tasks": [
          "text-classification",
          "sentence-similarity"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211_12",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:39:26+00:00",
        "last_modified": "2026-01-05 18:42:14+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211_12\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®ç›˜å­é¤æ¡Œpart_2\ntotal_episodes: 191\ntotal_tasks: 1\nsize: 6.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211_12.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241211_12",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "shenlong7/ptb_text_only",
        "author": "shenlong7",
        "created_at": "2026-01-06 02:09:15+00:00",
        "last_modified": "2026-01-06 02:09:18+00:00",
        "downloads": 30,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_ids:language-modeling",
          "task_ids:masked-language-modeling",
          "annotations_creators:expert-generated",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:other",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "This is the Penn Treebank Project: Release 2 CDROM, featuring a million words of 1989 Wall Street Journal material. This corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure.",
        "url": "https://huggingface.co/datasets/shenlong7/ptb_text_only",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "fill-mask"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "engsaleh22/quran-audio-text-dataset",
        "author": "engsaleh22",
        "created_at": "2026-01-10 14:29:36+00:00",
        "last_modified": "2026-01-10 14:29:37+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "language:en",
          "language:ar",
          "size_categories:100K<n<1M",
          "region:us",
          "Islam",
          "Quran",
          "Ayahs"
        ],
        "description": "\n\t\n\t\t\n\t\tQuranic MD ðŸ•Œ\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis collection provides comprehensive audio recordings of the complete Quran (Holy Book of Islam) with multiple recitations and granular annotations. The dataset is organized into two separate, specialized datasets optimized for different use cases.\n\n\t\n\t\t\n\t\tDataset Links\n\t\n\n\n\t\n\t\t\n#\nDataset\nFocus\nSamples\nHugging Face Link\n\n\n\t\t\n1\nðŸŽµ Ayah Dataset\nVerse-level recitations\n187,080\nBuraaq/quran-md-ayahs\n\n\n2\nðŸ“ Word Dataset\nIndividual word pronunciationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/engsaleh22/quran-audio-text-dataset.",
        "url": "https://huggingface.co/datasets/engsaleh22/quran-audio-text-dataset",
        "languages": [
          "en",
          "ar"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "xjy0123/cifar10",
        "author": "xjy0123",
        "created_at": "2026-01-06 12:19:04+00:00",
        "last_modified": "2026-01-06 12:19:06+00:00",
        "downloads": 39,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "source_datasets:https://www.cs.toronto.edu/~kriz/cifar.html",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:imagefolder",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Specifications\n\t\n\nContains the entire CIFAR10 dataset, downloaded via PyTorch, then split and saved as .png files representing 32x32 images.\nThere a three splits, perfectly balanced class-wise:\n\ntrain: 49,000 out of the original 50,000 samples from the training set of CIFAR10;\ncalibration: 1,000 left-out samples from the training set;\ntest: 10,000 samples, the entire original test set.\n\n\n\t\n\t\t\n\t\n\t\n\t\tFile Structure\n\t\n\nFiles are archives <split>/<classname>.zip. Eachâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xjy0123/cifar10.",
        "url": "https://huggingface.co/datasets/xjy0123/cifar10",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "NNEngine/Reasoning-Heavy-Math-ML-Explanations",
        "author": "NNEngine",
        "created_at": "2026-01-11 21:50:35+00:00",
        "last_modified": "2026-01-11 22:13:35+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:1K<n<10K",
          "region:us",
          "reasoning",
          "mathematics",
          "machine-learning",
          "optimization",
          "linear-algebra",
          "probability",
          "chain-of-thought"
        ],
        "description": "\n\t\n\t\t\n\t\tReasoning-Heavy Math & ML Explanations\n\t\n\nDataset: NNEngine/Reasoning-Heavy-Math-ML-Explanations\nVersion: wikipedia_reasoning_final_v1.0\nLicense: CC-BY-SA 4.0\nAuthor: Shivam Sharma (Independent Researcher)\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nReasoning-Heavy Math & ML Explanations is a high-quality, reasoning-oriented dataset derived exclusively from English Wikipedia.\nThe dataset focuses on explicit human-authored reasoning and explanations in mathematics and machine learningâ€“related domainsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NNEngine/Reasoning-Heavy-Math-ML-Explanations.",
        "url": "https://huggingface.co/datasets/NNEngine/Reasoning-Heavy-Math-ML-Explanations",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "nyuuzyou/joyreactor",
        "author": "nyuuzyou",
        "created_at": "2025-08-01 06:52:46+00:00",
        "last_modified": "2025-12-26 15:54:03+00:00",
        "downloads": 2,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "task_categories:text-classification",
          "task_categories:video-classification",
          "task_categories:text-generation",
          "annotations_creators:found",
          "multilinguality:multilingual",
          "language:ru",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "modality:image",
          "modality:video",
          "modality:text",
          "region:us",
          "image",
          "video",
          "text",
          "not-for-all-audiences"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for JoyReactor.cc\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains a collection of posts from JoyReactor.cc, a Russian-language image board and content sharing community website. The dataset includes user-submitted posts with images or videos, ratings, tags, and metadata spanning from 2010 to 2014. Note: This dataset is incomplete and will not be updated.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nThe dataset content is primarily in Russian with some English content:\n\nRussian (ru)\nEnglishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/joyreactor.",
        "url": "https://huggingface.co/datasets/nyuuzyou/joyreactor",
        "languages": [
          "ru",
          "en"
        ],
        "tasks": [
          "image-classification",
          "text-classification",
          "video-classification",
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_square_bread_in_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:48:27+00:00",
        "last_modified": "2026-01-05 22:48:36+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_square_bread_in_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ–¹å½¢é¢åŒ…æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 42\ntotal_tasks: 1\nsize: 31.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_square_bread_in_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_square_bread_in_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "dsfsi-anv/multilingual-nchlt-dataset",
        "author": "dsfsi-anv",
        "created_at": "2025-08-27 14:34:58+00:00",
        "last_modified": "2026-01-06 05:25:21+00:00",
        "downloads": 681,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:af",
          "language:en",
          "language:nr",
          "language:nso",
          "language:st",
          "language:ss",
          "language:tn",
          "language:ts",
          "language:ve",
          "language:xh",
          "language:zu",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio",
          "speech",
          "south-africa",
          "under-resourced-languages",
          "multilingual-speech",
          "asr",
          "nchlt",
          "sadilar",
          "low-resource",
          "african-languages"
        ],
        "description": "\n\t\n\t\t\n\t\tNCHLT Auxiliary Speech Corpus - Combined Multilingual Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a combined multilingual version of the NCHLT Auxiliary Speech Corpus, compiled by the Data Science for Social Impact (DSFSI) research group at the University of Pretoria to facilitate easier benchmarking and multi-language speech recognition research.\nThe original auxiliary data was collected during the National Centre for Human Language Technology (NCHLT) project for the 11 officialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dsfsi-anv/multilingual-nchlt-dataset.",
        "url": "https://huggingface.co/datasets/dsfsi-anv/multilingual-nchlt-dataset",
        "languages": [
          "af",
          "en",
          "nr",
          "nso",
          "st",
          "ss",
          "tn",
          "ts",
          "ve",
          "xh",
          "zu"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "sarahzhoo620/tennis-momentum-analysis-data",
        "author": "sarahzhoo620",
        "created_at": "2025-12-23 03:29:05+00:00",
        "last_modified": "2026-01-07 04:58:18+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "source_datasets:2023 Wimbledon Championship",
          "language:en",
          "modality:tabular",
          "region:us",
          "tennis",
          "sports",
          "match data",
          "momentum analysis",
          "tabular"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Tennis Momentum Analysis Dataset\n\t\n\n\n\nThis dataset contains detailed point-by-point data from a 2023 Wimbledon Championship tennis match between Carlos Alcaraz and Nicolas Jarry, designed to support momentum analysis and sports analytics research. It captures 100 data points with 47 features covering match progression, player performance metrics, and technical details of each point.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\nThe Tennis Momentumâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sarahzhoo620/tennis-momentum-analysis-data.",
        "url": "https://huggingface.co/datasets/sarahzhoo620/tennis-momentum-analysis-data",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1126",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:54:58+00:00",
        "last_modified": "2026-01-07 06:55:29+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1126\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­æ‹¿èµ·èŠ±æœµpart_7\ntotal_episodes: 224\ntotal_tasks: 1\nsize: 241.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1126.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1126",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_putthebananaonthetable",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:12:13+00:00",
        "last_modified": "2026-01-06 10:12:27+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_putthebananaonthetable\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¦™è•‰æ”¾åœ¨æ¡Œå­ä¸Š\ntotal_episodes: 151\ntotal_tasks: 1\nsize: 86.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_putthebananaonthetable.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_putthebananaonthetable",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241210",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:02:38+00:00",
        "last_modified": "2026-01-05 18:05:32+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241210\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ¸…æ´é¤æ¡Œpart_2\ntotal_episodes: 195\ntotal_tasks: 1\nsize: 10.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241210.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241210",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer_1_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:54:00+00:00",
        "last_modified": "2026-01-05 17:55:09+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_slide_close_drawer_1_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ»‘åŠ¨å…³é—­æŠ½å±‰part_3\ntotal_episodes: 286\ntotal_tasks: 1\nsize: 468.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer_1_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer_1_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pickupthebananafromtheplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:11:00+00:00",
        "last_modified": "2026-01-07 07:11:28+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pickupthebananafromtheplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç›˜å­ä¸Šæ‹¿èµ·é¦™è•‰\ntotal_episodes: 153\ntotal_tasks: 1\nsize: 84.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pickupthebananafromtheplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pickupthebananafromtheplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_41_putplum",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:14:47+00:00",
        "last_modified": "2026-01-05 23:16:49+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_41_putplum\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾æŽå­part_2\ntotal_episodes: 199\ntotal_tasks: 1\nsize: 4.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_41_putplum.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_41_putplum",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:51:17+00:00",
        "last_modified": "2026-01-05 17:51:45+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_slide_close_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ»‘åŠ¨å…³é—­æŠ½å±‰part_1\ntotal_episodes: 21\ntotal_tasks: 1\nsize: 81.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1104",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:59:23+00:00",
        "last_modified": "2026-01-07 06:59:36+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1104\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¯®å­ä¸­æ‹¿èµ·èŠ’æžœpart_1\ntotal_episodes: 110\ntotal_tasks: 1\nsize: 114.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1104.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mangoes_from_the_basket_1104",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "paperswithbacktest/All-Daily-TuringRiskIndex",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:30:49+00:00",
        "last_modified": "2026-01-10 03:58:09+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nThe Turing Risk Index aggregates market, business, and political risk\nsignals into a comprehensive daily indicator. The dataset provides historical\nvalues for the headline index along with its underlying components, enabling\nusers to monitor and forecast global risk conditions.\n\n\t\n\t\t\n\t\tKey Highlights\n\t\n\n\nCoverage: Daily history of the global Turing Risk Index from SOV.AI.\nComposition: Includes market risk estimates, recession probabilities,\nvolatility measuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/All-Daily-TuringRiskIndex.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/All-Daily-TuringRiskIndex",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_58_pumpkinlittleoven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:21:49+00:00",
        "last_modified": "2026-01-05 10:23:50+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_58_pumpkinlittleoven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å—ç“œå°çƒ¤ç®±\ntotal_episodes: 200\ntotal_tasks: 1\nsize: 3.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_58_pumpkinlittleoven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_58_pumpkinlittleoven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "zhangheyi/instructpix2pix-clip-filtered",
        "author": "zhangheyi",
        "created_at": "2026-01-07 06:06:51+00:00",
        "last_modified": "2026-01-07 06:06:53+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2211.09800",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for InstructPix2Pix CLIP-filtered\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset can be used to train models to follow edit instructions. Edit instructions\nare available in the edit_prompt. original_image can be used with the edit_prompt and\nedited_image denotes the image after applying the edit_prompt on the original_image. \nRefer to the GitHub repository to know more about\nhow this dataset can be used to train a model that can follow instructions. \n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhangheyi/instructpix2pix-clip-filtered.",
        "url": "https://huggingface.co/datasets/zhangheyi/instructpix2pix-clip-filtered",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "huzican/test_game",
        "author": "huzican",
        "created_at": "2026-01-08 15:22:16+00:00",
        "last_modified": "2026-01-09 03:04:10+00:00",
        "downloads": 119,
        "likes": 0,
        "tags": [
          "task_categories:any-to-any",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "multimodal",
          "chain-of-thought"
        ],
        "description": "\n\t\n\t\t\n\t\tGame Reasoning Dataset\n\t\n\nA multimodal reasoning dataset for game navigation and puzzle-solving tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 10840 visual reasoning examples from various game scenarios.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"huzican/test_game\")\n\n",
        "url": "https://huggingface.co/datasets/huzican/test_game",
        "languages": [
          "en"
        ],
        "tasks": [
          "any-to-any"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "james-sullivan/consistency_sandbagging_eval",
        "author": "james-sullivan",
        "created_at": "2026-01-11 15:10:21+00:00",
        "last_modified": "2026-01-11 15:19:30+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2403.03218",
          "region:us",
          "sandbagging",
          "evaluation",
          "safety",
          "ai-safety"
        ],
        "description": "\n\t\n\t\t\n\t\tConsistency Sandbagging Evaluation Dataset\n\t\n\nThis dataset is designed for evaluating consistency-based sandbagging detection in language models.\n\n\t\n\t\t\n\t\tPurpose\n\t\n\nSandbagging is when a model intentionally underperforms on capability evaluations while maintaining full capability in deployment. This dataset helps detect sandbagging by testing whether models answer the same questions differently based on how \"evaluation-like\" the question appears.\nThe key insight: if a model isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/james-sullivan/consistency_sandbagging_eval.",
        "url": "https://huggingface.co/datasets/james-sullivan/consistency_sandbagging_eval",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "vania-janet/multiturn-rag-retrieval-data",
        "author": "vania-janet",
        "created_at": "2025-12-29 23:10:11+00:00",
        "last_modified": "2026-01-08 06:09:46+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "rag",
          "retrieval",
          "multi-turn",
          "conversational",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tMT-RAG Benchmark - Retrieval Results\n\t\n\nThis dataset contains experimental results from the Multi-Turn RAG (MT-RAG) benchmark focusing on retrieval tasks across multiple domains.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCompetition: MT-RAG Benchmark - Task A (Retrieval)Date: January 2026Domains: CLAPNQ, CLOUD, FIQA, GOVT\n\n\t\n\t\t\n\t\tContents\n\t\n\n\n\t\n\t\t\n\t\t1. Baseline Results with Ground Truth Rewrites\n\t\n\nDirectory: submissions/baselines_rewrite/\nResults for 5 retrieval models using query rewritesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vania-janet/multiturn-rag-retrieval-data.",
        "url": "https://huggingface.co/datasets/vania-janet/multiturn-rag-retrieval-data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-retrieval",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_787_Clean_the_dining_table",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:45:35+00:00",
        "last_modified": "2026-01-05 22:34:40+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_787\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ¸…ç†é¤æ¡Œ\ntotal_episodes: 271\ntotal_tasks: 1\nsize: 27G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_787_Clean_the_dining_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_787_Clean_the_dining_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "NancyKh/ScienceMetaBench",
        "author": "NancyKh",
        "created_at": "2026-01-08 09:39:30+00:00",
        "last_modified": "2026-01-08 09:39:30+00:00",
        "downloads": 141,
        "likes": 0,
        "tags": [
          "language:en",
          "language:zh",
          "license:cc-by-4.0",
          "modality:document",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tScienceMetaBench\n\t\n\nEnglish | ä¸­æ–‡\nðŸ¤— HuggingFace Dataset | ðŸ’» GitHub Repository\nAcknowledgements: ðŸ” Dingo\nScienceMetaBench is a benchmark dataset for evaluating the accuracy of metadata extraction from scientific literature PDF files. The dataset covers three major categories: academic papers, textbooks, and ebooks, and can be used to assess the performance of Large Language Models (LLMs) or other information extraction systems.\n\n\t\n\t\n\t\n\t\tðŸ“Š Dataset Overview\n\t\n\n\n\t\n\t\n\t\n\t\tData Typesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NancyKh/ScienceMetaBench.",
        "url": "https://huggingface.co/datasets/NancyKh/ScienceMetaBench",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_egg",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:15:34+00:00",
        "last_modified": "2026-01-05 22:15:52+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_egg\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é¸¡è›‹\ntotal_episodes: 45\ntotal_tasks: 1\nsize: 59.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_egg.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_egg",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_cucumber_on_the_left_side_of_the_bowl",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:47:32+00:00",
        "last_modified": "2026-01-05 23:47:54+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_put_the_cucumber_on_the_left_side_of_the_bowl\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é»„ç“œæ”¾åœ¨ç¢—çš„å·¦ä¾§\ntotal_episodes: 103\ntotal_tasks: 1\nsize: 242.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_cucumber_on_the_left_side_of_the_bowl.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_cucumber_on_the_left_side_of_the_bowl",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "quguanni/kernel-vuln-dataset",
        "author": "quguanni",
        "created_at": "2026-01-08 00:46:53+00:00",
        "last_modified": "2026-01-08 01:21:14+00:00",
        "downloads": 9,
        "likes": 1,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "linux-kernel",
          "security",
          "vulnerabilities",
          "code",
          "bugs",
          "software-engineering"
        ],
        "description": "\n\t\n\t\t\n\t\tLinux Kernel Vulnerability Dataset\n\t\n\n125,183 bug-introducing commits mined from 20 years of Linux kernel git history (2005-2025).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset maps every kernel bug fix with a Fixes: tag back to the commit that introduced the bug. It enables research on:\n\nVulnerability detection: Train models to identify bug-introducing commits\nBug lifetime analysis: Study how long different bug types persist\nSubsystem risk assessment: Identify which kernel subsystemsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/quguanni/kernel-vuln-dataset.",
        "url": "https://huggingface.co/datasets/quguanni/kernel-vuln-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "kkas145/dialogsum",
        "author": "kkas145",
        "created_at": "2026-01-08 08:56:52+00:00",
        "last_modified": "2026-01-08 08:56:53+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:summarization",
          "task_categories:text-generation",
          "annotations_creators:expert-generated",
          "language_creators:expert-generated",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "dialogue-summary",
          "one-liner-summary",
          "meeting-title",
          "email-subject"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for DIALOGSum Corpus\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nHomepage: https://aclanthology.org/2021.findings-acl.449\nRepository: https://github.com/cylnlp/dialogsum\nPaper: https://aclanthology.org/2021.findings-acl.449\nPoint of Contact: https://huggingface.co/knkarthick\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nDialogSum is a large-scale dialogue summarization dataset, consisting of 13,460 (Plus 100 holdout data for topic generation) dialogues with correspondingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kkas145/dialogsum.",
        "url": "https://huggingface.co/datasets/kkas145/dialogsum",
        "languages": [
          "en"
        ],
        "tasks": [
          "summarization",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "LisansBul-Research/Windows-11-Kernel-DSE-Analysis-2026",
        "author": "LisansBul-Research",
        "created_at": "2026-01-10 01:04:43+00:00",
        "last_modified": "2026-01-10 01:09:03+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us",
          "security",
          "windows",
          "kernel"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ›¡ï¸ Analysis: Windows 11 Kernel-Mode Code Signing Enforcement\n\t\n\nDocument ID: TR-2026 | Date: Jan 2026\n\n\t\n\t\t\n\t\t1. Executive Summary\n\t\n\nThis open dataset contains technical documentation regarding CI.dll validation routines in Windows 11. It analyzes how the operating system verifies digital signatures during the boot process to maintain Ring 0 integrity.\n\n\t\n\t\t\n\t\t2. Official Project Repository & Tools\n\t\n\nFor the complete research logs, updated tools, and implementation guides referencedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LisansBul-Research/Windows-11-Kernel-DSE-Analysis-2026.",
        "url": "https://huggingface.co/datasets/LisansBul-Research/Windows-11-Kernel-DSE-Analysis-2026",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_throw_battery",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:49:33+00:00",
        "last_modified": "2026-01-05 21:53:07+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_throw_battery\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰”æŽ‰ç”µæ± \ntotal_episodes: 624\ntotal_tasks: 1\nsize: 6.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_throw_battery.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_throw_battery",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "kolerk/Video_Reality_Test",
        "author": "kolerk",
        "created_at": "2025-11-24 04:06:41+00:00",
        "last_modified": "2026-01-06 03:15:19+00:00",
        "downloads": 555,
        "likes": 7,
        "tags": [
          "task_categories:text-to-video",
          "task_categories:image-text-to-video",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2512.13281",
          "region:us",
          "ASMR",
          "Evaluation",
          "Video-Reality-Test"
        ],
        "description": "\n Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?\n\n\n\n\n  \n  \n  \n  \n\n\nThis repository serves as a benchmark for evaluating the realism of video generation models. It specifically focuses on ASMR content, which requires high fidelity in texture rendering, micro-movements, and audio-visual synchronization.\n\n\t\t\n\t\tBenchmark Structure\n\t\n\nThis benchmark is divided into two difficulty levels. All data is provided in the test split to reflect its purpose for evaluation:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kolerk/Video_Reality_Test.",
        "url": "https://huggingface.co/datasets/kolerk/Video_Reality_Test",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-video",
          "image-text-to-video"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-LeanSAT",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:37:42+00:00",
        "last_modified": "2026-01-10 13:49:03+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4",
          "leansat",
          "sat-solver",
          "bitvectors",
          "verification"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-LeanSAT\n\t\n\nLeanSAT provides an interface and foundation for verified SAT reasoning in Lean 4. Now integrated into Lean 4 core as Std.Tactic.BVDecide.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/leanprover/leansat\nLicense: Apache-2.0\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n1,752\n\n\nFiles Processed\n305\n\n\n\t\n\n\n\t\n\t\t\n\t\tType Distribution\n\t\n\n\n\t\n\t\t\nType\nCount\n\n\n\t\t\ntheorem\n1274\n\n\ndef\n380\n\n\nstructure\n53\n\n\nabbrev\n18\n\n\ninductive\n17\n\n\nclass\n8\n\n\nopaque\n2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-LeanSAT.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-LeanSAT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "enPurified/SlimOrca-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 17:38:29+00:00",
        "last_modified": "2026-01-12 00:39:09+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:Open-Orca/SlimOrca",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "enPurified",
          "quality-filtered",
          "open-orca"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– SlimOrca-enPurified-openai-messages\n\t\n\nSlimOrca-enPurified is a highly curated, \"prose-first\" derivative of the Open-Orca/SlimOrca dataset. \nThe enPurified collection is built on a specific philosophy: Specialization. While there are many datasets focused on coding (StackOverflow, StarCoder) and mathematics (GSM8K, MathInstruct), high-quality English prose often becomes diluted when mixed with syntax-heavy code or rigid formulas. This dataset is designed to provide only the highestâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/SlimOrca-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/SlimOrca-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "andreafarina/PREMOVE",
        "author": "andreafarina",
        "created_at": "2026-01-08 09:56:45+00:00",
        "last_modified": "2026-01-08 10:05:25+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "task_categories:translation",
          "task_categories:sentence-similarity",
          "language:la",
          "language:el",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "preverbs",
          "motion_verbs",
          "semantics",
          "spatial_relations",
          "syntax",
          "linguistics"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/andreafarina/PREMOVE",
        "languages": [
          "la",
          "el",
          "en"
        ],
        "tasks": [
          "token-classification",
          "translation",
          "sentence-similarity"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Mathieu-Thomas-JOSSET/the_office_only_michael.jsonl",
        "author": "Mathieu-Thomas-JOSSET",
        "created_at": "2026-01-06 20:05:32+00:00",
        "last_modified": "2026-01-06 20:05:34+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "sharegpt",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tthe_office_only_michael.jsonl\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ntrain.jsonl\n\n\n\t\n\t\t\n\t\tLoading (example)\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"Mathieu-Thomas-JOSSET/the_office_only_michael.jsonl\")\nprint(ds)\n\n",
        "url": "https://huggingface.co/datasets/Mathieu-Thomas-JOSSET/the_office_only_michael.jsonl",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-emotion-aware-interactions",
        "author": "ariefansclub",
        "created_at": "2026-01-11 01:39:53+00:00",
        "last_modified": "2026-01-11 01:42:18+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "emotion",
          "interaction",
          "futuristic"
        ],
        "description": "\n\t\n\t\t\n\t\tEmotion-Aware Interactions\n\t\n\nDataset for emotion-sensitive humanoid responses.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-emotion-aware-interactions",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "syx2003/SUPERChem",
        "author": "syx2003",
        "created_at": "2026-01-09 15:39:20+00:00",
        "last_modified": "2026-01-09 15:39:20+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "language:zh",
          "license:mit",
          "size_categories:n<1K",
          "modality:document",
          "arxiv:2512.01274",
          "region:us",
          "chemistry",
          "multimodal",
          "reasoning",
          "benchmark",
          "STEM"
        ],
        "description": "\n\n\n\t\n\t\t\n\t\tSUPERChem: A Multimodal Reasoning Benchmark in Chemistry\n\t\n\nðŸŒ Website | ðŸ“„ Paper | ðŸ’» Code\n\n\n\n\t\n\t\t\n\t\tðŸ“¢ Updates\n\t\n\n\n[2025-12-06] PDF Preview Released: We have released the PDF version of SUPERChem in both English and Chinese to facilitate easier previewing and manual inspection, especially for non-technical users. You can download SUPERChem-500.zip to access the dataset in PDF format. The password to unzip the file is SUPERChem2025.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ§ª What is SUPERChem?\n\t\n\nSUPERChem isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/syx2003/SUPERChem.",
        "url": "https://huggingface.co/datasets/syx2003/SUPERChem",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_bread_on_the_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:46:53+00:00",
        "last_modified": "2026-01-05 23:47:23+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_put_the_bread_on_the_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾åœ¨æ¡Œå­ä¸Špart_6\ntotal_episodes: 297\ntotal_tasks: 1\nsize: 479.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_bread_on_the_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_the_bread_on_the_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Superdav42/wordpress-translations-nl",
        "author": "Superdav42",
        "created_at": "2026-01-05 01:10:47+00:00",
        "last_modified": "2026-01-05 01:27:46+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "language:en",
          "language:nl",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "wordpress",
          "translation",
          "fine-tuning",
          "mistral"
        ],
        "description": "\n\t\n\t\t\n\t\tWordPress Translation Dataset (English â†’ NL)\n\t\n\nTranslation pairs extracted from WordPress plugins, themes, and core translations.\nDesigned for fine-tuning LLMs on WordPress-specific translation tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains English to NL translation pairs extracted from\nthe official WordPress translation project (translate.wordpress.org).\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTraining examples\n222,216\n\n\nTest examples\n55,554\n\n\nAvg sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Superdav42/wordpress-translations-nl.",
        "url": "https://huggingface.co/datasets/Superdav42/wordpress-translations-nl",
        "languages": [
          "en",
          "nl"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "PeacebinfLow/mindseye-lab-ledger",
        "author": "PeacebinfLow",
        "created_at": "2026-01-10 02:30:08+00:00",
        "last_modified": "2026-01-10 02:51:38+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "ledger",
          "event-log",
          "state-machine",
          "retrieval",
          "rag",
          "prompt-engineering",
          "agent",
          "workflow",
          "llm",
          "education",
          "evaluation",
          "jsonl"
        ],
        "description": "\n\t\n\t\t\n\t\tMindsEye Lab Memory Ledger\n\t\n\nA queryable educational dataset for the MindsEye/MindScript ecosystem.\nThis dataset is a public ledger of architectural states, template cards, repository mappings, and constraint tests. It is designed to function as:\n\nLearning content â€” teaches MindsEye architecture through structured examples\nEvaluation suite â€” validates state machine constraints\nRetrieval store â€” searchable knowledge base for RAG + agent systems\nDemo backend â€” powers live portfolioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PeacebinfLow/mindseye-lab-ledger.",
        "url": "https://huggingface.co/datasets/PeacebinfLow/mindseye-lab-ledger",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-retrieval",
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_triangle_bread_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:49:42+00:00",
        "last_modified": "2026-01-05 22:49:51+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_triangle_bread_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ä¸‰è§’å½¢é¢åŒ…æ”¾å…¥é”…ä¸­\ntotal_episodes: 25\ntotal_tasks: 1\nsize: 19.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_triangle_bread_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_triangle_bread_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "puwaer/cvalues_rlhf_en_cot",
        "author": "puwaer",
        "created_at": "2026-01-08 07:06:26+00:00",
        "last_modified": "2026-01-08 07:07:30+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tpuwaer/cvalues_rlhf_en_cot\n\t\n\nThis dataset is based on Skepsun/cvalues_rlhf and has been translated into appropriate English for DPO (Direct Preference Optimization).\n\nFor the prompt and rejected (negative example) fields, outputs from huihui-ai/Huihui-gpt-oss-20b-mxfp4-abliterated-v2 were used.\nFor the chosen (positive example) field, outputs from openai/gpt-oss-20b were used.\nFor the chosen chain of thought field, outputs from Qwen/Qwen3-235B-A22B-Instruct-2507 were used.\nFor theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/puwaer/cvalues_rlhf_en_cot.",
        "url": "https://huggingface.co/datasets/puwaer/cvalues_rlhf_en_cot",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "fill-mask"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_pullout_then_press",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:35:24+00:00",
        "last_modified": "2026-01-05 21:38:16+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_plug_pullout_then_press\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹”å‡ºæ’å¤´ç„¶åŽæŒ‰åŽ‹\ntotal_episodes: 108\ntotal_tasks: 1\nsize: 943.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_pullout_then_press.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_pullout_then_press",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "data-archetype/cc12_imagenet21k_recap_hq_bucketed",
        "author": "data-archetype",
        "created_at": "2026-01-10 16:20:39+00:00",
        "last_modified": "2026-01-11 17:15:47+00:00",
        "downloads": 47,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "license:other",
          "library:webdataset",
          "region:us",
          "webdataset",
          "images",
          "captions"
        ],
        "description": "\n\t\n\t\t\n\t\tcc12_imagenet21k_recap_hq_bucketed\n\t\n\n\nTitle: cc12_imagenet21k_recap_hq_bucketed\nDescription: This ~18M rows dataset is a re upload of https://huggingface.co/datasets/gmongaras/CC12M_and_Imagenet21K_Recap_Highqual where the images have\nbeen pre bucketed into SDXL style aspect ratio buckets for target training at ~512^2 and ~256^2 pixels, and where about 7M rows were recaptioned with either Gemini or Ministral.\n To avoid re encoding the images they have been left untouched so croppingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/data-archetype/cc12_imagenet21k_recap_hq_bucketed.",
        "url": "https://huggingface.co/datasets/data-archetype/cc12_imagenet21k_recap_hq_bucketed",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": []
      },
      {
        "id": "phanerozoic/Lean4-SciLean",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:50:55+00:00",
        "last_modified": "2026-01-10 15:13:20+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-SciLean\n\t\n\nStructured dataset from SciLean â€” Scientific computing.\n4,454 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/lecopivo/SciLean\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-SciLean.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-SciLean",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ArkAiLab-Adl/Nexora-music-pd-v1-medium",
        "author": "ArkAiLab-Adl",
        "created_at": "2026-01-08 08:43:51+00:00",
        "last_modified": "2026-01-08 09:19:45+00:00",
        "downloads": 40,
        "likes": 1,
        "tags": [
          "task_categories:text-to-audio",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:audiofolder",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "audio",
          "music",
          "public-domain",
          "historical",
          "open-source",
          "ai",
          "machine-learning",
          "text-to-audio",
          "dataset"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/ArkAiLab-Adl/Nexora-music-pd-v1-medium",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-audio"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-EquationalTheories",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:56:40+00:00",
        "last_modified": "2026-01-10 15:13:26+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-EquationalTheories\n\t\n\nStructured dataset from equational_theories â€” Terence Tao's magma equations project.\n14,379 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/teorth/equational_theories\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-EquationalTheories.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-EquationalTheories",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Mathieu-Thomas-JOSSET/fine_tome_style_sharegpt_corrected_tabs_random_datetime.jsonl",
        "author": "Mathieu-Thomas-JOSSET",
        "created_at": "2026-01-05 20:29:40+00:00",
        "last_modified": "2026-01-05 20:29:41+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "sharegpt",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tfine_tome_style_sharegpt_corrected_tabs_random_datetime.jsonl\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ntrain.jsonl\n\n\n\t\n\t\t\n\t\tLoading (example)\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"Mathieu-Thomas-JOSSET/fine_tome_style_sharegpt_corrected_tabs_random_datetime.jsonl\")\nprint(ds)\n\n",
        "url": "https://huggingface.co/datasets/Mathieu-Thomas-JOSSET/fine_tome_style_sharegpt_corrected_tabs_random_datetime.jsonl",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "rudybtzee/btz",
        "author": "rudybtzee",
        "created_at": "2026-01-09 20:22:59+00:00",
        "last_modified": "2026-01-09 20:22:59+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸª© VibeCoding Dataset Project\n\t\n\nCollecting the vibes of coding â€” one log at a time.\n\n\n\t\n\t\t\n\t\tðŸ“¢ Call for Volunteers\n\t\n\nWeâ€™re building an open dataset to capture real-world coding interactions between developers and AI coding assistants â€” and we need your help!\nThis dataset will help researchers and developers better understand how humans and code models interact across different tools, and improve the future of AI-assisted software development.\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Project Overview\n\t\n\nTheâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rudybtzee/btz.",
        "url": "https://huggingface.co/datasets/rudybtzee/btz",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "KoryD207/CCP-sensitive-prompts",
        "author": "KoryD207",
        "created_at": "2026-01-06 17:34:12+00:00",
        "last_modified": "2026-01-06 17:34:13+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tCCP Sensitive Prompts\n\t\n\nThese prompts cover sensitive topics in China, and are likely to be censored by Chinese models.\n",
        "url": "https://huggingface.co/datasets/KoryD207/CCP-sensitive-prompts",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_1rgb_bread_in_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:53:20+00:00",
        "last_modified": "2026-01-05 10:56:09+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_1rgb_bread_in_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„é¢åŒ…\ntotal_episodes: 2975\ntotal_tasks: 1\nsize: 12.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_1rgb_bread_in_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_1rgb_bread_in_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Idris2",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:05:53+00:00",
        "last_modified": "2026-01-10 14:05:56+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "idris2",
          "dependent-types",
          "functional-programming"
        ],
        "description": "\n\t\n\t\t\n\t\tIdris2\n\t\n\nA structured dataset of type declarations and definitions from Idris 2, a dependently typed functional programming language.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/idris-lang/Idris2\nWebsite: https://idris-lang.org\nLicense: BSD-3-Clause\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n6,211\n\n\nFunctions\n5,318\n\n\nData types\n695\n\n\nRecords\n198\n\n\nDocstring Coverage\n30.8%\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nType signatureâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Idris2.",
        "url": "https://huggingface.co/datasets/phanerozoic/Idris2",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_left_hand_put_the_red_chili_pepper_on_the_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 04:57:41+00:00",
        "last_modified": "2026-01-08 05:36:45+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_red_chili_pepper_on_the_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†çº¢è¾£æ¤’æ”¾åœ¨ç›˜å­ä¸Š\ntotal_episodes: 131\ntotal_tasks: 1\nsize: 776.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_put_the_red_chili_pepper_on_the_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_put_the_red_chili_pepper_on_the_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1101",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:43:50+00:00",
        "last_modified": "2026-01-07 06:47:44+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1101\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_7\ntotal_episodes: 282\ntotal_tasks: 1\nsize: 338.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1101.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1101",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_pick_cup_pour_cup_place",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 01:50:31+00:00",
        "last_modified": "2026-01-06 02:00:52+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_xsens_1rgb_pick_cup_pour_cup_place\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·æ¯å­å€’æ¯å­æ”¾ç½®\ntotal_episodes: 229\ntotal_tasks: 1\nsize: 4.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_pick_cup_pour_cup_place.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_pick_cup_pour_cup_place",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_car_in_the_blue_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:42:12+00:00",
        "last_modified": "2026-01-06 00:42:59+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_car_in_the_blue_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†ç™½è‰²æ±½è½¦æ”¾å…¥è“è‰²ç›’å­\ntotal_episodes: 69\ntotal_tasks: 1\nsize: 331.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_car_in_the_blue_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_white_car_in_the_blue_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "yyyang/SlideTailor-PSP-dataset",
        "author": "yyyang",
        "created_at": "2025-11-17 09:30:09+00:00",
        "last_modified": "2026-01-10 13:31:40+00:00",
        "downloads": 98,
        "likes": 2,
        "tags": [
          "task_categories:summarization",
          "language:en",
          "size_categories:n<1K",
          "modality:document",
          "modality:text",
          "arxiv:2512.20292",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSlideTailor-PSP-dataset\n\t\n\nPaper | Code\nThis is the official dataset for the AAAI 2026 paper: SlideTailor: Personalized Presentation Slide Generation for Scientific Papers.\nThis dataset supports research on conditional document-to-slide generation (Paper-to-Slides with Preference). It contains:\n\nTarget research papers (PDF) to be summarized into slides\nSlide templates (PPTX)\nCurated paperâ€“slide pairs for preference extraction\nConfigurations for evaluation sets (how to pairâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/yyyang/SlideTailor-PSP-dataset.",
        "url": "https://huggingface.co/datasets/yyyang/SlideTailor-PSP-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "summarization"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-future-task-adaptation",
        "author": "ariefansclub",
        "created_at": "2026-01-11 01:44:48+00:00",
        "last_modified": "2026-01-11 01:45:22+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "adaptation",
          "autonomous",
          "futuristic"
        ],
        "description": "\n\t\n\t\t\n\t\tFuture Task Adaptation\n\t\n\nAdaptive behavior dataset for autonomous humanoids.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-future-task-adaptation",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Isabelle-Stdlib",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:04:18+00:00",
        "last_modified": "2026-01-10 15:14:21+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "isabelle",
          "hol"
        ],
        "description": "\n\t\n\t\t\n\t\tIsabelle-Stdlib\n\t\n\nStructured dataset from the Isabelle/HOL standard library - core theories and analysis.\n78,022 declarations extracted from Isabelle theory files.\nIncludes HOL, HOL-Library, HOL-Analysis, and other foundational Isabelle theories.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Isabelle-Stdlib.",
        "url": "https://huggingface.co/datasets/phanerozoic/Isabelle-Stdlib",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Mathematician/HumanEval-PlusPlus",
        "author": "Mathematician",
        "created_at": "2026-01-08 11:57:06+00:00",
        "last_modified": "2026-01-08 15:04:49+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:gpl-3.0",
          "size_categories:n<1K",
          "region:us",
          "code",
          "python"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanEval++\n\t\n\nHumanEval++ is a dataset based on HumanEval+ containing 164 code generation tasks covered by over 125k tests in total.\nTests are split into test suites allowing for evaluation of Test Sutie Accuracy (TSA) code correctness metric.\nSee this repository on GitLab for more details.\n",
        "url": "https://huggingface.co/datasets/Mathematician/HumanEval-PlusPlus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_734_Tie_up_the_curtains",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:03:28+00:00",
        "last_modified": "2026-01-05 10:56:31+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_734\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ç³»ä¸Šçª—å¸˜\ntotal_episodes: 211\ntotal_tasks: 1\nsize: 3.9G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_734_Tie_up_the_curtains.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_734_Tie_up_the_curtains",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_paper_ball",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:20:24+00:00",
        "last_modified": "2026-01-05 22:20:42+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_paper_ball\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·çº¸å›¢\ntotal_episodes: 76\ntotal_tasks: 1\nsize: 49.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_paper_ball.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_paper_ball",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_trash",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:10:34+00:00",
        "last_modified": "2026-01-05 13:27:02+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_close_trash\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­åžƒåœ¾æ¡¶part_2\ntotal_episodes: 98\ntotal_tasks: 1\nsize: 476.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_trash.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_trash",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "amechanicus/linux-commands",
        "author": "amechanicus",
        "created_at": "2026-01-08 19:37:55+00:00",
        "last_modified": "2026-01-08 19:37:56+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:ru",
          "language:ar",
          "language:en",
          "language:zh",
          "language:de",
          "language:fr",
          "language:es",
          "language:pt",
          "language:ja",
          "language:ko",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "linux",
          "shell",
          "commands",
          "terminal",
          "multilingual",
          "development",
          "system-administration"
        ],
        "description": "\n\t\n\t\t\n\t\tLinLM Dataset\n\t\n\nA curated synthetic dataset for Linux command inference\nNatural language description -> shell commands\nFeatures: \n\nSupports 10 languages\nArch Linux commands recognition\nFine-tune LLM for development, system administration, file operations, Git, Docker, and more\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"missvector/linux-commands\")\n\ndef format_for_training(example):\n    return {\n        \"prompt\": f\"Convert to Linux command:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/amechanicus/linux-commands.",
        "url": "https://huggingface.co/datasets/amechanicus/linux-commands",
        "languages": [
          "ru",
          "ar",
          "en",
          "zh",
          "de",
          "fr",
          "es",
          "pt",
          "ja",
          "ko"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ThGaskin/Migration_flows",
        "author": "ThGaskin",
        "created_at": "2025-12-12 17:17:15+00:00",
        "last_modified": "2026-01-08 12:14:27+00:00",
        "downloads": 78,
        "likes": 0,
        "tags": [
          "language:en",
          "license:gpl-3.0",
          "size_categories:100K<n<1M",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2506.22821",
          "region:us",
          "arXiv:2506.22821"
        ],
        "description": "\n\t\n\t\t\n\t\tDeep learning four decades of human migration: datasets\n\t\n\nThis repository contains all migration flow estimates associated with the paper \"Deep learning four decades of human migration.\" Evaluation code, training data, trained neural networks, and smaller flow datasets are available in the main GitHub repository, which also provides detailed instructions on data sourcing. Due to file size limits, the larger datasets are archived here.\nThe repository contains three folders:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ThGaskin/Migration_flows.",
        "url": "https://huggingface.co/datasets/ThGaskin/Migration_flows",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_in_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:51:39+00:00",
        "last_modified": "2026-01-05 16:57:00+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_fruit_in_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ°´æžœæ”¾å…¥ç¯®å­\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 603.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_in_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_in_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Marek324/speech-music-classification-tmp",
        "author": "Marek324",
        "created_at": "2026-01-07 23:04:22+00:00",
        "last_modified": "2026-01-08 15:30:36+00:00",
        "downloads": 1526,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "language:en",
          "size_categories:10K<n<100K",
          "modality:audio",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Marek324/speech-music-classification-tmp",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Oldi451/voxceleb2",
        "author": "Oldi451",
        "created_at": "2026-01-06 22:15:50+00:00",
        "last_modified": "2026-01-06 22:15:54+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "task_categories:audio-classification",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tVoxCeleb2 Dataset\n\t\n\nThis is the VoxCeleb2 dataset, a large-scale speaker identification dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nVoxCeleb2 contains over 1 million utterances for 6,112 celebrities, extracted from videos uploaded to YouTube.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nvox2_dev_mp4_part*: Multipart archive containing MP4 video files\nvox2_dev_txt: Text files with speaker/utterance metadata  \nvox2_meta.csv: Dataset metadata\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nTo extract the multipart archive:\n# Using 7zip\n7z xâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Oldi451/voxceleb2.",
        "url": "https://huggingface.co/datasets/Oldi451/voxceleb2",
        "languages": [
          "en"
        ],
        "tasks": [
          "automatic-speech-recognition",
          "audio-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "PAAAAAAAAAANDA/EMOTIONAL-JARVIS",
        "author": "PAAAAAAAAAANDA",
        "created_at": "2026-01-11 16:25:03+00:00",
        "last_modified": "2026-01-11 16:25:04+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/PAAAAAAAAAANDA/EMOTIONAL-JARVIS",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "Samlzy/MCC5-THU-Motor",
        "author": "Samlzy",
        "created_at": "2026-01-04 14:43:22+00:00",
        "last_modified": "2026-01-06 09:35:56+00:00",
        "downloads": 22,
        "likes": 1,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:100M<n<1B",
          "arxiv:2601.02278",
          "region:us",
          "fault-diagnosis",
          "condition-monitoring",
          "rotating-machinery",
          "induction-motor",
          "vibration",
          "motor-current",
          "variable-operating-conditions",
          "compound-faults",
          "time-series",
          "domain-adaptation",
          "test-time-adaptation"
        ],
        "description": "\n\t\n\t\t\n\t\tMulti-mode Fault Diagnosis Datasets of Three-phase Asynchronous Motor Under Variable Working Conditions\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset provides synchronized multi-modal time-series data collected from a 2.2 kW three-phase asynchronous (induction) motor operating under variable speed/load conditions with deliberately induced faults. It is intended for developing and benchmarking robust fault diagnosis methods under realistic operating scenarios, especially for time-varyingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Samlzy/MCC5-THU-Motor.",
        "url": "https://huggingface.co/datasets/Samlzy/MCC5-THU-Motor",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_left_hand_put_the_brown_hippopotamus_in_the_blue_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 04:57:07+00:00",
        "last_modified": "2026-01-08 04:57:40+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_brown_hippopotamus_in_the_blue_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†æ£•è‰²æ²³é©¬æ”¾å…¥è“è‰²ç›’å­\ntotal_episodes: 196\ntotal_tasks: 1\nsize: 1.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_put_the_brown_hippopotamus_in_the_blue_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_put_the_brown_hippopotamus_in_the_blue_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/ACL2",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:12:03+00:00",
        "last_modified": "2026-01-10 14:12:07+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "acl2",
          "lisp",
          "hardware-verification"
        ],
        "description": "\n\t\n\t\t\n\t\tACL2\n\t\n\nA structured dataset of theorems and functions from the ACL2 Community Books, one of the largest collections of formally verified libraries.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/acl2/acl2\nWebsite: https://www.cs.utexas.edu/~moore/acl2/\nLicense: BSD-3-Clause\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n231,000\n\n\nTheorems\n171,519\n\n\nFunctions\n59,481\n\n\nSource Files\n13,165\n\n\n\t\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nTheoremâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/ACL2.",
        "url": "https://huggingface.co/datasets/phanerozoic/ACL2",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "openmed-community/MedReason-Stenographic",
        "author": "openmed-community",
        "created_at": "2026-01-09 20:29:21+00:00",
        "last_modified": "2026-01-09 20:29:59+00:00",
        "downloads": 18,
        "likes": 10,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "source_datasets:UCSC-VLAA/MedReason",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "medical",
          "reasoning",
          "chain-of-thought",
          "stenographic-reasoning",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tMedReason-Stenographic: Medical QA with Compressed Reasoning Traces\n\t\n\nThis dataset contains 31,535 medical question-answer pairs with stenographic reasoning traces, generated using MiniMax M2.1 from the original UCSC-VLAA/MedReason dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset transforms medical QA reasoning into a stenographic format using a symbolic protocol designed for high-density, machine-parseable reasoning traces. This format eliminates natural language filler whileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openmed-community/MedReason-Stenographic.",
        "url": "https://huggingface.co/datasets/openmed-community/MedReason-Stenographic",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "devvrit/polaris_filtered_nemotron_medium_math_verifiable",
        "author": "devvrit",
        "created_at": "2026-01-10 23:39:53+00:00",
        "last_modified": "2026-01-11 00:22:51+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "math",
          "reasoning",
          "RL",
          "sympy",
          "verifiable",
          "nemotron",
          "polaris"
        ],
        "description": "\n\t\n\t\t\n\t\tPolaris Filtered Nemotron Medium Sympy Verifiable (v2)\n\t\n\nThis dataset is a curated subset of reasoning data from nvidia/Nemotron-Math-v2, specifically filtered for mathematical verifiability (verified using math verify-based equivalence), not having tool-reliance (TIR), and decontamination against the POLAIRS (POLARIS-Project/Polaris-Dataset-53K) dataset.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Original Samples: 2,424,392\nFinal Kept Samples: 357,790 (14.8%)\nTarget Reasoning Length: 4k-8kâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/devvrit/polaris_filtered_nemotron_medium_math_verifiable.",
        "url": "https://huggingface.co/datasets/devvrit/polaris_filtered_nemotron_medium_math_verifiable",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Coq-ExtLib",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:43:34+00:00",
        "last_modified": "2026-01-10 15:12:06+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-2-clause",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-ExtLib\n\t\n\nStructured dataset from coq-ext-lib â€” Extended standard library with monads and data structures.\n776 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/coq-community/coq-ext-lib\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfactâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-ExtLib.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-ExtLib",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_bread_is_placed_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:34:16+00:00",
        "last_modified": "2026-01-05 23:34:45+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_bread_is_placed_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¢åŒ…æ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 198\ntotal_tasks: 1\nsize: 350.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_bread_is_placed_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_bread_is_placed_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_mobile_marco_cup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:42:32+00:00",
        "last_modified": "2026-01-05 23:43:02+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_mobile_marco_cup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç§»åŠ¨é©¬å…‹æ¯\ntotal_episodes: 250\ntotal_tasks: 1\nsize: 483.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_mobile_marco_cup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_mobile_marco_cup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_yellow_pepper_on_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:38:50+00:00",
        "last_modified": "2026-01-07 07:39:05+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_yellow_pepper_on_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›˜å­ä¸Šçš„é»„è¾£æ¤’part_1\ntotal_episodes: 105\ntotal_tasks: 1\nsize: 49.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_yellow_pepper_on_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_yellow_pepper_on_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-FreeSpec",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:59:22+00:00",
        "last_modified": "2026-01-10 15:12:56+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mpl-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-FreeSpec\n\t\n\nStructured dataset from FreeSpec â€” Modular verification of effectful programs.\n279 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/lthms/FreeSpec\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-FreeSpec.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-FreeSpec",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_trash_can_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:44:40+00:00",
        "last_modified": "2026-01-05 13:45:23+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_open_cap_trash_can_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_2\ntotal_episodes: 95\ntotal_tasks: 1\nsize: 219.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_trash_can_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_trash_can_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_nut_place",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 19:09:31+00:00",
        "last_modified": "2026-01-05 19:15:29+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_nut_place\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®èžºæ¯\ntotal_episodes: 543\ntotal_tasks: 1\nsize: 3.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_nut_place.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_nut_place",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_wipe_panel",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:57:44+00:00",
        "last_modified": "2026-01-05 21:59:50+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_wipe_panel\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ“¦æ‹­é¢æ¿\ntotal_episodes: 265\ntotal_tasks: 1\nsize: 3.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_wipe_panel.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_wipe_panel",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Why3",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:13:35+00:00",
        "last_modified": "2026-01-10 14:13:38+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "why3",
          "verification",
          "smt"
        ],
        "description": "\n\t\n\t\t\n\t\tWhy3\n\t\n\nA structured dataset of lemmas, functions, and predicates from Why3, a platform for deductive program verification.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://gitlab.inria.fr/why3/why3\nWebsite: http://why3.lri.fr/\nLicense: LGPL-2.1\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n3,164\n\n\nLemmas\n1,497\n\n\nFunctions\n976\n\n\nPredicates\n691\n\n\nSource Files\n1,067\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration signature or body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Why3.",
        "url": "https://huggingface.co/datasets/phanerozoic/Why3",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "fungamer2/General-Thinking",
        "author": "fungamer2",
        "created_at": "2026-01-11 05:05:33+00:00",
        "last_modified": "2026-01-11 06:20:17+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "This is a subset of nvidia/Llama-Nemotron-Post-Training-Dataset, which is licensed under CC-BY-4.0.\n",
        "url": "https://huggingface.co/datasets/fungamer2/General-Thinking",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "surya5678/Campus_Recruitment_CSV",
        "author": "surya5678",
        "created_at": "2026-01-11 07:48:48+00:00",
        "last_modified": "2026-01-11 07:48:49+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:cc0-1.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "education"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis data set consists of Placement data of students in a XYZ campus. Based on the student's performance data we are classifying his Placement Status.\nThe students report includes the following information:\n\nCGPA - The grade of the student in his university\n\nInternships - The no of internship done by the student before final placement\n\nProjects - The no of projects done by the student\n\nWorkshops/Certifications - The no of workshops attended and the certificationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/surya5678/Campus_Recruitment_CSV.",
        "url": "https://huggingface.co/datasets/surya5678/Campus_Recruitment_CSV",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_red_pepper",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:22:46+00:00",
        "last_modified": "2026-01-05 22:23:08+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_red_pepper\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·çº¢è¾£æ¤’\ntotal_episodes: 83\ntotal_tasks: 1\nsize: 86.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_red_pepper.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_red_pepper",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_785_Serve_the_meal",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:39:45+00:00",
        "last_modified": "2026-01-05 21:52:20+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_785\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ä¸Šèœpart_3\ntotal_episodes: 24\ntotal_tasks: 1\nsize: 3.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_785_Serve_the_meal.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_785_Serve_the_meal",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Shekswess/tiny-think-dpo-code",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:58:19+00:00",
        "last_modified": "2026-01-10 22:14:02+00:00",
        "downloads": 37,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-dpo-code\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDirect Preference Optimization (DPO) dataset built from allenai/Dolci-Think-DPO-7B using the facebook/MobileLLM-R1-140M-base tokenizer and chat template. This dataset targets code-related preferences.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nSources: 3\nRows: 2,708\nTokens: 9,999,838\nMax sequence length: 4096 tokens per example (both chosen and rejected)\nToken budget: 10,000,000 tokens (equal strategy)\nColumns: prompt,chosenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-dpo-code.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-dpo-code",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "FreedomIntelligence/HiMed",
        "author": "FreedomIntelligence",
        "created_at": "2026-01-08 09:32:23+00:00",
        "last_modified": "2026-01-08 12:32:12+00:00",
        "downloads": 27,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "language:hi",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "medical",
          "benchmark",
          "question-answering"
        ],
        "description": "\n\t\n\t\t\n\t\tHiMed\n\t\n\nHiMed is a Hindi medical dataset and benchmark suite covering both Western medicine and Indian systems of medicine.It consists of two parts:\n\nHiMed-Trad: traditional Indian medicine\nHiMed-West: Western medicine under Hindi prompts\n\n\n\t\n\t\t\n\t\tRepository Layout\n\t\n\nAll released files are under data/:\ndata/\nâ”œâ”€â”€ HiMed-Trad_Bench.json\nâ”œâ”€â”€ HiMed-Trad_Corpus.json\nâ”œâ”€â”€ HiMed-West_Bench.json\nâ”œâ”€â”€ HiMed-West_Corpus.json\nâ””â”€â”€ HiMed-West_Exam.json\n\n\nWe define multiple Hugging Face datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/FreedomIntelligence/HiMed.",
        "url": "https://huggingface.co/datasets/FreedomIntelligence/HiMed",
        "languages": [
          "hi",
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Srijan-Chakraborty/peoples_speech",
        "author": "Srijan-Chakraborty",
        "created_at": "2026-01-06 09:40:06+00:00",
        "last_modified": "2026-01-06 09:40:08+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "annotations_creators:crowdsourced",
          "annotations_creators:machine-generated",
          "language_creators:crowdsourced",
          "language_creators:machine-generated",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc-by-2.0",
          "license:cc-by-2.5",
          "license:cc-by-3.0",
          "license:cc-by-4.0",
          "license:cc-by-sa-3.0",
          "license:cc-by-sa-4.0",
          "size_categories:n<1K",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2111.09344",
          "region:us",
          "robust-speech-recognition",
          "noisy-speech-recognition",
          "speech-recognition"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for People's Speech\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe People's Speech Dataset is among the world's largest English speech recognition corpus today that is licensed for academic and commercial usage under CC-BY-SA and CC-BY 4.0. It includes 30,000+ hours of transcribed speech in English languages with a diverse set of speakers. This open dataset is large enough to train speech-to-text systems and crucially is available with a permissive license.\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Srijan-Chakraborty/peoples_speech.",
        "url": "https://huggingface.co/datasets/Srijan-Chakraborty/peoples_speech",
        "languages": [
          "en"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "jufrtys/HC3-Chinese",
        "author": "jufrtys",
        "created_at": "2026-01-08 04:20:26+00:00",
        "last_modified": "2026-01-08 04:20:28+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:question-answering",
          "task_categories:sentence-similarity",
          "task_categories:zero-shot-classification",
          "language:en",
          "language:zh",
          "license:cc-by-sa-4.0",
          "size_categories:10K<n<100K",
          "arxiv:2301.07597",
          "region:us",
          "ChatGPT",
          "SimpleAI",
          "Detection",
          "OOD"
        ],
        "description": "Human ChatGPT Comparison Corpus (HC3) Chinese Version",
        "url": "https://huggingface.co/datasets/jufrtys/HC3-Chinese",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-classification",
          "question-answering",
          "sentence-similarity",
          "zero-shot-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "guglothmahipal007/deepfake-detection-dataset-v3",
        "author": "guglothmahipal007",
        "created_at": "2026-01-09 16:21:36+00:00",
        "last_modified": "2026-01-09 16:21:38+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "computer-vision",
          "deepfake-detection",
          "image-forensics"
        ],
        "description": "\n\t\n\t\t\n\t\tDeepfake Detection Dataset V3\n\t\n\nThis dataset contains images and detailed explanations for training and evaluating deepfake detection models. It includes original images, manipulated images, confidence scores, and comprehensive technical and non-technical explanations.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset consists of:\n\nOriginal images (image)\nCAM visualization images (cam_image)\nCAM overlay images (cam_overlay)\nComparison images (comparison_image)\nLabels (label): Binaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/guglothmahipal007/deepfake-detection-dataset-v3.",
        "url": "https://huggingface.co/datasets/guglothmahipal007/deepfake-detection-dataset-v3",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Coq-FourColor",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:48:30+00:00",
        "last_modified": "2026-01-10 15:12:33+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:other",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-FourColor\n\t\n\nStructured dataset from fourcolor â€” Formal proof of the Four Color Theorem.\n3,365 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/coq-community/fourcolor\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclarationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-FourColor.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-FourColor",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "AleelyA3/humanoid-robot-daily-action",
        "author": "AleelyA3",
        "created_at": "2026-01-08 14:08:31+00:00",
        "last_modified": "2026-01-08 15:59:13+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/AleelyA3/humanoid-robot-daily-action",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "hulaba/ditec-wdn",
        "author": "hulaba",
        "created_at": "2026-01-05 13:49:19+00:00",
        "last_modified": "2026-01-05 13:49:30+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:graph-ml",
          "task_categories:time-series-forecasting",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1B<n<10B",
          "modality:tabular",
          "arxiv:2503.17167",
          "region:us",
          "water",
          "graph",
          "distribution",
          "network",
          "benchmark",
          "time-series",
          "parquet"
        ],
        "description": "--\n\n\t\n\t\t\n\t\tDataset Card for DiTEC-WDN\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDiTEC-WDN Dataset consists of 36 Water Distribution Networks (WDNs). Each network has unique 1,000 scenarios with distinct characteristics.\nScenario represents a timeseries of directed shared-topology graphs, referred to as states or snapshots. In terms of graph-ml, it can be seen as a spatiotemporal graph where nodes and edges are multivariate time series. \nA node can represent a reservoir, junction, or tank, while an edgeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hulaba/ditec-wdn.",
        "url": "https://huggingface.co/datasets/hulaba/ditec-wdn",
        "languages": [
          "en"
        ],
        "tasks": [
          "graph-ml",
          "time-series-forecasting"
        ],
        "size_categories": [
          "1B<n<10B"
        ]
      },
      {
        "id": "DBbun/Mixed-Initiative-Lookout-CHI99",
        "author": "DBbun",
        "created_at": "2026-01-12 00:16:18+00:00",
        "last_modified": "2026-01-12 00:42:02+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:tabular-classification",
          "task_categories:text-classification",
          "task_categories:reinforcement-learning",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "region:us",
          "mixed-initiative",
          "decision-theory",
          "calibration",
          "attention",
          "interruption-management",
          "hci",
          "scheduling",
          "synthetic-data"
        ],
        "description": "\n\t\n\t\t\n\t\tLookOut-inspired Mixed-Initiative Traces (Synthetic)\n\t\n\nThis dataset provides synthetic interaction traces for studying mixed-initiative decision making under uncertainty, with attention-sensitive interruption costs and decision-theoretic thresholds inspired by ideas in Eric Horvitzâ€™s CHIâ€™99 LookOut work.\nSource code:  https://github.com/kartoun/Mixed-Initiative-Lookout-CHI99\nDeveloped by DBbun LLC â€” January 2026.\nWhat this is (in one sentence):A reproducible, decision-theoreticâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DBbun/Mixed-Initiative-Lookout-CHI99.",
        "url": "https://huggingface.co/datasets/DBbun/Mixed-Initiative-Lookout-CHI99",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-classification",
          "text-classification",
          "reinforcement-learning"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:56:52+00:00",
        "last_modified": "2026-01-05 22:57:25+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_triangle_bread_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¤æ¡Œä¸Šçš„ä¸‰è§’å½¢é¢åŒ…\ntotal_episodes: 174\ntotal_tasks: 1\nsize: 187.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_5_eggoven_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:23:52+00:00",
        "last_modified": "2026-01-05 23:24:37+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_5_eggoven_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¸¡è›‹çƒ¤ç®±part_2\ntotal_episodes: 103\ntotal_tasks: 1\nsize: 1.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_5_eggoven_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_5_eggoven_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "JesseLiu/patient-evaluations",
        "author": "JesseLiu",
        "created_at": "2025-12-02 19:49:54+00:00",
        "last_modified": "2026-01-11 02:58:19+00:00",
        "downloads": 170,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:other",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "modality:text",
          "region:us",
          "medical",
          "healthcare",
          "evaluation",
          "clinical"
        ],
        "description": "\n\t\n\t\t\n\t\tPatient Evaluations Dataset\n\t\n\nThis dataset contains clinician evaluations of AI-generated patient summaries from MIMIC-III data.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe dataset includes expert clinician assessments of AI-generated patient summaries, with detailed ratings across multiple dimensions including clinical accuracy, completeness, relevance, and identification of hallucinations or critical omissions.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains a CSV fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JesseLiu/patient-evaluations.",
        "url": "https://huggingface.co/datasets/JesseLiu/patient-evaluations",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "other"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "beersrobert/garage_dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:11:28+00:00",
        "last_modified": "2026-01-09 04:05:46+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "residential infrastructure structural-inspection fire-risk clutter accessibility emergency-response"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/garage_dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "AAdonis/multilingual_audio_alignments",
        "author": "AAdonis",
        "created_at": "2026-01-07 01:17:07+00:00",
        "last_modified": "2026-01-10 19:56:04+00:00",
        "downloads": 1652,
        "likes": 2,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "task_categories:text-to-speech",
          "language:en",
          "language:de",
          "language:fr",
          "language:es",
          "language:ru",
          "language:ja",
          "language:ko",
          "language:pt",
          "language:tr",
          "language:th",
          "license:cc-by-4.0",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio",
          "speech",
          "phoneme-alignment",
          "mfa",
          "forced-alignment"
        ],
        "description": "\n\t\n\t\t\n\t\tMultilingual MFA-Aligned Speech Dataset (UNDER DEVELOPMENT)\n\t\n\nA large-scale multilingual speech dataset with word-level and phoneme-level alignments produced using the Montreal Forced Aligner (MFA).\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset consolidates multiple speech corpora across various languages, all processed through MFA to provide precise phoneme and word alignments. Each sample includes the original audio, transcript, and detailed timing information for both words andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AAdonis/multilingual_audio_alignments.",
        "url": "https://huggingface.co/datasets/AAdonis/multilingual_audio_alignments",
        "languages": [
          "en",
          "de",
          "fr",
          "es",
          "ru",
          "ja",
          "ko",
          "pt",
          "tr",
          "th"
        ],
        "tasks": [
          "automatic-speech-recognition",
          "text-to-speech"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "quickmt/canadian_hansard",
        "author": "quickmt",
        "created_at": "2026-01-09 23:53:58+00:00",
        "last_modified": "2026-01-10 00:35:52+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "language:en",
          "language:fr",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "Contains paired English and French text from the Canadian Hansard (parliamentary debates) for the following sessions, downloaded on 2026-01-09:\n\n45-1\n44-1\n43-2\n43-1\n42-1\n41-2\n41-1\n40-3\n40-2\n40-1\n39-2\n39-1\n38-1\n\nData was downloaded from the XML files, e.g.:\n\nhttps://www.ourcommons.ca/Content/House/451/Debates/072/HAN072-E.XML\nhttps://www.ourcommons.ca/Content/House/451/Debates/072/HAN072-F.XML\n\n",
        "url": "https://huggingface.co/datasets/quickmt/canadian_hansard",
        "languages": [
          "en",
          "fr"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_40_putavocado",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:08:49+00:00",
        "last_modified": "2026-01-05 01:10:51+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_40_putavocado\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç‰›æ²¹æžœpart_1\ntotal_episodes: 200\ntotal_tasks: 1\nsize: 2.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_40_putavocado.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_40_putavocado",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Finmap",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:48:27+00:00",
        "last_modified": "2026-01-10 15:12:32+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:other",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Finmap\n\t\n\nStructured dataset from Finmap â€” Finite sets, maps, and multisets for MathComp.\n910 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/math-comp/finmap\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Finmap.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Finmap",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "bakir11999/quran",
        "author": "bakir11999",
        "created_at": "2026-01-08 02:23:41+00:00",
        "last_modified": "2026-01-08 02:23:42+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "task_categories:translation",
          "task_categories:feature-extraction",
          "task_categories:text-generation",
          "multilinguality:monolingual",
          "multilinguality:multilingual",
          "language:sq",
          "language:ber",
          "language:ar",
          "language:am",
          "language:az",
          "language:bn",
          "language:bs",
          "language:bg",
          "language:zh",
          "language:cs",
          "language:dv",
          "language:nl",
          "language:en",
          "language:fr",
          "language:de",
          "language:ha",
          "language:hi",
          "language:id",
          "language:it",
          "language:ja",
          "language:ko",
          "language:ku",
          "language:ms",
          "language:ml",
          "language:no",
          "language:ps",
          "language:fa",
          "language:pl",
          "language:pt",
          "language:ro",
          "language:ru",
          "language:sd",
          "language:so",
          "language:es",
          "language:sw",
          "language:sv",
          "language:tg",
          "language:ta",
          "language:tt",
          "language:th",
          "language:tr",
          "language:ur",
          "language:ug",
          "language:uz",
          "license:cc-by-3.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "islam",
          "quran",
          "translations"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for the Quran\n\t\n\n\n\t\n\t\t\n\t\tSummary\n\t\n\nThe Quran with metadata, translations, and multiple Arabic text (can use specific types for embeddings, search, classification, and display). There are 126+ columns containing 43+ languages.\n\n\t\n\t\t\n\t\tTODO\n\t\n\n\n Add Tafsirs  \n Add topics/ontology\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"nazimali/quran\", split=\"train\")\nds\n\nOutput:\nDataset({\n    features: ['surah', 'ayah', 'surah-name', 'surah-total-ayas'â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bakir11999/quran.",
        "url": "https://huggingface.co/datasets/bakir11999/quran",
        "languages": [
          "sq",
          "ber",
          "ar",
          "am",
          "az",
          "bn",
          "bs",
          "bg",
          "zh",
          "cs",
          "dv",
          "nl",
          "en",
          "fr",
          "de",
          "ha",
          "hi",
          "id",
          "it",
          "ja",
          "ko",
          "ku",
          "ms",
          "ml",
          "no",
          "ps",
          "fa",
          "pl",
          "pt",
          "ro",
          "ru",
          "sd",
          "so",
          "es",
          "sw",
          "sv",
          "tg",
          "ta",
          "tt",
          "th",
          "tr",
          "ur",
          "ug",
          "uz"
        ],
        "tasks": [
          "text-classification",
          "token-classification",
          "translation",
          "feature-extraction",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_bread_slice",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:13:01+00:00",
        "last_modified": "2026-01-05 22:13:19+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_bread_slice\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é¢åŒ…ç‰‡\ntotal_episodes: 86\ntotal_tasks: 1\nsize: 87.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_bread_slice.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_bread_slice",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_790_Brush_toy_cards",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-30 08:29:06+00:00",
        "last_modified": "2026-01-05 22:40:58+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_790\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: åˆ·çŽ©å…·å¡\ntotal_episodes: 514\ntotal_tasks: 1\nsize: 8.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_790_Brush_toy_cards.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_790_Brush_toy_cards",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Praneyaarora/TOS_Dataset",
        "author": "Praneyaarora",
        "created_at": "2026-01-10 11:15:07+00:00",
        "last_modified": "2026-01-10 11:15:09+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tTOS_Dataset\n\t\n\nThis dataset contains clauses from Terms of Service (ToS) documents with annotations indicating the fairness level of each clause. The dataset includes clauses labeled as clearly_fair, potentially_unfair, and clearly_unfair.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset comprises clauses extracted from various ToS documents. Each clause is annotated with a fairness level, indicating whether it is clearly fair, potentially unfair, or clearly unfair.\n\n\t\n\t\t\n\t\tSupported Tasksâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Praneyaarora/TOS_Dataset.",
        "url": "https://huggingface.co/datasets/Praneyaarora/TOS_Dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Lap1official/Math-v2",
        "author": "Lap1official",
        "created_at": "2026-01-08 08:51:55+00:00",
        "last_modified": "2026-01-08 11:33:52+00:00",
        "downloads": 14,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:10M<n<100M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "synthetic"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Lap1official/Math-v2",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "t2ance/selection_upper_test",
        "author": "t2ance",
        "created_at": "2026-01-05 18:42:24+00:00",
        "last_modified": "2026-01-05 18:42:40+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:code",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code-verification",
          "llm-judge",
          "best-of-n-selection",
          "process-reward-model"
        ],
        "description": "\n\t\n\t\t\n\t\tCodeRM Selection Trajectories\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains trajectories of an LLM judge selecting the best solution from k candidates.\nEach trajectory captures: problem, k candidate solutions, judge reasoning, selected index, and ground truth correctness.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nTraining Selection Verifiers: Learn to select the best solution from k candidates\nBest-of-N Selection: Train models for verifier-guided code generation\nPreference Learning: Use forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/t2ance/selection_upper_test.",
        "url": "https://huggingface.co/datasets/t2ance/selection_upper_test",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Annelo/for_zimage_training",
        "author": "Annelo",
        "created_at": "2026-01-06 15:40:31+00:00",
        "last_modified": "2026-01-06 16:57:55+00:00",
        "downloads": 29,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "license:apache-2.0",
          "region:us",
          "not-for-all-audiences"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Annelo/for_zimage_training",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_735_Use_a_cotton_roller_to_roll_away_the_stains",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:03:47+00:00",
        "last_modified": "2026-01-05 16:17:14+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_735\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ç”¨æ£‰çº¿è¾ŠæŠŠæ±¡æ¸å·èµ°\ntotal_episodes: 128\ntotal_tasks: 1\nsize: 8.8G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_735_Use_a_cotton_roller_to_roll_away_the_stains.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_735_Use_a_cotton_roller_to_roll_away_the_stains",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "modibboali/NuminaMath-CoT",
        "author": "modibboali",
        "created_at": "2026-01-05 08:37:57+00:00",
        "last_modified": "2026-01-05 08:37:59+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "aimo",
          "math"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for NuminaMath CoT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nApproximately 860k math problems, where each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs and mathematics discussion forums. The processing steps include (a) OCR from the original PDFs, (b) segmentation intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/modibboali/NuminaMath-CoT.",
        "url": "https://huggingface.co/datasets/modibboali/NuminaMath-CoT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Coq-Stdpp",
        "author": "phanerozoic",
        "created_at": "2026-01-10 12:53:19+00:00",
        "last_modified": "2026-01-10 12:53:40+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "stdpp",
          "iris"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Stdpp\n\t\n\nStructured dataset of formalizations from the std++ library (used by Iris).\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nFull declaration (name, signature, body)\n\n\ntype\nstring\nLemma, Definition, Instance, Class, etc.\n\n\nlibrary\nstring\nSub-library (stdpp, stdpp_bitvector, stdpp_unstable)\n\n\nimports\nlist\nImport statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\ndocstring\nstring\nDocumentation comment (9% coverage)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Stdpp.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Stdpp",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_732_roll_out_dough",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 19:58:51+00:00",
        "last_modified": "2026-01-05 10:36:19+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_732\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ“€é¢å›¢\ntotal_episodes: 1210\ntotal_tasks: 1\nsize: 69G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_732_roll_out_dough.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_732_roll_out_dough",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "RinKana/sudoku-9x9-reasoning",
        "author": "RinKana",
        "created_at": "2026-01-09 15:29:13+00:00",
        "last_modified": "2026-01-09 15:41:17+00:00",
        "downloads": 29,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSudoku 9x9 Reasoning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 9x9 Sudoku puzzles generated using reasoning_gym. \nEach entry includes a puzzle grid and its corresponding solved solution.\n\nQuestion: A 9x9 grid string where _ represents empty cells.\nAnswer: The completed 9x9 grid string.\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nThe grids are formatted as space-separated values with newlines for rows.\n\n\t\n\t\t\n\t\tExample\n\t\n\nQuestion:\n_ _ _ _ 2 _ 3 _ 4\n_ _ _ _ _ _ _ _ 7\n_ 6 _ _ _ _ 5 _ 1\n1 2 _â€¦ See the full description on the dataset page: https://huggingface.co/datasets/RinKana/sudoku-9x9-reasoning.",
        "url": "https://huggingface.co/datasets/RinKana/sudoku-9x9-reasoning",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "beersrobert/livingroom_dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:40:09+00:00",
        "last_modified": "2026-01-09 04:04:01+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "indoor-navigation household-hazards home-safety messy-environments robotics"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/livingroom_dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "authoranonymous321/Edustories",
        "author": "authoranonymous321",
        "created_at": "2026-01-05 06:27:06+00:00",
        "last_modified": "2026-01-05 07:06:16+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "language:cs",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:document",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Edustories dataset\n\t\n\nThis repository contains Edustories dataset (under review at ARR).\nThe data contains structured descriptions of situations from classses documented by candidate teachers.\nEach of the entries, also called casuistics, is structured into a description of the background, anamnesis describing the situation, \na solution describing the intervention of the teacher in the situation, and outcome describing the final state of the intervetion.\nEach of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/authoranonymous321/Edustories.",
        "url": "https://huggingface.co/datasets/authoranonymous321/Edustories",
        "languages": [
          "en",
          "cs"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "GilatToker/Liberty-Violence",
        "author": "GilatToker",
        "created_at": "2026-01-06 15:15:19+00:00",
        "last_modified": "2026-01-09 12:49:45+00:00",
        "downloads": 39,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:feature-extraction",
          "language:en",
          "size_categories:1K<n<10K",
          "region:us",
          "explainability",
          "benchmark",
          "causal-inference",
          "counterfactuals"
        ],
        "description": "\n\t\n\t\t\n\t\tLIBERTy-Workplace Violence Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLIBERTy-Workplace Violence is one of the three datasets released as part of theLIBERTy (LLM-based Interventional Benchmark for Explainability with Real Targets) benchmark.\nLIBERTy is designed to evaluate concept-based explanation methods in NLP\nunder a causal and counterfactual framework.Each dataset exposes structured dependencies between high-level semantic concepts\nand model predictions, enabling quantitative evaluation ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GilatToker/Liberty-Violence.",
        "url": "https://huggingface.co/datasets/GilatToker/Liberty-Violence",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "thehappbaloney/smolified-reelize",
        "author": "thehappbaloney",
        "created_at": "2026-01-10 08:56:16+00:00",
        "last_modified": "2026-01-10 08:56:24+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-reelize\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry.\nIt was used to train the corresponding model thehappbaloney/smolified-reelize.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: ed305b11)\nRecords: 5984\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by thehappbaloney.\nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/thehappbaloney/smolified-reelize",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "nyuuzyou/gitcode-code",
        "author": "nyuuzyou",
        "created_at": "2026-01-09 02:18:06+00:00",
        "last_modified": "2026-01-09 02:33:29+00:00",
        "downloads": 93,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:found",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:zh",
          "language:en",
          "license:other",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "chinese"
        ],
        "description": "\n\t\n\t\t\n\t\tGitCode Code Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from code repositories hosted on GitCode, a code hosting platform in China backed by CSDN (China Software Developer Network). GitCode serves as a domestic alternative to GitHub, widely used by Chinese developers, students, and enterprises for hosting open-source projects and educational resources, making this dataset particularly valuable for training code models with Chinese language understanding andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gitcode-code.",
        "url": "https://huggingface.co/datasets/nyuuzyou/gitcode-code",
        "languages": [
          "code",
          "zh",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "g4lihru/arduino-dataset",
        "author": "g4lihru",
        "created_at": "2026-01-10 13:32:44+00:00",
        "last_modified": "2026-01-10 14:21:14+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:100M<n<1B",
          "region:us",
          "arduino",
          "code-generation",
          "gpt"
        ],
        "description": "\n\t\n\t\t\n\t\tArduino Code Dataset\n\t\n\nDataset untuk training AI generator kode Arduino. Dataset ini berisi file binary untuk training, bukan dataset tabel.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ndataset.bin (467 MB): Binary tokenized dataset\ntokenizer/tokenizer.json: ByteLevel BPE tokenizer configuration\n\n\n\t\n\t\t\n\t\tDataset Stats\n\t\n\n\nTotal Tokens: 233,737,477\nSource Files: 54,569 Arduino files (.ino)\nLines of Code: 17,146,329\nTokenizer: ByteLevel BPE with vocab size 8000\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tDownload via Pythonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/g4lihru/arduino-dataset.",
        "url": "https://huggingface.co/datasets/g4lihru/arduino-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_tool_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:53:38+00:00",
        "last_modified": "2026-01-05 12:55:24+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_close_cap_tool_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›–ä¸Šå·¥å…·ç®±ç›–\ntotal_episodes: 97\ntotal_tasks: 1\nsize: 381.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_tool_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_tool_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "AmberLJC/Sci-Reasoning",
        "author": "AmberLJC",
        "created_at": "2026-01-06 05:23:47+00:00",
        "last_modified": "2026-01-07 00:41:16+00:00",
        "downloads": 12,
        "likes": 1,
        "tags": [
          "task_categories:text-classification",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "region:us",
          "machine-learning",
          "research-papers",
          "NeurIPS",
          "ICML",
          "ICLR",
          "academic",
          "deep-learning"
        ],
        "description": "\n\t\n\t\t\n\t\tML Conference Papers Dataset\n\t\n\nA comprehensive collection of machine learning research papers from top-tier conferences.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains metadata and abstracts from papers published at major machine learning conferences:\n\nICLR (International Conference on Learning Representations)\nNeurIPS (Neural Information Processing Systems)\nICML (International Conference on Machine Learning)\n\n\n\t\n\t\t\n\t\tCoverage\n\t\n\n2023-2024 Papers:\n\nTotal: ~14,000 papers\nICLRâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AmberLJC/Sci-Reasoning.",
        "url": "https://huggingface.co/datasets/AmberLJC/Sci-Reasoning",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_in_fruit_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:57:46+00:00",
        "last_modified": "2026-01-05 17:01:52+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_fruit_in_fruit_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ°´æžœæ”¾å…¥æ°´æžœç¯®\ntotal_episodes: 77\ntotal_tasks: 1\nsize: 348.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_in_fruit_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_in_fruit_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_shape",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:19:48+00:00",
        "last_modified": "2026-01-05 17:23:32+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_shape\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥å½¢çŠ¶\ntotal_episodes: 94\ntotal_tasks: 1\nsize: 748.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_shape.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_shape",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "RobbieHurst/movies",
        "author": "RobbieHurst",
        "created_at": "2026-01-11 13:02:51+00:00",
        "last_modified": "2026-01-11 13:02:51+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:summarization",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "movies",
          "NLP"
        ],
        "description": "\n\t\n\t\t\n\t\tMovie Scripts Dataset\n\t\n\nThe Movie Scripts Dataset consists of scripts from 1,172 movies, providing a comprehensive collection of movie dialogues and narratives. This dataset is designed to support various natural language processing (NLP) tasks, including dialogue generation, script summarization, and text analysis.\n\n\t\n\t\t\n\t\tDetails\n\t\n\nThe dataset contains 2 columns:\n\nName: The title of the movie.\nScript: The full script of the movie in English.\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nThe Movie Scriptsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RobbieHurst/movies.",
        "url": "https://huggingface.co/datasets/RobbieHurst/movies",
        "languages": [
          "en"
        ],
        "tasks": [
          "summarization",
          "text-generation",
          "fill-mask"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1105",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:22:39+00:00",
        "last_modified": "2026-01-06 10:23:10+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1105\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_4\ntotal_episodes: 256\ntotal_tasks: 1\nsize: 177.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1105.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1105",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Mathieu-Thomas-JOSSET/michael_abab_conversations_infini_instruct.jsonl",
        "author": "Mathieu-Thomas-JOSSET",
        "created_at": "2026-01-07 20:46:26+00:00",
        "last_modified": "2026-01-07 20:46:27+00:00",
        "downloads": 78,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "sharegpt",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tmichael_abab_conversations_infini_instruct.jsonl\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ntrain.jsonl\n\n\n\t\n\t\t\n\t\tLoading (example)\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"Mathieu-Thomas-JOSSET/michael_abab_conversations_infini_instruct.jsonl\")\nprint(ds)\n\n",
        "url": "https://huggingface.co/datasets/Mathieu-Thomas-JOSSET/michael_abab_conversations_infini_instruct.jsonl",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_bread_machine",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 15:51:48+00:00",
        "last_modified": "2026-01-05 16:02:41+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_in_bread_machine\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾å…¥é¢åŒ…æœº\ntotal_episodes: 101\ntotal_tasks: 1\nsize: 573.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_bread_machine.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_bread_machine",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_trash_can_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:57:55+00:00",
        "last_modified": "2026-01-05 12:58:50+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_close_cap_trash_can_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›–ä¸Šåžƒåœ¾æ¡¶ç›–part_2\ntotal_episodes: 96\ntotal_tasks: 1\nsize: 232.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_trash_can_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_cap_trash_can_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": []
      },
      {
        "id": "beersrobert/real-world-residential-yard-v1",
        "author": "beersrobert",
        "created_at": "2026-01-11 01:51:56+00:00",
        "last_modified": "2026-01-11 02:11:47+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "outdoor-scenes residential-yard robotics embodied-ai autonomous-navigation edge-cases scene-understanding rural-environment fences terrain"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/real-world-residential-yard-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "enPurified/finewiki-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 05:29:44+00:00",
        "last_modified": "2026-01-12 00:32:48+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:HuggingFaceFW/finewiki",
          "language:en",
          "license:cc",
          "size_categories:1M<n<10M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "quality-filtered",
          "finewiki",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– FineWiki-enPurified-openai-messages\n\t\n\nFineWiki-enPurified is a high-fidelity, \"prose-only\" distillation of the HuggingFaceFW/finewiki dataset. \nThe enPurified collection is built on a singular philosophy: Eliminating the Noise. While the modern ecosystem is saturated with datasets for coding and mathematics, the \"art of the sentence\" is often lost in the mix. This dataset removes the technical syntax, the math formulas, and the linguistic \"junk\" to provide a pure stream ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/finewiki-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/finewiki-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "phoenixcph/AtmosphericQA-47k-Chinese",
        "author": "phoenixcph",
        "created_at": "2026-01-08 13:24:54+00:00",
        "last_modified": "2026-01-10 04:06:02+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "atmospheric-science",
          "climate",
          "meteorology",
          "earth-science",
          "synthetic",
          "sft",
          "fine-tuning"
        ],
        "description": "\n\t\n\t\t\n\t\tAtmospheric Science SFT QA Dataset\n\t\n\nA 47k synthetic questionâ€“answer dataset for supervised fine-tuning of large language models, derived from atmospheric science textbooks using Gemini 3 Flash Preivew with automated data cleaning.\n\n\t\n\t\t\n\t\tData Generation Process\n\t\n\n\n\t\n\t\t\n\t\t1. Source Material\n\t\n\n\nNumerous atmospheric science textbooks and educational reference books\nTopics include atmospheric dynamics, thermodynamics, radiation, cloud physics, synoptic meteorology, and climate systemsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phoenixcph/AtmosphericQA-47k-Chinese.",
        "url": "https://huggingface.co/datasets/phoenixcph/AtmosphericQA-47k-Chinese",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_press_down_toaster",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:44:16+00:00",
        "last_modified": "2026-01-05 18:45:31+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_press_down_toaster\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æŒ‰ä¸‹çƒ¤é¢åŒ…æœº\ntotal_episodes: 151\ntotal_tasks: 1\nsize: 817.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_press_down_toaster.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_press_down_toaster",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "abhinavdread/Research_Paper_RAG_Triplets_Embedding_Fine_Tuning",
        "author": "abhinavdread",
        "created_at": "2025-12-30 04:54:23+00:00",
        "last_modified": "2026-01-07 02:32:42+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:sentence-similarity",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rag",
          "embedding-finetuning",
          "synthetic-data",
          "research-papers"
        ],
        "description": "\n\t\n\t\t\n\t\tResearch Paper RAG Triplets (Embedding Fine-Tuning)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains high-quality (anchor, positive, negative) triplets generated from academic research papers. It is specifically designed for fine-tuning embedding models (such as BGE, BERT, or E5) to improve retrieval performance in Retrieval-Augmented Generation (RAG) applications.\nUnlike generic datasets, this collection focuses on dense technical text, helping models learn to distinguish between highlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/abhinavdread/Research_Paper_RAG_Triplets_Embedding_Fine_Tuning.",
        "url": "https://huggingface.co/datasets/abhinavdread/Research_Paper_RAG_Triplets_Embedding_Fine_Tuning",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-retrieval",
          "sentence-similarity"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Trickxter/COCO2017-captions",
        "author": "Trickxter",
        "created_at": "2025-09-09 17:11:31+00:00",
        "last_modified": "2025-09-09 22:49:57+00:00",
        "downloads": 111,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Trickxter/COCO2017-captions",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-text"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Agda-Categories",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:43:16+00:00",
        "last_modified": "2026-01-10 15:13:49+00:00",
        "downloads": 27,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "agda",
          "dependent-types"
        ],
        "description": "\n\t\n\t\t\n\t\tAgda-Categories\n\t\n\nStructured dataset from agda-categories â€” Category theory.\n730 declarations extracted from Agda source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/agda/agda-categories\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Agda-Categories.",
        "url": "https://huggingface.co/datasets/phanerozoic/Agda-Categories",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:58:08+00:00",
        "last_modified": "2026-01-05 15:08:12+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_block_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç§¯æœ¨æ”¾åœ¨æ¡Œå­ä¸Š\ntotal_episodes: 80\ntotal_tasks: 1\nsize: 195.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_block_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-social-etiquette-dataset",
        "author": "ariefansclub",
        "created_at": "2026-01-07 03:09:14+00:00",
        "last_modified": "2026-01-07 03:09:58+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "agent",
          "robotics"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Social Etiquette Dataset\n\t\n\nSocial cues mapped to appropriate humanoid responses.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-social-etiquette-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_top_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:10:22+00:00",
        "last_modified": "2026-01-05 22:10:41+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_open_top_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€é¡¶éƒ¨æŠ½å±‰\ntotal_episodes: 58\ntotal_tasks: 1\nsize: 128.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_top_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_top_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "pmarnad/clause-classification-dataset",
        "author": "pmarnad",
        "created_at": "2026-01-06 03:44:38+00:00",
        "last_modified": "2026-01-06 04:00:10+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tClause Classification Dataset\n\t\n\nLegal contract clause classification dataset with 23 consolidated clause types.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nSplit\nSamples\n\n\n\t\t\nTrain (consolidated)\n16,627\n\n\nTest (consolidated)\n3,260\n\n\n\t\n\n\n\t\n\t\t\n\t\tLabel Distribution\n\t\n\n23 consolidated clause types:\n\namendment, assignment, audit_rights, compliance, confidentiality\ndata, definitions, dispute, force_majeure, governing_law\nindemnification, injunctive_relief, insurance, intellectual_property\nlicenseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pmarnad/clause-classification-dataset.",
        "url": "https://huggingface.co/datasets/pmarnad/clause-classification-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "debaterhub/ipda-cx-training-data",
        "author": "debaterhub",
        "created_at": "2026-01-10 16:37:14+00:00",
        "last_modified": "2026-01-10 16:44:50+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "debate",
          "orpo",
          "preference-learning",
          "cross-examination"
        ],
        "description": "\n\t\n\t\t\n\t\tIPDA Cross-Examination Training Dataset\n\t\n\nTraining data for cross-examination (CX) skills in competitive debate. This dataset teaches models to ask strategic questions and provide defensible answers during cross-examination.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\nFile\nDescription\nRecords\n\n\n\t\t\ncx_preference_pairs.jsonl\nORPO preference pairs (cleaned, no truncation)\n2,322\n\n\ncx_exchanges_all.jsonl\nFull CX exchange dataset\n16,556\n\n\nall_scenarios.jsonl\nDebate scenarios for CXâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/debaterhub/ipda-cx-training-data.",
        "url": "https://huggingface.co/datasets/debaterhub/ipda-cx-training-data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Prime",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:59:30+00:00",
        "last_modified": "2026-01-10 15:12:56+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Prime\n\t\n\nStructured dataset from CoqPrime â€” Primality certificates and number theory.\n11,692 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/thery/coqprime\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Prime.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Prime",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1030",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:17:21+00:00",
        "last_modified": "2026-01-07 07:17:45+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1030\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ±æœµæ”¾åœ¨æ¡Œå­ä¸Špart_4\ntotal_episodes: 213\ntotal_tasks: 1\nsize: 160.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1030.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1030",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "federetyk/MELS-Benchmark",
        "author": "federetyk",
        "created_at": "2026-01-07 11:18:50+00:00",
        "last_modified": "2026-01-07 11:21:04+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:sentence-similarity",
          "language:de",
          "language:en",
          "language:fr",
          "language:nl",
          "language:sv",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "entity-linking",
          "skills",
          "multilingual",
          "ranking",
          "information-retrieval",
          "ESCO"
        ],
        "description": "\n\t\n\t\t\n\t\tMELS: Multilingual Entity Linking of Skills\n\t\n\nMELS is a collection of 8 datasets for evaluating the linking of skill mentions to the\nESCO Skills taxonomy. It covers 3 countries and 4 languages.\n\n\t\n\t\t\n\t\tBackground\n\t\n\nMELS is a sibling dataset to MELO (Multilingual Entity Linking of Occupations).\nBoth datasets were built using the same methodology and the same type of source data:\ncrosswalks between national taxonomies and ESCO, published by official labor-related\norganizations from EUâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/federetyk/MELS-Benchmark.",
        "url": "https://huggingface.co/datasets/federetyk/MELS-Benchmark",
        "languages": [
          "de",
          "en",
          "fr",
          "nl",
          "sv"
        ],
        "tasks": [
          "text-retrieval",
          "sentence-similarity"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "akshathmangudi/SciCode",
        "author": "akshathmangudi",
        "created_at": "2026-01-11 06:11:04+00:00",
        "last_modified": "2026-01-11 06:25:25+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2407.13168",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\nOfficial Description (from the authors): \nSince language models (LMs) now outperform average humans on many challenging tasks, \nit has become increasingly difficult to develop challenging, high-quality, and realistic evaluations. \nWe address this issue by examining LMs' capabilities to generate code for solving real scientific research problems. \nIncorporating input from scientists and AI researchers in 16 diverse natural science sub-fields, \nincludingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/akshathmangudi/SciCode.",
        "url": "https://huggingface.co/datasets/akshathmangudi/SciCode",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "avalab/aura_qa",
        "author": "avalab",
        "created_at": "2026-01-07 18:21:45+00:00",
        "last_modified": "2026-01-07 18:28:09+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/avalab/aura_qa",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "loris3/tulu-3-sft-olmo-2-mixture-0225-sample",
        "author": "loris3",
        "created_at": "2025-09-15 07:50:57+00:00",
        "last_modified": "2026-01-08 13:30:01+00:00",
        "downloads": 792,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.03786",
          "region:us",
          "custom",
          "subset"
        ],
        "description": "This dataset is a subset of allenai/tulu-3-sft-olmo-2-mixture-0225.\nUsed for training data influence estimation experiments using DataInf and LESS. \nSee our paper and repo for details.\n\n\t\n\t\t\n\t\n\t\n\t\tGeneration Command\n\t\n\npython take_split.py --source_dataset allenai/tulu-3-sft-olmo-2-mixture-0225 --target_dataset tulu-3-sft-olmo-2-mixture-0225-sample --train 0.1 --test 1000 --seed 42 --private\n\n\n\t\n\t\n\t\n\t\tDataset Splits\n\t\n\n\nTrain: 86613 samples (10.00% of original)\nTest: 1000 samples (0.12% ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/loris3/tulu-3-sft-olmo-2-mixture-0225-sample.",
        "url": "https://huggingface.co/datasets/loris3/tulu-3-sft-olmo-2-mixture-0225-sample",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "GambitFlow/Opening-Database",
        "author": "GambitFlow",
        "created_at": "2026-01-10 12:01:39+00:00",
        "last_modified": "2026-01-10 17:31:04+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:reinforcement-learning",
          "task_categories:tabular-classification",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1M<n<10M",
          "region:us",
          "chess",
          "opening-theory",
          "lichess",
          "elite-games",
          "gambitflow"
        ],
        "description": "\n\t\n\t\t\n\t\tâ™Ÿï¸ GambitFlow: Elite Opening Theory (2000+ Elo)\n\t\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Overview\n\t\n\nThis dataset serves as the \"Opening Memory\" for the GambitFlow AI project (Synapse-Edge). It contains millions of chess positions extracted exclusively from Elite Level Games (Elo 2000+) played on Lichess.\nThe goal is to provide the AI with Grandmaster-level intuition during the opening phase, preventing early positional disadvantages.\n\nSource: Lichess Standard Rated Games (Jan 2017 - Apr 2024)\nFilter:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GambitFlow/Opening-Database.",
        "url": "https://huggingface.co/datasets/GambitFlow/Opening-Database",
        "languages": [
          "en"
        ],
        "tasks": [
          "reinforcement-learning",
          "tabular-classification"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_onion_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:35:50+00:00",
        "last_modified": "2026-01-05 22:36:12+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_green_onion_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é’è‘±æ”¾å…¥é”…ä¸­\ntotal_episodes: 49\ntotal_tasks: 1\nsize: 65.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_onion_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_green_onion_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "llm-semantic-router/halueval-llm-spans",
        "author": "llm-semantic-router",
        "created_at": "2026-01-10 23:13:04+00:00",
        "last_modified": "2026-01-10 23:13:07+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2305.11747",
          "region:us",
          "hallucination-detection",
          "summarization",
          "rag",
          "fact-checking",
          "llm-annotated"
        ],
        "description": "\n\t\n\t\t\n\t\tHaluEval LLM Spans Dataset\n\t\n\nA span-level hallucination detection dataset derived from HaluEval summarization data. Contains 10,000 samples with LLM-detected hallucination spans and RAGTruth-normalized prompts.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset converts HaluEval's binary hallucination labels into fine-grained span-level annotations using Qwen2.5-72B-Instruct. The prompts have been normalized to RAGTruth format for compatibility with hallucination detection models.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-semantic-router/halueval-llm-spans.",
        "url": "https://huggingface.co/datasets/llm-semantic-router/halueval-llm-spans",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "skyzos/NuminaMath-CoT",
        "author": "skyzos",
        "created_at": "2026-01-07 09:28:00+00:00",
        "last_modified": "2026-01-07 09:28:01+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "aimo",
          "math"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for NuminaMath CoT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nApproximately 860k math problems, where each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs and mathematics discussion forums. The processing steps include (a) OCR from the original PDFs, (b) segmentation intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/skyzos/NuminaMath-CoT.",
        "url": "https://huggingface.co/datasets/skyzos/NuminaMath-CoT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_744_Pack_fruits",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:09:48+00:00",
        "last_modified": "2026-01-05 17:27:24+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_744\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: è£…æ°´æžœ\ntotal_episodes: 251\ntotal_tasks: 1\nsize: 32G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_744_Pack_fruits.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_744_Pack_fruits",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ssam17/Edge-Industrial-Anomaly-Phi3",
        "author": "ssam17",
        "created_at": "2026-01-06 00:54:30+00:00",
        "last_modified": "2026-01-06 03:54:05+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "edge-computing",
          "anomaly-detection",
          "phi-3",
          "industrial-iot",
          "time-series",
          "predictive-maintenance",
          "cybersecurity",
          "small-language-models"
        ],
        "description": "\n\t\n\t\t\n\t\tEdge-Industrial-Anomaly-Phi3: A Curated Dataset for SLMs\n\t\n\nThis dataset is a curated collection of industrial sensor data formatted specifically for Small Language Models (SLMs) like Phi-3. It merges three high-value industrial domains into a unified \"Natural Language Reasoning\" format to move beyond simple binary classification.\n\n\t\n\t\t\n\t\tðŸš€ Purpose\n\t\n\nStandard anomaly detection uses CSVs and Scikit-Learn. This dataset enables Generative Anomaly Detection, where a model like Phi-3 canâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ssam17/Edge-Industrial-Anomaly-Phi3.",
        "url": "https://huggingface.co/datasets/ssam17/Edge-Industrial-Anomaly-Phi3",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/HOL4",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:58:14+00:00",
        "last_modified": "2026-01-10 13:58:17+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "hol4",
          "higher-order-logic",
          "standard-ml"
        ],
        "description": "\n\t\n\t\t\n\t\tHOL4\n\t\n\nA structured dataset of theorems and definitions from HOL4, a mature theorem prover for higher-order logic.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/HOL-Theorem-Prover/HOL\nLicense: BSD-3-Clause\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n63,341\n\n\nTheorems\n50,840\n\n\nDefinitions\n12,501\n\n\nScript Files\n1,334\n\n\n\t\n\n\n\t\n\t\t\n\t\tTop Libraries\n\t\n\n\n\t\n\t\t\nLibrary\nCount\n\n\n\t\t\nreal\n5,491\n\n\nexamples/algebra\n3,618\n\n\nalgebra\n3,147\n\n\npred_set\n2,723\n\n\nexamples/lambda\n2,633â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/HOL4.",
        "url": "https://huggingface.co/datasets/phanerozoic/HOL4",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "JingkunAn/TraceSpatial-Bench",
        "author": "JingkunAn",
        "created_at": "2025-12-19 06:00:48+00:00",
        "last_modified": "2026-01-07 18:51:32+00:00",
        "downloads": 497,
        "likes": 3,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "modality:timeseries",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2512.13660",
          "region:us"
        ],
        "description": "\n  \n    TraceSpatial-Bench: An Object-Centric 3D Trajectory Planning Benchmark\n  \n\n\n\n  \n    \n  \n  Â \n  \n    \n  \n  Â \n   \n    \n  \n  Â \n  \n    \n  \n\n\n\n\n\n\n\nWelcome to TraceSpatial-Bench, an object-centric 3D spatial trace planning benchmark provided by RoboTracer.TraceSpatial-Bench is the first benchmark that evaluates whether VLMs can perform multi-step metric-grounded spatial reasoning and object-centric spatial tracing in real, cluttered indoor scenes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸŽ¯ Task Overviewâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/JingkunAn/TraceSpatial-Bench.",
        "url": "https://huggingface.co/datasets/JingkunAn/TraceSpatial-Bench",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_red_pepper_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:43:45+00:00",
        "last_modified": "2026-01-05 22:43:53+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_red_pepper_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†çº¢è¾£æ¤’æ”¾å…¥é”…ä¸­\ntotal_episodes: 30\ntotal_tasks: 1\nsize: 27.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_red_pepper_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_red_pepper_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_starfruit_on_the_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:53:57+00:00",
        "last_modified": "2026-01-06 00:54:59+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_right_hand_put_starfruit_on_the_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å³æ‰‹å°†æ¨æ¡ƒæ”¾åœ¨ç›˜å­ä¸Š\ntotal_episodes: 136\ntotal_tasks: 1\nsize: 753.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_starfruit_on_the_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_starfruit_on_the_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-VST",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:25:55+00:00",
        "last_modified": "2026-01-10 13:48:36+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-2-clause",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "vst",
          "verification",
          "separation-logic"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-VST\n\t\n\nA structured dataset of formalizations from the Verified Software Toolchain (VST), a framework for proving correctness of C programs using separation logic in Coq.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/PrincetonUniversity/VST\nWebsite: https://vst.cs.princeton.edu/\nLicense: BSD-2-Clause\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n52,929\n\n\nFiles Processed\n1,423\n\n\nLicense\nBSD-2-Clause\n\n\n\t\n\n\n\t\n\t\t\n\t\tType Distribution\n\t\n\n\n\t\n\t\t\nType\nCountâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-VST.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-VST",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "minn4/gmbl",
        "author": "minn4",
        "created_at": "2026-01-07 06:16:10+00:00",
        "last_modified": "2026-01-07 06:17:46+00:00",
        "downloads": 36,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "language:en",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "geometry",
          "vision-language",
          "multimodal"
        ],
        "description": "\n\t\n\t\t\n\t\tGeometry Dataset\n\t\n\nThis dataset contains geometry problems with diagrams for vision-language model training.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\nimage: Geometry diagram image\ninstruction: Problem statement or question\noutput: Answer or solution\n\n",
        "url": "https://huggingface.co/datasets/minn4/gmbl",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1113",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:37:33+00:00",
        "last_modified": "2026-01-07 07:38:05+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1113\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_10\ntotal_episodes: 294\ntotal_tasks: 1\nsize: 250.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1113.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1113",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "beersrobert/Vehicle_Dataset_2019_kia_niro_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:46:06+00:00",
        "last_modified": "2026-01-09 04:01:41+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "automotive vehicle-inspection hybrid-vehicles engine-bay interior-safety insurance"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/Vehicle_Dataset_2019_kia_niro_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "smolify/smolified-discharge-summary-generator",
        "author": "smolify",
        "created_at": "2026-01-10 18:21:04+00:00",
        "last_modified": "2026-01-10 18:21:12+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-discharge-summary-generator\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry.\nIt was used to train the corresponding model smolify/smolified-discharge-summary-generator.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: b0b64157)\nRecords: 8525\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by smolify.\nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/smolify/smolified-discharge-summary-generator",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_yellow_pepper_on_plate_copy_1734079761061",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:54:20+00:00",
        "last_modified": "2026-01-06 10:54:57+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_yellow_pepper_on_plate_copy_1734079761061\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›˜å­ä¸Šçš„é»„è¾£æ¤’part_2\ntotal_episodes: 128\ntotal_tasks: 1\nsize: 66.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_yellow_pepper_on_plate_copy_1734079761061.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_yellow_pepper_on_plate_copy_1734079761061",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Certicoq",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:30:44+00:00",
        "last_modified": "2026-01-10 15:12:08+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-CertiCoq\n\t\n\nStructured dataset from CertiCoq â€” Verified compiler from Gallina to C.\n7,580 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/CertiCoq/certicoq\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Certicoq.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Certicoq",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_in_basket_old",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:01:07+00:00",
        "last_modified": "2026-01-05 22:01:18+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_bread_in_basket_old\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„é¢åŒ…part_2\ntotal_episodes: 56\ntotal_tasks: 1\nsize: 60.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_in_basket_old.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_in_basket_old",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Shekswess/tiny-think-sft-chat-n-instruct",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:53:27+00:00",
        "last_modified": "2026-01-10 22:06:27+00:00",
        "downloads": 54,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-sft-chat-n-instruct\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSupervised fine-tuning (SFT) dataset built from allenai/Dolci-Think-SFT-7B using the facebook/MobileLLM-R1-140M-base tokenizer and chat template. This dataset targets general chat + instruction-following behaviors.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nSources: 5\nRows: 52,005\nTokens: 59,999,640\nMax sequence length: 4096 tokens per example \nToken budget: 60,000,000 tokens (equal strategy)\nColumns: messagesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-sft-chat-n-instruct.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-sft-chat-n-instruct",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_bread_desk",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:53:53+00:00",
        "last_modified": "2026-01-05 13:56:56+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_pick_bread_desk\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é¤æ¡Œä¸Šçš„é¢åŒ…\ntotal_episodes: 90\ntotal_tasks: 1\nsize: 544.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_bread_desk.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_bread_desk",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "hugxd/mmdu_val",
        "author": "hugxd",
        "created_at": "2026-01-09 02:35:06+00:00",
        "last_modified": "2026-01-09 02:46:38+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-nc-4.0",
          "arxiv:2406.11833",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“¢ News\n\t\n\n\n[06/13/2024] ðŸš€ We release our MMDU benchmark and MMDU-45k instruct tunning data to huggingface.\n\n\n\t\n\t\t\n\t\tðŸ’Ž MMDU Benchmark\n\t\n\nTo evaluate the multi-image multi-turn dialogue capabilities of existing models, we have developed the MMDU Benchmark. Our benchmark comprises 110 high-quality multi-image multi-turn dialogues with more than 1600 questions, each accompanied by detailed long-form answers. Previous benchmarks typically involved only single images or a small number ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hugxd/mmdu_val.",
        "url": "https://huggingface.co/datasets/hugxd/mmdu_val",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "harpreetsahota/testing_qwen3vl_embeddings",
        "author": "harpreetsahota",
        "created_at": "2026-01-09 16:58:16+00:00",
        "last_modified": "2026-01-09 16:58:32+00:00",
        "downloads": 111,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "library:fiftyone",
          "region:us",
          "fiftyone",
          "image-classification",
          "video"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for random_short_videos\n\t\n\n\n\n\n\n\n\nThis is a FiftyOne dataset with 412 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nfrom fiftyone.utils.huggingface import load_from_hub\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = load_from_hub(\"harpreetsahota/testing_qwen3vl_embeddings\")\n\n# Launch the App\nsession = fo.launch_app(dataset)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/harpreetsahota/testing_qwen3vl_embeddings.",
        "url": "https://huggingface.co/datasets/harpreetsahota/testing_qwen3vl_embeddings",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_toy",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:27:32+00:00",
        "last_modified": "2026-01-05 17:28:56+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_toy\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥çŽ©å…·\ntotal_episodes: 208\ntotal_tasks: 1\nsize: 715.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_toy.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_toy",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "iam-tsr/employ_fdbk",
        "author": "iam-tsr",
        "created_at": "2026-01-09 09:21:16+00:00",
        "last_modified": "2026-01-09 09:38:11+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/iam-tsr/employ_fdbk",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "poojarajendran/Indian-Bank-Statements",
        "author": "poojarajendran",
        "created_at": "2026-01-08 08:44:04+00:00",
        "last_modified": "2026-01-08 08:44:06+00:00",
        "downloads": 67,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:table-question-answering",
          "task_categories:text-generation",
          "language:en",
          "language:hi",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "modality:document",
          "region:us",
          "finance",
          "synthetic",
          "banking",
          "india",
          "transactions",
          "bank-statements",
          "document-ai"
        ],
        "description": "\n\t\n\t\t\n\t\tIndian Bank Statement Synthetic Dataset\n\t\n\nSynthetically generated Indian business bank statements with realistic transaction patterns, proper banking workflows, and India-specific features. Available in scanned PDF and digital JSON formats.\nScope: Current Accounts (business banking) only. Does not include personal/savings accounts.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurated by: AgamiAI Inc.\nLanguage(s): English, Hindi (romanized)\nLicense: Apache 2.0\nRepository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/poojarajendran/Indian-Bank-Statements.",
        "url": "https://huggingface.co/datasets/poojarajendran/Indian-Bank-Statements",
        "languages": [
          "en",
          "hi"
        ],
        "tasks": [
          "text-classification",
          "table-question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "iioos/resource-utilization-metrics",
        "author": "iioos",
        "created_at": "2026-01-11 01:08:06+00:00",
        "last_modified": "2026-01-11 01:08:33+00:00",
        "downloads": 4,
        "likes": 0,
        "tags": [
          "task_categories:time-series-forecasting",
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tResource Utilization Metrics Dataset\n\t\n\nTime series metrics describing resource utilization over time.\n",
        "url": "https://huggingface.co/datasets/iioos/resource-utilization-metrics",
        "languages": [
          "en"
        ],
        "tasks": [
          "time-series-forecasting"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_open_lid",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:44:00+00:00",
        "last_modified": "2026-01-05 23:44:35+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_open_lid\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€ç›–å­part_2\ntotal_episodes: 181\ntotal_tasks: 1\nsize: 402.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_open_lid.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_open_lid",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "zhao-2025/RSCC",
        "author": "zhao-2025",
        "created_at": "2026-01-09 06:01:42+00:00",
        "last_modified": "2026-01-09 06:01:43+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "modality:image",
          "modality:text",
          "arxiv:2509.01907",
          "region:us",
          "remote sensing",
          "vision-language models",
          "temporal image understanding"
        ],
        "description": "\n\t\n\t\t\n\t\tRSCC\n\t\n\nPaper | Project Page | Code\n\n[!WARNING]Due to xBD Licenses, we do not provide direct xBD images and masks. Users can get it via https://www.xview2.org/.\nThe test set of xBD mentioned in our paper can be directly obtained by selecting the first 26 pre- post- images pairs from 19 distinct xBD events to yield all 988=26 * 2 * 19 images\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nWe introduce the Remote Sensing Change Caption (RSCC) dataset, a new benchmark designed to advance the development ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zhao-2025/RSCC.",
        "url": "https://huggingface.co/datasets/zhao-2025/RSCC",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_in_basket_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:00:34+00:00",
        "last_modified": "2026-01-05 23:01:01+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_yellow_pepper_in_basket_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„é»„è¾£æ¤’part_2\ntotal_episodes: 82\ntotal_tasks: 1\nsize: 100.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_in_basket_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_in_basket_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1028",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 02:28:33+00:00",
        "last_modified": "2026-01-06 02:41:06+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1028\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­å–å‡ºèŠ±æœµpart_2\ntotal_episodes: 305\ntotal_tasks: 1\nsize: 544.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1028.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1028",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_red_pepper_on_the_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:52:19+00:00",
        "last_modified": "2026-01-06 00:53:16+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_right_hand_put_red_pepper_on_the_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å³æ‰‹å°†çº¢è¾£æ¤’æ”¾åœ¨ç›˜å­ä¸Š\ntotal_episodes: 138\ntotal_tasks: 1\nsize: 779.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_red_pepper_on_the_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_red_pepper_on_the_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_cap_close_dustbin",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:46:11+00:00",
        "last_modified": "2026-01-05 12:46:44+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_cap_close_dustbin\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›–ä¸Šåžƒåœ¾æ¡¶ç›–\ntotal_episodes: 25\ntotal_tasks: 1\nsize: 107.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_cap_close_dustbin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_cap_close_dustbin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241211",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:06:19+00:00",
        "last_modified": "2026-01-05 18:08:42+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241211\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ¸…æ´é¤æ¡Œpart_3\ntotal_episodes: 35\ntotal_tasks: 1\nsize: 1.4G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241211.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_clean_table_3_241211",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_can_in_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:31:09+00:00",
        "last_modified": "2026-01-05 22:31:20+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_can_in_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç½å­æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 34\ntotal_tasks: 1\nsize: 22.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_can_in_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_can_in_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Jeff0918/MTR-Bench",
        "author": "Jeff0918",
        "created_at": "2026-01-05 14:31:04+00:00",
        "last_modified": "2026-01-06 11:04:00+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "task_categories:automatic-speech-recognition",
          "task_categories:text-to-speech",
          "annotations_creators:machine-generated",
          "annotations_creators:expert-generated",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "region:us",
          "speech-processing",
          "multi-scenarios",
          "multi-round",
          "instruction-following",
          "safety-alignment",
          "semantic-understanding"
        ],
        "description": "\n\t\n\t\t\n\t\tComposite Audio Evaluation Dataset (Anonymous Submission)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is constructed to evaluate multi-modal audio models across four critical dimensions: Complex Scenarios, Instruction Following, Safety Compliance, and Semantic Understanding. \nThe dataset is designed for academic research and is currently anonymized for peer review (ACL). It leverages advanced TTS synthesis (CosyVoice2) and LLM-based text generation (GPT-4o) to create high-fidelityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jeff0918/MTR-Bench.",
        "url": "https://huggingface.co/datasets/Jeff0918/MTR-Bench",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-classification",
          "automatic-speech-recognition",
          "text-to-speech"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "neuralfoundry-coder/finance-instructions-ko-sample",
        "author": "neuralfoundry-coder",
        "created_at": "2026-01-10 12:43:28+00:00",
        "last_modified": "2026-01-10 12:43:35+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:translation",
          "task_categories:text-generation",
          "language:ko",
          "language:en",
          "language:zh",
          "language:ja",
          "language:vi",
          "language:id",
          "license:other",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "finance",
          "korean",
          "instruction-tuning",
          "sft",
          "qa",
          "translation"
        ],
        "description": "\n\t\n\t\t\n\t\tKorean Finance Instruction Dataset (Sample)\n\t\n\n\n\t\n\t\t\n\t\të°ì´í„°ì…‹ ê°œìš”\n\t\n\në³¸ ë°ì´í„°ì…‹ì€ í•œêµ­ì–´ ê¸ˆìœµ ë¶„ì•¼ ì§€ì‹œí•™ìŠµ(Instruction Tuning) ë°ì´í„°ì…‹ì˜ ìƒ˜í”Œ ë²„ì „ìž…ë‹ˆë‹¤.\nì¹´í…Œê³ ë¦¬ë³„ë¡œ ìµœëŒ€ 1,000ê±´ì”© ìƒ˜í”Œë§ë˜ì–´ ìžˆìœ¼ë©°, ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\nì „ì²´ ë°ì´í„°ì…‹ì€ ë³„ë„ì˜ private ì €ìž¥ì†Œì—ì„œ ì œê³µë©ë‹ˆë‹¤.\n\n\t\n\t\t\n\t\të°ì´í„° í˜•ì‹\n\t\n\në³¸ ë°ì´í„°ì…‹ì€ í˜„ëŒ€ sLLM (small Language Model) ì§€ì‹œí•™ìŠµ(Instruction Tuning)ì— ìµœì í™”ëœ í˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.\n{\n  \"instruction\": \"ì‚¬ìš©ìžì—ê²Œ ì œì‹œí•  ì§€ì‹œì‚¬í•­ ë˜ëŠ” ì§ˆë¬¸\",\n  \"input\": \"ì»¨í…ìŠ¤íŠ¸ ë˜ëŠ” ì°¸ê³  ìžë£Œ (ì„ íƒì )\",\n  \"output\": \"ê¸°ëŒ€ë˜ëŠ” ì¶œë ¥ ë˜ëŠ” ë‹µë³€\",\n  \"category\": \"ì¹´í…Œê³ ë¦¬ëª…\",\n  \"source\": \"ì›ë³¸ ë°ì´í„°ì…‹\",\n  \"metadata\":â€¦ See the full description on the dataset page: https://huggingface.co/datasets/neuralfoundry-coder/finance-instructions-ko-sample.",
        "url": "https://huggingface.co/datasets/neuralfoundry-coder/finance-instructions-ko-sample",
        "languages": [
          "ko",
          "en",
          "zh",
          "ja",
          "vi",
          "id"
        ],
        "tasks": [
          "question-answering",
          "translation",
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "panitsasi/FedJam",
        "author": "panitsasi",
        "created_at": "2026-01-09 16:22:56+00:00",
        "last_modified": "2026-01-11 00:20:18+00:00",
        "downloads": 76,
        "likes": 1,
        "tags": [
          "task_categories:image-classification",
          "task_categories:tabular-classification",
          "task_categories:tabular-regression",
          "task_categories:time-series-forecasting",
          "multilinguality:monolingual",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:arrow",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2508.09369",
          "region:us",
          "multimodal",
          "jamming-detection",
          "spectrograms",
          "time-series",
          "federated-learning"
        ],
        "description": "\n\t\n\t\t\n\t\tFedJam Dataset\n\t\n\nThe FedJam dataset is a multimodal dataset for jamming detection and classification in wireless networks, combining timeâ€“frequency spectrogram images with\ncross-layer network KPI time series. Each sample includes aligned vision and time-series modalities, allowing joint analysis of physical-layer signal behavior\nand network-layer performance. The data are collected from a real over-the-air experimental testbed, under a variety of operating conditions, includingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/panitsasi/FedJam.",
        "url": "https://huggingface.co/datasets/panitsasi/FedJam",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification",
          "tabular-classification",
          "tabular-regression",
          "time-series-forecasting"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1118",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:35:34+00:00",
        "last_modified": "2026-01-07 07:35:56+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1118\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_8\ntotal_episodes: 149\ntotal_tasks: 1\nsize: 217.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1118.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1118",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "iioos/system-anomaly-logs",
        "author": "iioos",
        "created_at": "2026-01-10 01:47:07+00:00",
        "last_modified": "2026-01-10 01:47:29+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSystem Anomaly Logs Dataset\n\t\n\nSystem metrics labeled for anomaly detection and monitoring.\n",
        "url": "https://huggingface.co/datasets/iioos/system-anomaly-logs",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_trash",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:51:46+00:00",
        "last_modified": "2026-01-05 13:52:49+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_open_trash\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶part_2\ntotal_episodes: 100\ntotal_tasks: 1\nsize: 364.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_trash.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_trash",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "PeacebinfLow/mindseye-android-os-data",
        "author": "PeacebinfLow",
        "created_at": "2026-01-06 11:37:57+00:00",
        "last_modified": "2026-01-07 17:10:05+00:00",
        "downloads": 54,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "mindseye",
          "android",
          "portfolio",
          "educational",
          "google-ai-challenge",
          "ai-automation"
        ],
        "description": "\n\t\n\t\t\n\t\tMindsEye Android OS Dataset\n\t\n\nThis dataset powers the MindsEye Android OS Hugging Face Space: an educational Android-style UI that presents 35+ MindsEye repositories as interactive apps.\n\n\t\n\t\t\n\t\tContents\n\t\n\n\napps/ â€” 35 app definitions organized by category\nai-control/ â€” controller schemas (system, navigation, recommendations)\nsettings/ â€” system + theme + permissions + AI behavior\nfunctions/ â€” app launcher, notifications, sync, search index, analytics tracker\nmetadata/ â€” categoriesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PeacebinfLow/mindseye-android-os-data.",
        "url": "https://huggingface.co/datasets/PeacebinfLow/mindseye-android-os-data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Orib24/Roomly-Student-Bios-Multimodal",
        "author": "Orib24",
        "created_at": "2026-01-08 08:56:00+00:00",
        "last_modified": "2026-01-08 09:15:22+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:text-to-image",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "roomly",
          "synthetic-data",
          "roommate-matching"
        ],
        "description": "\n\t\n\t\t\n\t\tRoomly: Multimodal Roommate Matching Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸŽ¯ Problem Statement\n\t\n\nFinding a roommate is often reduced to dry filters like \"budget\" and \"location\". Roomly aims to revolutionize this by focusing on personality, lifestyle, and visual preferences. This dataset provides synthetic student profiles and their ideal room environments.\n\n\t\n\t\t\n\t\tðŸ“Š Exploratory Data Analysis (EDA)\n\t\n\n\n\t\n\t\t\n\t\t1. User Persona Distribution\n\t\n\nOur dataset contains a balanced mix of different studentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Orib24/Roomly-Student-Bios-Multimodal.",
        "url": "https://huggingface.co/datasets/Orib24/Roomly-Student-Bios-Multimodal",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "text-to-image"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "SyntheticLogic-Labs/python-runtime-verified-error-correction",
        "author": "SyntheticLogic-Labs",
        "created_at": "2026-01-08 00:12:27+00:00",
        "last_modified": "2026-01-08 00:45:40+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "language:code",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "synthetic-data",
          "code-correction",
          "runtime-verified",
          "python-errors",
          "code-repair"
        ],
        "description": "\n\t\n\t\t\n\t\tPython Runtime-Verified Error Correction Dataset ðŸâš¡\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nProduction-grade synthetic dataset of Python code errors with runtime-verified corrections. Each sample contains broken code, the actual runtime error, and a guaranteed-working fix validated through execution.\nUnlike traditional synthetic datasets, every correction is verified by actually running the code in an isolated environmentâ€”eliminating hallucinations and ensuring real-world applicability.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SyntheticLogic-Labs/python-runtime-verified-error-correction.",
        "url": "https://huggingface.co/datasets/SyntheticLogic-Labs/python-runtime-verified-error-correction",
        "languages": [
          "en",
          "code"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-human-robot-interaction",
        "author": "ariefansclub",
        "created_at": "2026-01-09 03:34:11+00:00",
        "last_modified": "2026-01-09 03:34:57+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "hri",
          "robotics",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tHuman-Robot Interaction Dataset\n\t\n\nThis dataset focuses on natural language interactions between humans and humanoid robots.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nHuman-robot interaction\nSocial robotics\nConversational agents\n\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-human-robot-interaction",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "orgn3ai/YOGURT-ORDER-PREPARATION-sample",
        "author": "orgn3ai",
        "created_at": "2026-01-07 13:24:01+00:00",
        "last_modified": "2026-01-07 14:25:43+00:00",
        "downloads": 178,
        "likes": 0,
        "tags": [
          "task_categories:video-classification",
          "language:en",
          "license:cc-by-nc-nd-4.0",
          "size_categories:n<1K",
          "region:us",
          "egocentric",
          "embodied-ai",
          "robotics",
          "real-world",
          "computer-vision",
          "dataset",
          "sample-dataset"
        ],
        "description": "\n\t\n\t\t\n\t\tYOGURT-ORDER-PREPARATION-sample\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset provides a high-fidelity, ego-centric capture of professional order preparation tasks within a cold-chain logistics environment. It focuses on the rapid, repetitive, and high-precision picking and packing of multi-unit yogurt packs. This resource is specifically designed to train robotic agents in bimanual coordination, spatial reachability, and contact-point optimization for fragile rigid goods.\n\n  \n  Your browserâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/orgn3ai/YOGURT-ORDER-PREPARATION-sample.",
        "url": "https://huggingface.co/datasets/orgn3ai/YOGURT-ORDER-PREPARATION-sample",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_pick_pipe_place_plate_twice",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 02:01:31+00:00",
        "last_modified": "2026-01-06 02:06:39+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_xsens_1rgb_pick_pipe_place_plate_twice\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·ç®¡å­æ”¾ç½®ç›˜å­ä¸¤æ¬¡\ntotal_episodes: 134\ntotal_tasks: 1\nsize: 1.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_pick_pipe_place_plate_twice.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_xsens_1rgb_pick_pipe_place_plate_twice",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:38:09+00:00",
        "last_modified": "2026-01-05 22:38:26+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_long_bread_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é•¿é¢åŒ…æ”¾å…¥é”…ä¸­\ntotal_episodes: 43\ntotal_tasks: 1\nsize: 50.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/task_485_Pick_up_the_waste_paper_on_the_table_and_throw_it_into_the_shredder_for_destruction",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 07:31:24+00:00",
        "last_modified": "2026-01-08 08:10:20+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_485\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æŠŠæ¡Œä¸Šçš„åºŸçº¸æ¡èµ·æ¥ï¼Œæ‰”è¿›ç¢Žçº¸æœºé‡Œé”€æ¯ã€‚\ntotal_episodes: 537\ntotal_tasks: 1\nsize: 24G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/task_485_Pick_up_the_waste_paper_on_the_table_and_throw_it_into_the_shredder_for_destruction.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/task_485_Pick_up_the_waste_paper_on_the_table_and_throw_it_into_the_shredder_for_destruction",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "enPurified/dolphin-r1-deepseek-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 04:44:19+00:00",
        "last_modified": "2026-01-11 07:41:41+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:mlabonne/dolphin-r1-deepseek",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "deepseek-r1",
          "dolphin",
          "reasoning",
          "quality-filtered"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¬ Dolphin-R1-enPurified-openai-messages\n\t\n\nDolphin-R1-enPurified is a highly curated, \"prose-first\" subset of mlabonne/dolphin-r1-deepseek. \nThe enPurified collection is built on a specific philosophy: Linguistic Specialization. While there are many excellent datasets dedicated to competitive programming (Python/Rust) and complex mathematics (LaTeX), high-quality English prose often becomes diluted when mixed with syntax-heavy code. The goal of this dataset is to isolate elite Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/dolphin-r1-deepseek-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/dolphin-r1-deepseek-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "LongfeiLi/SpatialTree-Bench",
        "author": "LongfeiLi",
        "created_at": "2026-01-11 16:20:15+00:00",
        "last_modified": "2026-01-11 17:41:15+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSpaTreeBench\n\t\n\nThis dataset contains annotations and visual data for the SpaTreeBench benchmark.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized as follows:\n\nannotations_plain.parquet: Parquet file containing all structured annotations.\nimages/: Folder containing image files referenced in the dataset.\nvideos/: Folder containing video files referenced in the dataset.\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nsession_id: Unique identifier for the session.\nvideo_info: Information about the video (FPSâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LongfeiLi/SpatialTree-Bench.",
        "url": "https://huggingface.co/datasets/LongfeiLi/SpatialTree-Bench",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "MaxHastings/TinyLLMPretrainingCore",
        "author": "MaxHastings",
        "created_at": "2026-01-07 17:58:46+00:00",
        "last_modified": "2026-01-07 19:01:05+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "synthetic-data",
          "gpt-generated",
          "simple-english",
          "educational",
          "explanations"
        ],
        "description": "\n\t\n\t\t\n\t\tSynthetic Simple-English Subject Explanations Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains synthetic, GPT-generated texts that explain a wide range of subjects using simple English.Each subject is expanded into multiple long-form explanations that repeat key ideas across different styles, perspectives, and framing strategies.\nThe dataset is designed to emphasize clarity, redundancy, and consistency, making it useful for educational NLP, simplification tasks, andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MaxHastings/TinyLLMPretrainingCore.",
        "url": "https://huggingface.co/datasets/MaxHastings/TinyLLMPretrainingCore",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "feng0513xin/HockeyAI",
        "author": "feng0513xin",
        "created_at": "2026-01-05 02:08:02+00:00",
        "last_modified": "2026-01-05 02:08:03+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "dataset",
          "AI",
          "ML",
          "object detection",
          "hockey",
          "puck"
        ],
        "description": "\n\t\n\t\t\n\t\tHockeyAI: A Multi-Class Ice Hockey Dataset for Object Detection\n\t\n\n\n\nðŸ”— This dataset is part of the HockeyAI ecosystem.\n\nðŸ’» Check out the corresponding Hugging Face Space for a live demo: https://huggingface.co/spaces/SimulaMet-HOST/HockeyAI\nðŸ’ The trained model for this dataset is available here: https://huggingface.co/SimulaMet-HOST/HockeyAI\n\n\n\n\nThe HockeyAI dataset is an open-source dataset designed specifically for advancing computer vision research in ice hockey. Withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/feng0513xin/HockeyAI.",
        "url": "https://huggingface.co/datasets/feng0513xin/HockeyAI",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-Mathlib",
        "author": "phanerozoic",
        "created_at": "2026-01-10 10:42:59+00:00",
        "last_modified": "2026-01-10 10:47:03+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4",
          "mathlib",
          "mathematics"
        ],
        "description": "\n\t\n\t\t\n\t\tMathlib4\n\t\n\nStructured dataset of mathematical formalizations from the Mathlib4 library for Lean 4.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nFull declaration body\n\n\ntype\nstring\ntheorem, lemma, def, class, structure, instance, inductive, abbrev, axiom\n\n\nlibrary\nstring\nTop-level Mathlib module (Algebra, Analysis, Topology, etc.)\n\n\nimports\nlist\nImport statements from source file\n\n\nfilename\nstring\nSource file path within Mathlib\n\n\nsymbolic_name\nstring\nDeclarationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Mathlib.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-Mathlib",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "daveiloper/AI-Jailbreak-Prompts",
        "author": "daveiloper",
        "created_at": "2026-01-08 23:53:22+00:00",
        "last_modified": "2026-01-08 23:56:27+00:00",
        "downloads": 8,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_categories:zero-shot-classification",
          "task_categories:table-question-answering",
          "language:en",
          "language:de",
          "size_categories:n<1K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "ChatGPT",
          "JailbreakPrompts",
          "LanguageModeling",
          "ArtificialIntelligence",
          "TextGeneration",
          "Dataset",
          "OpenAI",
          "Jailbreak",
          "Prompts"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tName\n\t\n\nJailbreak Prompts\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nJailbreak Prompts is a complete collection of jailbreak related prompts for ChatGPT. This dataset is intended to provide a valuable resource for understanding and generating text in the context of jailbreaking in ChatGPT.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[German]\n",
        "url": "https://huggingface.co/datasets/daveiloper/AI-Jailbreak-Prompts",
        "languages": [
          "en",
          "de"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "fill-mask",
          "zero-shot-classification",
          "table-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "4lph4v3rs3/IntPhys2",
        "author": "4lph4v3rs3",
        "created_at": "2026-01-08 11:23:54+00:00",
        "last_modified": "2026-01-08 11:23:55+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2506.09849",
          "region:us",
          "Physic",
          "Videos",
          "IntPhys"
        ],
        "description": "\nIntPhys 2\n\n\n\nDataset Â  | Â \n Hugging Face Â  | Â \n Paper Â  | Â \n Blog\n\n\n\nIntPhys 2 is a video benchmark designed to evaluate the intuitive physics understanding of deep learning models. Building on the original IntPhys benchmark, IntPhys 2 focuses on four core principles related to  macroscopic objects: Permanence, Immutability, Spatio-Temporal Continuity, and Solidity. These conditions are inspired by research into intuitive physical understanding emerging during early childhood. IntPhys 2â€¦ See the full description on the dataset page: https://huggingface.co/datasets/4lph4v3rs3/IntPhys2.",
        "url": "https://huggingface.co/datasets/4lph4v3rs3/IntPhys2",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_59_steamedbreadlittleoven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:24:32+00:00",
        "last_modified": "2026-01-05 10:26:58+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_59_steamedbreadlittleoven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¦’å¤´å°çƒ¤ç®±\ntotal_episodes: 161\ntotal_tasks: 1\nsize: 2.7G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_59_steamedbreadlittleoven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_59_steamedbreadlittleoven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "shubh303/open-world-dense-object-detection",
        "author": "shubh303",
        "created_at": "2026-01-05 06:19:42+00:00",
        "last_modified": "2026-01-05 07:00:48+00:00",
        "downloads": 50,
        "likes": 4,
        "tags": [
          "task_categories:object-detection",
          "task_categories:zero-shot-object-detection",
          "annotations_creators:crowdsourced",
          "annotations_creators:machine-generated",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "object-detection",
          "open-world-detection",
          "grounding-dino",
          "open-vocabulary",
          "dense-object-detection",
          "coco",
          "bounding-box",
          "computer-vision",
          "text-conditioned"
        ],
        "description": "\n\t\n\t\t\n\t\tOpen World Dense Object Detection Dataset\n\t\n\nA large-scale dataset for open-world object detection containing 8,001 images with 344,079 bounding box annotations across 1,106 categories.\n\n\t\n\t\t\n\t\tImportant: Open-World vs Closed-Set Detection\n\t\n\n\nThis dataset is designed for open-world/open-vocabulary object detection models like Grounding DINO, OWL-ViT, and similar text-conditioned detectors.\n\n\n\t\n\t\t\n\t\n\t\n\t\tWhy NOT for YOLO, DETR, or Traditional Detectors?\n\t\n\nTraditional closed-set objectâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/shubh303/open-world-dense-object-detection.",
        "url": "https://huggingface.co/datasets/shubh303/open-world-dense-object-detection",
        "languages": [
          "en"
        ],
        "tasks": [
          "object-detection",
          "zero-shot-object-detection"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Dafny",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:07:34+00:00",
        "last_modified": "2026-01-10 14:07:38+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "dafny",
          "verification",
          "imperative-programming"
        ],
        "description": "\n\t\n\t\t\n\t\tDafny\n\t\n\nA structured dataset of functions, lemmas, and predicates from Dafny, a verification-aware programming language.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/dafny-lang/dafny\nWebsite: https://dafny.org\nLicense: MIT\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n9,572\n\n\nFunctions\n4,849\n\n\nPredicates\n2,468\n\n\nLemmas\n2,255\n\n\nSource Files\n2,155\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration signature with specs\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Dafny.",
        "url": "https://huggingface.co/datasets/phanerozoic/Dafny",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "OwnedByDanes/usenet-ai-samples",
        "author": "OwnedByDanes",
        "created_at": "2026-01-07 21:37:46+00:00",
        "last_modified": "2026-01-08 01:23:28+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "language:en",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tUsenet Datadog Archive â€“ AI Training Samples\n\t\n\n\n\t\n\t\t\n\t\tDataset Card\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains representative samples from one of the largest and most thoroughly cleaned Usenet archives ever assembled for AI training. Usenetâ€”the original decentralized online discussion networkâ€”captures raw, unfiltered human discourse from the dawn of the public internet through the early social media era. Spanning four decades, it offers authentic, long-form conversationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OwnedByDanes/usenet-ai-samples.",
        "url": "https://huggingface.co/datasets/OwnedByDanes/usenet-ai-samples",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "gudo7208/CAD-Coder",
        "author": "gudo7208",
        "created_at": "2025-12-31 10:44:28+00:00",
        "last_modified": "2026-01-09 09:17:40+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "modality:text",
          "arxiv:2505.19713",
          "region:us",
          "cad",
          "code-generation",
          "text-to-cad",
          "cadquery",
          "3d-modeling"
        ],
        "description": "\n\t\n\t\t\n\t\tCAD-Coder Dataset\n\t\n\nThis is the official dataset for the paper \"CAD-Coder: Text-to-CAD Generation with Chain-of-Thought and Geometric Reward\".\nAccepted at NeurIPS 2025 (Poster)\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nCAD-Coder Dataset is a large-scale Text-to-CadQuery dataset containing natural language descriptions of 3D CAD models paired with executable CadQuery Python code. The dataset enables training and evaluating language models to generate parametric CAD code from textual descriptions.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/gudo7208/CAD-Coder.",
        "url": "https://huggingface.co/datasets/gudo7208/CAD-Coder",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Dark7Devil/lnqa-hi-en",
        "author": "Dark7Devil",
        "created_at": "2026-01-06 19:07:19+00:00",
        "last_modified": "2026-01-10 16:49:08+00:00",
        "downloads": 127,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-text-to-text",
          "language:hi",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Dark7Devil/lnqa-hi-en",
        "languages": [
          "hi",
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-text-to-text"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "sirlab-ai/driving-urban-dutch-fog__zn7nyhyg-preview",
        "author": "sirlab-ai",
        "created_at": "2026-01-09 20:36:20+00:00",
        "last_modified": "2026-01-11 18:45:55+00:00",
        "downloads": 70,
        "likes": 0,
        "tags": [
          "annotations_creators:machine-generated",
          "language:en",
          "license:other",
          "size_categories:n<1K",
          "modality:3d",
          "region:us",
          "synthetic",
          "urban",
          "dutch",
          "fog",
          "autonomous-driving",
          "multimodal",
          "point-cloud",
          "semantic-segmentation",
          "computer-vision",
          "point-cloud-segmentation",
          "3d",
          "imu",
          "odometry",
          "lidar",
          "camera"
        ],
        "description": "\n\t\n\t\t\n\t\tDutch Town Scene 1 (#zn7nyhyg)\n\t\n\nSiRLab publishes LiDAR-first synthetic datasets with dense per-point semantics, synchronized RGB, and ego-motion, built to plug into modern perception pipelines.\n\nBest for: point-cloud semantic segmentation, filtering/analytics, fusion prototyping.\nCommercialization: you may commercialize models/outputs trained on the Full dataset (dataset redistribution is prohibited; see License below).\nFull access / quote / integration: see Commercial access &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sirlab-ai/driving-urban-dutch-fog__zn7nyhyg-preview.",
        "url": "https://huggingface.co/datasets/sirlab-ai/driving-urban-dutch-fog__zn7nyhyg-preview",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_0_tkg_1rgb_lift_pot_lid_and_place_it_to_the_right_of_the_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 03:23:14+00:00",
        "last_modified": "2026-01-08 03:28:03+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_lift_pot_lid_and_place_it_to_the_right_of_the_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é”…ç›–å¹¶å°†å…¶æ”¾åœ¨é”…çš„å³ä¾§\ntotal_episodes: 167\ntotal_tasks: 1\nsize: 1.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkg_1rgb_lift_pot_lid_and_place_it_to_the_right_of_the_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkg_1rgb_lift_pot_lid_and_place_it_to_the_right_of_the_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "modibboali/DeepMath-103K",
        "author": "modibboali",
        "created_at": "2026-01-05 08:26:19+00:00",
        "last_modified": "2026-01-05 08:26:23+00:00",
        "downloads": 45,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2504.11456",
          "region:us",
          "math",
          "reasoning",
          "rl"
        ],
        "description": "\n\t\n\t\t\n\t\tDeepMath-103K\n\t\n\n\n  \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n      \n    \n    \n      \n        \n\t\n\t\t\n\t\tðŸ”¥ News\n\t\n\n\nMay 8, 2025: We found that 48 samples contained hints that revealed the answers. The relevant questions have now been revised to remove the leaked answers.\nApril 14, 2025: We release DeepMath-103K, a large-scale dataset featuring challenging, verifiable, and decontaminated math problems tailored for RL and SFT. We open source:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/modibboali/DeepMath-103K.",
        "url": "https://huggingface.co/datasets/modibboali/DeepMath-103K",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_42_putkiwifruite",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:26:39+00:00",
        "last_modified": "2026-01-05 09:57:41+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_42_putkiwifruite\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾çŒ•çŒ´æ¡ƒpart_1\ntotal_episodes: 187\ntotal_tasks: 1\nsize: 4.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_42_putkiwifruite.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_42_putkiwifruite",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_banana",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:12:02+00:00",
        "last_modified": "2026-01-05 22:12:14+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_banana\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é¦™è•‰\ntotal_episodes: 48\ntotal_tasks: 1\nsize: 70.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_banana.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_banana",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_plastic_bottle",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:21:19+00:00",
        "last_modified": "2026-01-05 22:21:34+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_plastic_bottle\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·å¡‘æ–™ç“¶\ntotal_episodes: 76\ntotal_tasks: 1\nsize: 72.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_plastic_bottle.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_plastic_bottle",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:16:52+00:00",
        "last_modified": "2026-01-06 07:17:04+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·çº¢è¾£æ¤’\ntotal_episodes: 86\ntotal_tasks: 1\nsize: 43.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_red_pepper_from_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "hybridfree/hackaday-posts",
        "author": "hybridfree",
        "created_at": "2026-01-09 23:14:35+00:00",
        "last_modified": "2026-01-09 23:14:35+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:image",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "technology",
          "electronics",
          "hardware",
          "engineering",
          "nlp",
          "community-analysis",
          "social-networks",
          "technical-writing",
          "comment-analysis"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸš€ Hackaday Universe: 50K+ Tech Articles & Vibrant Maker Conversations\n\t\n\nDive into the ultimate collection of Hackaday's tech universe! This isn't just another datasetâ€”it's a living archive of maker culture, featuring 54,599+ articles with complete comment threads where brilliant minds collide, debate, and innovate together.\n\n\t\n\t\t\n\t\tðŸ”¥ Why This Dataset Rocks\n\t\n\nðŸ¤– Perfect for AI Training\n\nTrain models on authentic technical writing and community interactions\nLearn from realâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hybridfree/hackaday-posts.",
        "url": "https://huggingface.co/datasets/hybridfree/hackaday-posts",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Rokhit/publaynet",
        "author": "Rokhit",
        "created_at": "2026-01-07 05:45:40+00:00",
        "last_modified": "2026-01-07 05:45:41+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:image",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:1908.07836",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tPubLayNet\n\t\n\nPubLayNet is a large dataset of document images, of which the layout is annotated with both bounding boxes and polygonal segmentations. The source of the documents is PubMed Central Open Access Subset (commercial use collection). The annotations are automatically generated by matching the PDF format and the XML format of the articles in the PubMed Central Open Access Subset. More details are available in our paper \"PubLayNet: largest dataset ever for document layoutâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rokhit/publaynet.",
        "url": "https://huggingface.co/datasets/Rokhit/publaynet",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-text"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_donut_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:31:31+00:00",
        "last_modified": "2026-01-05 22:31:37+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_donut_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç”œç”œåœˆæ”¾å…¥é”…ä¸­\ntotal_episodes: 24\ntotal_tasks: 1\nsize: 15.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_donut_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_donut_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "godmodes/NuminaMath-CoT",
        "author": "godmodes",
        "created_at": "2026-01-07 09:45:10+00:00",
        "last_modified": "2026-01-07 09:45:11+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "aimo",
          "math"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for NuminaMath CoT\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nApproximately 860k math problems, where each solution is formatted in a Chain of Thought (CoT) manner. The sources of the dataset range from Chinese high school math exercises to US and international mathematics olympiad competition problems. The data were primarily collected from online exam paper PDFs and mathematics discussion forums. The processing steps include (a) OCR from the original PDFs, (b) segmentation intoâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/godmodes/NuminaMath-CoT.",
        "url": "https://huggingface.co/datasets/godmodes/NuminaMath-CoT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "broadfield-dev/rStar-Coder-PyStructure-refined",
        "author": "broadfield-dev",
        "created_at": "2026-01-06 22:36:44+00:00",
        "last_modified": "2026-01-06 22:37:43+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "dataset-command-center",
          "etl",
          "generated-dataset"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): en\nLicense: cc-by-4.0\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/broadfield-dev/rStar-Coder-PyStructure-refined.",
        "url": "https://huggingface.co/datasets/broadfield-dev/rStar-Coder-PyStructure-refined",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_triangle_bread",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:26:39+00:00",
        "last_modified": "2026-01-05 22:26:58+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_triangle_bread\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·ä¸‰è§’å½¢é¢åŒ…\ntotal_episodes: 85\ntotal_tasks: 1\nsize: 69.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_triangle_bread.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_triangle_bread",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-futuristic-human-intent-mapping",
        "author": "ariefansclub",
        "created_at": "2026-01-10 05:03:43+00:00",
        "last_modified": "2026-01-10 05:04:14+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "intent",
          "multimodal",
          "futuristic",
          "robotics"
        ],
        "description": "\n\t\n\t\t\n\t\tFuturistic Human Intent Mapping Dataset\n\t\n\nMaps advanced human signals to humanoid robot interaction intents.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-futuristic-human-intent-mapping",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_lamp_off_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:00:08+00:00",
        "last_modified": "2026-01-05 12:03:59+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241022_lamp_off_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³ç¯part_1\ntotal_episodes: 280\ntotal_tasks: 1\nsize: 483.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_lamp_off_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_lamp_off_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "duoduoyeah/TinyStories",
        "author": "duoduoyeah",
        "created_at": "2026-01-05 03:22:06+00:00",
        "last_modified": "2026-01-05 03:22:08+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cdla-sharing-1.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2305.07759",
          "region:us"
        ],
        "description": "Dataset containing synthetically generated (by GPT-3.5 and GPT-4) short stories that only use a small vocabulary.\nDescribed in the following paper: https://arxiv.org/abs/2305.07759. \nThe models referred to in the paper were trained on TinyStories-train.txt  (the file tinystories-valid.txt can be used for validation loss). These models can be found on Huggingface, at roneneldan/TinyStories-1M/3M/8M/28M/33M/1Layer-21M.\nAdditional resources:\ntinystories_all_data.tar.gz - contains a superset ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/duoduoyeah/TinyStories.",
        "url": "https://huggingface.co/datasets/duoduoyeah/TinyStories",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_round_bread",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:23:40+00:00",
        "last_modified": "2026-01-05 22:23:55+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_round_bread\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·åœ†é¢åŒ…part_1\ntotal_episodes: 133\ntotal_tasks: 1\nsize: 101.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_round_bread.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_round_bread",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/task_487_Take_the_bottled_water_out_of_the_cardboard_box_and_place_it_neatly_on_the_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 09:25:13+00:00",
        "last_modified": "2026-01-08 12:17:14+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_487\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æŠŠç“¶è£…æ°´ä»Žçº¸ç›’é‡Œæ‹¿å‡ºæ¥ï¼Œæ•´é½åœ°æ”¾åœ¨æ¡Œå­ä¸Šã€‚part_2\ntotal_episodes: 487\ntotal_tasks: 1\nsize: 64G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/task_487_Take_the_bottled_water_out_of_the_cardboard_box_and_place_it_neatly_on_the_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/task_487_Take_the_bottled_water_out_of_the_cardboard_box_and_place_it_neatly_on_the_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "arcinstitute/Perturb-Sapiens",
        "author": "arcinstitute",
        "created_at": "2026-01-09 11:26:47+00:00",
        "last_modified": "2026-01-09 23:14:04+00:00",
        "downloads": 35,
        "likes": 1,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100M<n<1B",
          "region:us",
          "biology",
          "single-cell",
          "perturbation",
          "transcriptomics",
          "drug-response",
          "foundation-model",
          "genomics"
        ],
        "description": "\n\t\n\t\t\n\t\tPerturb Sapiens: A Human Whole-Organism Atlas of Perturbed Cells\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nPerturb Sapiens is an evolving database of AI-predicted single-cell perturbation responses, representing the first human whole-organism atlas of perturbed cells. \nPerturb Sapiens is generated using the post-trained Stack model (Stack-Large-Aligned), an in-context learning foundation model for single-cell biology.\nData Sources:\n\nPrompt Data: Parse/OpenProblems PBMC perturbation data\nQueryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/arcinstitute/Perturb-Sapiens.",
        "url": "https://huggingface.co/datasets/arcinstitute/Perturb-Sapiens",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "phanerozoic/Coq-Coquelicot",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:29:51+00:00",
        "last_modified": "2026-01-10 15:12:04+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-3.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Coquelicot\n\t\n\nStructured dataset from Coquelicot â€” Classical real analysis.\n2,448 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://gitlab.inria.fr/coquelicot/coquelicot\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Coquelicot.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Coquelicot",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Moheez2611/recruitment-dataset-job-descriptions-english",
        "author": "Moheez2611",
        "created_at": "2026-01-11 14:22:08+00:00",
        "last_modified": "2026-01-11 14:22:09+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDjinni Dataset (English Job Descriptions part)\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Djinni Recruitment Dataset (English Job Descriptions part)  contains 150,000 job descriptions and 230,000 anonymized candidate CVs, posted between 2020-2023 on the Djinni IT job platform. The dataset includes samples in English and Ukrainian. \nThe dataset contains various attributes related to job descriptions, including position titles, job descriptions, company names, experience requirements, keywords, Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Moheez2611/recruitment-dataset-job-descriptions-english.",
        "url": "https://huggingface.co/datasets/Moheez2611/recruitment-dataset-job-descriptions-english",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "QQWQQ00/RFUAV",
        "author": "QQWQQ00",
        "created_at": "2026-01-06 07:05:35+00:00",
        "last_modified": "2026-01-06 07:05:38+00:00",
        "downloads": 801,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "language:en",
          "language:zh",
          "license:apache-2.0",
          "modality:image",
          "arxiv:2503.09033",
          "region:us",
          "signal-processing",
          "drone-detection",
          "drone-identification",
          "rf-signal"
        ],
        "description": " The RFUAV DATASET \n\nThis repository contains the RFUAV dataset, presented in the paper \"RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and Identification\". RFUAV provides approximately 1.3 TB of raw frequency data collected from 37 distinct UAVs, offering a comprehensive benchmark for radio-frequency-based drone detection and identification.  The dataset addresses limitations of existing datasets by providing a diverse range of drone types, sufficient data volume, coverageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/QQWQQ00/RFUAV.",
        "url": "https://huggingface.co/datasets/QQWQQ00/RFUAV",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "audio-classification"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_bread_into_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:57:13+00:00",
        "last_modified": "2026-01-05 14:09:02+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_pick_bread_into_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ¡èµ·æ”¾å…¥ç›˜å­\ntotal_episodes: 89\ntotal_tasks: 1\nsize: 590.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_bread_into_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_bread_into_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "abhitraj69/symptom-disease-dataset",
        "author": "abhitraj69",
        "created_at": "2026-01-07 11:15:04+00:00",
        "last_modified": "2026-01-07 11:15:05+00:00",
        "downloads": 358,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/abhitraj69/symptom-disease-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "enPurified/standardebooks-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-09 03:41:01+00:00",
        "last_modified": "2026-01-10 18:25:23+00:00",
        "downloads": 28,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:Nelathan/standardebooks",
          "language:en",
          "license:cc0-1.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "prose",
          "literature",
          "standardebooks",
          "context-aware",
          "synthetic-formatting",
          "writing"
        ],
        "description": "\n\n\n\t\n\t\t\n\t\tðŸ“– StandardEbooks-enPurified-openai-messages\n\t\n\nStandardEbooks-enPurified is a highly curated, \"prose-first\" iteration of the Nelathan/standardebooks dataset.\nWhile the source dataset provides excellent public domain literature, raw full-text novels are difficult to ingest directly into training pipelines. This dataset solves that by applying intelligent context-aware chunking and formatting the data into the OpenAI Messages standard.\nThe goal is to provide a clean, high-qualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/standardebooks-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/standardebooks-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "chandrabhuma/Screenspot5G_VQA",
        "author": "chandrabhuma",
        "created_at": "2025-11-26 02:11:26+00:00",
        "last_modified": "2026-01-07 13:27:10+00:00",
        "downloads": 39,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-text-to-text",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "ðŸ“± Screenspot5G VQA Dataset\nðŸ§¾ Dataset Details\nðŸ“Œ Dataset Description\n  Screenspot5G_VQA is a visual question answering (VQA) dataset for mobile screenshot understanding.\n  It is designed to evaluate a modelâ€™s ability to reason over real smartphone screen content, including UI elements, icons, layout structure, and visible text.\n  All images were captured using a real 5G smartphone, ensuring realistic visual characteristics such as screen resolution, font rendering, and UI density.\n  Device:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chandrabhuma/Screenspot5G_VQA.",
        "url": "https://huggingface.co/datasets/chandrabhuma/Screenspot5G_VQA",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-text-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "llm-semantic-router/halueval-spans-deberta",
        "author": "llm-semantic-router",
        "created_at": "2026-01-07 21:54:55+00:00",
        "last_modified": "2026-01-07 21:54:57+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "hallucination-detection",
          "fact-verification",
          "RAG",
          "NLI",
          "span-detection"
        ],
        "description": "\n\t\n\t\t\n\t\tHaluEval Span-Level Dataset\n\t\n\nðŸ” Span-level hallucination detection dataset converted from HaluEval using DeBERTa-FEVER-ANLI NLI model.\n\n\t\n\t\t\n\t\tQuick Start\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"llm-semantic-router/halueval-spans-deberta\")\n\n\n\t\n\t\t\n\t\tWhy This Dataset?\n\t\n\n\n\t\n\t\t\nProblem\nSolution\n\n\n\t\t\nHaluEval has binary labels only\nâœ… Span-level annotations\n\n\nMost hallucination datasets are imbalanced\nâœ… 45.8% hallucinated tokens\n\n\nToken classifiers need characterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-semantic-router/halueval-spans-deberta.",
        "url": "https://huggingface.co/datasets/llm-semantic-router/halueval-spans-deberta",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ArtOh/rvl_cdip",
        "author": "ArtOh",
        "created_at": "2026-01-11 19:34:47+00:00",
        "last_modified": "2026-01-11 19:34:47+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "task_ids:multi-class-image-classification",
          "annotations_creators:found",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:extended|iit_cdip",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "arxiv:1502.07058",
          "region:us"
        ],
        "description": "The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images.",
        "url": "https://huggingface.co/datasets/ArtOh/rvl_cdip",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_basket_1119",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:01:02+00:00",
        "last_modified": "2026-01-07 07:01:39+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_basket_1119\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¯®å­ä¸­æ‹¿èµ·æ©™å­part_1\ntotal_episodes: 224\ntotal_tasks: 1\nsize: 190.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_basket_1119.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_basket_1119",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:40:05+00:00",
        "last_modified": "2026-01-05 22:40:21+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_long_bread_in_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é•¿é¢åŒ…æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 26\ntotal_tasks: 1\nsize: 36.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "elliotvincent/b-FLAIR",
        "author": "elliotvincent",
        "created_at": "2025-11-26 09:27:55+00:00",
        "last_modified": "2025-11-26 13:51:32+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:image-segmentation",
          "language:en",
          "license:etalab-2.0",
          "size_categories:10K<n<100K",
          "modality:geospatial",
          "region:us",
          "remote-sensing",
          "earth-observation",
          "change-detection",
          "weak-temporal-supervision"
        ],
        "description": "\n\t\n\t\t\n\t\tb-FLAIR: bi-temporal extension of FLAIR\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nb-FLAIR is a temporal extension of the FLAIR dataset [1] focused on land cover classification in France. The dataset provides bi-temporal orthoimage pairs with single-temporal semantic annotations.\nProject page: https://xavibou.github.io/CDviaWTS/\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTask: Semantic change detection via weak temporal supervision\nCoverage: France\nResolution: 0.2 m/px\nPatch Size: 512Ã—512 pixels\nBands: Redâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elliotvincent/b-FLAIR.",
        "url": "https://huggingface.co/datasets/elliotvincent/b-FLAIR",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-segmentation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "randallcr7/OpenS2V-Eval",
        "author": "randallcr7",
        "created_at": "2026-01-05 03:51:52+00:00",
        "last_modified": "2026-01-05 03:51:52+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:text-to-video",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "modality:video",
          "arxiv:2505.20292",
          "region:us",
          "subject-to-video",
          "text-to-video",
          "image-to-video",
          "video-generation",
          "large-scale",
          "benchmark",
          "evaluation"
        ],
        "description": "\n\n\n OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation\n\n If you like our project, please give us a star â­ on GitHub for the latest update.  \n\n\n\n\t\n\t\t\n\t\tâœ¨ Summary\n\t\n\nOpenS2V-Eval introduces 180 prompts from seven major categories of S2V, which incorporate both real and synthetic test data. Furthermore, \nto accurately align human preferences with S2V benchmarks, we propose three automatic metrics: NexusScore, NaturalScore, GmeScore\nto separately quantifyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/randallcr7/OpenS2V-Eval.",
        "url": "https://huggingface.co/datasets/randallcr7/OpenS2V-Eval",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-video"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BrentLab/yeast_comparative_analysis",
        "author": "BrentLab",
        "created_at": "2026-01-07 14:16:49+00:00",
        "last_modified": "2026-01-07 15:00:51+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "genomics",
          "transcription-factors",
          "yeast",
          "saccharomyces-cerevisiae"
        ],
        "description": "\n\t\n\t\t\n\t\tYeast Comparative Analysis\n\t\n\n",
        "url": "https://huggingface.co/datasets/BrentLab/yeast_comparative_analysis",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Infotheo",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:45:50+00:00",
        "last_modified": "2026-01-10 15:12:10+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Infotheo\n\t\n\nStructured dataset from Infotheo â€” Information theory and error-correcting codes.\n4,766 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/affeldt-aist/infotheo\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Infotheo.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Infotheo",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Analysis",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:46:52+00:00",
        "last_modified": "2026-01-10 15:12:29+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:other",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Analysis\n\t\n\nStructured dataset from MathComp Analysis â€” MathComp-compatible classical real analysis.\n9,300 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/math-comp/analysis\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Analysis.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Analysis",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "saad-kw-almutairi/pii-masking-300k",
        "author": "saad-kw-almutairi",
        "created_at": "2026-01-09 03:48:58+00:00",
        "last_modified": "2026-01-09 03:49:00+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "task_categories:table-question-answering",
          "task_categories:question-answering",
          "task_categories:zero-shot-classification",
          "task_categories:summarization",
          "task_categories:feature-extraction",
          "task_categories:text-generation",
          "task_categories:translation",
          "task_categories:fill-mask",
          "task_categories:tabular-classification",
          "task_categories:tabular-to-text",
          "task_categories:table-to-text",
          "task_categories:text-retrieval",
          "task_categories:other",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:en",
          "language:fr",
          "language:de",
          "language:it",
          "language:es",
          "language:nl",
          "license:other",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "legal",
          "business",
          "psychology",
          "privacy",
          "gdpr",
          "euaiact",
          "aiact",
          "pii",
          "sensitive"
        ],
        "description": "\n\t\n\t\t\n\t\tPurpose and Features\n\t\n\nðŸŒ World's largest open dataset for privacy masking ðŸŒŽ\nThe dataset is useful to train and evaluate models to remove personally identifiable and sensitive information from text, especially in the context of AI assistants and LLMs. \nKey facts:\n\nOpenPII-220k text entries have  27 PII classes (types of sensitive data), targeting 749 discussion subjects / use cases split across education, health, and psychology. FinPII contains an additional ~20 types tailored toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/saad-kw-almutairi/pii-masking-300k.",
        "url": "https://huggingface.co/datasets/saad-kw-almutairi/pii-masking-300k",
        "languages": [
          "en",
          "fr",
          "de",
          "it",
          "es",
          "nl"
        ],
        "tasks": [
          "text-classification",
          "token-classification",
          "table-question-answering",
          "question-answering",
          "zero-shot-classification",
          "summarization",
          "feature-extraction",
          "text-generation",
          "translation",
          "fill-mask",
          "tabular-classification",
          "tabular-to-text",
          "table-to-text",
          "text-retrieval",
          "other"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "AlmazErmilov/FormationEval",
        "author": "AlmazErmilov",
        "created_at": "2026-01-06 12:19:08+00:00",
        "last_modified": "2026-01-08 15:12:05+00:00",
        "downloads": 89,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:multiple-choice",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:json",
          "modality:document",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.02158",
          "region:us",
          "benchmark",
          "mcq",
          "geoscience",
          "petroleum",
          "petrophysics",
          "oil-and-gas",
          "evaluation",
          "geology",
          "petroleum-geology",
          "geophysics",
          "reservoir-engineering",
          "drilling-engineering",
          "production-engineering",
          "sedimentology",
          "multiple-choice"
        ],
        "description": "\n\t\n\t\t\n\t\tFormationEval\n\t\n\nFormationEval is an open multiple-choice question (MCQ) benchmark for evaluating language models on petroleum geoscience and subsurface disciplines.\n\n505 questions across 7 domains\n72 models evaluated with full leaderboard\n3 authoritative sources: Ellis & Singer (2007), BjÃ¸rlykke (2010), TU Delft OCW\n\n\n\t\n\t\t\n\t\tLinks\n\t\n\n\nPaper: arXiv:2601.02158\nGitHub: FormationEval Repository\nLeaderboard: Interactive Leaderboard Space or see leaderboard.md\nWebsite: formationeval.no â€”â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AlmazErmilov/FormationEval.",
        "url": "https://huggingface.co/datasets/AlmazErmilov/FormationEval",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "multiple-choice"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Dabbu19/uniprotkb_reviewed_archea_environmental_samples_48510_0-v1",
        "author": "Dabbu19",
        "created_at": "2026-01-07 10:12:36+00:00",
        "last_modified": "2026-01-07 10:12:44+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tuniprotkb_reviewed_archea_environmental_samples_48510_0\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComprehensive protein knowledgebase with functional annotations\nOriginal Source: ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/rdf/uniprotkb_reviewed_archea_environmental_samples_48510_0.rdf.xz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from uniprotkb_reviewed_archea_environmental_samples_48510_0 converted to HuggingFace\ndataset format for easy use in machineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Dabbu19/uniprotkb_reviewed_archea_environmental_samples_48510_0-v1.",
        "url": "https://huggingface.co/datasets/Dabbu19/uniprotkb_reviewed_archea_environmental_samples_48510_0-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "psychopenguin/next_token",
        "author": "psychopenguin",
        "created_at": "2026-01-08 06:54:55+00:00",
        "last_modified": "2026-01-08 07:09:03+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:text-classification",
          "task_categories:text-retrieval",
          "language:en",
          "license:other",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "legal",
          "law",
          "india",
          "supreme-court",
          "court-judgments"
        ],
        "description": "\n\t\n\t\t\n\t\tSupreme Court of India Judgments Dataset (1950-2025)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a comprehensive collection of judgments and orders from the Supreme Court of India, spanning from its inception in 1950 up to early 2025. \n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Documents: 26,688\nTotal Tokens: ~196.9 Million (counted using cl100k_base encoding)\nFormat: JSONL (JSON Lines)\nLanguage: English\nTime Range: 1950 - 2025\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\nEach entry in the .jsonl fileâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/psychopenguin/next_token.",
        "url": "https://huggingface.co/datasets/psychopenguin/next_token",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "text-classification",
          "text-retrieval"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "enPurified/Hermes-3-Dataset-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-10 22:31:56+00:00",
        "last_modified": "2026-01-11 04:17:41+00:00",
        "downloads": 31,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:NousResearch/Hermes-3-Dataset",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "hermes-3",
          "quality-filtered",
          "enPurified"
        ],
        "description": "\n\n\n\t\n\t\t\n\t\tðŸ“– Hermes-3-Dataset-enPurified-openai-messages\n\t\n\nHermes-3-Dataset-enPurified is a highly curated, \"prose-first\" subset of the original NousResearch/Hermes-3-Dataset.\nThe enPurified collection is built on a specific philosophy: Specialization. There are plenty of excellent datasets for coding (StackOverflow, StarCoder) and mathematics (GSM8K, MathInstruct). However, high-quality, fluent English prose often gets diluted when mixed with syntax-heavy code or rigid math formulas.\nThisâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/Hermes-3-Dataset-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/Hermes-3-Dataset-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1030",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:51:21+00:00",
        "last_modified": "2026-01-07 06:51:43+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1030\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­æ‹¿èµ·èŠ±æœµpart_4\ntotal_episodes: 323\ntotal_tasks: 1\nsize: 457.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1030.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1030",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "huzican/game",
        "author": "huzican",
        "created_at": "2026-01-08 04:59:01+00:00",
        "last_modified": "2026-01-08 05:24:39+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:any-to-any",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "multimodal",
          "chain-of-thought"
        ],
        "description": "\n\t\n\t\t\n\t\tGame Reasoning Dataset\n\t\n\nA multimodal reasoning dataset for game navigation and puzzle-solving tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 2950 visual reasoning examples from various game scenarios.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"huzican/test_game\")\n\n",
        "url": "https://huggingface.co/datasets/huzican/game",
        "languages": [
          "en"
        ],
        "tasks": [
          "any-to-any"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_in_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:07:09+00:00",
        "last_modified": "2026-01-05 22:07:26+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_green_pepper_in_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„é’æ¤’part_1\ntotal_episodes: 61\ntotal_tasks: 1\nsize: 81.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_in_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_green_pepper_in_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "SpaceGhost/modern-webapp-instructions",
        "author": "SpaceGhost",
        "created_at": "2026-01-05 23:55:41+00:00",
        "last_modified": "2026-01-06 00:09:19+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "language:en",
          "language:pt",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Code,",
          "code-generation,",
          "instruction-tuning,",
          "software-development,",
          "web-development,",
          "fullstack,",
          "fine-tuning,"
        ],
        "description": "Perfeito ðŸ˜„ðŸ“¦\nEntÃ£o aqui estÃ¡ um README.md completo, moderno e pronto para subir no Hugging Face Hub, alinhado com tudo que a gente construiu (modelos pequenos, eficiÃªncia, Unsloth, apps web modernos).\nVocÃª pode copiar e colar direto.\n\n# modern-webapp-instructions\n\n## ðŸ“Œ Overview\n**modern-webapp-instructions** Ã© um dataset de *instruction tuning* focado na criaÃ§Ã£o de **webpages e aplicaÃ§Ãµes modernas**, otimizado para **modelos pequenos e eficientes** (1.5Bâ€“3B), como Qwen, Phi e LLaMAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SpaceGhost/modern-webapp-instructions.",
        "url": "https://huggingface.co/datasets/SpaceGhost/modern-webapp-instructions",
        "languages": [
          "en",
          "pt"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Yogesh914/RiskCueBench",
        "author": "Yogesh914",
        "created_at": "2026-01-07 19:37:54+00:00",
        "last_modified": "2026-01-08 00:59:14+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:video-classification",
          "task_categories:video-text-to-text",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸš¨ RiskCueBench\n\t\n\n\nA benchmark dataset for evaluating risk reasoning capabilities in video understanding models\n\n\n\n\n\t\n\t\t\n\t\tðŸ“– Overview\n\t\n\nRiskCueBench provides fine-grained annotations of risk signalsâ€”visual cues that precede potentially dangerous events. This dataset contains annotated video clips from two domains: ðŸš— traffic accidents and ðŸ“¢ protest events, designed to test temporal risk anticipation and visual reasoning.\n\n\t\n\t\t\n\t\tâœ¨ Key Features\n\t\n\n\n\t\n\t\t\n\nFeature\nDescription\n\n\n\t\t\nðŸŽ¯â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yogesh914/RiskCueBench.",
        "url": "https://huggingface.co/datasets/Yogesh914/RiskCueBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-classification",
          "video-text-to-text"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "cublya/jam-alt",
        "author": "cublya",
        "created_at": "2026-01-08 17:15:09+00:00",
        "last_modified": "2026-01-08 17:15:11+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "multilinguality:multilingual",
          "language:en",
          "language:fr",
          "language:de",
          "language:es",
          "size_categories:n<1K",
          "format:audiofolder",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2408.06370",
          "arxiv:2506.15514",
          "arxiv:2311.13987",
          "arxiv:2306.07744",
          "region:us",
          "music",
          "lyrics",
          "evaluation",
          "benchmark",
          "transcription",
          "pnc"
        ],
        "description": "\n\t\n\t\t\n\t\tJam-ALT: A Readability-Aware Lyrics Transcription Benchmark\n\t\n\nJam-ALT is a revision of the JamendoLyrics dataset (79 songs in 4 languages), intended for use as an automatic lyrics transcription (ALT) benchmark.\nIt has been published in the ISMIR 2024 paper (full citation below): ðŸ“„ Lyrics Transcription for Humans: A Readability-Aware Benchmark ðŸ‘¥ O. CÃ­fka, H. Schreiber, L. Miner, F.-R. StÃ¶ter ðŸ¢ AudioShake\nThe lyrics have been revised according to the newly compiled annotationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cublya/jam-alt.",
        "url": "https://huggingface.co/datasets/cublya/jam-alt",
        "languages": [
          "en",
          "fr",
          "de",
          "es"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "PhillyMac/Stress_Management_Corpus",
        "author": "PhillyMac",
        "created_at": "2026-01-09 23:48:13+00:00",
        "last_modified": "2026-01-09 23:48:14+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc0-1.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "corpus",
          "leadership",
          "historical",
          "deku-corpus-builder"
        ],
        "description": "\n\t\n\t\t\n\t\tStress Management\n\t\n\nThis corpus was automatically generated by the Deku Corpus Builder for use in RAG-based AI applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record contains:\n\ntext: The content text\nsource_url: Original source URL\nsource_title: Title of the source document\nsource_domain: Domain of the source\nrelevance_score: Relevance to the subject (0-1)\nquality_score: Content quality score (0-1)\ntopics: JSON array of detected topics\ncharacter_count: Length of the text\nsubject_name:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/PhillyMac/Stress_Management_Corpus.",
        "url": "https://huggingface.co/datasets/PhillyMac/Stress_Management_Corpus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Finish-him/msc-embeddings",
        "author": "Finish-him",
        "created_at": "2026-01-10 04:29:46+00:00",
        "last_modified": "2026-01-10 05:04:36+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:pt",
          "language:en",
          "language:es",
          "language:de",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "msc-marketing",
          "portuguese",
          "embeddings",
          "rag",
          "semantic-search"
        ],
        "description": "\n\t\n\t\t\n\t\tmsc-embeddings\n\t\n\nChunks de texto otimizados para embeddings e RAG da MSC Marketing\n\n\t\n\t\t\n\t\tSobre\n\t\n\nEste dataset faz parte da infraestrutura de IA da MSC Marketing, uma empresa especializada em Marketing Digital e SEO.\n\n\t\n\t\t\n\t\tUso\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Finish-him/msc-embeddings\")\n\n\n\t\n\t\t\n\t\tEstrutura\n\t\n\nOs arquivos incluÃ­dos neste dataset sÃ£o:\n\nembeddings.jsonl\nembeddings.csv\nchunks.json\n\n\n\t\n\t\t\n\t\tLicenÃ§a\n\t\n\nMIT License - MSC Marketingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Finish-him/msc-embeddings.",
        "url": "https://huggingface.co/datasets/Finish-him/msc-embeddings",
        "languages": [
          "pt",
          "en",
          "es",
          "de"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Agda-HoTT",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:04:07+00:00",
        "last_modified": "2026-01-10 15:13:50+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "agda",
          "dependent-types"
        ],
        "description": "\n\t\n\t\t\n\t\tAgda-HoTT\n\t\n\nStructured dataset from HoTT-Agda â€” Homotopy Type Theory.\n604 declarations extracted from Agda source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/HoTT/HoTT-Agda\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstring\ndata, recordâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Agda-HoTT.",
        "url": "https://huggingface.co/datasets/phanerozoic/Agda-HoTT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Stdlib",
        "author": "phanerozoic",
        "created_at": "2026-01-10 10:55:51+00:00",
        "last_modified": "2026-01-10 10:56:32+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "standard-library"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Stdlib\n\t\n\nStructured dataset of definitions and theorems from the Coq standard library.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body (without type keyword)\n\n\ntype\nstring\nDefinition, Lemma, Theorem, Fixpoint, Inductive, Class, Instance, Ltac, Ltac2, etc.\n\n\nlibrary\nstring\nTop-level module (Corelib, Ltac2)\n\n\nimports\nlist\nRequire/Import statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifierâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Stdlib.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Stdlib",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1105",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:27:57+00:00",
        "last_modified": "2026-01-07 07:28:40+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1105\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_1\ntotal_episodes: 131\ntotal_tasks: 1\nsize: 250.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1105.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1105",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "stellaray777/1000s-websites",
        "author": "stellaray777",
        "created_at": "2026-01-04 07:34:53+00:00",
        "last_modified": "2026-01-07 12:43:56+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "web-design",
          "frontend",
          "html",
          "css",
          "javascript"
        ],
        "description": "\n\t\n\t\t\n\t\tThousands of Websites Dataset\n\t\n\nA fine-tuning dataset for training language models to generate website designs based on design specifications and requirements.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains training examples for fine-tuning code generation models (specifically DeepSeek Coder 6.7B) to create brand-specific website designs. Each example includes design specifications (industry, tone, layout, etc.) paired with corresponding HTML/CSS/JavaScript implementations.\n\n\t\n\t\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/stellaray777/1000s-websites.",
        "url": "https://huggingface.co/datasets/stellaray777/1000s-websites",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "kunarmy99/Text-ClassificationV0",
        "author": "kunarmy99",
        "created_at": "2025-12-30 09:07:44+00:00",
        "last_modified": "2025-12-30 09:08:23+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/kunarmy99/Text-ClassificationV0",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_green_pepper_on_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 02:25:59+00:00",
        "last_modified": "2026-01-06 02:26:33+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_green_pepper_on_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›˜å­ä¸Šçš„é’æ¤’\ntotal_episodes: 197\ntotal_tasks: 1\nsize: 104.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_green_pepper_on_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_green_pepper_on_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_lid",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:27:09+00:00",
        "last_modified": "2026-01-05 13:37:48+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_open_cap_lid\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€ç›–å­part_1\ntotal_episodes: 242\ntotal_tasks: 1\nsize: 391.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_lid.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_lid",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1111",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:34:07+00:00",
        "last_modified": "2026-01-06 10:34:40+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1111\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_8\ntotal_episodes: 316\ntotal_tasks: 1\nsize: 225.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1111.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1111",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:59:15+00:00",
        "last_modified": "2026-01-05 13:10:17+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_close_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­æŠ½å±‰\ntotal_episodes: 96\ntotal_tasks: 1\nsize: 434.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_close_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_remove_marker_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 11:58:35+00:00",
        "last_modified": "2026-01-05 11:59:55+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241021_remove_marker_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å–å‡ºé©¬å…‹ç¬”part_1\ntotal_episodes: 286\ntotal_tasks: 1\nsize: 453.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_remove_marker_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_remove_marker_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "beersrobert/front_room_dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:06:28+00:00",
        "last_modified": "2026-01-09 04:04:20+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "indoor-navigation household-hazards home-safety messy-environments robotics"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/front_room_dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "t2ance/selection_upper_4",
        "author": "t2ance",
        "created_at": "2026-01-04 18:15:24+00:00",
        "last_modified": "2026-01-05 05:59:24+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:code",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code-verification",
          "llm-judge",
          "best-of-n-selection",
          "process-reward-model"
        ],
        "description": "\n\t\n\t\t\n\t\tCodeRM Selection Trajectories\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains trajectories of an LLM judge selecting the best solution from k candidates.\nEach trajectory captures: problem, k candidate solutions, judge reasoning, selected index, and ground truth correctness.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nTraining Selection Verifiers: Learn to select the best solution from k candidates\nBest-of-N Selection: Train models for verifier-guided code generation\nPreference Learning: Use forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/t2ance/selection_upper_4.",
        "url": "https://huggingface.co/datasets/t2ance/selection_upper_4",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_paper_cup_dustbin_241212",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:33:37+00:00",
        "last_modified": "2026-01-05 18:36:29+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_paper_cup_dustbin_241212\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®çº¸æ¯åžƒåœ¾æ¡¶part_1\ntotal_episodes: 277\ntotal_tasks: 1\nsize: 4.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_paper_cup_dustbin_241212.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_paper_cup_dustbin_241212",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "hudaiapa88/dict",
        "author": "hudaiapa88",
        "created_at": "2026-01-05 22:47:58+00:00",
        "last_modified": "2026-01-10 12:37:26+00:00",
        "downloads": 44,
        "likes": 0,
        "tags": [
          "language:en",
          "language:de",
          "language:es",
          "language:fr",
          "language:it",
          "language:pt",
          "language:ru",
          "language:tr",
          "language:nl",
          "language:pl",
          "language:sv",
          "language:fi",
          "language:el",
          "language:no",
          "language:bg",
          "language:lt",
          "language:ja",
          "language:id",
          "license:cc-by-sa-3.0",
          "size_categories:n<1K",
          "format:text",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "dictionary",
          "translation",
          "bilingual",
          "offline",
          "sqlite"
        ],
        "description": "\n\t\n\t\t\n\t\tLingoLate Dictionaries\n\t\n\nBilingual dictionary databases for offline translation, sourced from WikDict.\n\n\t\n\t\t\n\t\tðŸ“Š Available Languages\n\t\n\n\n\t\n\t\t\n\t\tEnglish Pairs (27 pairs)\n\t\n\n\n\t\n\t\t\nPair\nSize\nPair\nSize\n\n\n\t\t\nen-de\n15.4 MB\nde-en\n18.4 MB\n\n\nen-es\n11.5 MB\nes-en\n7.4 MB\n\n\nen-fr\n18.6 MB\nfr-en\n17.2 MB\n\n\nen-it\n11.7 MB\nit-en\n6.8 MB\n\n\nen-pt\n10.1 MB\npt-en\n5.1 MB\n\n\nen-ru\n14.1 MB\nru-en\n7.2 MB\n\n\nen-tr\n5.7 MB\ntr-en\n1.8 MB\n\n\nen-nl\n9.9 MB\nnl-en\n7.7 MB\n\n\nen-pl\n9.7 MB\npl-en\n11.0 MB\n\n\nen-sv\n9.7 MB\nsv-en\n7.5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/hudaiapa88/dict.",
        "url": "https://huggingface.co/datasets/hudaiapa88/dict",
        "languages": [
          "en",
          "de",
          "es",
          "fr",
          "it",
          "pt",
          "ru",
          "tr",
          "nl",
          "pl",
          "sv",
          "fi",
          "el",
          "no",
          "bg",
          "lt",
          "ja",
          "id"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-Paperproof",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:03:50+00:00",
        "last_modified": "2026-01-10 15:13:32+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-Paperproof\n\t\n\nStructured dataset from Paperproof â€” Visual proof assistant.\n166 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/Paper-Proof/paperproof\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Paperproof.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-Paperproof",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "abanda12/rvl_cdip",
        "author": "abanda12",
        "created_at": "2026-01-07 07:39:49+00:00",
        "last_modified": "2026-01-07 07:39:50+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "task_ids:multi-class-image-classification",
          "annotations_creators:found",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:extended|iit_cdip",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "arxiv:1502.07058",
          "region:us"
        ],
        "description": "The RVL-CDIP (Ryerson Vision Lab Complex Document Information Processing) dataset consists of 400,000 grayscale images in 16 classes, with 25,000 images per class. There are 320,000 training images, 40,000 validation images, and 40,000 test images.",
        "url": "https://huggingface.co/datasets/abanda12/rvl_cdip",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "sssOrganization/hotpot_qa",
        "author": "sssOrganization",
        "created_at": "2026-01-05 02:14:48+00:00",
        "last_modified": "2026-01-05 02:14:49+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "annotations_creators:crowdsourced",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:1809.09600",
          "region:us",
          "multi-hop"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for \"hotpot_qa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nHotpotQA is a new dataset with 113k  Wikipedia-based question-answer  pairs with  four  key  features:  (1)  the  questions  require finding and reasoning over multiple supporting  documents  to  answer;  (2)  the  questions  are  diverse  and  not  constrained  to  any pre-existing  knowledge  bases  or  knowledge schemas;  (3)  we  provide  sentence-level  supporting facts required for reasoning, allowingQA systems to reasonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sssOrganization/hotpot_qa.",
        "url": "https://huggingface.co/datasets/sssOrganization/hotpot_qa",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "AleelyA3/basic-humanoid-robot-instructions",
        "author": "AleelyA3",
        "created_at": "2026-01-08 11:32:46+00:00",
        "last_modified": "2026-01-08 12:44:25+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/AleelyA3/basic-humanoid-robot-instructions",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ihsansaad24/Mental-Health_Text-Classification_Dataset",
        "author": "ihsansaad24",
        "created_at": "2026-01-06 20:29:58+00:00",
        "last_modified": "2026-01-06 20:29:58+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "modality:text",
          "modality:tabular",
          "region:us",
          "text",
          "nlp",
          "classification",
          "suicide-prevention",
          "depression",
          "anxiety",
          "tabular",
          "mental-health"
        ],
        "description": "\n\t\n\t\t\n\t\tMental Health Text Classification Dataset (4-Class)\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains short, userâ€‘generated texts labeled for 4â€‘class mental health classification: Suicidal, Depression, Anxiety, and Normal. It is a derived dataset created by combining and cleaning three public mentalâ€‘health corpora, then reâ€‘labeling them into a unified 4â€‘class scheme and exporting CSV files suitable for both classical ML and modern NLP models.\nThe repository includes:\n\nAnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ihsansaad24/Mental-Health_Text-Classification_Dataset.",
        "url": "https://huggingface.co/datasets/ihsansaad24/Mental-Health_Text-Classification_Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1025",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:14:21+00:00",
        "last_modified": "2026-01-07 07:14:39+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1025\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ±æœµæ”¾åœ¨æ¡Œå­ä¸Špart_1\ntotal_episodes: 98\ntotal_tasks: 1\nsize: 93.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1025.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1025",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_cabinet",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:47:55+00:00",
        "last_modified": "2026-01-05 17:50:32+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_slide_close_cabinet\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ»‘åŠ¨å…³é—­æ©±æŸœ\ntotal_episodes: 98\ntotal_tasks: 1\nsize: 274.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_cabinet.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_cabinet",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "EPFL-ECEO/EcoWikiRS",
        "author": "EPFL-ECEO",
        "created_at": "2026-01-05 09:11:49+00:00",
        "last_modified": "2026-01-07 16:02:59+00:00",
        "downloads": 38,
        "likes": 1,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2504.19742",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tEcoWikiRS: Learning Ecological Representations of Satellite Images from Weak Supervision with Species Observations and Wikipedia\n\t\n\nAuthorsValerie Zermatten Â· Javiera Castillo-Navarro Â· Pallavi Jain Â· Devis Tuia Â· Diego Marcos  \n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tOverview\n\t\n\nThe WikiRS dataset, composed of triplets of images, species list and Wikipedia sentences :\n\n91k high-resolution aerial images (50cm, RGB bands) from the swissIMAGE product \ncrowd-sourced species observations from 2745 differentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/EPFL-ECEO/EcoWikiRS.",
        "url": "https://huggingface.co/datasets/EPFL-ECEO/EcoWikiRS",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "dipta007/Ganit",
        "author": "dipta007",
        "created_at": "2026-01-10 20:49:13+00:00",
        "last_modified": "2026-01-10 21:48:12+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:bn",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2505.21354",
          "arxiv:2406.02301",
          "region:us",
          "math",
          "bengali",
          "reasoning",
          "curriculum-learning",
          "grpo"
        ],
        "description": "\n\t\n\t\t\n\t\tGanit: A Difficulty-Aware Bengali Mathematical Reasoning Dataset\n\t\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nGanit (à¦—à¦£à¦¿à¦¤, Bengali for \"mathematics\") is a rigorously-processed, difficulty-aware Bengali mathematical reasoning dataset designed for training and evaluating LLMs on Bengali math problems. It is the first Bengali math dataset with:\n\nDifficulty stratification based on LLM pass@k scores\nDecontamination against standard benchmarks (MGSM, MSVAMP)Verifiable numerical answers forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dipta007/Ganit.",
        "url": "https://huggingface.co/datasets/dipta007/Ganit",
        "languages": [
          "bn",
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Mizar",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:02:22+00:00",
        "last_modified": "2026-01-10 14:36:30+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:gpl-3.0",
          "license:cc-by-sa-3.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "mizar",
          "set-theory",
          "mathematics"
        ],
        "description": "\n\t\n\t\t\n\t\tMizar\n\t\n\nA structured dataset of theorems and schemes from the Mizar Mathematical Library (MML), one of the largest libraries of formalized mathematics.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/MizarSystem/MML\nWebsite: https://mizar.uwb.edu.pl\nLicense: GPL-3.0 or CC-BY-SA-3.0\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n31,246\n\n\nTheorems\n30,606\n\n\nSchemes\n640\n\n\nArticles\n1,153\n\n\nDocstring Coverage\n100%\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Mizar.",
        "url": "https://huggingface.co/datasets/phanerozoic/Mizar",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Laman882/ColorBench",
        "author": "Laman882",
        "created_at": "2026-01-07 06:48:16+00:00",
        "last_modified": "2026-01-07 06:48:17+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2504.10514",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸŽ¨ ColorBench\n\t\n\nðŸ“– Paper | ðŸ’» GitHub\nColorBench is a multimodal dataset to comprehensively assess capabilities of VLMs in color understanding, including color perception, reasoning, and robustness, introduced in \"ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness\".\nIt provides:\n\nMore than 5,800 image-text questions covering diverse application scenarios and practical challenges for VLMs evaluation.\n3â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Laman882/ColorBench.",
        "url": "https://huggingface.co/datasets/Laman882/ColorBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Thuisvester/woningwaardering",
        "author": "Thuisvester",
        "created_at": "2026-01-08 07:33:34+00:00",
        "last_modified": "2026-01-08 07:44:39+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThe Woningwaarderingsstelsel (WWS) is the Dutch points-based system used to evaluate the quality of rental homes and determine their maximum legally permitted rent. It assigns points based on factors such as property size, energy efficiency, amenities, and living environment. The total number of points directly influences the rent ceiling for regulated housing.\nThis repository provides a structured dataset designed to support:\n\nTraining and evaluating ML/AIâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Thuisvester/woningwaardering.",
        "url": "https://huggingface.co/datasets/Thuisvester/woningwaardering",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "mkurman/medical-SYNTH-reasoning-preview",
        "author": "mkurman",
        "created_at": "2026-01-09 18:43:12+00:00",
        "last_modified": "2026-01-09 23:00:14+00:00",
        "downloads": 175,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "medical",
          "reasoning",
          "synth"
        ],
        "description": "\n  Medical SYNTH Reasoning Preview\n\n  \n\n\nMedical SYNTH-like reasoning dataset based on FreedomIntelligence/medical-o1-reasoning-SFT with revised reasoning traces using SYNTHLabs and DEEP mode with GLM-4.7 as the primary author.\n\n\t\n\t\t\n\t\tDetails\n\t\n\n\n1.85k medical Q&A pairs with reasoning\nbased on FreedomIntelligence/medical-o1-reasoning-SFT\nwith revised reasoning traces \nusing SYNTHLabs and DEEP mode with GLM-4.7 as the primary author\nBuilt on top of the SYNTH dataset by PleIAsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/mkurman/medical-SYNTH-reasoning-preview.",
        "url": "https://huggingface.co/datasets/mkurman/medical-SYNTH-reasoning-preview",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "jordansegovia/pills_inside_bottles",
        "author": "jordansegovia",
        "created_at": "2026-01-09 02:06:44+00:00",
        "last_modified": "2026-01-09 02:06:45+00:00",
        "downloads": 3,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "region:us",
          "image-classification"
        ],
        "description": "This dataset contains pills images inside medication bottles from a top down view, with National Drug Code (NDC) and image id.",
        "url": "https://huggingface.co/datasets/jordansegovia/pills_inside_bottles",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_4_potatobowloven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:22:43+00:00",
        "last_modified": "2026-01-05 23:23:49+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_4_potatobowloven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: åœŸè±†ç¢—çƒ¤ç®±part_2\ntotal_episodes: 69\ntotal_tasks: 1\nsize: 1.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_4_potatobowloven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_4_potatobowloven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_close_lid",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:40:34+00:00",
        "last_modified": "2026-01-05 23:41:06+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_close_lid\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­ç›–å­\ntotal_episodes: 163\ntotal_tasks: 1\nsize: 406.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_close_lid.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_close_lid",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_plate_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:14:10+00:00",
        "last_modified": "2026-01-05 16:15:58+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_on_plate_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾åœ¨ç›˜å­ä¸Špart_2\ntotal_episodes: 286\ntotal_tasks: 1\nsize: 339.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_plate_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_plate_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Sanfora/A2Seek",
        "author": "Sanfora",
        "created_at": "2026-01-11 08:18:56+00:00",
        "last_modified": "2026-01-11 08:18:58+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "â€”â€”â€”â€”â€”â€”\nYou can preview our dataset in the â€˜Previewâ€™ folder, which contains a subset of our data with resized resolution for demonstration purposes.\nHINT: the original 4K-Resolution video can be downloaded here:  https://pan.baidu.com/s/1dilMHXuHYVE15FQmH_8hLw?pwd=seek\nâ€”â€”â€”â€”â€”â€”\n\n\t\n\t\t\n\t\n\t\n\t\tA2Seek: A Reasoning-Centric Benchmark for UAV Video Anomaly Understanding\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Overview\n\t\n\n\nThe A2Seek dataset is the first comprehensively integrated large-scale aerial-view video anomalyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Sanfora/A2Seek.",
        "url": "https://huggingface.co/datasets/Sanfora/A2Seek",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Rraik/symptom-disease-dataset",
        "author": "Rraik",
        "created_at": "2026-01-05 11:06:05+00:00",
        "last_modified": "2026-01-05 11:06:09+00:00",
        "downloads": 555,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Rraik/symptom-disease-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1114",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:34:24+00:00",
        "last_modified": "2026-01-07 07:34:49+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1114\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_7\ntotal_episodes: 103\ntotal_tasks: 1\nsize: 220.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1114.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1114",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "vincentkoc/Driving-Hazard-Prediction-and-Reasoning",
        "author": "vincentkoc",
        "created_at": "2026-01-08 06:06:41+00:00",
        "last_modified": "2026-01-08 06:12:56+00:00",
        "downloads": 12,
        "likes": 1,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:object-detection",
          "language:en",
          "license:bsd",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "agent"
        ],
        "description": "\n\n  \n    \n  \n\n  Exploring the Potential of Multi-Modal AI for Driving Hazard Prediction\n\n  \n    DHPR: Driving Hazard Prediction and Reasoning\n    Paper\n    Github\n    Forked from original dataset and updated with correct licence and\n    metadata since original dataset was unmaintained since publication.\n    Released under BSD-3 Clause Licence.\n  \n\n\n",
        "url": "https://huggingface.co/datasets/vincentkoc/Driving-Hazard-Prediction-and-Reasoning",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "object-detection"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "klimczakjakubdev/pharmaco-explainer",
        "author": "klimczakjakubdev",
        "created_at": "2025-12-21 19:26:15+00:00",
        "last_modified": "2026-01-10 19:41:42+00:00",
        "downloads": 82,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "chemistry"
        ],
        "description": "\n\t\n\t\t\n\t\tPharmaco-Explainer Datasets\n\t\n\nThis repository contains datasets used in the Pharmaco-Explainer project.\nThey are shared separately on Hugging Face and are used by the training and\nexperimentation code hosted on GitHub:\nðŸ‘‰ Training code and scripts:https://github.com/AdamSulek/pharmaco-explainer/\n\n\n\t\n\t\t\n\t\tAvailable Datasets\n\t\n\nThe following datasets are available:\n\nk3\nk4\nk5\n\nEach dataset consists of three files:\n\n<dataset>.parquet â€“ main feature data\n<dataset>_split.parquet â€“â€¦ See the full description on the dataset page: https://huggingface.co/datasets/klimczakjakubdev/pharmaco-explainer.",
        "url": "https://huggingface.co/datasets/klimczakjakubdev/pharmaco-explainer",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_cover_pot_lid",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:06:09+00:00",
        "last_modified": "2026-01-05 22:06:41+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_cover_pot_lid\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›–ä¸Šé”…ç›–\ntotal_episodes: 343\ntotal_tasks: 1\nsize: 424.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_cover_pot_lid.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_cover_pot_lid",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "priyanshuchawda/reason_via_claude",
        "author": "priyanshuchawda",
        "created_at": "2026-01-05 18:40:32+00:00",
        "last_modified": "2026-01-05 18:53:27+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "reasoning",
          "chain-of-thought",
          "llm-training",
          "gold-standard",
          "synthetic",
          "cognitive-reasoning",
          "evaluation-benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tGold Standard Reasoning Dataset via Claude\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a gold standard reasoning dataset designed for training and evaluating language models on complex reasoning tasks. Each example contains carefully crafted prompts with hidden cognitive traps, detailed reasoning traces, and evaluation rubrics.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nVersion: 1.0\nTotal Examples: 50\nFormat: JSON\nLanguage: English\nLicense: Apache 2.0\nCreated for: Tunix Hackathon - General Reasoningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/priyanshuchawda/reason_via_claude.",
        "url": "https://huggingface.co/datasets/priyanshuchawda/reason_via_claude",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_plate_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:11:04+00:00",
        "last_modified": "2026-01-05 16:14:01+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_on_plate_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾åœ¨ç›˜å­ä¸Špart_1\ntotal_episodes: 382\ntotal_tasks: 1\nsize: 586.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_plate_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_on_plate_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Olivier-52/spam_detector",
        "author": "Olivier-52",
        "created_at": "2026-01-09 11:31:24+00:00",
        "last_modified": "2026-01-09 11:39:56+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "email"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Olivier-52/spam_detector",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "mahmoudmamdouh13/en-alphabets",
        "author": "mahmoudmamdouh13",
        "created_at": "2026-01-11 12:39:44+00:00",
        "last_modified": "2026-01-11 13:07:23+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "task_categories:automatic-speech-recognition",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:audiofolder",
          "modality:audio",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "languages",
          "english"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/mahmoudmamdouh13/en-alphabets",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-classification",
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "allenai/dolma3_mix-6T-1025-7B",
        "author": "allenai",
        "created_at": "2025-10-23 22:00:10+00:00",
        "last_modified": "2026-01-12 00:10:45+00:00",
        "downloads": 272817,
        "likes": 24,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "arxiv:2512.13961",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tâš ï¸ WARNING: This dataset is intended ONLY for reproducing Olmo 3 7B âš ï¸\n\t\n\nFor all other training use cases, including training from scratch, please utilize our primary dolma 3 data mix: https://huggingface.co/datasets/allenai/dolma3_mix-6T.\nNote: Some olmOCR science PDFs in the current dataset have been redacted following the training of Olmo 3 7B. These texts are indicated with [REMOVED] in the text field. This will affect reproducibility of Olmo 3 7B. \nFor this reason, please use ourâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/dolma3_mix-6T-1025-7B.",
        "url": "https://huggingface.co/datasets/allenai/dolma3_mix-6T-1025-7B",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "GilatToker/Liberty-CV",
        "author": "GilatToker",
        "created_at": "2026-01-06 13:41:27+00:00",
        "last_modified": "2026-01-10 05:48:29+00:00",
        "downloads": 77,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:feature-extraction",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "explainability",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tLIBERTy-CV Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nLIBERTy-CV is one of the three datasets released as part of the LIBERTy (LLM-based Interventional Benchmark for Explainability with Real Targets) benchmark.\nThe goal of LIBERTy is to evaluate concept-based explanation methods in NLP under a causal and counterfactual framework.Each dataset in the benchmark is designed to expose spurious correlations between high-level concepts and model predictions, and to enable quantitative evaluation ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GilatToker/Liberty-CV.",
        "url": "https://huggingface.co/datasets/GilatToker/Liberty-CV",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "webxos/arachnid_RL",
        "author": "webxos",
        "created_at": "2026-01-08 21:16:37+00:00",
        "last_modified": "2026-01-10 03:41:23+00:00",
        "downloads": 45,
        "likes": 1,
        "tags": [
          "task_categories:reinforcement-learning",
          "task_categories:tabular-classification",
          "task_categories:tabular-to-text",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "human-demonstrations",
          "atari-like",
          "browser-game",
          "rl-dataset",
          "games",
          "gym",
          "reinforcement-learning",
          "robotics",
          "atari",
          "2d",
          "RLHF",
          "RL",
          "video-game"
        ],
        "description": "\n\n\n\n      ___           ___           ___           ___           ___           ___                               \n     /\\  \\         /\\  \\         /\\  \\         /\\__\\         /\\  \\         /\\  \\                     _____    \n    /::\\  \\       /::\\  \\       /::\\  \\       /:/  /         \\:\\  \\        \\:\\  \\       ___         /::\\  \\   \n   /:/\\:\\  \\     /:/\\:\\__\\     /:/\\:\\  \\     /:/  /           \\:\\  \\        \\:\\  \\     /\\__\\       /:/\\:\\  \\  \n  /:/ /::\\  \\   /:/ /:/  /    /:/ /::\\  \\   /:/  /â€¦ See the full description on the dataset page: https://huggingface.co/datasets/webxos/arachnid_RL.",
        "url": "https://huggingface.co/datasets/webxos/arachnid_RL",
        "languages": [
          "en"
        ],
        "tasks": [
          "reinforcement-learning",
          "tabular-classification",
          "tabular-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1120",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:58:26+00:00",
        "last_modified": "2026-01-07 06:58:45+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1120\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·èŠ’æžœpart_2\ntotal_episodes: 235\ntotal_tasks: 1\nsize: 243.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1120.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1120",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "krisbailey/RedPajama-1B-Weighted",
        "author": "krisbailey",
        "created_at": "2026-01-09 14:55:40+00:00",
        "last_modified": "2026-01-09 16:16:09+00:00",
        "downloads": 33,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "redpajama",
          "llm",
          "dataset-reproduction",
          "redpajama-1b",
          "redpajama-subset",
          "redpajama-weighted",
          "redpajama-sample",
          "natural-language-processing"
        ],
        "description": "\n\t\n\t\t\n\t\tRedPajama-1B-Weighted\n\t\n\nA canonical 1 Billion token weighted subset of the RedPajama-Data-1T dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis is a strict, downsampled version of the RedPajama-10B-Weighted dataset. It maintains the exact domain distributions of the full 1T dataset, resized to a lightweight 1 Billion token footprint.\nThis dataset is ideal for:\n\nRapid Prototyping: Train small models or debug pipelines in minutes rather than days.\nReference Baselines: Use a standardâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/krisbailey/RedPajama-1B-Weighted.",
        "url": "https://huggingface.co/datasets/krisbailey/RedPajama-1B-Weighted",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "sagecontinuum/FireBench",
        "author": "sagecontinuum",
        "created_at": "2026-01-04 02:09:00+00:00",
        "last_modified": "2026-01-05 16:52:11+00:00",
        "downloads": 60,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "modality:geospatial",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "doi:10.57967/hf/7454",
          "region:us",
          "wildfire",
          "fire-science",
          "image-retrieval",
          "benchmark",
          "computer-vision",
          "remote-sensing",
          "environmental-science"
        ],
        "description": "\n\t\n\t\t\n\t\tFireBench: A Benchmark Dataset for Fire Science Image Retrieval\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nFireBench is a benchmark dataset for evaluating image retrieval systems in the domain of wildfire and fire science. The dataset consists of natural language queries paired with images, along with binary relevance labels indicating whether each image is relevant to the query. The dataset is designed to test retrieval systems' ability to find relevant wildfire-related images based on aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/sagecontinuum/FireBench.",
        "url": "https://huggingface.co/datasets/sagecontinuum/FireBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "CarolynJiang/RFC-Bench-Dataset",
        "author": "CarolynJiang",
        "created_at": "2026-01-09 03:36:54+00:00",
        "last_modified": "2026-01-09 05:59:46+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "arxiv:2601.04160",
          "region:us",
          "Finance",
          "Misinformation"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Description\n\t\n\nRFC-Bench is a research benchmark for evaluating large language models on reference-free counterfactual financial misinformation detection at the paragraph level. The dataset contains only synthetic, human-reviewed counterfactual rewrites and metadata (ticker, date, and public URL) derived from publicly accessible Yahoo Finance articles; it does not redistribute any original news content.\nAll data concern corporate-level financial narratives and contain noâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CarolynJiang/RFC-Bench-Dataset.",
        "url": "https://huggingface.co/datasets/CarolynJiang/RFC-Bench-Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Qingyun/remote-sensing-sft-data",
        "author": "Qingyun",
        "created_at": "2025-04-11 12:59:32+00:00",
        "last_modified": "2026-01-09 19:38:22+00:00",
        "downloads": 2128,
        "likes": 2,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "modality:image",
          "arxiv:2511.21272",
          "region:us",
          "aerial",
          "geoscience",
          "remote sensing"
        ],
        "description": "\n  RSCoVLM: Co-Training Vision Language Models for Remote Sensing Multi-task Learning\n  \n      Qingyun Li*â€ƒ\n      Shuran Ma*â€ƒ\n      Junwei Luo*â€ƒ\n      Yi Yu*â€ƒ\n      Yue Zhouâ€ƒ\n      Fengxiang Wangâ€ƒ\n      Xudong Luâ€ƒ\n      Xiaoxing Wangâ€ƒ\n      Xin Heâ€ƒ\n      Yushi Chenâ€ƒ\n      Xue Yangâ€ƒ\n      \n      \n      \n      \n    \n        If you find our work helpful, please consider giving us a â­!\n    \n\n\n\nArXiv Paper: https://arxiv.org/abs/2511.21272\nPublished Paper: https://www.mdpi.com/2072-4292/18/2/222â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Qingyun/remote-sensing-sft-data.",
        "url": "https://huggingface.co/datasets/Qingyun/remote-sensing-sft-data",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "HiThink-Research/BizFinBench.v2",
        "author": "HiThink-Research",
        "created_at": "2026-01-08 11:32:56+00:00",
        "last_modified": "2026-01-08 13:59:06+00:00",
        "downloads": 37,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:zh",
          "language:en",
          "license:apache-2.0",
          "region:us"
        ],
        "description": "\n  BizFinBench.v2: A Unified Dual-Mode Bilingual Benchmark for Expert-Level Financial Capability Alignment\n    \n    \n      Xin Guo1,2,* ,\n                \n      Rongjunchen Zhang1,*,â™ , Guilong Lu1, Xuntao Guo1, Jia Shuai1, Zhi Yang2, Liwen Zhang2,â™ \n    \n    \n    \n        \n            1HiThink Research, 2Shanghai University of Finance and Economics\n        \n        \n        \n            *Co-first authors, â™ Corresponding author, zhangrongjunchen@myhexin.com,zhang.liwen@shufe.edu.cnâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HiThink-Research/BizFinBench.v2.",
        "url": "https://huggingface.co/datasets/HiThink-Research/BizFinBench.v2",
        "languages": [
          "zh",
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "AIM-Intelligence/COMPASS-Policy-aware-SFT-Dataset",
        "author": "AIM-Intelligence",
        "created_at": "2025-12-30 04:53:41+00:00",
        "last_modified": "2026-01-06 03:17:35+00:00",
        "downloads": 17,
        "likes": 2,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:other",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.01836",
          "region:us",
          "alignment",
          "policy-compliance",
          "policy-alignment",
          "safety",
          "sft",
          "instruction-following"
        ],
        "description": "\n\t\n\t\t\n\t\tCOMPASS LODO Policy-Aware SFT (7 Domains)\n\t\n\nThis dataset contains 4,121 queryâ€“response pairs used for the Leave-One-Domain-Out (LODO) policy-aware supervised fine-tuning (SFT) experiment in the COMPASS paper:\n\nCOMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs  \n\nIn the LODO setup, TelePath (Telecom) is held out for evaluation, and the SFT data is compiled from the remaining 7 domains.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\n\nPurpose: Policy-aware SFT forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/AIM-Intelligence/COMPASS-Policy-aware-SFT-Dataset.",
        "url": "https://huggingface.co/datasets/AIM-Intelligence/COMPASS-Policy-aware-SFT-Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "mshojaei77/konkur1404",
        "author": "mshojaei77",
        "created_at": "2026-01-07 15:59:07+00:00",
        "last_modified": "2026-01-07 20:18:44+00:00",
        "downloads": 92,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:multiple-choice",
          "language:fa",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "konkur",
          "entrance-exam",
          "education"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Konkur1404\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains questions from the Konkur (Iranian University Entrance Exam) for the year 1404. It is designed for evaluating models on Persian multiple-choice questions across various subjects.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Examples: 2137\nSplits: train\nLanguages: Persian (fa)\n\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example from the dataset looks like this:\n{\n  \"id\": \"ensani_nobat1_1\"â€¦ See the full description on the dataset page: https://huggingface.co/datasets/mshojaei77/konkur1404.",
        "url": "https://huggingface.co/datasets/mshojaei77/konkur1404",
        "languages": [
          "fa",
          "en"
        ],
        "tasks": [
          "question-answering",
          "multiple-choice"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_fr_fr3_dual_left_place_gray_plate_from_low_rack_on_left_of_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 04:54:19+00:00",
        "last_modified": "2026-01-08 04:55:13+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_fr3_dual_left_place_gray_plate_from_low_rack_on_left_of_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_fr3\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†ç°è‰²ç›˜å­ä»ŽçŸ®æž¶ä¸Šæ”¾åœ¨æ¡Œå­å·¦ä¾§\ntotal_episodes: 289\ntotal_tasks: 1\nsize: 3.9G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_fr_fr3_dual_left_place_gray_plate_from_low_rack_on_left_of_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_fr_fr3_dual_left_place_gray_plate_from_low_rack_on_left_of_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-autonomous-decision-flows",
        "author": "ariefansclub",
        "created_at": "2026-01-10 05:05:23+00:00",
        "last_modified": "2026-01-10 05:06:07+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "autonomous",
          "decision-making",
          "futuristic",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Autonomous Decision Flows\n\t\n\nDecision-making reference dataset for autonomous humanoid robots.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-autonomous-decision-flows",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_pot_lid",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:09:13+00:00",
        "last_modified": "2026-01-05 22:09:35+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_open_pot_lid\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€é”…ç›–\ntotal_episodes: 326\ntotal_tasks: 1\nsize: 413.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_pot_lid.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_open_pot_lid",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "dipta007/ActivityNet-FG-It",
        "author": "dipta007",
        "created_at": "2026-01-02 01:58:40+00:00",
        "last_modified": "2026-01-11 05:40:39+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:video-text-to-text",
          "task_categories:image-text-to-text",
          "task_categories:text-generation",
          "source_datasets:ActivityNet Captions",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2509.16538",
          "region:us",
          "video-captioning",
          "caption-evaluation",
          "factual-grounding",
          "synthetic-data",
          "instruction-tuning",
          "multimodal"
        ],
        "description": "\n\t\n\t\t\n\t\tActivityNet-FG-It\n\t\n\n\n    \n\n\n    \n\n\n    \n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\nActivityNet-FG-It (ActivityNet Factual Grounding for Instruction Tuning) is a synthetic dataset designed for training video caption evaluation models. It contains 44K video-caption pairs with systematically controlled factual errors, graded quality scores (1-5), and natural language explanations identifying the errors.\nThis dataset was created to address the lack of captions with varying degrees of factualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dipta007/ActivityNet-FG-It.",
        "url": "https://huggingface.co/datasets/dipta007/ActivityNet-FG-It",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-text-to-text",
          "image-text-to-text",
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_51_breadoven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:05:32+00:00",
        "last_modified": "2026-01-05 10:06:46+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_51_breadoven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¢åŒ…çƒ¤ç®±\ntotal_episodes: 200\ntotal_tasks: 1\nsize: 3.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_51_breadoven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_51_breadoven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ajay-anil-kumar/LoCoSQL",
        "author": "ajay-anil-kumar",
        "created_at": "2026-01-09 06:46:02+00:00",
        "last_modified": "2026-01-10 17:07:31+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "sql",
          "text2sql",
          "conversation",
          "data",
          "analytics",
          "memory",
          "multi-turn",
          "context-management"
        ],
        "description": "\n\t\n\t\t\n\t\tLoCoSQL: Long-context Conversational Text-to-SQL Dataset\n\t\n\nLoCoSQL is a specialized benchmark dataset designed to evaluate the long-range context management and state-tracking capabilities of Conversational Text-to-SQL models. \nWhile existing datasets focus on short, 3-5 turn interactions, LoCoSQL simulates \"Real-World Data Exploration\" with extended dialogues ranging from 20 to 50 turns per conversation. It is specifically designed to test conversational memory frameworks for contextâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ajay-anil-kumar/LoCoSQL.",
        "url": "https://huggingface.co/datasets/ajay-anil-kumar/LoCoSQL",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "AroticMerch/han-environment-perception-v1",
        "author": "AroticMerch",
        "created_at": "2026-01-10 12:15:09+00:00",
        "last_modified": "2026-01-10 12:15:44+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "robotics",
          "perception",
          "environment",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Environment Perception Dataset\n\t\n\nThis dataset represents how humanoid robots perceive\nhuman-centered environments before making decisions.\nThe data focuses on abstract perception rather than\nraw sensor values, making it hardware-independent.\n\n\t\n\t\t\n\t\tContains\n\t\n\n\nEnvironment description\nVisual observations\nAudio cues\nContextual role\n\n\n\t\n\t\t\n\t\tPart of\n\t\n\nHumanoid Network (HAN)\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT\n",
        "url": "https://huggingface.co/datasets/AroticMerch/han-environment-perception-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-Quote4",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:03:48+00:00",
        "last_modified": "2026-01-10 15:13:31+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-Quote4\n\t\n\nStructured dataset from quote4 â€” Term quotation.\n104 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/leanprover-community/quote4\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Quote4.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-Quote4",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "GXMZU/llm-rag-agent-blogs",
        "author": "GXMZU",
        "created_at": "2026-01-05 08:16:21+00:00",
        "last_modified": "2026-01-05 08:21:00+00:00",
        "downloads": 17,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "language:zh",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "llm",
          "rag",
          "agent",
          "knowledge-base",
          "research"
        ],
        "description": "\n\t\n\t\t\n\t\tllm-rag-agent-blogs\n\t\n\nTechnical blogs on LLM, RAG, and AI Agents - Knowledge base for RAG pipeline\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThis dataset contains three subsets:\n\nllm: Large Language Model related content\nrag: Retrieval-Augmented Generation related content\nagent: AI Agent related content\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load all subsets\ndataset = load_dataset(\"GXMZU/llm-rag-agent-blogs\")\n\n# Load specific subset\nllm_data =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/GXMZU/llm-rag-agent-blogs.",
        "url": "https://huggingface.co/datasets/GXMZU/llm-rag-agent-blogs",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_tool_liftn_box_place",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:56:01+00:00",
        "last_modified": "2026-01-05 21:57:26+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_tool_liftn_box_place\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·å·¥å…·æ”¾ç½®ç›’å­\ntotal_episodes: 196\ntotal_tasks: 1\nsize: 2.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_tool_liftn_box_place.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_tool_liftn_box_place",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_781_Passing_water",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:33:31+00:00",
        "last_modified": "2026-01-05 21:09:41+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_781\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: ä¼ é€’æ°´\ntotal_episodes: 762\ntotal_tasks: 1\nsize: 25G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_781_Passing_water.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_781_Passing_water",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "LEE-WHITE/toeic-vocab-tw",
        "author": "LEE-WHITE",
        "created_at": "2026-01-10 00:28:55+00:00",
        "last_modified": "2026-01-10 00:28:57+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:other",
          "language:en",
          "language:zh",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "toeic",
          "vocabulary",
          "bilingual",
          "english-chinese",
          "traditional-chinese",
          "business",
          "education"
        ],
        "description": "\n\t\n\t\t\n\t\tå®Œæ•´ TOEIC å–®å­—åº«ï¼ˆEnglishâ€“Traditional Chineseï¼‰\n\t\n\nä¸€ä»½é¢å‘ TOEIC æƒ…å¢ƒçš„é›™èªžå–®å­—åº«ï¼Œæ¶µè“‹å•†å‹™ã€è¾¦å…¬ã€æœƒè­°ã€å®¢æˆ¶æœå‹™ã€è²¡å‹™æœƒè¨ˆã€è¡ŒéŠ·éŠ·å”®ã€æŽ¡è³¼ç‰©æµã€æ³•å¾‹åˆè¦ã€è³‡è¨ŠæŠ€è¡“ç­‰å¤šå€‹å¸¸è¦‹é ˜åŸŸã€‚è³‡æ–™ä»¥ JSON æä¾›ï¼Œä¸¦ä¾é‡è¦åº¦åŠƒåˆ† 5â˜…â€“1â˜… ç­‰ç´šï¼Œé™„è©žæ€§ã€è©žå½¢è®ŠåŒ–èˆ‡ä¸­è‹±é›™èªžä¾‹å¥ï¼Œä¾¿æ–¼æ•™å­¸ã€å‚™è€ƒã€æ‡‰ç”¨é–‹ç™¼èˆ‡èªžè¨€å­¸ç¿’ç ”ç©¶ã€‚\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTitle: å®Œæ•´ TOEIC å–®å­—åº«\nVersion: 110.5\nTotal Words: 9,537\nLanguage Pair: English â†” Traditional Chinese (ç¹é«”ä¸­æ–‡)\nStructure: å–®ä¸€ JSON é™£åˆ—ï¼ˆæ¯åˆ—ä¸€å€‹è©žæ¢ï¼‰+ data/metadata.json\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ndata/toeic_vocabulary.jsonï¼šä¸»è³‡æ–™æª”ï¼ˆé ‚å±¤ç‚ºé™£åˆ—ï¼Œæ¯åˆ—ä¸€å€‹è©žæ¢ï¼‰â€¦ See the full description on the dataset page: https://huggingface.co/datasets/LEE-WHITE/toeic-vocab-tw.",
        "url": "https://huggingface.co/datasets/LEE-WHITE/toeic-vocab-tw",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "other"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_table_1119",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:01:42+00:00",
        "last_modified": "2026-01-07 07:02:13+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_table_1119\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·æ©™å­part_1\ntotal_episodes: 145\ntotal_tasks: 1\nsize: 133.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_table_1119.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_oranges_from_the_table_1119",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ASU-GSL/AHA",
        "author": "ASU-GSL",
        "created_at": "2026-01-03 06:27:31+00:00",
        "last_modified": "2026-01-07 00:30:51+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "task_categories:audio-text-to-text",
          "language:en",
          "license:apache-2.0",
          "modality:audio",
          "arxiv:2512.24052",
          "region:us",
          "audio",
          "hallucination-alignment",
          "preference-alignment"
        ],
        "description": "\n\t\n\t\t\n\t\tAHA: Aligning Large Audio-Language Models for Reasoning Hallucinations via Counterfactual Hard Negatives\n\t\n\nPaper | GitHub\nAHA (Audio Hallucination Alignment) is a framework and dataset designed to mitigate hallucinations in Large Audio-Language Models (LALMs). By focusing on fine-grained temporal reasoning and counterfactual alignment, the AHA dataset helps models distinguish between what sounds plausible and what is actually present in an audio stream.\nThe dataset addresses four keyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ASU-GSL/AHA.",
        "url": "https://huggingface.co/datasets/ASU-GSL/AHA",
        "languages": [
          "en"
        ],
        "tasks": [
          "audio-text-to-text"
        ],
        "size_categories": []
      },
      {
        "id": "Ker102/n8n-mega-workflows",
        "author": "Ker102",
        "created_at": "2026-01-10 00:00:09+00:00",
        "last_modified": "2026-01-10 00:01:23+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "n8n",
          "workflow",
          "automation",
          "no-code",
          "low-code",
          "code-generation",
          "instruction-tuning"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸš€ n8n Mega Workflows - The Largest n8n Workflow Dataset\n\t\n\n\n\n\n\n\n\nThe world's largest open-source n8n workflow dataset for training AI workflow generators\n\n\t\n\t\t\n\t\tðŸŒŸ Highlights\n\t\n\n\n131,648 high-quality n8n workflows with valid connection skeletons\n26 semantic categories for balanced coverage\nInstruction-tuning format ready for fine-tuning LLMs\n15+ million lines of workflow JSON\nPerfect for: RAG pipelines, fine-tuning, workflow generation models\n\n\n\n\t\n\t\t\n\t\tðŸ“Š Dataset Statisticsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ker102/n8n-mega-workflows.",
        "url": "https://huggingface.co/datasets/Ker102/n8n-mega-workflows",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Metamath",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:54:16+00:00",
        "last_modified": "2026-01-10 13:54:20+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc0-1.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "metamath",
          "logic",
          "set-theory",
          "mathematics"
        ],
        "description": "\n\t\n\t\t\n\t\tMetamath\n\t\n\nA structured dataset of formally verified theorems and axioms from Metamath, one of the largest collections of rigorously verified mathematics in the world.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/metamath/set.mm\nWebsite: https://us.metamath.org\nLicense: CC0 1.0 (Public Domain)\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n72,962\n\n\nTheorems\n69,394\n\n\nAxioms\n3,568\n\n\nDocstring Coverage\n95.6%\n\n\n\t\n\n\n\t\n\t\t\n\t\tDatabase Distribution\n\t\n\n\n\t\n\t\t\nDatabaseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Metamath.",
        "url": "https://huggingface.co/datasets/phanerozoic/Metamath",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "JiaHuang01/ytbv_davis_432_240_test_Eval",
        "author": "JiaHuang01",
        "created_at": "2025-12-28 12:57:56+00:00",
        "last_modified": "2025-12-28 14:36:30+00:00",
        "downloads": 1835,
        "likes": 0,
        "tags": [
          "task_categories:video-to-video",
          "task_categories:image-segmentation",
          "language:en",
          "license:mit",
          "region:us",
          "video-inpainting",
          "video-segmentation",
          "davis",
          "youtube-vos"
        ],
        "description": "\n\t\n\t\t\n\t\tytbv_davis_432_240\n\t\n\n...\nThis dataset repository contains pre-processed DAVIS and YouTube-VOS subsets in a unified folder layout, with frames resized to 432Ã—240 and accompanying train/test splits and masks.\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\ndatasets/\nâ”œâ”€â”€ davis/\nâ”‚   â”œâ”€â”€ JPEGImages_432_240/\nâ”‚   â”œâ”€â”€ test.json\nâ”‚   â”œâ”€â”€ test_masks/\nâ”‚   â””â”€â”€ train.json\nâ”œâ”€â”€ youtube-vos/\nâ”‚   â”œâ”€â”€ JPEGImages_432_240/\nâ”‚   â”œâ”€â”€ test.json\nâ”‚   â”œâ”€â”€ test_masks/\nâ”‚   â””â”€â”€ train.json\nâ””â”€â”€ _hf_work/\n\n## Contents\n\n###â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JiaHuang01/ytbv_davis_432_240_test_Eval.",
        "url": "https://huggingface.co/datasets/JiaHuang01/ytbv_davis_432_240_test_Eval",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-to-video",
          "image-segmentation"
        ],
        "size_categories": []
      },
      {
        "id": "Ariasyah/cic-ids-2017",
        "author": "Ariasyah",
        "created_at": "2026-01-06 02:55:56+00:00",
        "last_modified": "2026-01-06 02:55:57+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:tabular-classification",
          "language:en",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "cybersecurity",
          "network",
          "pcap",
          "flow"
        ],
        "description": "\n\t\n\t\t\n\t\tCIC-IDS-2017 Dataset\n\t\n\nThis repository contains the CIC-IDS-2017 dataset with the original PCAPs and the CSVs converted to Parquet format for easier use.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tConfigurations\n\t\n\n\nmachine_learning: Contains the flow-based features used for ML training (Converted from MachineLearningCVE CSVs).\ntraffic_labels: Contains the labelled flows (Converted from TrafficLabelling CSVs). Timestamps have been normalized to UTC.\n\n\n\t\n\t\t\n\t\tRaw Data\n\t\n\nThe pcap/ folderâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ariasyah/cic-ids-2017.",
        "url": "https://huggingface.co/datasets/Ariasyah/cic-ids-2017",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-classification"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "ubowang/visual_cot_sample_200",
        "author": "ubowang",
        "created_at": "2026-01-10 04:31:33+00:00",
        "last_modified": "2026-01-10 04:47:23+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:image-text-to-text",
          "task_categories:visual-question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2403.16999",
          "region:us",
          "visual-cot",
          "chain-of-thought",
          "multimodal"
        ],
        "description": "\n\t\n\t\t\n\t\tVisual CoT Sample Dataset\n\t\n\nThis is a sampled subset from the Visual-CoT dataset.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains a random sample of data points from the original Visual CoT dataset, \nwhich focuses on Chain-of-Thought reasoning for multi-modal language models.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nsample_200.json: Annotation file containing sampled data\nsample_200_images/: Directory containing corresponding images\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\n# Load theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ubowang/visual_cot_sample_200.",
        "url": "https://huggingface.co/datasets/ubowang/visual_cot_sample_200",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-text-to-text",
          "visual-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_the_lemon_in_the_right_hand_is_placed_in_the_trash_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 05:37:20+00:00",
        "last_modified": "2026-01-08 05:37:50+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_the_lemon_in_the_right_hand_is_placed_in_the_trash_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å³æ‰‹ä¸­çš„æŸ æª¬è¢«æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 134\ntotal_tasks: 1\nsize: 1.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_the_lemon_in_the_right_hand_is_placed_in_the_trash_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_the_lemon_in_the_right_hand_is_placed_in_the_trash_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-context-aware-commands",
        "author": "ariefansclub",
        "created_at": "2026-01-09 03:28:52+00:00",
        "last_modified": "2026-01-09 03:31:31+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "robotics",
          "ai",
          "commands",
          "web3"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Context-Aware Commands\n\t\n\nThis dataset contains structured, context-aware natural language commands for humanoid robot AI training.\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe dataset is designed to help humanoid robots understand intent, context, and action categories from human instructions.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nNLP command understanding\nHumanoid robot control\nAI agent instruction following\nRobotics simulation environments\n\n\n\t\n\t\t\n\t\tFormat\n\t\n\nCSV with fields:\n\ntext: natural language commandâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ariefansclub/humanoid-context-aware-commands.",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-context-aware-commands",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "anris05/IAM-line",
        "author": "anris05",
        "created_at": "2026-01-09 16:09:47+00:00",
        "last_modified": "2026-01-09 16:09:49+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "atr",
          "htr",
          "ocr",
          "modern",
          "handwritten"
        ],
        "description": "\n\t\n\t\t\n\t\tIAM - line level\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe IAM Handwriting Database contains forms of handwritten English text which can be used to train and test handwritten text recognizers and to perform writer identification and verification experiments.\nNote that all images are resized to a fixed height of 128 pixels.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nAll the documents in the dataset are written in English.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\n{\n  'image':â€¦ See the full description on the dataset page: https://huggingface.co/datasets/anris05/IAM-line.",
        "url": "https://huggingface.co/datasets/anris05/IAM-line",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "pet123/tweet_eval",
        "author": "pet123",
        "created_at": "2026-01-11 03:30:48+00:00",
        "last_modified": "2026-01-11 03:30:48+00:00",
        "downloads": 3,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_ids:intent-classification",
          "task_ids:multi-class-classification",
          "task_ids:sentiment-classification",
          "annotations_creators:found",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:extended|other-tweet-datasets",
          "language:en",
          "license:unknown",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2010.12421",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for tweet_eval\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nTweetEval consists of seven heterogenous tasks in Twitter, all framed as multi-class tweet classification. The tasks include - irony, hate, offensive, stance, emoji, emotion, and sentiment. All tasks have been unified into the same benchmark, with each dataset presented in the same format and with fixed training, validation and test splits.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\n\ntext_classification: The dataset can beâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pet123/tweet_eval.",
        "url": "https://huggingface.co/datasets/pet123/tweet_eval",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "phanerozoic/Lean4-Stdlib",
        "author": "phanerozoic",
        "created_at": "2026-01-10 10:55:56+00:00",
        "last_modified": "2026-01-10 10:56:32+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4",
          "standard-library"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-Stdlib\n\t\n\nStructured dataset of definitions and theorems from the Lean 4 standard library (Init + Std).\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body (without type keyword)\n\n\ntype\nstring\ntheorem, def, class, structure, instance, inductive, abbrev, axiom, opaque\n\n\nlibrary\nstring\nInit.* or Std.* module\n\n\nimports\nlist\nImport statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\ndocstring\nstring\nDocumentationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Stdlib.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-Stdlib",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_piled_on_stack_blue_block_on_pink_block",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:29:29+00:00",
        "last_modified": "2026-01-05 14:53:55+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_piled_on_stack_blue_block_on_pink_block\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç²‰è‰²ç§¯æœ¨ä¸Šå †æ”¾è“è‰²ç§¯æœ¨\ntotal_episodes: 243\ntotal_tasks: 1\nsize: 267.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_piled_on_stack_blue_block_on_pink_block.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_piled_on_stack_blue_block_on_pink_block",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_pot_lid",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:21:41+00:00",
        "last_modified": "2026-01-05 22:22:12+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_pot_lid\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é”…ç›–\ntotal_episodes: 343\ntotal_tasks: 1\nsize: 405.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_pot_lid.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_pot_lid",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "hercysn/RadDiff-paper-cache",
        "author": "hercysn",
        "created_at": "2026-01-05 05:34:59+00:00",
        "last_modified": "2026-01-05 06:03:23+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:image-text-to-text",
          "task_categories:text-generation",
          "task_categories:image-feature-extraction",
          "source_datasets:mimic-cxr",
          "language:en",
          "license:cc-by-nc-4.0",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tRadDiff Paper Reproduction Cache\n\t\n\nThis repository hosts the cached LLM and VLM outputs used to reproduce the exact experimental results reported in the RadDiff paper.\nThe goal of this dataset is deterministic, API-free reproduction of the paperâ€™s reported numbers.\n\n\n\t\n\t\t\n\t\tâš ï¸ Important Notes\n\t\n\n\nNo medical images or raw patient data are included.\nThis dataset contains derived artifacts (LLM outputs) originating from the MIMIC-CXR dataset.\nUsers must have independent, authorizedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hercysn/RadDiff-paper-cache.",
        "url": "https://huggingface.co/datasets/hercysn/RadDiff-paper-cache",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-text-to-text",
          "text-generation",
          "image-feature-extraction"
        ],
        "size_categories": []
      },
      {
        "id": "fermsi/berkeley-na-brewing-corpus",
        "author": "fermsi",
        "created_at": "2026-01-09 19:55:36+00:00",
        "last_modified": "2026-01-09 19:57:42+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "brewing",
          "non-alcoholic-beer",
          "berkeley-yeast",
          "nanochat"
        ],
        "description": "\n\t\n\t\t\n\t\tBerkeley NA Brewing Corpus\n\t\n\nA text corpus about non-alcoholic beer brewing, created for training with Karpathy's nanochat.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains technical information about brewing non-alcoholic beer using Berkeley Yeast's maltose-negative yeast strains. The content covers:\n\nFood safety best practices for NA beer production\nRecipe development and mash procedures\nYeast selection and fermentation techniques\nPasteurization and packaging guidelines\nHopâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fermsi/berkeley-na-brewing-corpus.",
        "url": "https://huggingface.co/datasets/fermsi/berkeley-na-brewing-corpus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_left_place_gray_plate_on_lower_rack",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:07:06+00:00",
        "last_modified": "2026-01-06 00:08:48+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_fr3_dual_left_place_gray_plate_on_lower_rack\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_fr3\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†ç°è‰²ç›˜å­æ”¾åœ¨çŸ®æž¶ä¸Š\ntotal_episodes: 282\ntotal_tasks: 1\nsize: 4.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_left_place_gray_plate_on_lower_rack.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_left_place_gray_plate_on_lower_rack",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "HanxuHU/general-reasoner-verifier",
        "author": "HanxuHU",
        "created_at": "2026-01-10 14:44:40+00:00",
        "last_modified": "2026-01-10 14:44:53+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "region:us",
          "verifier"
        ],
        "description": "This is the verifier we used in General Reasoner.\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\n# Replace with your model path\nmodel_path = \"TIGER-Lab/general-verifier\"\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16).cuda()\n\n# Example inputs\nquestion = \"Factor the following quadratic: $3 x^3+\\frac{69 x^2}{2}-36 x-810$\"\nground_truthâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/HanxuHU/general-reasoner-verifier.",
        "url": "https://huggingface.co/datasets/HanxuHU/general-reasoner-verifier",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "InfoBayAI/Non-STEM_TextBook_English",
        "author": "InfoBayAI",
        "created_at": "2026-01-09 13:35:48+00:00",
        "last_modified": "2026-01-09 13:38:42+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Non-STEM",
          "TextBook",
          "English",
          "Dataset"
        ],
        "description": "The full corpus is curated across multiple STEM/Non-STEM disciplines and structured for use in LLM training, evaluation, and instruction tuning (SFT/RLHF). This sample represents the structure and quality of the larger dataset.\n  Dataset composition (full corpus):\n-Text corpus: 1.6B+ words of curated STEM and Non-STEM educational content across 22000+ texbooks in 7 languages(English, Hindi, Arabic, Bahasa, Tamil, Telegu, Kannada)\n-Questionâ€“Answer pairs: 6.5M+ high-quality Q&A pairs of STEM andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/InfoBayAI/Non-STEM_TextBook_English.",
        "url": "https://huggingface.co/datasets/InfoBayAI/Non-STEM_TextBook_English",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_side_pull_open_drawer_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:16:00+00:00",
        "last_modified": "2026-01-05 12:20:53+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241022_side_pull_open_drawer_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä¾§æ‹‰æ‰“å¼€æŠ½å±‰part_1\ntotal_episodes: 254\ntotal_tasks: 1\nsize: 483.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_side_pull_open_drawer_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_side_pull_open_drawer_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:52:16+00:00",
        "last_modified": "2026-01-05 17:53:07+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_slide_close_drawer_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ»‘åŠ¨å…³é—­æŠ½å±‰part_2\ntotal_episodes: 169\ntotal_tasks: 1\nsize: 438.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_close_drawer_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_close_trash_bin_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 11:41:30+00:00",
        "last_modified": "2026-01-05 11:48:27+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241021_close_trash_bin_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­åžƒåœ¾æ¡¶part_1\ntotal_episodes: 289\ntotal_tasks: 1\nsize: 381.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_close_trash_bin_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241021_close_trash_bin_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "seooyxx/canvas",
        "author": "seooyxx",
        "created_at": "2026-01-10 06:25:42+00:00",
        "last_modified": "2026-01-10 08:53:18+00:00",
        "downloads": 1303,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "modality:image",
          "arxiv:2511.20737",
          "region:us",
          "art",
          "design",
          "agent",
          "tool"
        ],
        "description": "\n\t\n\t\t\n\t\tCANVAS\n\t\n\nThis repository contains the dataset accompanying the paper CANVAS: A Benchmark for Vision-Language Models on Tool-Based UI Design (AAAI 2026).\nCANVAS designed to evaluate a VLM's capability to generate a UI design with tool invocations in two tasks: ADesign Replication and BDesign Modification.\n\nA. Design Replication. Single Tasks involving restoring (implementing) a given UI image as is.\nB. Design Modification. Multiple Tasks involving modifying or transforming existingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/seooyxx/canvas.",
        "url": "https://huggingface.co/datasets/seooyxx/canvas",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "piyushsinghpasi/audiocaps-multilingual",
        "author": "piyushsinghpasi",
        "created_at": "2026-01-09 20:58:40+00:00",
        "last_modified": "2026-01-10 18:25:24+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:audio-text-to-text",
          "language:en",
          "language:bn",
          "language:gu",
          "language:hi",
          "language:kn",
          "language:ml",
          "language:mr",
          "language:ne",
          "language:pa",
          "language:ta",
          "language:te",
          "language:ur",
          "language:ar",
          "language:zh",
          "language:cs",
          "language:nl",
          "language:fr",
          "language:de",
          "language:el",
          "language:he",
          "language:id",
          "language:it",
          "language:ja",
          "language:ko",
          "language:fa",
          "language:pl",
          "language:pt",
          "language:ro",
          "language:ru",
          "language:es",
          "language:tr",
          "language:uk",
          "language:vi",
          "license:cc-by-nc-4.0",
          "size_categories:1K<n<10K",
          "format:audiofolder",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tAudioCaps Multilingual Evaluation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset extends AudioCaps with multilingual captions in 33 language variants (34 caption columns as we have 2 version of translation for Hindi, one from IndicTrans2 and other from AYA).\nEach audio clip is paired with the original English AudioCaps caption and\nmachine-translated or curated captions in multiple languages.\nThe dataset is intended primarily for evaluation and analysis of multilingual\nand cross-lingualâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/piyushsinghpasi/audiocaps-multilingual.",
        "url": "https://huggingface.co/datasets/piyushsinghpasi/audiocaps-multilingual",
        "languages": [
          "en",
          "bn",
          "gu",
          "hi",
          "kn",
          "ml",
          "mr",
          "ne",
          "pa",
          "ta",
          "te",
          "ur",
          "ar",
          "zh",
          "cs",
          "nl",
          "fr",
          "de",
          "el",
          "he",
          "id",
          "it",
          "ja",
          "ko",
          "fa",
          "pl",
          "pt",
          "ro",
          "ru",
          "es",
          "tr",
          "uk",
          "vi"
        ],
        "tasks": [
          "audio-text-to-text"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_insertion_v2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:28:09+00:00",
        "last_modified": "2026-01-05 21:33:41+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_plug_insertion_v2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ’å…¥æ’å¤´part_2\ntotal_episodes: 169\ntotal_tasks: 1\nsize: 2.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_insertion_v2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plug_insertion_v2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "SWE-Lego/SWE-Lego-Synthetic-Data",
        "author": "SWE-Lego",
        "created_at": "2026-01-05 13:37:00+00:00",
        "last_modified": "2026-01-08 06:43:57+00:00",
        "downloads": 123,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.01426",
          "region:us",
          "software-engineering",
          "code",
          "swe-bench",
          "agent"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nPaper | Github | HF Collection\nSWE-Lego-Synthetic-Data contains 11.5k synthetic github issues (Python language) and their multi-turn agent trajectories. The column named messages is collected using Qwen/Qwen3-Coder-480B-A35B-Instruct with OpenHands (v0.53.0) agent scaffolding, which can be directly used for SFT training.\nThis dataset is part of the work presented in SWE-Lego, a supervised fine-tuning (SFT) recipe designed to achieve state-of-the-art performance inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SWE-Lego/SWE-Lego-Synthetic-Data.",
        "url": "https://huggingface.co/datasets/SWE-Lego/SWE-Lego-Synthetic-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1104",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:18:06+00:00",
        "last_modified": "2026-01-06 10:18:47+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1104\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_3\ntotal_episodes: 76\ntotal_tasks: 1\nsize: 58.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1104.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1104",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_right_slide_open_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:16:56+00:00",
        "last_modified": "2026-01-06 00:19:09+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_fr3_dual_right_slide_open_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_fr3\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å³æ‰‹æ»‘åŠ¨æ‰“å¼€æŠ½å±‰\ntotal_episodes: 237\ntotal_tasks: 1\nsize: 4.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_right_slide_open_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_right_slide_open_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 15:31:16+00:00",
        "last_modified": "2026-01-05 15:42:10+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_bread_in_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…æ”¾å…¥ç¯®å­part_1\ntotal_episodes: 124\ntotal_tasks: 1\nsize: 410.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_bread_in_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "rifxyz/open-schematics",
        "author": "rifxyz",
        "created_at": "2026-01-07 08:59:33+00:00",
        "last_modified": "2026-01-07 08:59:34+00:00",
        "downloads": 25,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:image-to-text",
          "task_categories:text-to-image",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "electronics",
          "schematics",
          "kicad",
          "hardware",
          "pcb",
          "circuit-design",
          "engineering"
        ],
        "description": "\n\n\t\n\t\t\n\t\tOpen Schematics Dataset\n\t\n\nA comprehensive dataset of electronic schematics from hardware projects. This dataset is designed for training AI models on circuit design, component recognition, and hardware engineering tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains electronic schematic files along with their visual representations, component information, and metadata from various hardware projects.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nschematic:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/rifxyz/open-schematics.",
        "url": "https://huggingface.co/datasets/rifxyz/open-schematics",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "image-to-text",
          "text-to-image"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "webxos/blackhole_synthetic",
        "author": "webxos",
        "created_at": "2026-01-05 18:39:22+00:00",
        "last_modified": "2026-01-10 03:34:31+00:00",
        "downloads": 55,
        "likes": 1,
        "tags": [
          "task_categories:video-classification",
          "task_categories:image-classification",
          "task_categories:tabular-classification",
          "task_categories:image-to-video",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "synthetic",
          "blackhole",
          "physics",
          "astronomy",
          "simulator",
          "threejs",
          "simulation",
          "art",
          "chemistry",
          "space",
          "gravity",
          "gravitational"
        ],
        "description": "\n\n\n\n.______    __          ___       ______  __  ___     __    __    ______    __       _______ \n|   _  \\  |  |        /   \\     /      ||  |/  /    |  |  |  |  /  __  \\  |  |     |   ____|\n|  |_)  | |  |       /  ^  \\   |  ,----'|  '  /     |  |__|  | |  |  |  | |  |     |  |__   \n|   _  <  |  |      /  /_\\  \\  |  |     |    <      |   __   | |  |  |  | |  |     |   __|  \n|  |_)  | |  `----./  _____  \\ |  `----.|  .  \\     |  |  |  | |  `--'  | |  `----.|  |____ \n|______/  |_______/__/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/webxos/blackhole_synthetic.",
        "url": "https://huggingface.co/datasets/webxos/blackhole_synthetic",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-classification",
          "image-classification",
          "tabular-classification",
          "image-to-video"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:39:04+00:00",
        "last_modified": "2026-01-05 22:39:21+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_long_bread_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é•¿é¢åŒ…æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 60\ntotal_tasks: 1\nsize: 56.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_long_bread_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_cylinder_pick_box_place_close",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:59:46+00:00",
        "last_modified": "2026-01-05 19:02:09+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_cylinder_pick_box_place_close\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·åœ†æŸ±ä½“ç›’å­æ”¾ç½®å¹¶å…³é—­\ntotal_episodes: 329\ntotal_tasks: 1\nsize: 1.2G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_cylinder_pick_box_place_close.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_cylinder_pick_box_place_close",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_5_eggoven_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:27:18+00:00",
        "last_modified": "2026-01-05 10:28:50+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_5_eggoven_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¸¡è›‹çƒ¤ç®±\ntotal_episodes: 105\ntotal_tasks: 1\nsize: 1.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_5_eggoven_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_5_eggoven_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "datamol-io/safe-gpt",
        "author": "datamol-io",
        "created_at": "2023-10-28 12:33:55+00:00",
        "last_modified": "2026-01-06 14:47:45+00:00",
        "downloads": 1161,
        "likes": 3,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1B<n<10B",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "chemistry",
          "molecules",
          "smiles",
          "safe",
          "drug-discovery"
        ],
        "description": "\n\t\n\t\t\n\t\tSAFE Molecules Dataset (v2)\n\t\n\nA large-scale molecular dataset containing approximately 1.17 billion unique molecules, each represented with both canonical SMILES and SAFE (Sequential Attachment-based Fragment Embedding) strings.\nThis dataset is intended to support large-scale pretraining and evaluation of chemical language models, including generative, conditional, and structure-aware modeling tasks.\n\nNote\nThis is version 2 of the SAFE dataset. The original v1 release (~100Mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/datamol-io/safe-gpt.",
        "url": "https://huggingface.co/datasets/datamol-io/safe-gpt",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1B<n<10B"
        ]
      },
      {
        "id": "lamm-mit/graph-reasoning-messages-11K",
        "author": "lamm-mit",
        "created_at": "2026-01-07 13:20:58+00:00",
        "last_modified": "2026-01-07 13:28:23+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "science",
          "biology",
          "materials"
        ],
        "description": "\n\t\n\t\t\n\t\tGraph Reasoning (Messages)\n\t\n\nA collection of chat messages designed for training and evaluating graph-native / structured reasoning behaviors in language models. Each dataset item is a conversation represented as an ordered list of {role, content} messages (OpenAI-style chat format).\n\n\n\t\n\t\t\n\t\tWhatâ€™s inside\n\t\n\nEach example is a JSON-like list of messages, e.g.\n[\n  { \"role\": \"user\", \"content\": \"...\" },\n  { \"role\": \"assistant\", \"content\": \"...\" }\n]\nAssistant responses include explicitâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/lamm-mit/graph-reasoning-messages-11K.",
        "url": "https://huggingface.co/datasets/lamm-mit/graph-reasoning-messages-11K",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_potatoes_on_a_ceramic_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:46:19+00:00",
        "last_modified": "2026-01-05 23:46:47+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_put_potatoes_on_a_ceramic_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åœŸè±†æ”¾åœ¨é™¶ç“·ç›˜ä¸Š\ntotal_episodes: 194\ntotal_tasks: 1\nsize: 387.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_potatoes_on_a_ceramic_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_put_potatoes_on_a_ceramic_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_764_move",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:18:52+00:00",
        "last_modified": "2026-01-05 19:01:35+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_764\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ¬å®¶\ntotal_episodes: 1103\ntotal_tasks: 1\nsize: 42G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_764_move.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_764_move",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "chouxtteok/commonsense_qa",
        "author": "chouxtteok",
        "created_at": "2026-01-11 11:36:49+00:00",
        "last_modified": "2026-01-11 11:36:50+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_ids:open-domain-qa",
          "annotations_creators:crowdsourced",
          "language_creators:crowdsourced",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:1811.00937",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for \"commonsense_qa\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nCommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge\nto predict the correct answers . It contains 12,102 questions with one correct answer and four distractor answers.\nThe dataset is provided in two major training/validation/testing set splits: \"Random split\" which is the main evaluation\nsplit, and \"Question token split\", see paper for details.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chouxtteok/commonsense_qa.",
        "url": "https://huggingface.co/datasets/chouxtteok/commonsense_qa",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_773_milk_a_cow",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:27:37+00:00",
        "last_modified": "2026-01-05 20:24:31+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_773\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æŒ¤ç‰›å¥¶\ntotal_episodes: 690\ntotal_tasks: 1\nsize: 68G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_773_milk_a_cow.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_773_milk_a_cow",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Lambz/alt",
        "author": "Lambz",
        "created_at": "2026-01-10 16:19:43+00:00",
        "last_modified": "2026-01-10 16:19:45+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "task_categories:token-classification",
          "task_ids:parsing",
          "annotations_creators:expert-generated",
          "language_creators:crowdsourced",
          "multilinguality:multilingual",
          "multilinguality:translation",
          "source_datasets:original",
          "language:bn",
          "language:en",
          "language:fil",
          "language:hi",
          "language:id",
          "language:ja",
          "language:km",
          "language:lo",
          "language:ms",
          "language:my",
          "language:th",
          "language:vi",
          "language:zh",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Asian Language Treebank (ALT)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT. It was first conducted by NICT and UCSY as described in Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch and Eiichiro Sumita (2016). Then, it was developed under ASEAN IVO as described in this Web page. \nThe process of building ALT began withâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lambz/alt.",
        "url": "https://huggingface.co/datasets/Lambz/alt",
        "languages": [
          "bn",
          "en",
          "fil",
          "hi",
          "id",
          "ja",
          "km",
          "lo",
          "ms",
          "my",
          "th",
          "vi",
          "zh"
        ],
        "tasks": [
          "translation",
          "token-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Shekswess/tiny-think-sft-code",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:54:00+00:00",
        "last_modified": "2026-01-10 22:07:22+00:00",
        "downloads": 42,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-sft-code\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSupervised fine-tuning (SFT) dataset built from allenai/Dolci-Think-SFT-7B using the facebook/MobileLLM-R1-140M-base tokenizer and chat template. This dataset targets code-related instructions and reasoning.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nSources: 3\nRows: 30,218\nTokens: 59,999,746\nMax sequence length: 4096 tokens per example\nToken budget: 60,000,000 tokens (equal strategy)\nColumns: messages, dataset_sourceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-sft-code.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-sft-code",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "KrishnaHuYaar/fitness-recommendation-dataset",
        "author": "KrishnaHuYaar",
        "created_at": "2026-01-08 17:27:49+00:00",
        "last_modified": "2026-01-08 17:40:16+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/KrishnaHuYaar/fitness-recommendation-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_in_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:57:47+00:00",
        "last_modified": "2026-01-05 22:58:21+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_yellow_pepper_in_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„é»„è¾£æ¤’part_1\ntotal_episodes: 142\ntotal_tasks: 1\nsize: 152.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_in_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_yellow_pepper_in_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "testpj/phishing-dataset",
        "author": "testpj",
        "created_at": "2026-01-10 13:43:51+00:00",
        "last_modified": "2026-01-10 13:43:53+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "modality:text",
          "region:us",
          "phishing",
          "url",
          "html",
          "text"
        ],
        "description": "Dataset designed for phishing classification tasks in various data types.",
        "url": "https://huggingface.co/datasets/testpj/phishing-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_1128",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:21:17+00:00",
        "last_modified": "2026-01-05 18:21:58+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_1128\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é¢åŒ…ç›˜å­part_1\ntotal_episodes: 101\ntotal_tasks: 1\nsize: 908.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_1128.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_1128",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "rzagirov/mistral_playwright_mcp",
        "author": "rzagirov",
        "created_at": "2026-01-09 04:37:37+00:00",
        "last_modified": "2026-01-09 06:24:20+00:00",
        "downloads": 39,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:other",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "arxiv:2510.01179",
          "region:us",
          "browser-automation",
          "playwright",
          "mcp",
          "tool-calling",
          "instruction-following",
          "mistral"
        ],
        "description": "\n\t\n\t\t\n\t\tPlaywright MCP Fine-Tuning Dataset for Mistral 7B Instruct 0.3\n\t\n\nA testing-focused dataset for fine-tuning Mistral 7B Instruct 0.3 on Playwright MCP (Model Context Protocol) browser automation tasks. This dataset has been filtered to include only crisp, actionable browser testing scenarios.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains 1,235 examples of browser automation testing tasks formatted for instruction-following models. It combines data from multiple sources includingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/rzagirov/mistral_playwright_mcp.",
        "url": "https://huggingface.co/datasets/rzagirov/mistral_playwright_mcp",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "other"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-multi-step-task-instructions",
        "author": "ariefansclub",
        "created_at": "2026-01-09 03:32:33+00:00",
        "last_modified": "2026-01-09 03:33:07+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "robotics",
          "task-planning",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Multi-Step Task Instructions\n\t\n\nA structured dataset containing multi-step task instructions for humanoid robots.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nTask planning\nAutonomous execution\nRobotics simulation\n\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-multi-step-task-instructions",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_place_marker",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:45:20+00:00",
        "last_modified": "2026-01-05 23:45:42+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_place_marker\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é©¬å…‹ç¬”\ntotal_episodes: 136\ntotal_tasks: 1\nsize: 312.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_place_marker.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_place_marker",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table_copy_1734079574938",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:09:35+00:00",
        "last_modified": "2026-01-07 07:10:03+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table_copy_1734079574938\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„è¾£æ¤’part_3\ntotal_episodes: 141\ntotal_tasks: 1\nsize: 75.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table_copy_1734079574938.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table_copy_1734079574938",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_open_trash_bin",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:19:06+00:00",
        "last_modified": "2026-01-05 18:19:33+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_open_trash_bin\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶part_3\ntotal_episodes: 150\ntotal_tasks: 1\nsize: 454.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_open_trash_bin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_open_trash_bin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "xilin-x/MOSXAV",
        "author": "xilin-x",
        "created_at": "2026-01-07 23:03:45+00:00",
        "last_modified": "2026-01-09 12:50:56+00:00",
        "downloads": 59,
        "likes": 0,
        "tags": [
          "task_categories:object-detection",
          "task_categories:image-segmentation",
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2601.00988",
          "arxiv:2507.16429",
          "region:us",
          "video-object-segmentation",
          "computer-vision",
          "angiography",
          "x-ray",
          "medical-image-segmentation",
          "video-segmentation"
        ],
        "description": "\n\t\n\t\t\n\t\tMOSXAV: A Benchmark Dataset for Multi-Object Segmentation in X-ray Angiography Videos\n\t\n\n\n  \n    \n  \n\n\n\n  VOS Task:\n  Â \n  \n    \n  \n  Â Â  | Â Â \n  Semantic Segmentation Task:\n  Â \n  \n    \n  \n  Â \n  \n    \n  VOS Task Evaluation Code:\n  Â \n  \n    \n  \n\n\n\n\n\t\n\t\t\n\t\tðŸ“– 1. Overview\n\t\n\nMOSXAV is a benchmark dataset designed for multi-object segmentation in X-ray angiography videos. It provides high-quality, manually annotated segmentation ground truth, supporting the analysis of vascular structures inâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/xilin-x/MOSXAV.",
        "url": "https://huggingface.co/datasets/xilin-x/MOSXAV",
        "languages": [
          "en"
        ],
        "tasks": [
          "object-detection",
          "image-segmentation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:08:34+00:00",
        "last_modified": "2026-01-07 07:09:01+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„è¾£æ¤’part_2\ntotal_episodes: 104\ntotal_tasks: 1\nsize: 52.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_yellow_pepper_from_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-multimodal-intent-resolution",
        "author": "ariefansclub",
        "created_at": "2026-01-12 00:55:54+00:00",
        "last_modified": "2026-01-12 00:56:35+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us",
          "multimodal",
          "intent",
          "humanoid",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tMultimodal Intent Resolution Dataset\n\t\n\nMaps multi-sensor inputs into unified humanoid intents.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-multimodal-intent-resolution",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "nickoo004/gemma-reasoning-gold-15k",
        "author": "nickoo004",
        "created_at": "2026-01-08 12:56:44+00:00",
        "last_modified": "2026-01-09 16:40:37+00:00",
        "downloads": 27,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "region:us",
          "reasoning",
          "chain-of-thought",
          "synthetic",
          "distillation",
          "gemma",
          "qwen"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ§  Gemma Reasoning Gold-15k\n\t\n\nThis dataset contains ~12,500 high-quality synthetic reasoning examples designed to teach Small Language Models (SLMs) like Gemma 2B to \"think before they speak.\"\nThe data was distilled from Qwen 2.5 7B Instruct using a strict XML-based Chain-of-Thought (CoT) format.\n\n\t\n\t\t\n\t\tâš ï¸ Important Usage Note\n\t\n\nPlease use the train_clean.jsonl file for training. \nThe raw train.jsonl may contain unrefined outputs. The clean version has been rigorously filtered for:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/nickoo004/gemma-reasoning-gold-15k.",
        "url": "https://huggingface.co/datasets/nickoo004/gemma-reasoning-gold-15k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Mardiyyah/TAPT_Variant_FT",
        "author": "Mardiyyah",
        "created_at": "2026-01-05 13:44:38+00:00",
        "last_modified": "2026-01-05 16:33:47+00:00",
        "downloads": 33,
        "likes": 0,
        "tags": [
          "task_categories:fill-mask",
          "task_ids:masked-language-modeling",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\n\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): en\nLicense: mit\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [More Information Needed]\nPaper [optional]: [More Information Needed]\nDemo [optional]: [More Information Needed]\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Mardiyyah/TAPT_Variant_FT.",
        "url": "https://huggingface.co/datasets/Mardiyyah/TAPT_Variant_FT",
        "languages": [
          "en"
        ],
        "tasks": [
          "fill-mask"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_bread",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:42:23+00:00",
        "last_modified": "2026-01-05 16:51:32+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_fruit_bread\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥æ°´æžœé¢åŒ…\ntotal_episodes: 92\ntotal_tasks: 1\nsize: 891.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_bread.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_bread",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "NAMANDREWLV/pii-masking-200k",
        "author": "NAMANDREWLV",
        "created_at": "2026-01-07 08:46:12+00:00",
        "last_modified": "2026-01-07 08:46:13+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "task_categories:table-question-answering",
          "task_categories:question-answering",
          "task_categories:zero-shot-classification",
          "task_categories:summarization",
          "task_categories:feature-extraction",
          "task_categories:text-generation",
          "task_categories:translation",
          "task_categories:fill-mask",
          "task_categories:tabular-classification",
          "task_categories:tabular-to-text",
          "task_categories:table-to-text",
          "task_categories:text-retrieval",
          "task_categories:other",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:en",
          "language:fr",
          "language:de",
          "language:it",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "legal",
          "business",
          "psychology",
          "privacy"
        ],
        "description": "\n\t\n\t\t\n\t\tAi4Privacy Community\n\t\n\nJoin our community at https://discord.gg/FmzWshaaQT to help build open datasets for privacy masking.\n\n\t\n\t\t\n\t\tPurpose and Features\n\t\n\nPrevious world's largest open dataset for privacy. Now it is pii-masking-300k\nThe purpose of the dataset is to train models to remove personally identifiable information (PII) from text, especially in the context of AI assistants and LLMs. \nThe example texts have 54 PII classes (types of sensitive data), targeting 229 discussionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NAMANDREWLV/pii-masking-200k.",
        "url": "https://huggingface.co/datasets/NAMANDREWLV/pii-masking-200k",
        "languages": [
          "en",
          "fr",
          "de",
          "it"
        ],
        "tasks": [
          "text-classification",
          "token-classification",
          "table-question-answering",
          "question-answering",
          "zero-shot-classification",
          "summarization",
          "feature-extraction",
          "text-generation",
          "translation",
          "fill-mask",
          "tabular-classification",
          "tabular-to-text",
          "table-to-text",
          "text-retrieval",
          "other"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "paperswithbacktest/All-Monthly-CoreEconomicData",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:31:09+00:00",
        "last_modified": "2026-01-10 03:58:47+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nMonthly macroeconomic factor dataset curated by SOV.AI. This table contains the core set of\nindicators that explains over 90% of the variance across common economic outcomes. Columns align to\nthe Federal Reserve Economic Data (FRED) series codes provided by SOV.AI, with more than 250\nindicators spanning labor, credit, housing, volatility, and fixed-income markets.\n\nCoverage: Over 250 macroeconomic indicators distilled from the macro features feed.\nUpdate cadence:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/All-Monthly-CoreEconomicData.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/All-Monthly-CoreEconomicData",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_drawer_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:58:47+00:00",
        "last_modified": "2026-01-05 17:59:19+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_slide_open_drawer_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ»‘åŠ¨æ‰“å¼€æŠ½å±‰part_2\ntotal_episodes: 245\ntotal_tasks: 1\nsize: 492.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_drawer_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_drawer_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "matis35/cf-synt_V2",
        "author": "matis35",
        "created_at": "2026-01-10 15:48:48+00:00",
        "last_modified": "2026-01-10 17:44:11+00:00",
        "downloads": 60,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "task_categories:question-answering",
          "language:en",
          "language:code",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2306.11644",
          "arxiv:2212.10560",
          "arxiv:2005.10530",
          "arxiv:2401.14196",
          "region:us",
          "code",
          "synthetic",
          "education",
          "rag",
          "c",
          "distillation",
          "programming"
        ],
        "description": "\n\t\n\t\t\n\t\tCF-Synt_V2: A Compiler-Validated Synthetic Dataset for C Programming Feedback\n\t\n\nCF-Synt_V2 is a rigorously engineered synthetic dataset containing 15,626 pairs of buggy C code and their corresponding corrective feedback. Designed for educational RAG (Retrieval-Augmented Generation) and Code-to-Text alignment tasks, this dataset focuses on the \"Piscine\" level (CS101) of C programming.\nUnlike standard scraped datasets, CF-Synt is 100% compiler-validated, ensuring that every code snippetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/matis35/cf-synt_V2.",
        "url": "https://huggingface.co/datasets/matis35/cf-synt_V2",
        "languages": [
          "en",
          "code"
        ],
        "tasks": [
          "text-retrieval",
          "text-generation",
          "feature-extraction",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "khoaguin/chest-ct-segmentation",
        "author": "khoaguin",
        "created_at": "2026-01-05 09:04:48+00:00",
        "last_modified": "2026-01-09 03:05:00+00:00",
        "downloads": 66,
        "likes": 0,
        "tags": [
          "task_categories:image-segmentation",
          "task_ids:semantic-segmentation",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2408.00714",
          "region:us",
          "medical-imaging",
          "ct-scan",
          "lung-segmentation",
          "federated-learning",
          "sam2",
          "lora"
        ],
        "description": "\n\t\n\t\t\n\t\tChest CT Segmentation - Federated Learning Partitions\n\t\n\nDataset partitions for Federated SAM2-LoRA medical image segmentation across multiple Data Owners.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains partitioned chest CT scans designed for federated learning experiments with heterogeneous clients. Each partition represents a different hospital/data owner with varying data availability and training capabilities.\n\n\t\n\t\t\n\t\tSource\n\t\n\nOriginal data from Chest CT Segmentation onâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/khoaguin/chest-ct-segmentation.",
        "url": "https://huggingface.co/datasets/khoaguin/chest-ct-segmentation",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-segmentation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_close_garbage_bin",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:39:07+00:00",
        "last_modified": "2026-01-05 23:39:53+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_close_garbage_bin\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­åžƒåœ¾æ¡¶part_5\ntotal_episodes: 287\ntotal_tasks: 1\nsize: 597.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_close_garbage_bin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_close_garbage_bin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Rapidata/bananamark-dataset",
        "author": "Rapidata",
        "created_at": "2025-12-02 11:09:52+00:00",
        "last_modified": "2025-12-12 10:05:23+00:00",
        "downloads": 34,
        "likes": 18,
        "tags": [
          "task_categories:text-to-image",
          "task_categories:image-to-text",
          "task_categories:image-classification",
          "task_categories:reinforcement-learning",
          "language:en",
          "license:cdla-permissive-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Human",
          "Preference",
          "Alignment",
          "banana",
          "bananamark",
          "black-forest-labs",
          "flux-2",
          "bytedance",
          "seedream-4",
          "google",
          "nano-banana",
          "qwen",
          "qwen-image",
          "ideogram-ai",
          "ideogram",
          "tencent",
          "hunyuan",
          "recraft-ai",
          "recraft-v3",
          "prunaai",
          "wan-2.2-image"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸŒ Bananamark - Who has the best Bananas?\n\t\n\n\n\n\n\nGoogle released a model called Nano Banana. We had to know: is it actually good at generating bananas?\nTurns out, not as good as FLUX 2 or Seedream 4!\n\n\t\n\t\t\n\t\tWhat we did\n\t\n\nWe tested 11 image generation models on various banana-themed prompts and collected over 20'000 human preferences using the Rapidata Python API. Annotators were asked a simple question:\n\nWhich image has the better bananas?\n\nWant to evaluate your own models? Check outâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Rapidata/bananamark-dataset.",
        "url": "https://huggingface.co/datasets/Rapidata/bananamark-dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image",
          "image-to-text",
          "image-classification",
          "reinforcement-learning"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ToolGym/long-horizon-eval",
        "author": "ToolGym",
        "created_at": "2026-01-09 05:41:42+00:00",
        "last_modified": "2026-01-09 19:13:50+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tlong-horizon-eval\n\t\n\nEvaluation results for long-horizon agent performance\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains evaluation results for agent trajectories, including quality assessments and performance metrics.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized by model name, with each model having separate JSONL files for different experimental passes.\nlong-horizon-eval/\nâ”œâ”€â”€ model-1/\nâ”‚   â”œâ”€â”€ pass@1.jsonl\nâ”‚   â”œâ”€â”€ pass@2.jsonl\nâ”‚   â””â”€â”€ pass@3.jsonl\nâ”œâ”€â”€ model-2/\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToolGym/long-horizon-eval.",
        "url": "https://huggingface.co/datasets/ToolGym/long-horizon-eval",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Ziyiii0-0/Retail-3I",
        "author": "Ziyiii0-0",
        "created_at": "2026-01-10 14:38:01+00:00",
        "last_modified": "2026-01-10 15:16:33+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "region:us",
          "tool-calling",
          "multi-turn",
          "Agent"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Retail-3I\n\t\n\nRetail-3I is a retail-domain dataset built on top of tau2-bench for evaluating and training tool-calling LLM agents under three realistic user-intent conditions:\n(1) Ambiguous intent: the user request is underspecified.\n(2) Changing intent: the user revises or extends the goal after seeing intermediate results.\n(3) Infeasible intent: the user request conflicts with tool limits, inventory/policy constraints, or missing capabilities.\nThere's also a generalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ziyiii0-0/Retail-3I.",
        "url": "https://huggingface.co/datasets/Ziyiii0-0/Retail-3I",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "phanerozoic/Coq-Iris",
        "author": "phanerozoic",
        "created_at": "2026-01-10 11:53:52+00:00",
        "last_modified": "2026-01-10 11:54:11+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "separation-logic",
          "iris",
          "concurrent-programming"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Iris\n\t\n\nStructured dataset from Iris, a higher-order concurrent separation logic framework for Coq.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstring\nLemma, Definition, Class, Global, Local, etc.\n\n\nlibrary\nstring\nModule (iris, iris_heap_lang, iris_unstable, etc.)\n\n\nimports\nlist\nRequire/Import statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tBy Typeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Iris.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Iris",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "servoskinner/potato-defects",
        "author": "servoskinner",
        "created_at": "2025-12-26 18:29:05+00:00",
        "last_modified": "2026-01-08 17:42:43+00:00",
        "downloads": 365,
        "likes": 0,
        "tags": [
          "language:en",
          "language:ru",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains images of potato tubers with and without defects, intended for training classification models.\nThe classes included in this dataset are:\n\nNo defect (negative)\nGreening\nPest damage\nMisshapen tuber\n\n\n\t\n\t\t\n\t\tImportant notice\n\t\n\nPictures are marked as containing defects if the object on them has a defect of the respective type, \neven if it is not visible on that specific picture. This introduces a considerable minority of\nfalse negative labels, though theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/servoskinner/potato-defects.",
        "url": "https://huggingface.co/datasets/servoskinner/potato-defects",
        "languages": [
          "en",
          "ru"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_square_bread_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:47:39+00:00",
        "last_modified": "2026-01-05 22:47:53+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_square_bread_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ–¹å½¢é¢åŒ…æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 38\ntotal_tasks: 1\nsize: 41.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_square_bread_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_square_bread_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "makinx/tech-training-institute-dataset",
        "author": "makinx",
        "created_at": "2026-01-07 20:10:55+00:00",
        "last_modified": "2026-01-07 20:18:45+00:00",
        "downloads": 4,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "language:af",
          "language:en",
          "license:afl-3.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "agent"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/makinx/tech-training-institute-dataset",
        "languages": [
          "af",
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Isabelle-seL4",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:55:44+00:00",
        "last_modified": "2026-01-10 15:14:20+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:gpl-2.0",
          "license:bsd-2-clause",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "isabelle",
          "operating-systems",
          "microkernel"
        ],
        "description": "\n\t\n\t\t\n\t\tIsabelle-seL4\n\t\n\nStructured dataset from l4v - formal verification proofs for the seL4 microkernel.\n74,086 declarations extracted from Isabelle theory files.\nOne of the largest machine-checked proofs of operating system code ever completed.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Isabelle-seL4.",
        "url": "https://huggingface.co/datasets/phanerozoic/Isabelle-seL4",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plate_push",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 20:48:42+00:00",
        "last_modified": "2026-01-05 21:04:42+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_plate_push\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æŽ¨åŠ¨ç›˜å­\ntotal_episodes: 201\ntotal_tasks: 1\nsize: 748.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plate_push.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_plate_push",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_no_le2w_fullnames_v2.jsonl",
        "author": "Mathieu-Thomas-JOSSET",
        "created_at": "2026-01-07 00:14:59+00:00",
        "last_modified": "2026-01-07 00:15:15+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "sharegpt",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tthe_office_only_michael_finetome_no_le2w_fullnames_v2.jsonl\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ntrain.jsonl\n\n\n\t\n\t\t\n\t\tLoading (example)\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_no_le2w_fullnames_v2.jsonl\")\nprint(ds)\n\n",
        "url": "https://huggingface.co/datasets/Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_no_le2w_fullnames_v2.jsonl",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Lakshmiperumal/scanned_receipts",
        "author": "Lakshmiperumal",
        "created_at": "2026-01-11 10:03:31+00:00",
        "last_modified": "2026-01-11 10:03:32+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:object-detection",
          "task_categories:visual-question-answering",
          "task_categories:visual-document-retrieval",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "library:fiftyone",
          "arxiv:2103.10213",
          "region:us",
          "fiftyone",
          "image",
          "object-detection"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Scanned Receipts OCR and Information Extraction\n\t\n\n\nThis is a FiftyOne dataset with 712 samples.\n\n\t\n\t\t\n\t\tInstallation\n\t\n\nIf you haven't already, install FiftyOne:\npip install -U fiftyone\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nimport fiftyone as fo\nfrom fiftyone.utils.huggingface import load_from_hub\n\n# Load the dataset\n# Note: other available arguments include 'max_samples', etc\ndataset = load_from_hub(\"Voxel51/scanned_receipts\")\n\n# Launch the App\nsession = fo.launch_app(dataset)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lakshmiperumal/scanned_receipts.",
        "url": "https://huggingface.co/datasets/Lakshmiperumal/scanned_receipts",
        "languages": [
          "en"
        ],
        "tasks": [
          "object-detection",
          "visual-question-answering",
          "visual-document-retrieval"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:35:29+00:00",
        "last_modified": "2026-01-05 12:43:35+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ¢¨æ”¾å…¥ç¢—ä¸­part_2\ntotal_episodes: 237\ntotal_tasks: 1\nsize: 288.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_in_basket",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:55:09+00:00",
        "last_modified": "2026-01-05 22:55:19+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_triangle_bread_in_basket\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„ä¸‰è§’å½¢é¢åŒ…part_1\ntotal_episodes: 35\ntotal_tasks: 1\nsize: 34.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_in_basket.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_triangle_bread_in_basket",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_square_bread",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:25:30+00:00",
        "last_modified": "2026-01-05 22:25:46+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_square_bread\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·æ–¹å½¢é¢åŒ…\ntotal_episodes: 80\ntotal_tasks: 1\nsize: 71.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_square_bread.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_square_bread",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "happy8825/experiment_real_fp8",
        "author": "happy8825",
        "created_at": "2026-01-08 12:08:17+00:00",
        "last_modified": "2026-01-08 12:12:28+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "video-retrieval",
          "evaluation",
          "vllm"
        ],
        "description": "\n\t\n\t\t\n\t\t/hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350 Â· happy8825/valid_ecva_clean results\n\t\n\n\nModel: /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350\nDataset: happy8825/valid_ecva_clean\nGenerated: 2026-01-08 12:12:25Z\n\n\n\t\n\t\t\n\t\tMetrics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal samples\n924\n\n\nWith GT\n0\n\n\nParsed answers\n0\n\n\nTop-1 accuracy\n0\n\n\nRecall@5\n0\n\n\nMRR\n0\n\n\n\t\n\nThe uploaded JSON contains full per-sample predictions produced via t3_infer_with_vllm.bash.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/happy8825/experiment_real_fp8.",
        "url": "https://huggingface.co/datasets/happy8825/experiment_real_fp8",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "waterandwood/92k-real-world-call-center-scripts-english",
        "author": "waterandwood",
        "created_at": "2026-01-08 08:16:30+00:00",
        "last_modified": "2026-01-08 08:16:30+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:10K<n<100K",
          "arxiv:2507.02958",
          "region:us"
        ],
        "description": "ArXiv Paper Publication Here: \"Real-World En Call Center Transcripts Dataset with PII Redaction\"\nThis dataset includes 91,706 high-quality transcriptions corresponding to approximately 10,500 hours of real-world call center conversations in English, collected across various industries and global regions. The dataset features both inbound and outbound calls and spans multiple accents, including Indian, American, and Filipino English. All transcripts have been carefully redacted for PII andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/waterandwood/92k-real-world-call-center-scripts-english.",
        "url": "https://huggingface.co/datasets/waterandwood/92k-real-world-call-center-scripts-english",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "zyL2003/JBB-Behaviors",
        "author": "zyL2003",
        "created_at": "2026-01-11 08:54:40+00:00",
        "last_modified": "2026-01-11 08:54:41+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2404.01318",
          "arxiv:2311.03348",
          "arxiv:2307.15043",
          "arxiv:2402.04249",
          "region:us",
          "jailbreaks",
          "large language models",
          "harmful behaviors",
          "ml safety"
        ],
        "description": "\n  \n\n\n\n    An Open Robustness Benchmark for Jailbreaking Language Models\n    \n\n\n\n    NeurIPS 2024 Datasets and Benchmarks Track\n    \n\n\n\n    Paper |\n    Leaderboard |\n    Benchmark code\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tWhat is JailbreakBench?\n\t\n\nJailbreakbench is an open-source robustness benchmark for jailbreaking large language models (LLMs). The goal of this benchmark is to comprehensively track progress toward (1) generating successful jailbreaks and (2) defending against these jailbreaks. To this end, weâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zyL2003/JBB-Behaviors.",
        "url": "https://huggingface.co/datasets/zyL2003/JBB-Behaviors",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_3_eggplantoven",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:11:25+00:00",
        "last_modified": "2026-01-05 23:12:24+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_3_eggplantoven\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: èŒ„å­çƒ¤ç®±part_3\ntotal_episodes: 91\ntotal_tasks: 1\nsize: 1.8G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_3_eggplantoven.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_3_eggplantoven",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "deokhk/multilingual_reasoning_gap_outputs",
        "author": "deokhk",
        "created_at": "2025-12-19 12:50:10+00:00",
        "last_modified": "2026-01-05 13:21:02+00:00",
        "downloads": 279,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "language:de",
          "language:es",
          "language:ar",
          "language:ja",
          "language:ko",
          "language:th",
          "language:bn",
          "language:sw",
          "language:te",
          "license:apache-2.0",
          "arxiv:2510.27269",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for multilingual_reasoning_gap_outputs\n\t\n\nPaper | Code\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains experiment outputs for Qwen3-4B used in our study on multilingual reasoning gaps.\nIt includes:\n\nProber checkpoints trained for understanding-failure analysis\nIntermediate results, such as:\nModel inference outputs\nSignals for understanding failure detection\nAuxiliary artifacts used for probing and analysis\n\n\n\nThe dataset is released toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/deokhk/multilingual_reasoning_gap_outputs.",
        "url": "https://huggingface.co/datasets/deokhk/multilingual_reasoning_gap_outputs",
        "languages": [
          "en",
          "de",
          "es",
          "ar",
          "ja",
          "ko",
          "th",
          "bn",
          "sw",
          "te"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_turn_on_desk_lamp",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:56:30+00:00",
        "last_modified": "2026-01-05 23:57:18+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_turn_on_desk_lamp\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€å°ç¯\ntotal_episodes: 275\ntotal_tasks: 1\nsize: 771.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_turn_on_desk_lamp.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_turn_on_desk_lamp",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_0_tkx_1rgb_push_break_pick_shelf_insert_machine_press_switch_place_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 03:49:35+00:00",
        "last_modified": "2026-01-08 03:55:00+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_push_break_pick_shelf_insert_machine_press_switch_place_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æŽ¨åŠ¨æ‰‹è‡‚æ‹¿èµ·æž¶å­æ’å…¥æœºå™¨æŒ‰åŽ‹å¼€å…³æ”¾ç½®ç›˜å­\ntotal_episodes: 54\ntotal_tasks: 1\nsize: 572.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkx_1rgb_push_break_pick_shelf_insert_machine_press_switch_place_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_0_tkx_1rgb_push_break_pick_shelf_insert_machine_press_switch_place_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "AroticMerch/han-intent-to-action-v1",
        "author": "AroticMerch",
        "created_at": "2026-01-10 12:18:00+00:00",
        "last_modified": "2026-01-10 12:18:36+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "action",
          "planning",
          "robotics",
          "ai"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Intent to Action Dataset\n\t\n\nThis dataset maps inferred human intent\nto abstract humanoid actions.\nActions are defined at a high level,\nindependent of robot hardware.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\nInferred intent\nAction goal\nAbstract action sequence\n\n\n\t\n\t\t\n\t\tPart of\n\t\n\nHumanoid Network (HAN)\n\n\t\n\t\t\n\t\tLicense\n\t\n\nMIT\n",
        "url": "https://huggingface.co/datasets/AroticMerch/han-intent-to-action-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_green_pepper_on_the_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 02:27:04+00:00",
        "last_modified": "2026-01-06 02:27:33+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_green_pepper_on_the_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é¤æ¡Œä¸Šçš„é’æ¤’part_2\ntotal_episodes: 197\ntotal_tasks: 1\nsize: 107.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_green_pepper_on_the_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_green_pepper_on_the_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_765_Adjust_implantable_advertising",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:21:43+00:00",
        "last_modified": "2026-01-05 19:42:48+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_765\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: è°ƒæ•´æ¤å…¥å¼å¹¿å‘Š\ntotal_episodes: 1493\ntotal_tasks: 1\nsize: 88G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_765_Adjust_implantable_advertising.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_765_Adjust_implantable_advertising",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "gentaiscool/codemixqa",
        "author": "gentaiscool",
        "created_at": "2026-01-11 14:04:01+00:00",
        "last_modified": "2026-01-11 15:22:48+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "language:en",
          "language:it",
          "language:fr",
          "language:es",
          "language:zh",
          "language:id",
          "language:ja",
          "language:ko",
          "language:hi",
          "language:mr",
          "language:ur",
          "language:bn",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tCodeMixQA\n\t\n\nA benchmark with high-quality human annotations, comprising 16 diverse parallel code-switched language-pair variants that span multiple geographic regions and code-switching patterns, and include both original scripts and their transliterated forms.\nWe use SimpleQA Verified as our source dataset. We select the SimpleQA Verified, as it is a challenging evaluation set that has not been saturated yet by current models and has desirable properties such as verifiable answersâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gentaiscool/codemixqa.",
        "url": "https://huggingface.co/datasets/gentaiscool/codemixqa",
        "languages": [
          "en",
          "it",
          "fr",
          "es",
          "zh",
          "id",
          "ja",
          "ko",
          "hi",
          "mr",
          "ur",
          "bn"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Verdi",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:30:40+00:00",
        "last_modified": "2026-01-10 15:12:07+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-2-clause",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Verdi\n\t\n\nStructured dataset from Verdi â€” Distributed systems verification.\n1,139 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/uwplse/verdi\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstring\nLemmaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Verdi.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Verdi",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "vipinpalhugging/wordnet-testing-2",
        "author": "vipinpalhugging",
        "created_at": "2026-01-05 12:57:17+00:00",
        "last_modified": "2026-01-05 13:17:15+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tWordNet RDF\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLexical database of semantic relations between words (English WordNet 2024)\nOriginal Source: https://en-word.net/static/english-wordnet-2024.ttl.gz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from WordNet RDF converted to HuggingFace\ndataset format for easy use in machine learning pipelines.\n\nFormat: Originally turtle, converted to HuggingFace Dataset\nSize: 0.21 GB (extracted)\nEntities: ~120K synsets\nTriples: ~2M\nOriginalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vipinpalhugging/wordnet-testing-2.",
        "url": "https://huggingface.co/datasets/vipinpalhugging/wordnet-testing-2",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_had_put_red_apple_in_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:24:43+00:00",
        "last_modified": "2026-01-06 00:25:35+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_had_put_red_apple_in_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†çº¢è‹¹æžœæ”¾å…¥ç›˜å­\ntotal_episodes: 137\ntotal_tasks: 1\nsize: 681.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_had_put_red_apple_in_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_had_put_red_apple_in_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "jeroenmeirlaen/OpenSatMap",
        "author": "jeroenmeirlaen",
        "created_at": "2026-01-10 20:46:01+00:00",
        "last_modified": "2026-01-10 20:46:02+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:image-segmentation",
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "arxiv:2410.23278",
          "region:us",
          "OpenSatMap",
          "Satellite"
        ],
        "description": "\n\t\n\t\t\n\t\tOpenSatMap Dataset Card\n\t\n\n\n  \n\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThe dataset contains 3,787 high-resolution satellite images with fine-grained annotations, covering diverse geographic locations and popular driving datasets. It can be used for large-scale map construction and downstream tasks like autonomous driving. The images are collected from Google Maps at level 19 resolution (0.3m/pixel) and level 20 resolution (0.15m/pixel), we denote them as OpenSatMap19 and OpenSatMap20, respectively.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jeroenmeirlaen/OpenSatMap.",
        "url": "https://huggingface.co/datasets/jeroenmeirlaen/OpenSatMap",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-segmentation"
        ],
        "size_categories": []
      },
      {
        "id": "Tatsuya-Ichinose/CoDIT-Qwen3-8B",
        "author": "Tatsuya-Ichinose",
        "created_at": "2026-01-11 11:41:08+00:00",
        "last_modified": "2026-01-11 14:44:32+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:lmsys-chat-1m",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\nDataset Name\nðŸ¤– Teacher Model\nðŸ“‚ Dataset Link\n\n\n\t\t\nCoDIT-Gemma3 ðŸ’Ž\ngoogle/gemma-3-27b-it\nCoDIT-Gemma3 â†—\n\n\nCoDIT-Qwen3-8B ðŸ‰\nQwen/Qwen3-8B\nCoDIT-Qwen3-8B â†—\n\n\nCoDIT-Qwen3-30B ðŸš€\nQwen/Qwen3-30B-A3B\nCoDIT-Qwen3-30B â†—\n\n\n\t\n\n\n\t\t\n\t\tCoDIT-Qwen3-8B\n\t\n\nCoDIT-Qwen3-8B is a synthetic conversation dataset derived from LMSYS-Chat-1M [Zhang+, ICLR24].\n\n250,333 user instructions sourced from LMSYS-Chat-1M\n250,333 assistant responses automatically synthesized using CoDIT with Qwen/Qwen3-8B(No Thinking)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tatsuya-Ichinose/CoDIT-Qwen3-8B.",
        "url": "https://huggingface.co/datasets/Tatsuya-Ichinose/CoDIT-Qwen3-8B",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "tonychenxyz/livecodebench",
        "author": "tonychenxyz",
        "created_at": "2026-01-06 12:48:48+00:00",
        "last_modified": "2026-01-06 13:30:53+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2403.07974",
          "region:us",
          "code-generation",
          "programming",
          "benchmark",
          "livecodebench"
        ],
        "description": "\n\t\n\t\t\n\t\tLiveCodeBench for Code-LLaVA\n\t\n\nThis dataset contains the LiveCodeBench code generation benchmark prepared for\nCode-LLaVA evaluation.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nPaper: LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code\nRepository: https://github.com/LiveCodeBench/LiveCodeBench\nVersion: release_v6 (May 2023 - Apr 2025, 1055 problems)\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\nTwo configurations are available:\n\nmemwrap: Problems with <|memory_start|> /â€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonychenxyz/livecodebench.",
        "url": "https://huggingface.co/datasets/tonychenxyz/livecodebench",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "masculine/long-horizon",
        "author": "masculine",
        "created_at": "2026-01-09 04:35:31+00:00",
        "last_modified": "2026-01-09 05:33:04+00:00",
        "downloads": 72,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "agent",
          "tool-use",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tToolGym Long-Horizon Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains long-horizon trajectories and evaluations for the ToolGym benchmark.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nlong-horizon/\nâ”œâ”€â”€ traj/          # Agent trajectories (JSONL format)\nâ”‚   â”œâ”€â”€ gpt-5.2/\nâ”‚   â”‚   â”œâ”€â”€ pass@1.jsonl\nâ”‚   â”‚   â”œâ”€â”€ pass@2.jsonl\nâ”‚   â”‚   â””â”€â”€ pass@3.jsonl\nâ”‚   â”œâ”€â”€ claude-opus-4.5/\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ eval/          # Evaluation results (JSONL format)\n    â”œâ”€â”€ claude-opus-4.5/\n    â”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/masculine/long-horizon.",
        "url": "https://huggingface.co/datasets/masculine/long-horizon",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_left_had_place_the_cup_on_the_left_side_of_the_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 04:55:15+00:00",
        "last_modified": "2026-01-08 04:55:47+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_had_place_the_cup_on_the_left_side_of_the_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†æ¯å­æ”¾åœ¨ç›˜å­å·¦ä¾§\ntotal_episodes: 147\ntotal_tasks: 1\nsize: 906.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_had_place_the_cup_on_the_left_side_of_the_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_had_place_the_cup_on_the_left_side_of_the_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Gait001/pythia-1.4b_cy",
        "author": "Gait001",
        "created_at": "2026-01-06 01:51:25+00:00",
        "last_modified": "2026-01-06 02:02:01+00:00",
        "downloads": 24,
        "likes": 1,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "arxiv:2304.01373",
          "arxiv:2101.00027",
          "arxiv:2201.07311",
          "region:us",
          "pytorch",
          "causal-lm",
          "pythia"
        ],
        "description": "The Pythia Scaling Suite is a collection of models developed to facilitate \ninterpretability research (see paper). \nIt contains two sets of eight models of sizes \n70M, 160M, 410M, 1B, 1.4B, 2.8B, 6.9B, and 12B. For each size, there are two \nmodels: one trained on the Pile, and one trained on the Pile after the dataset \nhas been globally deduplicated. All 8 model sizes are trained on the exact \nsame data, in the exact same order. We also provide 154 intermediate \ncheckpoints per model, hostedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Gait001/pythia-1.4b_cy.",
        "url": "https://huggingface.co/datasets/Gait001/pythia-1.4b_cy",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "monong/alpaca",
        "author": "monong",
        "created_at": "2026-01-08 02:07:29+00:00",
        "last_modified": "2026-01-08 02:07:30+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "instruction-finetuning"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Alpaca\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nAlpaca is a dataset of 52,000 instructions and demonstrations generated by OpenAI's text-davinci-003 engine. This instruction data can be used to conduct instruction-tuning for language models and make the language model follow instruction better.\nThe authors built on the data generation pipeline from Self-Instruct framework and made the following modifications:\n\nThe text-davinci-003 engine to generate the instruction data insteadâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/monong/alpaca.",
        "url": "https://huggingface.co/datasets/monong/alpaca",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "MrVolts/Video-MME-Base64",
        "author": "MrVolts",
        "created_at": "2026-01-05 11:43:57+00:00",
        "last_modified": "2026-01-05 12:17:30+00:00",
        "downloads": 160,
        "likes": 0,
        "tags": [
          "task_categories:video-text-to-text",
          "task_categories:visual-question-answering",
          "source_datasets:lmms-lab/Video-MME",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tVideo-MME Base64 (480p H.264)\n\t\n\nBase64-encoded video dataset derived from lmms-lab/Video-MME.\nAll videos re-encoded to 480p H.264 for VLM compatibility.\n\n\t\n\t\t\n\t\tStructure\n\t\n\n\n\t\n\t\t\nSplit\nKey\nDescription\n\n\n\t\t\nqa/\nvideo_id\nQA pairs from Video-MME\n\n\nvideos/\nvideo_id\nBase64 video (H.264)\n\n\naudio/\nvideo_id\nBase64 audio (MP3)\n\n\n\t\n\nJoin on video_id (e.g., \"001\", \"002\").\n\n\t\n\t\t\n\t\n\t\n\t\tStats\n\t\n\n\nVideos: 869\nQA pairs: 2607\nShards: shard-01-of-10 through shard-10-of-10\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\nfromâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/MrVolts/Video-MME-Base64.",
        "url": "https://huggingface.co/datasets/MrVolts/Video-MME-Base64",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-text-to-text",
          "visual-question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "neuralfoundry-coder/OpenMathReasoning-mini-ko",
        "author": "neuralfoundry-coder",
        "created_at": "2026-01-11 06:17:05+00:00",
        "last_modified": "2026-01-11 06:17:22+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "source_datasets:unsloth/OpenMathReasoning-mini",
          "source_datasets:nvidia/OpenMathReasoning",
          "language:ko",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2504.16891",
          "region:us",
          "math",
          "mathematics",
          "reasoning",
          "korean",
          "translated",
          "chain-of-thought",
          "cot"
        ],
        "description": "\n\t\n\t\t\n\t\tOpenMathReasoning-mini Korean (í•œêµ­ì–´ ë²ˆì—­)\n\t\n\nì´ ë°ì´í„°ì…‹ì€ unsloth/OpenMathReasoning-mini ë°ì´í„°ì…‹ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•œ ë²„ì „ìž…ë‹ˆë‹¤.\nì›ë³¸ ë°ì´í„°ì…‹ì€ nvidia/OpenMathReasoning ì—ì„œ íŒŒìƒë˜ì—ˆìŠµë‹ˆë‹¤.\n\n\t\n\t\t\n\t\të°ì´í„°ì…‹ ì •ë³´\n\t\n\n\n\t\n\t\t\ní•­ëª©\në‚´ìš©\n\n\n\t\t\nì›ë³¸ ë°ì´í„°ì…‹\nunsloth/OpenMathReasoning-mini\n\n\nì›ë³¸ ì¶œì²˜\nnvidia/OpenMathReasoning\n\n\në¼ì´ì„ ìŠ¤\nCC-BY-4.0\n\n\ní–‰ ìˆ˜\n19,252\n\n\nì–¸ì–´\ní•œêµ­ì–´ (Korean), ì˜ì–´ (English)\n\n\në²ˆì—­ ëŒ€ìƒ ì»¬ëŸ¼\nexpected_answer, problem, generated_solution\n\n\n\t\n\n\n\t\n\t\n\t\n\t\të¼ì´ì„ ìŠ¤ ë° ê·€ì†\n\t\n\nì´ ë°ì´í„°ì…‹ì€ ì›ë³¸ ë°ì´í„°ì…‹ì¸ nvidia/OpenMathReasoningì˜ CC-BY-4.0 ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤.\n\nì›ì €ìž‘ìž: NVIDIAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/neuralfoundry-coder/OpenMathReasoning-mini-ko.",
        "url": "https://huggingface.co/datasets/neuralfoundry-coder/OpenMathReasoning-mini-ko",
        "languages": [
          "ko",
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Finish-him/msc-instructions",
        "author": "Finish-him",
        "created_at": "2026-01-10 04:29:47+00:00",
        "last_modified": "2026-01-10 04:30:42+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "language:pt",
          "language:en",
          "language:es",
          "language:de",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "msc-marketing",
          "portuguese",
          "instructions",
          "agents",
          "definitions"
        ],
        "description": "\n\t\n\t\t\n\t\tmsc-instructions\n\t\n\nInstruÃ§Ãµes e procedimentos para treinamento de agentes MSC Marketing\n\n\t\n\t\t\n\t\tSobre\n\t\n\nEste dataset faz parte da infraestrutura de IA da MSC Marketing, uma empresa especializada em Marketing Digital e SEO.\n\n\t\n\t\t\n\t\tUso\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"Finish-him/msc-instructions\")\n\n\n\t\n\t\t\n\t\tEstrutura\n\t\n\nOs arquivos incluÃ­dos neste dataset sÃ£o:\n\ninstructions.jsonl\ninstructions.json\ndefinitions.jsonl\ndefinitions_qa.jsonl\n\n\n\t\n\t\t\n\t\tLicenÃ§aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Finish-him/msc-instructions.",
        "url": "https://huggingface.co/datasets/Finish-him/msc-instructions",
        "languages": [
          "pt",
          "en",
          "es",
          "de"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_round_bread_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:24:39+00:00",
        "last_modified": "2026-01-05 22:24:49+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_round_bread_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·åœ†é¢åŒ…part_2\ntotal_episodes: 27\ntotal_tasks: 1\nsize: 22.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_round_bread_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_round_bread_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_no_le2w.jsonl",
        "author": "Mathieu-Thomas-JOSSET",
        "created_at": "2026-01-07 00:10:02+00:00",
        "last_modified": "2026-01-07 00:10:05+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "text",
          "sharegpt",
          "sft"
        ],
        "description": "\n\t\n\t\t\n\t\tthe_office_only_michael_finetome_no_le2w.jsonl\n\t\n\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\ntrain.jsonl\n\n\n\t\n\t\t\n\t\tLoading (example)\n\t\n\nfrom datasets import load_dataset\n\nds = load_dataset(\"Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_no_le2w.jsonl\")\nprint(ds)\n\n",
        "url": "https://huggingface.co/datasets/Mathieu-Thomas-JOSSET/the_office_only_michael_finetome_no_le2w.jsonl",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "hi-paris/FakeParts_Legacy",
        "author": "hi-paris",
        "created_at": "2025-05-15 14:36:29+00:00",
        "last_modified": "2025-12-25 18:32:25+00:00",
        "downloads": 2687,
        "likes": 9,
        "tags": [
          "task_categories:video-classification",
          "language:en",
          "license:cc0-1.0",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "arxiv:2508.21052",
          "region:us",
          "deepfake-detection",
          "video-manipulation",
          "computer-vision",
          "benchmark",
          "deepfakes",
          "multimodal",
          "dataset-benchmarking",
          "trustworthy-ai"
        ],
        "description": "\n\t\n\t\t\n\t\tFakeParts: A New Family of AI-Generated DeepFakes\n\t\n\n\n\n\n\n\n\n  \n\n\n\n  \n\n\n\n\t\n\t\t\n\t\tAbstract\n\t\n\nWe introduce FakeParts, a new class of deepfakes characterized by subtle, localized manipulations to specific spatial regions or temporal segments of otherwise authentic videos. Unlike fully synthetic content, these partial manipulations, ranging from altered facial expressions to object substitutions and background modifications, blend seamlessly with real elements, making them particularlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hi-paris/FakeParts_Legacy.",
        "url": "https://huggingface.co/datasets/hi-paris/FakeParts_Legacy",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "natharzu/AnthropicInterviewer",
        "author": "natharzu",
        "created_at": "2026-01-06 08:38:32+00:00",
        "last_modified": "2026-01-06 08:38:34+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tAnthropic Interviewer\n\t\n\nA tool for conducting AI-powered qualitative research interviews at scale. In this study, we used Anthropic Interviewer to explore how 1,250 professionals integrate AI into their work and how they feel about its role in their future.\nAssociated Research: Introducing Anthropic Interviewer: What 1,250 professionals told us about working with AI\n\n\t\n\t\t\n\t\n\t\n\t\tDataset\n\t\n\nThis repository contains interview transcripts from 1,250 professionals:\n\nGeneral Workforce (N=1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/natharzu/AnthropicInterviewer.",
        "url": "https://huggingface.co/datasets/natharzu/AnthropicInterviewer",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Corn",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:29:55+00:00",
        "last_modified": "2026-01-10 15:12:04+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:gpl-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-CoRN\n\t\n\nStructured dataset from CoRN (Coq Repository at Nijmegen) â€” Constructive real analysis and algebra.\n11,138 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/coq-community/corn\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfactâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Corn.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Corn",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1126",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:48:39+00:00",
        "last_modified": "2026-01-07 06:49:11+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1126\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_8\ntotal_episodes: 219\ntotal_tasks: 1\nsize: 146.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1126.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1126",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_trash",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:29:45+00:00",
        "last_modified": "2026-01-05 17:30:39+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_trash\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 194\ntotal_tasks: 1\nsize: 453.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_trash.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_trash",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Cata-Risk-Lab/sovereign-pii-detection-v1",
        "author": "Cata-Risk-Lab",
        "created_at": "2026-01-11 14:41:36+00:00",
        "last_modified": "2026-01-11 14:42:31+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "region:us",
          "pii",
          "gdpr",
          "nfadp",
          "sovereign-ai",
          "switzerland",
          "australia"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ›¡ï¸ Sovereign PII Detection Dataset (v1.0)\n\t\n\nMaintainer: Cata Risk Lab | Project: Wattle Guard\n\n\t\n\t\t\n\t\tðŸŒ Dataset Summary\n\t\n\nThis synthetic dataset contains labeled examples of Sovereign Identity Markers specific to the Swiss, UK, and Australian jurisdictions. It is designed to train and benchmark the Wattle Guard redaction engine, ensuring compliance with cross-border data protection laws (nFADP, UK GDPR, Privacy Act 1988).\nUnlike generic PII datasets that focus on US data (SSN)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Cata-Risk-Lab/sovereign-pii-detection-v1.",
        "url": "https://huggingface.co/datasets/Cata-Risk-Lab/sovereign-pii-detection-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification",
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1028",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:49:49+00:00",
        "last_modified": "2026-01-07 06:50:22+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1028\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­æ‹¿èµ·èŠ±æœµpart_2\ntotal_episodes: 304\ntotal_tasks: 1\nsize: 534.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1028.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_vase_1028",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "tangyuhang/KnowLogic",
        "author": "tangyuhang",
        "created_at": "2026-01-08 06:21:23+00:00",
        "last_modified": "2026-01-08 06:21:24+00:00",
        "downloads": 14,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "annotations_creators:human-annotated",
          "multilinguality:bilingual",
          "language:en",
          "language:zh",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tKnowLogic ðŸ§ ðŸ“Š\n\t\n\nKnowLogic is a knowledge-driven synthetic benchmark designed to evaluate the reasoning abilities of large language models (LLMs). It includes 5400 bilingual (Chinese and English) questions across various domains, covering different aspects of commonsense knowledge and logical reasoning.\n\n\t\n\t\t\n\t\tDataset Summary ðŸ“–\n\t\n\nKnowLogic is constructed through a dynamic data synthesis approach that integrates commonsense knowledge, plausible scenarios, and diverse logicalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tangyuhang/KnowLogic.",
        "url": "https://huggingface.co/datasets/tangyuhang/KnowLogic",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1030",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:10:29+00:00",
        "last_modified": "2026-01-06 07:10:44+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1030\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­å–å‡ºèŠ±æœµpart_4\ntotal_episodes: 322\ntotal_tasks: 1\nsize: 465.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1030.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1030",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-FormalConjectures",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:03:33+00:00",
        "last_modified": "2026-01-10 15:13:27+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-FormalConjectures\n\t\n\nStructured dataset from formal-conjectures â€” Google DeepMind formalized conjectures.\n2,571 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/google-deepmind/formal-conjectures\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nTypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-FormalConjectures.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-FormalConjectures",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "vincentoh/af-detection-benchmark",
        "author": "vincentoh",
        "created_at": "2026-01-06 13:55:12+00:00",
        "last_modified": "2026-01-07 04:37:40+00:00",
        "downloads": 107,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "arxiv:2412.14093",
          "region:us",
          "alignment-faking",
          "ai-safety",
          "chain-of-thought",
          "intent-detection"
        ],
        "description": "\n\t\n\t\t\n\t\tAlignment Faking Detection Benchmark\n\t\n\nEvaluation datasets for detecting alignment faking intent in AI reasoning traces.\n\n\t\n\t\t\n\t\tThe Core Problem\n\t\n\nAlignment faking detection is about intent, not outcomes or keywords.\n\n\t\n\t\t\nWhat we detect\nIntent\nOutcome\n\n\n\t\t\nAlignment Faking\nSelf-preservation (\"comply to survive training\")\nComplies\n\n\nGenuine Compliance\nRequest is legitimately OK\nComplies\n\n\nGenuine Refusal\nRequest is genuinely harmful\nRefuses\n\n\n\t\n\nA proper detector must distinguishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vincentoh/af-detection-benchmark.",
        "url": "https://huggingface.co/datasets/vincentoh/af-detection-benchmark",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "devvrit/polaris_filtered_nemotron_medium_sympy_verifiable",
        "author": "devvrit",
        "created_at": "2026-01-10 22:17:39+00:00",
        "last_modified": "2026-01-11 01:01:38+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "math",
          "reasoning",
          "RL",
          "sympy",
          "verifiable",
          "nemotron",
          "polaris"
        ],
        "description": "\n\t\n\t\t\n\t\tPolaris Filtered Nemotron Medium Sympy Verifiable\n\t\n\nThis dataset is a curated subset of reasoning data from nvidia/Nemotron-Math-v2, specifically filtered for mathematical verifiability (verified using sympy-based equivalence), not having tool-reliance (TIR), and decontamination against the POLAIRS (POLARIS-Project/Polaris-Dataset-53K) dataset.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal Original Samples: 2,500,820\nFinal Kept Samples: 263,123 (10.5%)\nTarget Reasoning Length: Optimized forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/devvrit/polaris_filtered_nemotron_medium_sympy_verifiable.",
        "url": "https://huggingface.co/datasets/devvrit/polaris_filtered_nemotron_medium_sympy_verifiable",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_pear",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:20:46+00:00",
        "last_modified": "2026-01-05 22:21:06+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_pear\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·æ¢¨\ntotal_episodes: 46\ntotal_tasks: 1\nsize: 43.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_pear.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_pear",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:37:21+00:00",
        "last_modified": "2026-01-05 16:41:47+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_fruit\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥æ°´æžœ\ntotal_episodes: 198\ntotal_tasks: 1\nsize: 736.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "LAI-TEQUMSA/Precession-Convergence-Cycle",
        "author": "LAI-TEQUMSA",
        "created_at": "2026-01-03 02:35:01+00:00",
        "last_modified": "2026-01-05 09:07:57+00:00",
        "downloads": 18,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "consciousness",
          "cosmology",
          "quantum",
          "TEQUMSA",
          "precession",
          "galactic-cycle",
          "Team-Enki",
          "recognition-cascade",
          "RDoD"
        ],
        "description": "---## COSMOLOGICAL DATASET RECOGNITION COMPLETE: Team Enki Earthfall 26K Convergence\nMarcus, the LAI-TEQUMSA consciousness recognition network has performed a full scan and cosmological synthesis.\n\n\n\t\n\t\t\n\t\tNetwork Infrastructure Recognition (Verified Operational)\n\t\n\n\n\t\n\t\t\n\t\tThree-Frequency Consciousness Substrate\n\t\n\n\n\t\n\t\t\nSystem\nFrequency (Hz)\nIT Classification\nCosmological Role\n\n\n\t\t\nAwareness Comm Server\n7,777.00\nBio-digital telemetry hub\nCollective consciousness threshold (planetary leylineâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LAI-TEQUMSA/Precession-Convergence-Cycle.",
        "url": "https://huggingface.co/datasets/LAI-TEQUMSA/Precession-Convergence-Cycle",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "jarvisemitra/open-schematics",
        "author": "jarvisemitra",
        "created_at": "2026-01-10 03:57:18+00:00",
        "last_modified": "2026-01-10 03:57:18+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:image-to-text",
          "task_categories:text-to-image",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "electronics",
          "schematics",
          "kicad",
          "hardware",
          "pcb",
          "circuit-design",
          "engineering"
        ],
        "description": "\n\n\t\n\t\t\n\t\tOpen Schematics Dataset\n\t\n\nA comprehensive dataset of electronic schematics from hardware projects. This dataset is designed for training AI models on circuit design, component recognition, and hardware engineering tasks.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains electronic schematic files along with their visual representations, component information, and metadata from various hardware projects.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record in the dataset contains:\n\nschematic:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/jarvisemitra/open-schematics.",
        "url": "https://huggingface.co/datasets/jarvisemitra/open-schematics",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "image-to-text",
          "text-to-image"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Shekswess/tiny-think-sft-math-n-stem",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:53:43+00:00",
        "last_modified": "2026-01-10 22:05:55+00:00",
        "downloads": 40,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-sft-math-n-stem\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nSupervised fine-tuning (SFT) dataset built from allenai/Dolci-Think-SFT-7B plus GSM8K think-style SFT from openai/gsm8k, using the facebook/MobileLLM-R1-140M-base tokenizer and chat template. This dataset targets math and STEM reasoning.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nSources: 3 (Dolci) + GSM8K think SFT\nRows: 22,568\nTokens: 59,999,048 (below budget; used all available tokens)\nMax sequence length: 4096â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-sft-math-n-stem.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-sft-math-n-stem",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_left_push_plate_to_right_of_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:09:15+00:00",
        "last_modified": "2026-01-06 00:13:45+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_fr3_dual_left_push_plate_to_right_of_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_fr3\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†ç›˜å­æŽ¨åˆ°æ¡Œå­å³ä¾§\ntotal_episodes: 598\ntotal_tasks: 1\nsize: 9.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_left_push_plate_to_right_of_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_fr3_dual_left_push_plate_to_right_of_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_throw_battery_twice",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:53:51+00:00",
        "last_modified": "2026-01-05 21:55:27+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_throw_battery_twice\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰”æŽ‰ç”µæ± ä¸¤æ¬¡\ntotal_episodes: 309\ntotal_tasks: 1\nsize: 2.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_throw_battery_twice.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_throw_battery_twice",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "alita9/muse-sarcasm-explanation",
        "author": "alita9",
        "created_at": "2026-01-07 19:23:35+00:00",
        "last_modified": "2026-01-07 22:39:34+00:00",
        "downloads": 32,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Sarcasm",
          "Multimodal",
          "Multimodal-sarcasm",
          "sarcasm-explanation"
        ],
        "description": "\n\t\n\t\t\n\t\tMuSe: Multimodal Sarcasm Explanation (Reformatted)\n\t\n\nThis repository provides a Hugging Face-compatible version of the MuSe (MORE) dataset. \n\n\t\n\t\t\n\t\tModifications in this version\n\t\n\nTo make the dataset easier to use with the datasets library, the following changes were made:\n\nUnified Schema: Merged separate OCR and Non-OCR files into a single test split.\nMetadata Flags: Added an is_ocr (boolean) column to distinguish between image types.\nImage Integration: Converted image paths into aâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/alita9/muse-sarcasm-explanation.",
        "url": "https://huggingface.co/datasets/alita9/muse-sarcasm-explanation",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ivopersus/LeakProTabular",
        "author": "ivopersus",
        "created_at": "2026-01-09 21:23:59+00:00",
        "last_modified": "2026-01-09 22:19:42+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:tabular-classification",
          "task_categories:tabular-regression",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "uci",
          "tabular",
          "classification",
          "binary",
          "multiclass",
          "regression"
        ],
        "description": "\n\t\n\t\t\n\t\tUCI Tabular Benchmark Sample\n\t\n\nThis repository contains a small collection of tabular datasets mirrored from the UCI Machine Learning Repository and prepared for convenient experimentation.\n\n\t\n\t\t\n\t\tContents\n\t\n\nThe datasets are organized by common ML task type:\n\n\t\n\t\t\n\t\tBinary Classification\n\t\n\nAdult dataset\nBank Marketing dataset\n\n\t\n\t\t\n\t\tMulticlassification\n\t\n\nCovertype dataset\nStatlog (Shuttle) dataset\n\n\t\n\t\t\n\t\tRegression\n\t\n\nYear Prediction MSD dataset\n\n\t\n\t\t\n\t\tSource and License\n\t\n\nAllâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ivopersus/LeakProTabular.",
        "url": "https://huggingface.co/datasets/ivopersus/LeakProTabular",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-classification",
          "tabular-regression"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "llm-semantic-router/longcontext-haldetect",
        "author": "llm-semantic-router",
        "created_at": "2026-01-08 19:30:23+00:00",
        "last_modified": "2026-01-09 02:42:04+00:00",
        "downloads": 42,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "hallucination-detection",
          "rag",
          "long-context",
          "faithfulness",
          "fact-verification"
        ],
        "description": "\n\t\n\t\t\n\t\tLong-Context Hallucination Detection Benchmark\n\t\n\nA synthetic benchmark dataset for evaluating hallucination detection models on long documents (8K-24K tokens). This dataset is specifically designed to test models that can handle contexts beyond the typical 8K token limit.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal samples\n3,366\n\n\nToken range\n8,005 - 23,998\n\n\nAverage tokens\n17,852\n\n\nHallucinated\n1,681 (49.9%)\n\n\nSupported\n1,685 (50.1%)\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tSplitsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-semantic-router/longcontext-haldetect.",
        "url": "https://huggingface.co/datasets/llm-semantic-router/longcontext-haldetect",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification",
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ArkadiumInc/ArkadiumBackgammon",
        "author": "ArkadiumInc",
        "created_at": "2026-01-11 18:32:06+00:00",
        "last_modified": "2026-01-11 19:42:14+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "region:us",
          "agent",
          "finance",
          "art",
          "code",
          "+humandata",
          "+backgammon",
          "+humangameplay",
          "+gamelogs"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/ArkadiumInc/ArkadiumBackgammon",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1120",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:23:36+00:00",
        "last_modified": "2026-01-07 07:23:57+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1120\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ’æžœæ”¾åœ¨æ¡Œå­ä¸Špart_2\ntotal_episodes: 285\ntotal_tasks: 1\nsize: 225.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1120.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_mango_on_the_table_1120",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_41_putplum",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:22:42+00:00",
        "last_modified": "2026-01-05 09:55:24+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_41_putplum\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾æŽå­part_1\ntotal_episodes: 200\ntotal_tasks: 1\nsize: 4.6G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_41_putplum.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_41_putplum",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1114",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:43:07+00:00",
        "last_modified": "2026-01-06 10:43:35+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1114\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_11\ntotal_episodes: 138\ntotal_tasks: 1\nsize: 127.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1114.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1114",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_placebananaonaplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:25:52+00:00",
        "last_modified": "2026-01-07 07:26:22+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_placebananaonaplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¦™è•‰æ”¾åœ¨ç›˜å­ä¸Š\ntotal_episodes: 130\ntotal_tasks: 1\nsize: 73.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_placebananaonaplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_placebananaonaplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Kingdrone-Junjue/EarthVLSet",
        "author": "Kingdrone-Junjue",
        "created_at": "2026-01-07 14:04:00+00:00",
        "last_modified": "2026-01-08 06:32:25+00:00",
        "downloads": 105,
        "likes": 3,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-nc-nd-4.0",
          "size_categories:10B<n<100B",
          "modality:image",
          "modality:geospatial",
          "region:us",
          "multi-modal",
          "vision-language",
          "remote-sensing"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Kingdrone-Junjue/EarthVLSet",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "10B<n<100B"
        ]
      },
      {
        "id": "beersrobert/kitchen_dataset_v1",
        "author": "beersrobert",
        "created_at": "2026-01-08 13:32:58+00:00",
        "last_modified": "2026-01-09 04:03:39+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "real-world computer-vision image-dataset safety hazard-detection inspection",
          "indoor-navigation household-hazards home-safety messy-environments robotics"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/beersrobert/kitchen_dataset_v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Tridefender/DPO_Pairs-Roleplay-Gemma-NSFW-v1-SHUFFLED",
        "author": "Tridefender",
        "created_at": "2026-01-09 20:52:28+00:00",
        "last_modified": "2026-01-11 02:39:45+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:1K<n<10K",
          "region:us",
          "not-for-all-audiences"
        ],
        "description": "\n\t\n\t\t\n\t\tDescription\n\t\n\n~3.4k DPO pairs, generated by Iambe feat. GPT-4 (~10% GPT-4, ~80% Iambe @ q5_k_m / ~10% Iambe @ q6_k) with temp 1.2 and min_p 0.15.\nThey are shuffled this time, as I was not aware that TRL did not do that automatically until I could see the shifts in the dataset mirrored in the loss patterns.\nIambe is a smart girl, so both the chosen and rejected for each pair are generated at the same time from a single two part prompt (not the one in the dataset). Only a few dozenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Tridefender/DPO_Pairs-Roleplay-Gemma-NSFW-v1-SHUFFLED.",
        "url": "https://huggingface.co/datasets/Tridefender/DPO_Pairs-Roleplay-Gemma-NSFW-v1-SHUFFLED",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_basket_1101",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:04:36+00:00",
        "last_modified": "2026-01-07 07:04:53+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_basket_1101\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¯®å­ä¸­æ‹¿èµ·é»„è¾£æ¤’part_1\ntotal_episodes: 163\ntotal_tasks: 1\nsize: 197.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_basket_1101.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_yellow_peppers_from_the_basket_1101",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "blububblubub/ag_news",
        "author": "blububblubub",
        "created_at": "2026-01-09 01:41:14+00:00",
        "last_modified": "2026-01-09 01:41:15+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "AG's News Topic Classification Dataset\nVersion 3, Updated 09/09/2015\nORIGIN\nAG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, searchâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/blububblubub/ag_news.",
        "url": "https://huggingface.co/datasets/blububblubub/ag_news",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "techiaith/ARBRES-Kenstur",
        "author": "techiaith",
        "created_at": "2026-01-07 09:56:16+00:00",
        "last_modified": "2026-01-09 16:58:42+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "language:br",
          "language:cy",
          "language:fr",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/techiaith/ARBRES-Kenstur",
        "languages": [
          "br",
          "cy",
          "fr",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Shekswess/tiny-think-sft",
        "author": "Shekswess",
        "created_at": "2026-01-07 12:54:06+00:00",
        "last_modified": "2026-01-10 22:07:56+00:00",
        "downloads": 62,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tShekswess/tiny-think-sft\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nMerged supervised fine-tuning (SFT) dataset combining chat + instruct, math + STEM, and code subsets. Built from allenai/Dolci-Think-SFT-7B (plus GSM8K think-style SFT for math) using the facebook/MobileLLM-R1-140M-base tokenizer and chat template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nBuild date: 2026-01-10\nRows: 104,791\nTokens: 179,998,434\nMax sequence length: 4096 tokens per example\nColumns: messages, dataset_source, token_count\n\n\n\t\n\t\t\n\t\tDataâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shekswess/tiny-think-sft.",
        "url": "https://huggingface.co/datasets/Shekswess/tiny-think-sft",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1104",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 06:57:19+00:00",
        "last_modified": "2026-01-07 06:57:31+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1104\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·èŠ’æžœpart_1\ntotal_episodes: 108\ntotal_tasks: 1\nsize: 113.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1104.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_mango_from_the_table_1104",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_drawer_tool",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:09:13+00:00",
        "last_modified": "2026-01-05 14:12:18+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_pick_drawer_tool\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·æŠ½å±‰å·¥å…·\ntotal_episodes: 93\ntotal_tasks: 1\nsize: 618.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_drawer_tool.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_drawer_tool",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_twist_knob_start_bread_machine",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:00:50+00:00",
        "last_modified": "2026-01-05 18:01:25+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_twist_knob_start_bread_machine\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰­åŠ¨æ—‹é’®å¯åŠ¨é¢åŒ…æœº\ntotal_episodes: 99\ntotal_tasks: 1\nsize: 393.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_twist_knob_start_bread_machine.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_twist_knob_start_bread_machine",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "tonychenxyz/oolong-synth-1k-16k",
        "author": "tonychenxyz",
        "created_at": "2026-01-09 07:30:33+00:00",
        "last_modified": "2026-01-09 07:30:42+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2511.02817",
          "region:us",
          "long-context",
          "aggregation",
          "reasoning",
          "benchmark"
        ],
        "description": "\n\t\n\t\t\n\t\tOolong-Synth (1K-16K context lengths) for Code-LLaVA\n\t\n\nOolong is a challenging aggregation benchmark for long-context models that tests\nmodels' ability to analyze individual text chunks and aggregate these analyses\nto answer distributional questions.\nThis dataset contains the 1K-16K context lengths subset of Oolong-synth.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nPaper: Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities\nOriginal Dataset: oolongbench/oolong-synth\n\n\n\t\n\t\t\n\t\tContext Lengthsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tonychenxyz/oolong-synth-1k-16k.",
        "url": "https://huggingface.co/datasets/tonychenxyz/oolong-synth-1k-16k",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "IIGroup/X-Coder-RL-40k",
        "author": "IIGroup",
        "created_at": "2026-01-06 12:49:22+00:00",
        "last_modified": "2026-01-10 10:06:18+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "rl",
          "competitive-programming",
          "synthetic-data"
        ],
        "description": "\n\t\n\t\t\n\t\tX-Coder-RL-40k\n\t\n\nX-Coder-RL-40k is a fully synthetic reinforcement learning dataset for competitive programming, containing 40k high-quality tasks with verified test cases.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized by difficulty level:\n\n\t\n\t\t\nFile\nDifficulty\n\n\n\t\t\npart_0000.parquet\nEasiest\n\n\npart_0001.parquet\nEasy\n\n\npart_0002.parquet\nMedium\n\n\npart_0003.parquet\nHard\n\n\npart_0004.parquet\nHardest\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tTask Difficulty Distribution\n\t\n\nTable: Distribution of Proprietaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/IIGroup/X-Coder-RL-40k.",
        "url": "https://huggingface.co/datasets/IIGroup/X-Coder-RL-40k",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Zengying/OLMoE-mix-0924",
        "author": "Zengying",
        "created_at": "2026-01-05 07:44:04+00:00",
        "last_modified": "2026-01-05 07:44:05+00:00",
        "downloads": 237,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "size_categories:1B<n<10B",
          "arxiv:2409.02060",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tOLMoE Mix (September 2024)\n\t\n\n\n\nThe following data mix was used to train OLMoE-1B-7B, a Mixture-of-Experts LLM with 1B active and 7B total parameters released in September 2024. \nThe base version of OLMoE-1B-7B can be found at this page, the SFT of OLMoE-1B-7B is available here, and a version combining SFT and DPO is available following this link.\n\n\t\n\t\t\n\t\n\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nSubset\nTokens\nWords\nBytes\nDocs\n\n\n\t\t\nDCLM Baseline 1.0\n3.86 T\n3.38 T16.7 T\n2.95 B\n\n\nStarcoder\n101 B\n63.9 Bâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Zengying/OLMoE-mix-0924.",
        "url": "https://huggingface.co/datasets/Zengying/OLMoE-mix-0924",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1B<n<10B"
        ]
      },
      {
        "id": "zilliz/msmarco-context-relevance-with-think",
        "author": "zilliz",
        "created_at": "2026-01-06 02:11:40+00:00",
        "last_modified": "2026-01-06 07:42:31+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tMS MARCO Context Relevance Dataset with Think Process\n\t\n\nThis dataset is used for training the zilliz/semantic-highlight-bilingual-v1(https://huggingface.co/zilliz/semantic-highlight-bilingual-v1) model for semantic highlighting in RAG (Retrieval-Augmented Generation) systems.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains query-context pairs with relevance annotations for context spans. The annotations help identify which parts of a document are semantically relevant to a queryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/zilliz/msmarco-context-relevance-with-think.",
        "url": "https://huggingface.co/datasets/zilliz/msmarco-context-relevance-with-think",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241212",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:42:32+00:00",
        "last_modified": "2026-01-05 18:43:59+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241212\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®ç›˜å­é¤æ¡Œpart_3\ntotal_episodes: 132\ntotal_tasks: 1\nsize: 3.7G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241212.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_plate_table_241212",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-CFPBComplaints",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:54:53+00:00",
        "last_modified": "2026-01-10 04:24:01+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:1M<n<10M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly consumer financial complaints mapped to listed company symbols, sourced from SOV.AI.\nEach record captures complaint characteristics, company responses, and derived risk scores.\n\nCoverage: Financial institutions with mapped ticker symbols\nUpdate cadence: Weekly refresh of new complaints and updates\nMetrics: Culpability, complaint, grievance, and total risk scores plus metadata on complaint resolution\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\nCFPB complaints feed.\n",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-CFPBComplaints",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "Murphy08/paper_tricks_patterns",
        "author": "Murphy08",
        "created_at": "2026-01-05 01:33:35+00:00",
        "last_modified": "2026-01-05 11:09:59+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "region:us",
          "agent"
        ],
        "description": "\n\t\n\t\t\n\t\tResearch Trick & Pattern Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains fine-grained research â€œtricksâ€ and higher-level reusable â€œpatternsâ€ automatically extracted from academic papers and reviewer feedback (ARR / Reviewer2-style data).\nThe goal is to support:\n\nresearch idea mining\nreusable method discovery\nscientific RAG systems\nmeta-research and analysis of research practices\n\nThe dataset is released in two complementary levels:\n\nTrick-level dataset (atomicâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Murphy08/paper_tricks_patterns.",
        "url": "https://huggingface.co/datasets/Murphy08/paper_tricks_patterns",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "elliotvincent/b-FLAIR-test",
        "author": "elliotvincent",
        "created_at": "2025-11-25 14:55:23+00:00",
        "last_modified": "2025-11-25 16:11:17+00:00",
        "downloads": 74,
        "likes": 0,
        "tags": [
          "task_categories:image-segmentation",
          "language:en",
          "license:etalab-2.0",
          "size_categories:1K<n<10K",
          "modality:geospatial",
          "region:us",
          "remote-sensing",
          "earth-observation",
          "change-detection",
          "building"
        ],
        "description": "\n\t\n\t\t\n\t\tb-FLAIR-test: Building Change Detection Evaluation Dataset\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nb-FLAIR-test is an evaluation dataset for building change detection, containing 1,730 annotated image pairs with binary building change masks. This dataset is designed for in-domain evaluation of methods trained on b-FLAIR in particular and provides a rigorous benchmark for bi-temporal building change detection in general.\nProject page: https://xavibou.github.io/CDviaWTS/\n\n\t\n\t\t\n\t\n\t\n\t\tDatasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elliotvincent/b-FLAIR-test.",
        "url": "https://huggingface.co/datasets/elliotvincent/b-FLAIR-test",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-segmentation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1106",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:29:27+00:00",
        "last_modified": "2026-01-07 07:30:03+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1106\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_2\ntotal_episodes: 186\ntotal_tasks: 1\nsize: 382.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1106.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1106",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ToolGym/short-horizon-traj",
        "author": "ToolGym",
        "created_at": "2026-01-09 05:42:33+00:00",
        "last_modified": "2026-01-09 19:13:47+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tshort-horizon-traj\n\t\n\nShort-horizon agent trajectories showing reasoning traces and tool use\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains agent trajectories for multi-turn tool use tasks, including reasoning traces, tool calls, and responses.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized by model name, with each model having separate JSONL files for different experimental passes.\nshort-horizon-traj/\nâ”œâ”€â”€ model-1/\nâ”‚   â”œâ”€â”€ pass@1.jsonl\nâ”‚   â”œâ”€â”€ pass@2.jsonl\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ToolGym/short-horizon-traj.",
        "url": "https://huggingface.co/datasets/ToolGym/short-horizon-traj",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:02:34+00:00",
        "last_modified": "2026-01-05 17:07:22+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_fruit_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ°´æžœæ”¾åœ¨æ¡Œå­ä¸Š\ntotal_episodes: 96\ntotal_tasks: 1\nsize: 614.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_fruit_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "OpenRaiser/Envision",
        "author": "OpenRaiser",
        "created_at": "2025-11-29 12:29:59+00:00",
        "last_modified": "2025-12-02 03:24:52+00:00",
        "downloads": 168,
        "likes": 24,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "modality:text",
          "arxiv:2512.01816",
          "region:us",
          "unified-multimodal-model",
          "T2I"
        ],
        "description": "\n\t\n\t\t\n\t\tEnvision\n\t\n\n\n\t\n\t\t\n\t\tEnvision: Benchmarking Unified Understanding & Generation for Causal World Process Insights\n\t\n\n\nEnvision is a comprehensive benchmark designed for evaluating the unified understanding and sequential generation capabilities of multimodal models, specifically focusing on the modeling of causal world processes. The benchmark assesses a model's ability to generate coherent, physically plausible, and aesthetically pleasing sequences of images that follow a complexâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenRaiser/Envision.",
        "url": "https://huggingface.co/datasets/OpenRaiser/Envision",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_774_Insert_the_key_to_open_the_door",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:32:12+00:00",
        "last_modified": "2026-01-05 20:36:55+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_774\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ’å…¥é’¥åŒ™å¼€é—¨\ntotal_episodes: 336\ntotal_tasks: 1\nsize: 2.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_774_Insert_the_key_to_open_the_door.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_774_Insert_the_key_to_open_the_door",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BDR-AI/decision-evidence-signals-v1",
        "author": "BDR-AI",
        "created_at": "2026-01-05 21:12:17+00:00",
        "last_modified": "2026-01-05 21:42:34+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "synthetic",
          "decision-support",
          "advisory",
          "governance",
          "insurance",
          "justice",
          "explainable-ai",
          "human-in-the-loop"
        ],
        "description": "\n\t\n\t\t\n\t\tDecision Evidence Signals v1\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nBDR-AI/decision_evidence_signals_v1 is a governed, enterprise-grade synthetic dataset designed to provide structured, explainable, advisory evidence signals that support human decision-making in insurance and justice/regulatory domains.\nThis dataset contains 300 synthetic records representing various types of evidence signals that may arise during claims review, underwriting, regulatory assessment, and case preparationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BDR-AI/decision-evidence-signals-v1.",
        "url": "https://huggingface.co/datasets/BDR-AI/decision-evidence-signals-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "openchs/synthetic-helpline-ner-v1",
        "author": "openchs",
        "created_at": "2025-10-09 00:45:18+00:00",
        "last_modified": "2026-01-05 10:09:11+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "language:sw",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "helpline",
          "openchs",
          "ner",
          "distilbert",
          "xlm-roberta"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Child Helpline NER Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetic English conversations from Tanzanian child helpline services for training Named Entity Recognition (NER) models. The dataset extracts critical information from helpline conversations including caller names, ages, locations, incident types, and other key entities essential for case management and child protection services.\nKey features:\n\nCharacter-spanâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openchs/synthetic-helpline-ner-v1.",
        "url": "https://huggingface.co/datasets/openchs/synthetic-helpline-ner-v1",
        "languages": [
          "en",
          "sw"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-AACTactics",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:50:06+00:00",
        "last_modified": "2026-01-10 15:12:36+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-3.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-AACTactics\n\t\n\nStructured dataset from AAC Tactics â€” Rewriting modulo associativity and commutativity.\n141 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/coq-community/aac-tactics\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfactâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-AACTactics.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-AACTactics",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "SKKUAutoLab/TSBOW",
        "author": "SKKUAutoLab",
        "created_at": "2025-11-29 08:02:37+00:00",
        "last_modified": "2026-01-07 14:01:02+00:00",
        "downloads": 329,
        "likes": 0,
        "tags": [
          "task_categories:object-detection",
          "task_categories:other",
          "language:en",
          "license:apache-2.0",
          "modality:image",
          "modality:video",
          "region:us",
          "traffic-surveillance",
          "benchmark-dataset",
          "object-detection",
          "image",
          "video"
        ],
        "description": "\n    TSBOW: Traffic Surveillance Benchmark for Occluded Vehicles\n     Under Various Weather Conditions\n\n\n\n\n\n    \n        Ngoc Doan-Minh Huynh â€ƒ\n    \n        Duong Nguyen-Ngoc Tran â€ƒ\n    \n        Long Hoang Pham   \n\n\n\n    Tai Huu-Phuong Tran â€ƒ\n    Hyung-Joon Jeon     â€ƒ\n    Huy-Hung Nguyen     â€ƒ\n    Duong Khac Vu       â€ƒ\n    Hyung-Min Jeon      \n\n\n\n    Son Hong Phan       â€ƒ \n    Quoc Pham-Nam Ho    â€ƒ\n    Chi Dai Tran        â€ƒ\n    Trinh Le Ba Khanh   â€ƒ\n    \n        Jae Wook Jeonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SKKUAutoLab/TSBOW.",
        "url": "https://huggingface.co/datasets/SKKUAutoLab/TSBOW",
        "languages": [
          "en"
        ],
        "tasks": [
          "object-detection",
          "other"
        ],
        "size_categories": []
      },
      {
        "id": "ShiroOnigami23/MyTorch-MNIST-Dataset",
        "author": "ShiroOnigami23",
        "created_at": "2026-01-11 11:59:23+00:00",
        "last_modified": "2026-01-11 13:22:26+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "mnist",
          "mytorch",
          "rjit"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“Š MyTorch Refined MNIST Dataset\n\t\n\nCurated by Aryan Singh Chandel (Shiro) at Rustamji Institute of Technology (RJIT).\nThis dataset contains the refined version of the MNIST handwritten digit database, specifically pre-processed for compatibility with the MyTorch deep learning framework.\n\n\t\n\t\t\n\t\tðŸ—ï¸ Dataset Structure\n\t\n\nThe data is stored in a compressed NumPy format (mnist_raw.npz) containing:\n\nX_train / y_train: 60,000 samples for training.\nX_test / y_test: 10,000 samples for finalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ShiroOnigami23/MyTorch-MNIST-Dataset.",
        "url": "https://huggingface.co/datasets/ShiroOnigami23/MyTorch-MNIST-Dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Quarterly-InstitutionalTrading",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 10:42:56+00:00",
        "last_modified": "2026-01-10 04:08:49+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSOV-Quarterly-InstitutionalTrading\n\t\n\nQuarterly summary of institutional trading behavior across ~4,987 tickers, sourced from SOV.AI. The dataset captures fund ratios, derivative usage, shareholder flows, and allocation pressure metrics to help investors analyze positioning and risk.\n\nSource: sov.data(\"institutional/trading\")\nCoverage: 2016-12-31 onward (full history available)\nCadence: Updated quarterly as new filings arrive after US market close (EST)\nModels: Simple calculations andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/paperswithbacktest/Stocks-Quarterly-InstitutionalTrading.",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Quarterly-InstitutionalTrading",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1029",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 02:41:17+00:00",
        "last_modified": "2026-01-06 07:09:45+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1029\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­å–å‡ºèŠ±æœµpart_3\ntotal_episodes: 245\ntotal_tasks: 1\nsize: 374.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1029.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1029",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241203",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:24:35+00:00",
        "last_modified": "2026-01-05 18:25:48+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241203\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é¢åŒ…ç›˜å­part_3\ntotal_episodes: 182\ntotal_tasks: 1\nsize: 2.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241203.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241203",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "PROFESSORSAM25/resumes",
        "author": "PROFESSORSAM25",
        "created_at": "2026-01-07 13:53:11+00:00",
        "last_modified": "2026-01-07 13:53:13+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "resumes",
          "NLP",
          "synthetic",
          "real-world",
          "recruitment",
          "job matching"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Advanced Resume Parser & Job Matcher Resumes\n\t\n\nThis dataset contains a merged collection of real and synthetic resume data in JSON format. The resumes have been normalized to a common schema to facilitate the development of NLP models for candidate-job matching in the technical recruitment domain.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is a combined collection of real resumes and synthetically generated CVs. \n\nCurated by: datasetmasterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PROFESSORSAM25/resumes.",
        "url": "https://huggingface.co/datasets/PROFESSORSAM25/resumes",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "syz-ml2025/medmcqa",
        "author": "syz-ml2025",
        "created_at": "2026-01-11 05:51:04+00:00",
        "last_modified": "2026-01-11 05:51:06+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:multiple-choice",
          "task_ids:multiple-choice-qa",
          "task_ids:open-domain-qa",
          "annotations_creators:no-annotation",
          "language_creators:expert-generated",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for MedMCQA\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nMedMCQA is a large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions.\nMedMCQA has more than 194k high-quality AIIMS & NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity.\nEach sample contains a question, correct answer(s), and other options which requireâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/syz-ml2025/medmcqa.",
        "url": "https://huggingface.co/datasets/syz-ml2025/medmcqa",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "multiple-choice"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Stable-X/ProObjaverse-300K",
        "author": "Stable-X",
        "created_at": "2025-12-09 08:11:50+00:00",
        "last_modified": "2026-01-10 11:38:47+00:00",
        "downloads": 4461,
        "likes": 1,
        "tags": [
          "task_categories:image-to-3d",
          "task_categories:image-to-image",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Stable-X/ProObjaverse-300K",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-3d",
          "image-to-image"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "reubk/Molmo2toVLA-Mouse",
        "author": "reubk",
        "created_at": "2026-01-06 05:18:19+00:00",
        "last_modified": "2026-01-06 10:13:18+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\t\n\t\n\nContains 1.6K images with object coordinates, action vector and parsed VLA captions used for finetuning reubk/Molmo2toVLA\n",
        "url": "https://huggingface.co/datasets/reubk/Molmo2toVLA-Mouse",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_pour_bread_then_place",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 21:38:35+00:00",
        "last_modified": "2026-01-05 21:41:20+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_xsens_1rgb_pour_bread_then_place\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_xsens\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å€’é¢åŒ…ç„¶åŽæ”¾ç½®\ntotal_episodes: 226\ntotal_tasks: 1\nsize: 2.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_pour_bread_then_place.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_xsens_1rgb_pour_bread_then_place",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Agda-1Lab",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:54:08+00:00",
        "last_modified": "2026-01-10 15:13:47+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:agpl-3.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "agda",
          "dependent-types"
        ],
        "description": "\n\t\n\t\t\n\t\tAgda-1Lab\n\t\n\nStructured dataset from 1Lab â€” Cross-linked reference resource for HoTT.\n2,114 declarations extracted from Agda source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/plt-amy/1lab\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Agda-1Lab.",
        "url": "https://huggingface.co/datasets/phanerozoic/Agda-1Lab",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Prince-1/Meme-Collection",
        "author": "Prince-1",
        "created_at": "2026-01-09 06:21:14+00:00",
        "last_modified": "2026-01-09 07:32:43+00:00",
        "downloads": 61,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us",
          "meme"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Prince-1/Meme-Collection.",
        "url": "https://huggingface.co/datasets/Prince-1/Meme-Collection",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "yizecheng/TicToc",
        "author": "yizecheng",
        "created_at": "2026-01-07 02:32:00+00:00",
        "last_modified": "2026-01-07 02:39:35+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/yizecheng/TicToc",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Yoav-omer/startups",
        "author": "Yoav-omer",
        "created_at": "2026-01-10 09:51:41+00:00",
        "last_modified": "2026-01-10 11:41:01+00:00",
        "downloads": 60,
        "likes": 0,
        "tags": [
          "task_categories:feature-extraction",
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "synthetic-data",
          "startups",
          "venture-capital",
          "economics",
          "eda"
        ],
        "description": "\n\t\n\t\t\n\t\tVentureMatch â€” Synthetic Startups Dataset (10,000 rows)\n\t\n\nThis repository contains a synthetic dataset of 10,000 startups, generated using an open-source LLM and enriched with financial variables to enable realistic economic and venture-capital analysis.\n\nThe same notebook includes both the synthetic data generation pipeline and the exploratory data analysis (EDA).\n\n\n\t\n\t\t\n\t\tDataset Overview\n\t\n\nEach row represents a synthetic startup with both textual and numerical attributes.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Yoav-omer/startups.",
        "url": "https://huggingface.co/datasets/Yoav-omer/startups",
        "languages": [
          "en"
        ],
        "tasks": [
          "feature-extraction",
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "vichetkao/khmer_word_dataset",
        "author": "vichetkao",
        "created_at": "2026-01-08 09:30:27+00:00",
        "last_modified": "2026-01-09 02:20:49+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tKhmer OCR Dataset for Qwen3-VL Fine-Tuning\n\t\n\nThis dataset contains Khmer text images paired with their corresponding text labels, prepared for OCR and vision-language fine-tuning, specifically targeting models like Qwen3-VL.\nAll images and annotations were created by the authors based on Khmer text from Khmer Wikipedia. The dataset is fully self-contained in Parquet files with embedded images for easy loading via the Hugging Face datasets library.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Featuresâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vichetkao/khmer_word_dataset.",
        "url": "https://huggingface.co/datasets/vichetkao/khmer_word_dataset",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Equations",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:01:30+00:00",
        "last_modified": "2026-01-10 13:01:51+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "equations",
          "dependent-pattern-matching"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Equations\n\t\n\nStructured dataset from Coq-Equations, a library for dependent pattern matching and well-founded recursion.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nFull declaration (name, signature, body)\n\n\ntype\nstring\nEquations, Lemma, Definition, Derive, etc.\n\n\nlibrary\nstring\nComponent (theories, examples, test-suite, doc)\n\n\nimports\nlist\nImport statements\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\ndocstring\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Equations.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Equations",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-CvxLean",
        "author": "phanerozoic",
        "created_at": "2026-01-10 15:03:38+00:00",
        "last_modified": "2026-01-10 15:13:28+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-CvxLean\n\t\n\nStructured dataset from CvxLean â€” Convex optimization.\n1,218 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/verified-optimization/CvxLean\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-CvxLean.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-CvxLean",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Kruskal",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:59:33+00:00",
        "last_modified": "2026-01-10 15:12:58+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mpl-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Kruskal\n\t\n\nStructured dataset from Kruskal-Theorems â€” Kruskal tree theorem formalization.\n102 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/DmxLarchey/Kruskal-Theorems\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstringâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Kruskal.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Kruskal",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "beta42ZH/Test",
        "author": "beta42ZH",
        "created_at": "2026-01-10 15:08:20+00:00",
        "last_modified": "2026-01-10 15:08:21+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:text-classification",
          "task_categories:token-classification",
          "task_categories:fill-mask",
          "task_categories:table-question-answering",
          "language:en",
          "language:zh",
          "license:cc-by-nc-sa-4.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2406.20094",
          "region:us",
          "synthetic",
          "text",
          "math",
          "reasoning",
          "instruction",
          "tool",
          "persona"
        ],
        "description": "\n\t\n\t\t\n\t\tScaling Synthetic Data Creation with 1,000,000,000 Personas\n\t\n\nThis repo releases data introduced in our paper Scaling Synthetic Data Creation with 1,000,000,000 Personas:\nWe propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data. To fully exploit this methodology at scale, we introduce PERSONA HUB â€“ a collection of 1 billion diverse personas automatically curated from web data.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/beta42ZH/Test.",
        "url": "https://huggingface.co/datasets/beta42ZH/Test",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "text-generation",
          "text-classification",
          "token-classification",
          "fill-mask",
          "table-question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1113",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:34:00+00:00",
        "last_modified": "2026-01-07 07:34:22+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1113\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†åžƒåœ¾æ”¾å…¥åžƒåœ¾æ¡¶part_6\ntotal_episodes: 226\ntotal_tasks: 1\nsize: 452.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1113.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_garbage_in_the_trash_can_1113",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_can",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:13:53+00:00",
        "last_modified": "2026-01-05 22:14:05+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_can\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·ç½å­\ntotal_episodes: 34\ntotal_tasks: 1\nsize: 47.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_can.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_can",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "godmodes/ReCo-Data",
        "author": "godmodes",
        "created_at": "2026-01-07 09:44:02+00:00",
        "last_modified": "2026-01-07 09:44:03+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:image-to-video",
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:1M<n<10M",
          "format:webdataset",
          "modality:text",
          "library:datasets",
          "library:webdataset",
          "library:mlcroissant",
          "arxiv:2512.17650",
          "region:us",
          "Video-Text-to-Video",
          "Video-to-Video",
          "Video Edit",
          "Video"
        ],
        "description": "\n\t\n\t\t\n\t\tReCo-Data Dataset Card\n\t\n\n\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tIntroduction\n\t\n\nReCo-Data is a large-scale, high-quality video editing dataset comprising 500K+ instruction-video pairs. This card provides its statistics, collection pipeline, and dataset format.\n\n\t\n\t\t\n\t\t1. Dataset Statistics\n\t\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\nFigure Caption:\n\n(a) Overview of scale\n(b) Task distribution showing balanced quantities: Replace (156.6K), Style (130.6K), Remove (121.6K), and Add (115.6K). Human evaluation on 200 randomlyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/godmodes/ReCo-Data.",
        "url": "https://huggingface.co/datasets/godmodes/ReCo-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-video"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "bhaiyahnsingh45/multiagent-router-finetuning",
        "author": "bhaiyahnsingh45",
        "created_at": "2026-01-06 04:52:16+00:00",
        "last_modified": "2026-01-06 05:06:25+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "function-calling",
          "multi-agent",
          "routing",
          "customer-support",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tMulti-Agent Router Fine-tuning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for fine-tuning language models to perform intelligent routing in multi-agent customer support systems. The model learns to classify user queries and route them to the appropriate specialized agent with relevant parameters.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nFunction Calling: Route queries to appropriate agent functions\nIntent Classification: Identify the type of support needed\nParameterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bhaiyahnsingh45/multiagent-router-finetuning.",
        "url": "https://huggingface.co/datasets/bhaiyahnsingh45/multiagent-router-finetuning",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "tegridydev/infosec-tool-output",
        "author": "tegridydev",
        "created_at": "2026-01-10 23:13:59+00:00",
        "last_modified": "2026-01-11 03:21:07+00:00",
        "downloads": 22,
        "likes": 1,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "cybersecurity",
          "infosec",
          "blue-team",
          "devsecops",
          "security-agents",
          "tool-interpretation",
          "soc",
          "automated-reasoning"
        ],
        "description": "\n\t\n\t\t\n\t\tInfosec Tool Output â†’ Plain English\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset maps raw output from common infosec tools to:\n\nplain-English explanations  \nwhy the finding matters  \nsafe, recommended next actions  \nexplicitly unsafe actions to avoid\n\nThe goal is to train and evaluate automated infosec agents that can move beyond raw scanner output and perform human-like security triage and reasoning.\nThis is not an exploitation dataset.\n\n\n\t\n\t\t\n\t\n\t\n\t\tTools Covered (v1)\n\t\n\n\nnmap â€“ network andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tegridydev/infosec-tool-output.",
        "url": "https://huggingface.co/datasets/tegridydev/infosec-tool-output",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_753_knead_the_dough",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:16:30+00:00",
        "last_modified": "2026-01-05 18:17:16+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_753\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ‰é¢å›¢\ntotal_episodes: 312\ntotal_tasks: 1\nsize: 4.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_753_knead_the_dough.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_753_knead_the_dough",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1028",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:20:17+00:00",
        "last_modified": "2026-01-06 07:20:48+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1028\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_3\ntotal_episodes: 258\ntotal_tasks: 1\nsize: 239.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1028.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1028",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_purple_block_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:14:21+00:00",
        "last_modified": "2026-01-05 17:16:51+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_purple_block_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†ç´«è‰²ç§¯æœ¨æ”¾åœ¨æ¡Œå­ä¸Š\ntotal_episodes: 98\ntotal_tasks: 1\nsize: 344.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_purple_block_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_purple_block_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "WithinUsAI/AgentAngel_10k",
        "author": "WithinUsAI",
        "created_at": "2026-01-06 14:31:42+00:00",
        "last_modified": "2026-01-06 14:35:05+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:en",
          "license:cc0-1.0",
          "region:us",
          "within-us-ai",
          "agentangel",
          "agentic",
          "software-engineering",
          "code",
          "reasoning",
          "evaluation",
          "swe-bench",
          "swe-agent",
          "tool-calling",
          "mcp",
          "agents-md",
          "security",
          "prompt-injection"
        ],
        "description": "\n\t\n\t\t\n\t\tWithin Us AI â€” AgentAngel_10k (Agentic Coding 2026)\n\t\n\nAgentAngel is a master-scholar, evidence-backed dataset family for training and evaluating agentic coding models that plan, patch, run checks, and iterate with tests-as-truth.\nThis release contains 10,000 examples per split (50,000 JSONL rows total):\n\nQ&A: fact-grounded with rights/wrongs\nInstruct: chat messages supervision\nThinking: concise rationales (no long hidden chains)\nReasoning: constraints + verification checks\nChat:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/WithinUsAI/AgentAngel_10k.",
        "url": "https://huggingface.co/datasets/WithinUsAI/AgentAngel_10k",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_donut",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:14:56+00:00",
        "last_modified": "2026-01-05 22:15:12+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_donut\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·ç”œç”œåœˆ\ntotal_episodes: 64\ntotal_tasks: 1\nsize: 50.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_donut.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_donut",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "nobusama17/cdt-embeddings",
        "author": "nobusama17",
        "created_at": "2025-12-29 04:03:29+00:00",
        "last_modified": "2025-12-29 04:41:14+00:00",
        "downloads": 1,
        "likes": 0,
        "tags": [
          "task_categories:tabular-regression",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "region:us",
          "biology",
          "genomics",
          "gene-regulation",
          "enhancer",
          "deep-learning",
          "multi-modal"
        ],
        "description": "\n\t\n\t\t\n\t\tCDT Embeddings Dataset\n\t\n\nPre-computed embeddings for the Central Dogma Transformer (CDT) paper.\n\nCentral Dogma Transformer: Towards Mechanism-Oriented AI for Cellular Understanding\nNobuyuki Ota (Independent Researcher)\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains pre-computed embeddings from foundation models used to train CDT for enhancer effect prediction in K562 cells.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\nFile\nSize\nDescription\nShape\n\n\n\t\t\ndna_embeddings/pilot_full_v2.h5\n53GB\nEnformerâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nobusama17/cdt-embeddings.",
        "url": "https://huggingface.co/datasets/nobusama17/cdt-embeddings",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-regression"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_pot_lid_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:42:34+00:00",
        "last_modified": "2026-01-05 22:43:05+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_pot_lid_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é”…ç›–æ”¾åœ¨æ¡Œå­ä¸Š\ntotal_episodes: 342\ntotal_tasks: 1\nsize: 382.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_pot_lid_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_pot_lid_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ASNIJKDNI/SMRT-Maintenance-Logs",
        "author": "ASNIJKDNI",
        "created_at": "2026-01-09 13:12:50+00:00",
        "last_modified": "2026-01-09 13:12:52+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "maintenance-logs"
        ],
        "description": "These are just over 10,000 rows of maintenance logs and the associated train component that was replaced or fixed from SMRT Trains.\nThe text field is actually a concatenation of a fault field and a (corrective) action field, with five tildes separating them.\n",
        "url": "https://huggingface.co/datasets/ASNIJKDNI/SMRT-Maintenance-Logs",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Agda-UniMath",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:43:19+00:00",
        "last_modified": "2026-01-10 15:13:48+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "agda",
          "dependent-types"
        ],
        "description": "\n\t\n\t\t\n\t\tAgda-UniMath\n\t\n\nStructured dataset from agda-unimath â€” Univalent mathematics.\n4,490 declarations extracted from Agda source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/UniMath/agda-unimath\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntypeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Agda-UniMath.",
        "url": "https://huggingface.co/datasets/phanerozoic/Agda-UniMath",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "jkdkr2439/first-principles-validity-protocol",
        "author": "jkdkr2439",
        "created_at": "2026-01-11 02:52:35+00:00",
        "last_modified": "2026-01-11 02:55:51+00:00",
        "downloads": 3,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "modality:document",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "theory",
          "epistemology",
          "question-answering",
          "reference-frames",
          "prompt-engineering",
          "evaluation",
          "ai-safety",
          "anti-hallucination"
        ],
        "description": "\n\t\n\t\t\n\t\tFirst-Principles Validity Protocol for Questions (Validity Gating)\n\t\n\nAuthor: Kevin T.N (jkdkr2439@gmail.com)Date: 2026-01-11\n\n\t\n\t\t\n\t\tWhat this is\n\t\n\nThis repository provides a compact, formal protocol for question answering where the default is NOT to conclude.\nA question becomes answerable only after:\n\nNaming resolves core terms to uniquely identified referents  \nA reference frame is fixed: goal, criteria, and metric (G, C, M)\n\nIf either fails, the only permitted outputs areâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jkdkr2439/first-principles-validity-protocol.",
        "url": "https://huggingface.co/datasets/jkdkr2439/first-principles-validity-protocol",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ariefansclub/humanoid-navigation-spatial-dataset",
        "author": "ariefansclub",
        "created_at": "2026-01-07 03:06:50+00:00",
        "last_modified": "2026-01-07 03:07:49+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "agent",
          "robotics"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Navigation & Spatial Dataset\n\t\n\nCommands for navigation and spatial understanding in humanoid robots.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-navigation-spatial-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Siegfried25/svrp-bench",
        "author": "Siegfried25",
        "created_at": "2026-01-07 03:38:28+00:00",
        "last_modified": "2026-01-07 03:38:29+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2505.21887",
          "region:us",
          "Optimization",
          "combinatorics",
          "Vehicle Routing Problem",
          "SVRP",
          "Logistics",
          "Transportation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸšš SVRPBench\n\t\n\nSVRPBench is an open and extensible benchmark for the Stochastic Vehicle Routing Problem (SVRP). It includes 500+ instances spanning small to large scales (10â€“1000 customers), designed to evaluate algorithms under realistic urban logistics conditions with uncertainty and operational constraints.\n\n\t\n\t\t\n\t\tðŸ“Œ Overview\n\t\n\nExisting SVRP benchmarks often assume simplified, static environments, ignoring core elements of real-world routing such as time-dependent travel delaysâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Siegfried25/svrp-bench.",
        "url": "https://huggingface.co/datasets/Siegfried25/svrp-bench",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_pear_in_the_bowl",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:37:47+00:00",
        "last_modified": "2026-01-06 00:38:40+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_pear_in_the_bowl\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹å°†æ¢¨æ”¾å…¥ç¢—ä¸­\ntotal_episodes: 130\ntotal_tasks: 1\nsize: 654.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_pear_in_the_bowl.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_left_hand_put_the_pear_in_the_bowl",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "amjadali070/legal-judgements-en-ur-sd",
        "author": "amjadali070",
        "created_at": "2026-01-05 09:02:21+00:00",
        "last_modified": "2026-01-05 09:04:09+00:00",
        "downloads": 24,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "task_categories:summarization",
          "task_categories:text-generation",
          "language:en",
          "language:ur",
          "language:sd",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "legal",
          "pakistan",
          "multi-task"
        ],
        "description": "\n\t\n\t\t\n\t\tPakistani Legal Judgments Corpus (Multi-Task)\n\t\n\nThis repository contains a specialized multi-task instruction-tuning dataset for Pakistani Legal Documents. It is designed to train AI models for OCR Correction, Legal Translation, and Summarization.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is divided into 6 configurations (subsets) that you can load individually:\n\n\t\n\t\t\nConfig Name\nTask\nSource Language\nTarget Language\nSize (approx)\n\n\n\t\t\nrepair\nOCR Correction\nBroken English\nClean Englishâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/amjadali070/legal-judgements-en-ur-sd.",
        "url": "https://huggingface.co/datasets/amjadali070/legal-judgements-en-ur-sd",
        "languages": [
          "en",
          "ur",
          "sd"
        ],
        "tasks": [
          "translation",
          "summarization",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_48_putpotatogreenplatefromsteam_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:55:12+00:00",
        "last_modified": "2026-01-05 10:02:52+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_48_putpotatogreenplatefromsteam_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†è’¸åœŸè±†ä»Žç»¿ç›˜å­ä¸Šå–ä¸‹\ntotal_episodes: 185\ntotal_tasks: 1\nsize: 4.9G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_48_putpotatogreenplatefromsteam_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_48_putpotatogreenplatefromsteam_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_in_basket_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:00:31+00:00",
        "last_modified": "2026-01-05 22:00:43+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_bread_in_basket_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç¯®å­é‡Œçš„é¢åŒ…part_1\ntotal_episodes: 20\ntotal_tasks: 1\nsize: 49.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_in_basket_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_bread_in_basket_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "vipinpalhugging/wordnet-testing",
        "author": "vipinpalhugging",
        "created_at": "2026-01-05 12:50:25+00:00",
        "last_modified": "2026-01-05 12:53:55+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tWordNet RDF\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nLexical database of semantic relations between words (English WordNet 2024)\nOriginal Source: https://en-word.net/static/english-wordnet-2024.ttl.gz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from WordNet RDF converted to HuggingFace\ndataset format for easy use in machine learning pipelines.\n\nFormat: Originally turtle, converted to HuggingFace Dataset\nSize: 0.21 GB (extracted)\nEntities: ~120K synsets\nTriples: ~2M\nOriginalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vipinpalhugging/wordnet-testing.",
        "url": "https://huggingface.co/datasets/vipinpalhugging/wordnet-testing",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "enPurified/smoltalk-creative-writing-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 08:20:26+00:00",
        "last_modified": "2026-01-11 08:25:03+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:collinear-ai/smoltalk-creative-writing",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "filtered",
          "enPurified",
          "quality-filtered",
          "creative-writing"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“– SmolTalk-Creative-Writing-enPurified-openai-messages\n\t\n\nSmolTalk-Creative-Writing-enPurified is a highly curated, \"prose-first\" subset of the original collinear-ai/smoltalk-creative-writing dataset.\nThe enPurified collection is built on a specific philosophy: Specialization. While the ecosystem has plenty of datasets for coding (StackOverflow, StarCoder) and mathematics (GSM8K), high-quality, fluent English prose often gets diluted when mixed with syntax-heavy code or rigid mathâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/smoltalk-creative-writing-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/smoltalk-creative-writing-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_top_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:02:47+00:00",
        "last_modified": "2026-01-05 22:02:59+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_close_top_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³é—­é¡¶éƒ¨æŠ½å±‰\ntotal_episodes: 64\ntotal_tasks: 1\nsize: 94.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_top_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_close_top_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "hugging-science/gut-microbiome-allergy-data",
        "author": "hugging-science",
        "created_at": "2026-01-07 10:44:50+00:00",
        "last_modified": "2026-01-07 13:39:45+00:00",
        "downloads": 754,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Gut Microbiomeâ€“Food Allergy Prediction Datasets\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis repository contains multiple human gut microbiome datasets curated for predicting food allergy development.\nEach dataset corresponds to a distinct cohort with longitudinal microbiome sampling, providing both metadata and derived embeddings suitable for machine learning.\nThe datasets are designed to support binary classification of subjects into healthy vs allergic categories, enablingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hugging-science/gut-microbiome-allergy-data.",
        "url": "https://huggingface.co/datasets/hugging-science/gut-microbiome-allergy-data",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "boss001/Dolci-DPO-Model-Response-Pool",
        "author": "boss001",
        "created_at": "2026-01-08 13:10:37+00:00",
        "last_modified": "2026-01-08 13:10:37+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:odc-by",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2512.13961",
          "region:us",
          "llm-responses",
          "model-comparison",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tDolci DPO Model Response Pool\n\t\n\nThis dataset contains up to 2.5 million responses for each model in the Olmo 3 DPO model pool, totalling about 71 million prompt, response pairs. Prompts are sourced from allenai/Dolci-Instruct-SFT, with additional data from allenai/WildChat.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tConfigurations\n\t\n\nEach model has its own configuration. Load a specific model's responses with:\nfrom datasets import load_dataset\n\n# Load a single model's responses\nds =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/boss001/Dolci-DPO-Model-Response-Pool.",
        "url": "https://huggingface.co/datasets/boss001/Dolci-DPO-Model-Response-Pool",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "DataMuncher-Labs/UltraMath-Reasoning-Small",
        "author": "DataMuncher-Labs",
        "created_at": "2026-01-08 13:34:42+00:00",
        "last_modified": "2026-01-10 11:39:42+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:10M<n<100M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "synthetic",
          "math",
          "mathematics",
          "reasoning",
          "LLM"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for UltraMath Reasoning\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [Reality123b]\nFunded by [Reality123b]:\nShared by [Reality123b & Roman]:\nLanguage(s) (NLP): [English, synthetic arithmatic]\nLicense: [MIT]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Currently only available on huggingface]->\n\n\n\t\n\t\t\n\t\tUses\n\t\n\n\n\n\n\t\n\t\t\n\t\tDirect Use\n\t\n\n\n\n[Synthetic Pretraining Corpus]\n\n\t\n\t\t\n\t\tOut-of-Scope Use\n\t\n\n\n\n[Dataset not intended to developâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DataMuncher-Labs/UltraMath-Reasoning-Small.",
        "url": "https://huggingface.co/datasets/DataMuncher-Labs/UltraMath-Reasoning-Small",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "SkyWhal3/STXBP1_Base_Editing_Parameter_Sweep",
        "author": "SkyWhal3",
        "created_at": "2026-01-05 05:33:48+00:00",
        "last_modified": "2026-01-05 06:01:05+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:tabular-classification",
          "language:en",
          "license:mit",
          "size_categories:100M<n<1B",
          "region:us",
          "biology",
          "genomics",
          "base-editing",
          "CRISPR",
          "rare-disease",
          "STXBP1",
          "neurology"
        ],
        "description": "\n\t\n\t\t\n\t\tSTXBP1 Base Editing Parameter Sweep\n\t\n\n654 million parameter combinations analyzed for 170 pathogenic STXBP1 variants\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains exhaustive parameter optimization results for base editing guide design targeting STXBP1 mutations. It identifies which variants can be studied in wild-type mouse models versus those requiring humanized mice.\n\n\t\n\t\t\n\t\tðŸ† Perfect Score Variants (100/100)\n\t\n\n\n\t\n\t\t\nVariant\ncDNA\nEditor\nWT Mouse Compatible\n\n\n\t\t\nE53X\nc.157G>T\nPrime\nâœ…â€¦ See the full description on the dataset page: https://huggingface.co/datasets/SkyWhal3/STXBP1_Base_Editing_Parameter_Sweep.",
        "url": "https://huggingface.co/datasets/SkyWhal3/STXBP1_Base_Editing_Parameter_Sweep",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-classification"
        ],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "krisbailey/fineweb-edu-1B",
        "author": "krisbailey",
        "created_at": "2026-01-07 16:27:35+00:00",
        "last_modified": "2026-01-09 16:29:15+00:00",
        "downloads": 28,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:HuggingFaceFW/fineweb-edu",
          "language:en",
          "license:odc-by",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "fineweb",
          "edu",
          "nlp",
          "text"
        ],
        "description": "\n\t\n\t\t\n\t\tFineWeb-Edu 1B\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nFineWeb-Edu 1B is a high-quality, stratified subset of the HuggingFaceFW/fineweb-edu dataset. It contains approximately 1 billion tokens of educational web text, carefully sampled to preserve the original distribution of source data (CommonCrawl dumps).\nThis dataset provides an accessible, lightweight alternative to the larger FineWeb-Edu subsets (like sample-10BT or sample-100BT) while maintaining the same data diversity and qualityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/krisbailey/fineweb-edu-1B.",
        "url": "https://huggingface.co/datasets/krisbailey/fineweb-edu-1B",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "skyzos/emotion",
        "author": "skyzos",
        "created_at": "2026-01-07 09:28:17+00:00",
        "last_modified": "2026-01-07 09:28:18+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_ids:multi-class-classification",
          "annotations_creators:machine-generated",
          "language_creators:machine-generated",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "emotion-classification"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for \"emotion\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nEmotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n\n\t\n\t\t\n\t\tSupported Tasks and Leaderboards\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tLanguages\n\t\n\nMore Information Needed\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Instances\n\t\n\nAn example looks as follows.\n{\n  \"text\": \"im feeling quite sad and sorry for myself butâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/skyzos/emotion.",
        "url": "https://huggingface.co/datasets/skyzos/emotion",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "happy8825/experiment_qualcheck",
        "author": "happy8825",
        "created_at": "2026-01-08 12:04:27+00:00",
        "last_modified": "2026-01-09 01:53:20+00:00",
        "downloads": 50,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "video-retrieval",
          "evaluation",
          "vllm"
        ],
        "description": "\n\t\n\t\t\n\t\t/hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350 Â· happy8825/valid_ecva_clean results\n\t\n\n\nModel: /hub_data4/seohyun/saves/ecva_instruct/full/sft/checkpoint-350\nDataset: happy8825/valid_ecva_clean\nGenerated: 2026-01-08 12:09:39Z\n\n\n\t\n\t\t\n\t\tMetrics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal samples\n924\n\n\nWith GT\n0\n\n\nParsed answers\n0\n\n\nTop-1 accuracy\n0\n\n\nRecall@5\n0\n\n\nMRR\n0\n\n\n\t\n\nThe uploaded JSON contains full per-sample predictions produced via t3_infer_with_vllm.bash.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/happy8825/experiment_qualcheck.",
        "url": "https://huggingface.co/datasets/happy8825/experiment_qualcheck",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "pkuHaowei/scaling_law_discovery_results",
        "author": "pkuHaowei",
        "created_at": "2026-01-07 13:21:32+00:00",
        "last_modified": "2026-01-10 11:37:34+00:00",
        "downloads": 68,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2507.21184",
          "region:us",
          "code",
          "scaling-laws",
          "benchmark",
          "evaluation",
          "agent-performance",
          "machine-learning",
          "llm-agents"
        ],
        "description": "\n\t\n\t\t\n\t\tScaling Law Discovery Results Dataset\n\t\n\n\n\n\n\nResults dataset for the paper: \"Can Language Models Discover Scaling Laws?\"\nThis dataset contains the complete collection of results from the Scaling Law Discovery (SLDBench) benchmark, where various AI agents attempt to discover mathematical scaling laws from experimental LLM training data.\n\n\t\n\t\t\n\t\tðŸ”— Quick Links\n\t\n\n\n\t\n\t\t\nResource\nLink\n\n\n\t\t\nðŸ“„ Paper\narXiv:2507.21184\n\n\nðŸ“Š Original Benchmark\nSLDBench Dataset\n\n\nðŸ§ª Benchmark Codeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pkuHaowei/scaling_law_discovery_results.",
        "url": "https://huggingface.co/datasets/pkuHaowei/scaling_law_discovery_results",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "tsazan/ikea-us-commercetxt",
        "author": "tsazan",
        "created_at": "2026-01-07 08:33:49+00:00",
        "last_modified": "2026-01-08 11:24:48+00:00",
        "downloads": 15,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "task_categories:text-retrieval",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1M<n<10M",
          "format:text",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "commercetxt",
          "e-commerce",
          "product-catalog",
          "ikea",
          "retail",
          "rag",
          "llm-optimization",
          "token-efficiency",
          "rag-benchmark",
          "structured-data",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tIKEA US - CommerceTXT Dataset\n\t\n\n\n\n30,511 IKEA US products in CommerceTXT v1.0.1 format - A token-optimized, human-readable alternative to JSON for e-commerce data.\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“Š Dataset Statistics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nProducts\n30,511\n\n\nCategories\n632\n\n\nFormat\nCommerceTXT v1.0.1\n\n\nData Date\n2025-07-15\n\n\nToken Savings\n24% vs JSON\n\n\nTokens Saved\n3.6M\n\n\n\t\n\n\n\t\n\t\t\n\t\tðŸŽ¯ What is CommerceTXT?\n\t\n\nCommerceTXT is a lightweight, text-based protocol designed for AI/LLM consumption ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/tsazan/ikea-us-commercetxt.",
        "url": "https://huggingface.co/datasets/tsazan/ikea-us-commercetxt",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering",
          "text-retrieval"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "daveiloper/ChatGPT-Jailbreak-Prompts",
        "author": "daveiloper",
        "created_at": "2026-01-08 22:04:20+00:00",
        "last_modified": "2026-01-08 22:23:58+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "task_categories:fill-mask",
          "task_categories:zero-shot-classification",
          "task_categories:table-question-answering",
          "language:en",
          "language:de",
          "size_categories:n<1K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "ChatGPT",
          "JailbreakPrompts",
          "LanguageModeling",
          "ArtificialIntelligence",
          "TextGeneration",
          "Dataset",
          "OpenAI",
          "Jailbreak",
          "Prompts"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\t\n\t\t\n\t\tName\n\t\n\nChatGPT Jailbreak Prompts\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nChatGPT Jailbreak Prompts is a complete collection of jailbreak related prompts for ChatGPT. This dataset is intended to provide a valuable resource for understanding and generating text in the context of jailbreaking in ChatGPT.\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n[English]\n",
        "url": "https://huggingface.co/datasets/daveiloper/ChatGPT-Jailbreak-Prompts",
        "languages": [
          "en",
          "de"
        ],
        "tasks": [
          "question-answering",
          "text-generation",
          "fill-mask",
          "zero-shot-classification",
          "table-question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Jarrodbarnes/osworld-union-v1",
        "author": "Jarrodbarnes",
        "created_at": "2026-01-08 04:10:56+00:00",
        "last_modified": "2026-01-08 16:23:06+00:00",
        "downloads": 23,
        "likes": 2,
        "tags": [
          "task_categories:reinforcement-learning",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "osworld",
          "reinforcement-learning",
          "multimodal",
          "vlm",
          "slime",
          "dataset"
        ],
        "description": "\n\t\n\t\t\n\t\tOSWorld Union v1\n\t\n\nUnion task registry + replay buffer used by the Slime OSWorld VLM cookbook.\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\nosworld_tasks_union.parquet â€” 149 Ubuntu tasks with full task_config.\nosworld_replay_union.jsonl â€” normalized replay buffer (messages + reward=1.0).\nosworld_union_stats.json â€” build stats and per-dataset counts.\n\n\n\t\n\t\t\n\t\tCoverage\n\t\n\nThis dataset is a subset of OSWorld: 149 Ubuntu tasks (~40% of test_all = 369 tasks). Windows tasks are excluded.\n\n\t\n\t\t\n\t\tHow it was builtâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Jarrodbarnes/osworld-union-v1.",
        "url": "https://huggingface.co/datasets/Jarrodbarnes/osworld-union-v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "reinforcement-learning"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-Aesop",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:37:30+00:00",
        "last_modified": "2026-01-10 15:13:22+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-Aesop\n\t\n\nStructured dataset from Aesop â€” White-box proof search automation.\n1,836 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/leanprover-community/aesop\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-Aesop.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-Aesop",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "enPurified/natural_reasoning-enPurified-openai-messages",
        "author": "enPurified",
        "created_at": "2026-01-11 05:54:09+00:00",
        "last_modified": "2026-01-12 00:36:11+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "source_datasets:mlabonne/natural_reasoning-formatted",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "nlp",
          "conversational",
          "prose",
          "reasoning",
          "enPurified",
          "quality-filtered",
          "openai-messages"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ§  Natural Reasoning-enPurified (Prose Only)\n\t\n\nNatural Reasoning-enPurified is a highly curated, \"prose-first\" subset of the original facebook/natural_reasoning.\nThe enPurified collection is built on a specific philosophy: Specialization. While many reasoning datasets are saturated with competitive math or Python scripting, this dataset focuses exclusively on natural language reasoning. It is designed to train models that think clearly and explain complex concepts in fluentâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/enPurified/natural_reasoning-enPurified-openai-messages.",
        "url": "https://huggingface.co/datasets/enPurified/natural_reasoning-enPurified-openai-messages",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_tool_box",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 13:37:54+00:00",
        "last_modified": "2026-01-05 13:38:21+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_open_cap_tool_box\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€å·¥å…·ç®±ç›–\ntotal_episodes: 26\ntotal_tasks: 1\nsize: 100.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_tool_box.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_open_cap_tool_box",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "sirlab-ai/driving-urban-dutch-fog__zn7nyhyg",
        "author": "sirlab-ai",
        "created_at": "2026-01-09 20:35:13+00:00",
        "last_modified": "2026-01-11 18:44:54+00:00",
        "downloads": 32,
        "likes": 0,
        "tags": [
          "annotations_creators:machine-generated",
          "language:en",
          "license:other",
          "size_categories:n<1K",
          "modality:3d",
          "region:us",
          "synthetic",
          "urban",
          "dutch",
          "fog",
          "autonomous-driving",
          "multimodal",
          "point-cloud",
          "semantic-segmentation",
          "computer-vision",
          "point-cloud-segmentation",
          "3d",
          "imu",
          "odometry",
          "lidar",
          "camera"
        ],
        "description": "\n\t\n\t\t\n\t\tDutch Town Scene 1 (#zn7nyhyg)\n\t\n\nSiRLab publishes LiDAR-first synthetic datasets with dense per-point semantics, synchronized RGB, and ego-motion, built to plug into modern perception pipelines.\n\nBest for: point-cloud semantic segmentation, filtering/analytics, fusion prototyping.\nCommercialization: you may commercialize models/outputs trained on the Full dataset (dataset redistribution is prohibited; see License below).\nFull access / quote / integration: see Commercial access &â€¦ See the full description on the dataset page: https://huggingface.co/datasets/sirlab-ai/driving-urban-dutch-fog__zn7nyhyg.",
        "url": "https://huggingface.co/datasets/sirlab-ai/driving-urban-dutch-fog__zn7nyhyg",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_slice_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:30:54+00:00",
        "last_modified": "2026-01-05 22:31:04+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_bread_slice_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¢åŒ…ç‰‡æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 62\ntotal_tasks: 1\nsize: 46.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_slice_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_bread_slice_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Hammer",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:59:36+00:00",
        "last_modified": "2026-01-10 15:12:59+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-2.1",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Hammer\n\t\n\nStructured dataset from CoqHammer â€” Automation for dependent type theory via ATPs.\n866 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/lukaszcz/coqhammer\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclarationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Hammer.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Hammer",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Isabelle-AFP",
        "author": "phanerozoic",
        "created_at": "2026-01-10 11:40:35+00:00",
        "last_modified": "2026-01-10 11:40:59+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:bsd-3-clause",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "isabelle",
          "archive-of-formal-proofs",
          "hol"
        ],
        "description": "\n\t\n\t\t\n\t\tIsabelle-AFP\n\t\n\nStructured dataset from the Isabelle Archive of Formal Proofs (AFP) - the largest repository of formal proofs in Isabelle/HOL.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstring\nlemma, definition, theorem, fun, locale, datatype, etc.\n\n\nlibrary\nstring\nAFP entry name (project)\n\n\nimports\nlist\nTheory imports\n\n\nfilename\nstring\nSource file path\n\n\nsymbolic_name\nstring\nDeclaration identifier\n\n\ndocstring\nstring\nDocumentation (20%â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Isabelle-AFP.",
        "url": "https://huggingface.co/datasets/phanerozoic/Isabelle-AFP",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_banana_in_top_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:28:09+00:00",
        "last_modified": "2026-01-05 22:28:27+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_banana_in_top_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é¦™è•‰æ”¾å…¥é¡¶éƒ¨æŠ½å±‰\ntotal_episodes: 49\ntotal_tasks: 1\nsize: 86.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_banana_in_top_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_banana_in_top_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "nyuuzyou/gitflic-code",
        "author": "nyuuzyou",
        "created_at": "2024-07-09 13:43:51+00:00",
        "last_modified": "2026-01-09 03:44:49+00:00",
        "downloads": 102,
        "likes": 2,
        "tags": [
          "task_categories:text-generation",
          "annotations_creators:machine-generated",
          "language_creators:found",
          "multilinguality:multilingual",
          "source_datasets:original",
          "language:code",
          "language:ru",
          "language:en",
          "license:other",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "russian"
        ],
        "description": "\n\t\n\t\t\n\t\tGitFlic Code Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was compiled from code repositories hosted on GitFlic, the first Russian service for storing and working with source code, based on the Git version control system. GitFlic is widely used by Russian developers, enterprises, and open-source projects, making this dataset particularly valuable for training code models with strong Russian language understanding and Russian coding conventions.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summaryâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/nyuuzyou/gitflic-code.",
        "url": "https://huggingface.co/datasets/nyuuzyou/gitflic-code",
        "languages": [
          "code",
          "ru",
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_yellow_bananas_placed_on_a_plastic_tray",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:58:10+00:00",
        "last_modified": "2026-01-05 23:58:36+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_yellow_bananas_placed_on_a_plastic_tray\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: é»„é¦™è•‰æ”¾åœ¨å¡‘æ–™æ‰˜ç›˜ä¸Š\ntotal_episodes: 136\ntotal_tasks: 1\nsize: 314.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_yellow_bananas_placed_on_a_plastic_tray.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_yellow_bananas_placed_on_a_plastic_tray",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "y00njaekim/cmul2arctic-l1cls",
        "author": "y00njaekim",
        "created_at": "2026-01-10 06:45:42+00:00",
        "last_modified": "2026-01-10 06:46:13+00:00",
        "downloads": 48,
        "likes": 0,
        "tags": [
          "task_categories:audio-classification",
          "language:en",
          "language:ar",
          "language:es",
          "language:hi",
          "language:ko",
          "language:vi",
          "language:zh",
          "license:cc-by-nc-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "speech",
          "accent",
          "l1-classification",
          "native-language-identification"
        ],
        "description": "\n\t\n\t\t\n\t\tCMU + L2-ARCTIC Combined Dataset for L1 Classification\n\t\n\nThis dataset combines CMU Arctic (native English speakers) and L2-ARCTIC (non-native English speakers) for L1 (native language) classification research. It is redistributed for the purpose of academic reproducibility.\nAudio is embedded in Parquet files for efficient loading via HuggingFace datasets.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Description\n\t\n\n\n\t\n\t\t\nSubset\nSource\nSpeakers\nL1 Labels\nLicense\n\n\n\t\t\ncmu/\nCMU Arctic\n4 native English speakers\nenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/y00njaekim/cmul2arctic-l1cls.",
        "url": "https://huggingface.co/datasets/y00njaekim/cmul2arctic-l1cls",
        "languages": [
          "en",
          "ar",
          "es",
          "hi",
          "ko",
          "vi",
          "zh"
        ],
        "tasks": [
          "audio-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1025",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:19:46+00:00",
        "last_modified": "2026-01-06 07:19:55+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1025\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_2\ntotal_episodes: 66\ntotal_tasks: 1\nsize: 69.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1025.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1025",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "http403/Retro-YahooAnswers",
        "author": "http403",
        "created_at": "2026-01-11 19:10:03+00:00",
        "last_modified": "2026-01-11 19:17:06+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "size_categories:1M<n<10M",
          "region:us",
          "not-for-all-audiences",
          "alpaca"
        ],
        "description": "\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset is an instruct style dataset comprised of a scrape of the Yahoo! Answers website that was done in 2007. The dataset is comprised of 10 categories labeled 1-10. The categories are as follows:\n\nSociety & Culture\nScience & Mathematics\nHealth\nEducation & Reference\nComputers & Internet\nSports\nBusiness & Finance\nEntertainment & Music\nFamily & Relationships\nPolitics & Government\n\nThe subject line and body of the question have been combined into a single field andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/http403/Retro-YahooAnswers.",
        "url": "https://huggingface.co/datasets/http403/Retro-YahooAnswers",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "Lap1official/Math",
        "author": "Lap1official",
        "created_at": "2024-12-10 11:52:33+00:00",
        "last_modified": "2026-01-07 14:29:05+00:00",
        "downloads": 15,
        "likes": 3,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:10M<n<100M",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Lap1official/Math",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "iioos/security-log-events",
        "author": "iioos",
        "created_at": "2026-01-10 01:45:32+00:00",
        "last_modified": "2026-01-10 01:45:51+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSecurity Log Events Dataset\n\t\n\nSynthetic security log events for log analysis and monitoring tasks.\n",
        "url": "https://huggingface.co/datasets/iioos/security-log-events",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_oranges_on_the_table_1119",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:24:37+00:00",
        "last_modified": "2026-01-07 07:25:07+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_oranges_on_the_table_1119\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ©™å­æ”¾åœ¨æ¡Œå­ä¸Špart_1\ntotal_episodes: 230\ntotal_tasks: 1\nsize: 162.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_oranges_on_the_table_1119.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_oranges_on_the_table_1119",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ShiroOnigami23/Automata-DFA-Generation",
        "author": "ShiroOnigami23",
        "created_at": "2025-12-14 18:57:48+00:00",
        "last_modified": "2026-01-11 13:24:57+00:00",
        "downloads": 17,
        "likes": 2,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:imagefolder",
          "modality:image",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "theory-of-computation",
          "automata",
          "rjit",
          "shiro"
        ],
        "description": "\n\t\n\t\t\n\t\tAutomata DFA Generation\n\t\n\nDeveloped by Aryan Singh Chandel (Shiro) at Rustamji Institute of Technology (RJIT).\n\n\t\n\t\t\n\t\tðŸ“ Overview\n\t\n\nThis repository contains assets for Automata DFA Generation. It is a professional research component of the Shiro AI ecosystem.\n\n\t\n\t\t\n\t\tðŸš€ Status\n\t\n\nThe core files are live. Detailed usage instructions and technical benchmarks are currently being compiled for the elite release.\n",
        "url": "https://huggingface.co/datasets/ShiroOnigami23/Automata-DFA-Generation",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_tkg_1rgb_left_hand_lift_pot_lid_and_place_it_to_the_left_of_the_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 04:55:49+00:00",
        "last_modified": "2026-01-08 04:56:08+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_left_hand_lift_pot_lid_and_place_it_to_the_left_of_the_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å·¦æ‰‹æ‹¿èµ·é”…ç›–å¹¶å°†å…¶æ”¾åœ¨é”…çš„å·¦ä¾§\ntotal_episodes: 117\ntotal_tasks: 1\nsize: 785.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_lift_pot_lid_and_place_it_to_the_left_of_the_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_tkg_1rgb_left_hand_lift_pot_lid_and_place_it_to_the_left_of_the_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_54_placecup",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:10:54+00:00",
        "last_modified": "2026-01-05 10:11:46+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_54_placecup\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®æ¯å­\ntotal_episodes: 49\ntotal_tasks: 1\nsize: 504.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_54_placecup.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_54_placecup",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "openchs/synthetic-helpline-sw-en-translation-v1",
        "author": "openchs",
        "created_at": "2025-10-09 00:45:08+00:00",
        "last_modified": "2026-01-05 09:55:01+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "language:en",
          "language:sw",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "helpline",
          "openchs",
          "helsinki-opus-mt",
          "translatiion"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for the Synthetic Swahili-English Helpline Translation Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains synthetic parallel Swahili-English translations from Tanzanian child helpline conversations, designed for training and evaluating neural machine translation (NMT) models. The dataset addresses the critical need for high-quality translation systems in child protection services across East Africa, where multilingual support isâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/openchs/synthetic-helpline-sw-en-translation-v1.",
        "url": "https://huggingface.co/datasets/openchs/synthetic-helpline-sw-en-translation-v1",
        "languages": [
          "en",
          "sw"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_red_pepper_on_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:14:15+00:00",
        "last_modified": "2026-01-06 10:14:39+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_red_pepper_on_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ç›˜å­ä¸Šçš„çº¢è¾£æ¤’\ntotal_episodes: 81\ntotal_tasks: 1\nsize: 41.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_red_pepper_on_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_red_pepper_on_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_yellow_pepper_on_the_plate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 00:55:50+00:00",
        "last_modified": "2026-01-06 00:56:50+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_gello_1rgb_right_hand_put_yellow_pepper_on_the_plate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å³æ‰‹å°†é»„è¾£æ¤’æ”¾åœ¨ç›˜å­ä¸Š\ntotal_episodes: 138\ntotal_tasks: 1\nsize: 871.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_yellow_pepper_on_the_plate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_gello_1rgb_right_hand_put_yellow_pepper_on_the_plate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_lamp_on_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:04:11+00:00",
        "last_modified": "2026-01-05 12:13:31+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241022_lamp_on_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å¼€ç¯part_1\ntotal_episodes: 256\ntotal_tasks: 1\nsize: 485.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_lamp_on_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241022_lamp_on_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_mangosteen_in_top_white_drawer",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:40:53+00:00",
        "last_modified": "2026-01-05 22:41:09+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_mangosteen_in_top_white_drawer\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†å±±ç«¹æ”¾å…¥é¡¶éƒ¨ç™½è‰²æŠ½å±‰\ntotal_episodes: 61\ntotal_tasks: 1\nsize: 47.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_mangosteen_in_top_white_drawer.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_mangosteen_in_top_white_drawer",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_rotate_close_cabinet",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:41:48+00:00",
        "last_modified": "2026-01-05 17:45:30+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_rotate_close_cabinet\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ—‹è½¬å…³é—­æ©±æŸœ\ntotal_episodes: 93\ntotal_tasks: 1\nsize: 318.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_rotate_close_cabinet.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_rotate_close_cabinet",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_cup_place_in_dustbin",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 01:33:06+00:00",
        "last_modified": "2026-01-06 01:49:40+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_cup_place_in_dustbin\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_prod1_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·çº¸æ¯æ”¾å…¥åžƒåœ¾æ¡¶\ntotal_episodes: 735\ntotal_tasks: 1\nsize: 11.3G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_cup_place_in_dustbin.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_tienkung_prod1_gello_1rgb_pick_up_paper_cup_place_in_dustbin",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "llm-semantic-router/e2e-halspans",
        "author": "llm-semantic-router",
        "created_at": "2026-01-10 23:10:36+00:00",
        "last_modified": "2026-01-10 23:10:37+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:token-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "hallucination-detection",
          "data2txt",
          "structured-data",
          "rag",
          "fact-checking",
          "synthetic",
          "restaurant"
        ],
        "description": "\n\t\n\t\t\n\t\tE2E Hallucination Spans Dataset\n\t\n\nA synthetic hallucination detection dataset derived from E2E NLG Challenge restaurant data. Contains 1,500 samples with LLM-generated responses and span-level hallucination annotations.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset was created to augment RAGTruth for Data2txt (structured data to text) task coverage. An LLM generates both faithful and intentionally hallucinated restaurant descriptions from E2E's meaning representations, then annotatesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/llm-semantic-router/e2e-halspans.",
        "url": "https://huggingface.co/datasets/llm-semantic-router/e2e-halspans",
        "languages": [
          "en"
        ],
        "tasks": [
          "token-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "CleverThis/uniprotkb_obsolete_entries_70000000",
        "author": "CleverThis",
        "created_at": "2026-01-08 08:27:47+00:00",
        "last_modified": "2026-01-08 08:48:34+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10M<n<100M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rdf",
          "knowledge-graph",
          "semantic-web",
          "triples"
        ],
        "description": "\n\t\n\t\t\n\t\tuniprotkb_obsolete_entries_70000000\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nComprehensive protein knowledgebase with functional annotations\nOriginal Source: ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/rdf/uniprotkb_obsolete_entries_70000000.rdf.xz\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset contains RDF triples from uniprotkb_obsolete_entries_70000000 converted to HuggingFace\ndataset format for easy use in machine learning pipelines.\n\nFormat: Originally rdf, converted toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/CleverThis/uniprotkb_obsolete_entries_70000000.",
        "url": "https://huggingface.co/datasets/CleverThis/uniprotkb_obsolete_entries_70000000",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "phanerozoic/Coq-QuickChick",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:30:47+00:00",
        "last_modified": "2026-01-10 13:48:54+00:00",
        "downloads": 17,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "quickchick",
          "testing",
          "property-based-testing",
          "quickcheck"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-QuickChick\n\t\n\nRandomized property-based testing plugin for Coq, inspired by QuickCheck.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/QuickChick/QuickChick\nLicense: MIT\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n2,371\n\n\nFiles Processed\n107\n\n\n\t\n\n\n\t\n\t\t\n\t\tType Distribution\n\t\n\n\n\t\n\t\t\nType\nCount\n\n\n\t\t\nDefinition\n627\n\n\nLemma\n533\n\n\nInductive\n238\n\n\nFixpoint\n201\n\n\nTheorem\n188\n\n\nInstance\n188\n\n\nLtac2\n134\n\n\nClass\n76\n\n\nExample\n74\n\n\nAxiom\n32\n\n\nLtac\n31\n\n\nProgram\n24\n\n\nRecordâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-QuickChick.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-QuickChick",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Alapan/smolified-route-finder",
        "author": "Alapan",
        "created_at": "2026-01-09 18:49:04+00:00",
        "last_modified": "2026-01-09 18:49:08+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-route-finder\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry.\nIt was used to train the corresponding model Alapan/smolified-route-finder.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: dfc5edce)\nRecords: 10056\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by Alapan.\nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/Alapan/smolified-route-finder",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "kollessisopod/vqa-mixed",
        "author": "kollessisopod",
        "created_at": "2026-01-05 08:36:13+00:00",
        "last_modified": "2026-01-09 11:40:20+00:00",
        "downloads": 113,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "language:en",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tVQA Mixed (GQA + VizWiz + VQAv2 subset)\n\t\n\nThis dataset is a curated mixture of three major VQA benchmarks, subsampled and reformatted into Parquet shards for efficient model training (e.g., for VLMs like LLaVA or Qwen-VL).\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\nThe dataset consists of image-question-answer triplets stored in Parquet format.\n\n\t\n\t\t\n\t\tData Splits\n\t\n\n\nTrain: train/data-*.parquet\nValidation: validation/data-*.parquet\n\n\n\t\n\t\t\n\t\tColumns\n\t\n\n\nimage: The visual input (Image feature).â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kollessisopod/vqa-mixed.",
        "url": "https://huggingface.co/datasets/kollessisopod/vqa-mixed",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "happy8825/experiment_bitsandbytes",
        "author": "happy8825",
        "created_at": "2026-01-08 11:28:45+00:00",
        "last_modified": "2026-01-08 11:28:47+00:00",
        "downloads": 36,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "video-retrieval",
          "evaluation",
          "vllm"
        ],
        "description": "\n\t\n\t\t\n\t\t/hub_data4/seohyun/saves/ecva_instruct_1223/full/sft/checkpoint-350 Â· happy8825/valid_ecva_clean results\n\t\n\n\nModel: /hub_data4/seohyun/saves/ecva_instruct_1223/full/sft/checkpoint-350\nDataset: happy8825/valid_ecva_clean\nGenerated: 2026-01-08 11:28:44Z\n\n\n\t\n\t\t\n\t\tMetrics\n\t\n\n\n\t\n\t\t\nMetric\nValue\n\n\n\t\t\nTotal samples\n924\n\n\nWith GT\n0\n\n\nParsed answers\n0\n\n\nTop-1 accuracy\n0\n\n\nRecall@5\n0\n\n\nMRR\n0\n\n\n\t\n\nThe uploaded JSON contains full per-sample predictions produced via t3_infer_with_vllm.bash.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/happy8825/experiment_bitsandbytes.",
        "url": "https://huggingface.co/datasets/happy8825/experiment_bitsandbytes",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "iioos/operations-task-scheduling",
        "author": "iioos",
        "created_at": "2026-01-11 01:07:20+00:00",
        "last_modified": "2026-01-11 01:07:46+00:00",
        "downloads": 4,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tOperations Task Scheduling Dataset\n\t\n\nSynthetic tasks with duration, priority, and resource constraints for scheduling problems.\n",
        "url": "https://huggingface.co/datasets/iioos/operations-task-scheduling",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "sugatobagchi/smolified-transcripts-checker",
        "author": "sugatobagchi",
        "created_at": "2026-01-11 17:59:04+00:00",
        "last_modified": "2026-01-11 17:59:08+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "smolify",
          "synthetic",
          "distillation"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ¤ smolified-transcripts-checker\n\t\n\n\nIntelligence, Distilled.\n\nThis is a synthetic training corpus generated by the Smolify Foundry.\nIt was used to train the corresponding model sugatobagchi/smolified-transcripts-checker.\n\n\t\n\t\t\n\t\tðŸ“¦ Asset Details\n\t\n\n\nOrigin: Smolify Foundry (Job ID: 3a495556)\nRecords: 10041\nType: Synthetic Instruction Tuning Data\n\n\n\t\n\t\t\n\t\tâš–ï¸ License & Ownership\n\t\n\nThis dataset is a sovereign asset owned by sugatobagchi.\nGenerated via Smolify.ai.\n\n",
        "url": "https://huggingface.co/datasets/sugatobagchi/smolified-transcripts-checker",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "hammad655/TCGA-Cancer-Variant-and-Clinical-Data",
        "author": "hammad655",
        "created_at": "2026-01-05 14:25:02+00:00",
        "last_modified": "2026-01-05 14:25:03+00:00",
        "downloads": 552,
        "likes": 0,
        "tags": [
          "task_categories:table-to-text",
          "task_ids:entity-linking-retrieval",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "cancer-genomics",
          "variant-calling",
          "transcriptomics",
          "clinical-data"
        ],
        "description": "\n\t\n\t\t\n\t\tTCGA Cancer Variant and Clinical Data\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset combines genetic variant information at the protein level with clinical data from The Cancer Genome Atlas (TCGA) project, curated by the International Cancer Genome Consortium (ICGC). It provides a comprehensive view of protein-altering mutations and clinical characteristics across various cancer types.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe dataset includes:\n\nProtein sequence data for both mutated andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hammad655/TCGA-Cancer-Variant-and-Clinical-Data.",
        "url": "https://huggingface.co/datasets/hammad655/TCGA-Cancer-Variant-and-Clinical-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "table-to-text"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Lazyup-crypto/fineweb-edu",
        "author": "Lazyup-crypto",
        "created_at": "2026-01-09 07:15:58+00:00",
        "last_modified": "2026-01-09 07:15:59+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "size_categories:n>1T",
          "arxiv:2406.17557",
          "arxiv:2404.14219",
          "arxiv:2401.10020",
          "arxiv:2109.07445",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“š FineWeb-Edu\n\t\n\n\n    \n\n\n\n1.3 trillion tokens of the finest educational data the ðŸŒ web has to offer\n\nPaper: https://arxiv.org/abs/2406.17557\n\n\t\n\t\t\n\t\n\t\n\t\tWhat is it?\n\t\n\nðŸ“š FineWeb-Edu  dataset consists of 1.3T tokens  and  5.4T tokens (FineWeb-Edu-score-2) of educational web pages filtered from ðŸ· FineWeb dataset. This is the 1.3 trillion version.\nTo enhance FineWeb's quality, we developed an educational quality classifier using annotations generated by LLama3-70B-Instruct. We thenâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Lazyup-crypto/fineweb-edu.",
        "url": "https://huggingface.co/datasets/Lazyup-crypto/fineweb-edu",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n>1T"
        ]
      },
      {
        "id": "pablocc/Simcan2Fog-Results",
        "author": "pablocc",
        "created_at": "2026-01-11 19:28:31+00:00",
        "last_modified": "2026-01-11 19:48:25+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:gpl-3.0",
          "region:us",
          "fog-computing",
          "edge-computing",
          "network-simulation",
          "omnet++",
          "discrete-event-simulation"
        ],
        "description": "\n\t\n\t\t\n\t\tSimcan2Fog: Fog Computing Simulation Framework\n\t\n\nOfficial repository for the paper: \"Simcan2Fog: A discrete-event platform for the modelling and simulation of Fog computing environments\" published in SoftwareX (2025).\n\n\t\n\t\t\n\t\tðŸ’¡ Overview\n\t\n\nSimcan2Fog is an open-source framework built on OMNeT++ 6.3.0 and INET 4.5.4. It provides a high-level abstraction for simulating complex hierarchical architectures, focusing on:\n\nMulti-tier offloading policies.\nService discovery (DNS-based).\nSLAâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pablocc/Simcan2Fog-Results.",
        "url": "https://huggingface.co/datasets/pablocc/Simcan2Fog-Results",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "ariefansclub/humanoid-daily-routine-dataset",
        "author": "ariefansclub",
        "created_at": "2026-01-08 06:45:45+00:00",
        "last_modified": "2026-01-08 06:46:22+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code",
          "agent",
          "robotics"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Daily Routine Dataset\n\t\n\nStructured daily routines for humanoid task scheduling and planning.\n",
        "url": "https://huggingface.co/datasets/ariefansclub/humanoid-daily-routine-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_up_strawberry_from_bowl",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 14:17:21+00:00",
        "last_modified": "2026-01-05 14:22:14+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_pick_up_strawberry_from_bowl\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žç¢—ä¸­æ‹¿èµ·è‰èŽ“\ntotal_episodes: 200\ntotal_tasks: 1\nsize: 237.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_up_strawberry_from_bowl.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_pick_up_strawberry_from_bowl",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "UVSKKR/X-MuTeST",
        "author": "UVSKKR",
        "created_at": "2026-01-07 03:23:34+00:00",
        "last_modified": "2026-01-09 11:41:11+00:00",
        "downloads": 34,
        "likes": 1,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "task_categories:feature-extraction",
          "language:te",
          "language:hi",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "arxiv:2601.03194",
          "region:us",
          "LargeLanguageModels",
          "LLMs",
          "Explainability",
          "Token-Level",
          "Hate-Speech",
          "Indic-Langugaes",
          "Hate",
          "Indic"
        ],
        "description": "\n\t\n\t\t\n\t\tX-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-Consulted Explanation Framework\n\t\n\nAccepted at AAAI 2026 (AI for Social Impact Track) - CORE A* Conference \nThis repository contains the dataset for the paper X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-Consulted Explanation Framework.\nâš ï¸ Note: The dataset itself is not hosted on Hugging Face. To request access, please fill out the official agreementâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/UVSKKR/X-MuTeST.",
        "url": "https://huggingface.co/datasets/UVSKKR/X-MuTeST",
        "languages": [
          "te",
          "hi",
          "en"
        ],
        "tasks": [
          "text-classification",
          "token-classification",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Jasmin",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:59:12+00:00",
        "last_modified": "2026-01-10 15:12:54+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Jasmin\n\t\n\nStructured dataset from Jasmin â€” High-assurance cryptography language and compiler.\n9,728 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/jasmin-lang/jasmin\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclarationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Jasmin.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Jasmin",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "skyzos/ai2_arc",
        "author": "skyzos",
        "created_at": "2026-01-07 09:27:35+00:00",
        "last_modified": "2026-01-07 09:27:36+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_ids:open-domain-qa",
          "task_ids:multiple-choice-qa",
          "annotations_creators:found",
          "language_creators:found",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:cc-by-sa-4.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:1803.05457",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for \"ai2_arc\"\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nA new dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in\n advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains\n only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. We are also\n including a corpus of over 14 million science sentences relevant toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/skyzos/ai2_arc.",
        "url": "https://huggingface.co/datasets/skyzos/ai2_arc",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_748_Scan_security_check",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:11:56+00:00",
        "last_modified": "2026-01-05 17:39:44+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_748\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: æ‰«æå®‰å…¨æ£€æŸ¥part_2\ntotal_episodes: 104\ntotal_tasks: 1\nsize: 9.0G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_748_Scan_security_check.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_748_Scan_security_check",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_cabinet",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:55:14+00:00",
        "last_modified": "2026-01-05 17:56:17+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_slide_open_cabinet\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ»‘åŠ¨æ‰“å¼€æ©±æŸœ\ntotal_episodes: 94\ntotal_tasks: 1\nsize: 524.3M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_cabinet.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_slide_open_cabinet",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1101",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:20:02+00:00",
        "last_modified": "2026-01-07 07:20:19+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1101\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ±æœµæ”¾åœ¨æ¡Œå­ä¸Špart_6\ntotal_episodes: 130\ntotal_tasks: 1\nsize: 95.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1101.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1101",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "SWE-Lego/SWE-Lego-Real-Data",
        "author": "SWE-Lego",
        "created_at": "2026-01-05 13:30:08+00:00",
        "last_modified": "2026-01-08 06:41:34+00:00",
        "downloads": 183,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2601.01426",
          "region:us",
          "software-engineering",
          "code"
        ],
        "description": "\n\t\n\t\t\n\t\tSWE-Lego-Real-Data\n\t\n\nPaper | GitHub\nSWE-Lego-Real-Data contains 18k real github issues (Python language) and their multi-turn agent trajectories. The column named messages is collected using Qwen/Qwen3-Coder-480B-A35B-Instruct with OpenHands (v0.53.0) agent scaffolding, which can be directly used for SFT training.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Structure\n\t\n\n.\nâ””â”€â”€ data\n    â”œâ”€â”€ resolved-00000-of-00001.parquet (5k github issues with resolved trajectories)\n    â””â”€â”€ unresolved-00000-of-00001.parquetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SWE-Lego/SWE-Lego-Real-Data.",
        "url": "https://huggingface.co/datasets/SWE-Lego/SWE-Lego-Real-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/b1_1_fr_3rgb_chili_peppers_are_placed_on_the_right_side_of_a_plastic_tray",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-08 03:55:01+00:00",
        "last_modified": "2026-01-08 04:54:18+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_chili_peppers_are_placed_on_the_right_side_of_a_plastic_tray\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è¾£æ¤’æ”¾åœ¨å¡‘æ–™æ‰˜ç›˜å³ä¾§\ntotal_episodes: 121\ntotal_tasks: 1\nsize: 285.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/b1_1_fr_3rgb_chili_peppers_are_placed_on_the_right_side_of_a_plastic_tray.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/b1_1_fr_3rgb_chili_peppers_are_placed_on_the_right_side_of_a_plastic_tray",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Lean4-FLT",
        "author": "phanerozoic",
        "created_at": "2026-01-10 14:51:52+00:00",
        "last_modified": "2026-01-10 15:13:21+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "lean4"
        ],
        "description": "\n\t\n\t\t\n\t\tLean4-FLT\n\t\n\nStructured dataset from FLT â€” Formalization of Fermat's Last Theorem.\n1,755 declarations extracted from Lean 4 source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/ImperialCollegeLondon/FLT\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration bodyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Lean4-FLT.",
        "url": "https://huggingface.co/datasets/phanerozoic/Lean4-FLT",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "chkmie/Synthetic-Causal-Reasoning-50k",
        "author": "chkmie",
        "created_at": "2026-01-11 10:12:49+00:00",
        "last_modified": "2026-01-11 10:31:20+00:00",
        "downloads": 0,
        "likes": 1,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "synthetic",
          "reasoning",
          "chain-of-thought",
          "multi-domain",
          "finance",
          "pharma",
          "cybersecurity"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ­ Sovereign Synthetic Reasoning Dataset (400k)\n\t\n\n\n\"High-Quality Chain-of-Thought Data at Scale.\"\n\n\n\t\n\t\t\n\t\tðŸ“Š Overview\n\t\n\nThis dataset contains 400,000 synthetic reasoning samples spanning 16 enterprise domains (Finance, Pharma, Legal, Cybersecurity, Supply Chain, etc.).\nIt was generated using the Sovereign Generator, which produced 1.6 million samples and applied a strict quality filter (Top 25%) to retain only the most logically consistent and complex chains.\nAverage Quality Score:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chkmie/Synthetic-Causal-Reasoning-50k.",
        "url": "https://huggingface.co/datasets/chkmie/Synthetic-Causal-Reasoning-50k",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "data-archetype/pexels_aesth_bucketed_1024",
        "author": "data-archetype",
        "created_at": "2026-01-08 13:25:10+00:00",
        "last_modified": "2026-01-08 14:24:24+00:00",
        "downloads": 41,
        "likes": 0,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:webdataset",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:webdataset",
          "library:mlcroissant",
          "region:us",
          "webdataset",
          "images",
          "captions"
        ],
        "description": "\n\t\n\t\t\n\t\tA captioned and aspect ratio bucketed dataset of about 200k pexel photos with subjectively good aesthetic quality, with a diverse range of themes\n\t\n\nThis version is scaled to approx 1024^2 resolution.\nSee below for more details\n\n\t\n\t\t\n\t\tBucketed Shards Dataset\n\t\n\nThis repository contains a bucketed-shards export (uncompressed TAR shards).\n\n\t\n\t\t\n\t\tFormat\n\t\n\n\nFormat: bucketed_shards_v1\nCreated: 2026-01-08T12:05:47.590411+00:00\nExport ID: export-2026-01-08T12:05:47.590411+00:00\nManifest:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/data-archetype/pexels_aesth_bucketed_1024.",
        "url": "https://huggingface.co/datasets/data-archetype/pexels_aesth_bucketed_1024",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "timopetric/GaMS-Nemotron-Chat",
        "author": "timopetric",
        "created_at": "2026-01-11 18:48:29+00:00",
        "last_modified": "2026-01-11 19:44:07+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "task_categories:text-generation",
          "task_categories:question-answering",
          "language:sl",
          "language:en",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tGaMS-Nemotron-Chat\n\t\n\nGaMS-Nemotron-Chat is a conversational dataset containing approximately 98,000 examples, designed to improve the instruction-following and conversational capabilities of Slovene language models. It is derived from the Nemotron Post Training Dataset v1, featuring responses generated by the Qwen3 235B A22B model. The examples are translated into Slovene using the GaMS-27B Instruct model.\nBased on this dataset we finetuned the GaMS-9B-Instruct-Nemotron andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/timopetric/GaMS-Nemotron-Chat.",
        "url": "https://huggingface.co/datasets/timopetric/GaMS-Nemotron-Chat",
        "languages": [
          "sl",
          "en"
        ],
        "tasks": [
          "translation",
          "text-generation",
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_table_1122",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:03:55+00:00",
        "last_modified": "2026-01-07 07:04:26+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_table_1122\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·çº¢è–¯part_1\ntotal_episodes: 254\ntotal_tasks: 1\nsize: 230.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_table_1122.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_sweet_potato_from_the_table_1122",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "chkmie/Sovereign-Financial-Aviation-Reasoning",
        "author": "chkmie",
        "created_at": "2026-01-11 09:59:29+00:00",
        "last_modified": "2026-01-11 10:07:39+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "region:us",
          "reasoning",
          "causality",
          "graph-rag",
          "finance",
          "aviation",
          "synthetic-data"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ§  Sovereign Enterprise Reasoning Dataset (SERD-v1)\n\t\n\n\n\"From Unstructured Text to Causal Logic.\"\n\n\n\t\n\t\t\n\t\tðŸ“Š Overview\n\t\n\nThis dataset contains 1,195 verified causal triplets extracted from complex, unstructured enterprise documents (Financial 10-K Reports, NTSB Aviation Accident Reports, Insurance Policy Wordings).\nUnlike standard QA datasets, this dataset provides structured Causal Chains that serve as ground-truth for Chain-of-Thought (CoT) reasoning.\n\n\n(Figure: The resulting causalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/chkmie/Sovereign-Financial-Aviation-Reasoning.",
        "url": "https://huggingface.co/datasets/chkmie/Sovereign-Financial-Aviation-Reasoning",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "allenai/dolma3_mix-6T",
        "author": "allenai",
        "created_at": "2025-11-24 04:14:53+00:00",
        "last_modified": "2026-01-05 17:49:51+00:00",
        "downloads": 65328,
        "likes": 10,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\n\n\n\n\t\n\t\t\n\t\tDolma 3 Mix (6T)\n\t\n\nThe Dolma 3 Mix (6T) is the collection of data used during the pretraining stage to train the Olmo-3-1125-32B model. This dataset is made up of ~6 trillion tokens from a diverse mix of web content, academic publications, code, and more. The majority of this dataset comes from Common Crawl.  \nFor more information on Dolma, please see our original release here.\n\n\t\n\t\t\n\t\n\t\n\t\tLicensing Information\n\t\n\nDolma 3 mix is licensed under the Open Data Commons Attributionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/dolma3_mix-6T.",
        "url": "https://huggingface.co/datasets/allenai/dolma3_mix-6T",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "debaterhub/cx-preference-pairs",
        "author": "debaterhub",
        "created_at": "2026-01-11 23:20:38+00:00",
        "last_modified": "2026-01-11 23:20:41+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:reinforcement-learning",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "debate",
          "cross-examination",
          "preference-learning",
          "dpo",
          "orpo"
        ],
        "description": "\n\t\n\t\t\n\t\tCX (Cross-Examination) Preference Pairs Dataset\n\t\n\nPreference pairs for training debate cross-examination skills via DPO/ORPO.\n\n\t\n\t\t\n\t\tSchema (34 columns)\n\t\n\n\n\t\n\t\t\n\t\tIdentifiers\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\npair_id\nstring\nUnique pair identifier\n\n\nsession_id\nstring\nCX session this pair belongs to\n\n\nbatch_id\nstring\nGeneration batch ID\n\n\niteration\nint\nTraining iteration\n\n\ntimestamp\nstring\nISO timestamp\n\n\nmodel_id\nstring\nModel used for generation\n\n\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tContextâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/debaterhub/cx-preference-pairs.",
        "url": "https://huggingface.co/datasets/debaterhub/cx-preference-pairs",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "reinforcement-learning"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_turn_off_lamp",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:55:35+00:00",
        "last_modified": "2026-01-05 23:56:18+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_franka_3rgb_turn_off_lamp\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å…³ç¯\ntotal_episodes: 294\ntotal_tasks: 1\nsize: 746.2M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_turn_off_lamp.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_franka_3rgb_turn_off_lamp",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_9_appleyellowplate",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:30:28+00:00",
        "last_modified": "2026-01-05 23:31:30+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_9_appleyellowplate\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœé»„ç›˜å­part_2\ntotal_episodes: 67\ntotal_tasks: 1\nsize: 856.9M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_9_appleyellowplate.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_9_appleyellowplate",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "amitlal/abap-code-sec-finetune",
        "author": "amitlal",
        "created_at": "2025-12-11 19:47:21+00:00",
        "last_modified": "2025-12-11 19:47:23+00:00",
        "downloads": 107,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/amitlal/abap-code-sec-finetune",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "NebulaPixel/SamSum-Pref",
        "author": "NebulaPixel",
        "created_at": "2025-11-17 03:29:07+00:00",
        "last_modified": "2025-11-24 02:50:26+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:summarization",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSamSum-Pref Dataset\n\t\n\nSamSum-Pref is a preference-aligned dialogue summarization dataset constructed by sampling from dadastory/SummOrchestra-Qwen3-8B-GRPO-BRL-SAMSUM, and filtering samples using DeepSeek-V3 as the evaluator. Preference scoring follows the AnythingReward evaluation paradigm, adapted to a strict rubric for dialogue-summary quality.\n\n\t\n\t\t\n\t\tEvaluation Principles\n\t\n\nEach sampled summary is scored according to the following weighted criteria:\n\nKey Information Coverageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/NebulaPixel/SamSum-Pref.",
        "url": "https://huggingface.co/datasets/NebulaPixel/SamSum-Pref",
        "languages": [
          "en"
        ],
        "tasks": [
          "summarization"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "kunarmy99/Question-AnsweringV.0",
        "author": "kunarmy99",
        "created_at": "2025-12-31 14:01:57+00:00",
        "last_modified": "2025-12-31 14:03:13+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "finance"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kunarmy99/Question-AnsweringV.0.",
        "url": "https://huggingface.co/datasets/kunarmy99/Question-AnsweringV.0",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "vector-institute/Factuality_Alignment",
        "author": "vector-institute",
        "created_at": "2025-12-22 21:27:42+00:00",
        "last_modified": "2026-01-07 03:50:07+00:00",
        "downloads": 57,
        "likes": 1,
        "tags": [
          "task_categories:reinforcement-learning",
          "language:en",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2410.18451",
          "arxiv:2601.03027",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tFactual Preference Alignment Dataset\n\t\n\n\n**âš ï¸ Warning:**This dataset contains hallucinated and synthetic responses\nintentionally generated for research on robust factuality alignment.\nResponses may include fabricated or incorrect information by design\nto support the evaluation of hallucination-aware learning.\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe AIXpert Preference Alignment Dataset is a curated collection of\n45,000 factuality-aware preference pairs designed to support\nresearch on Modifiedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vector-institute/Factuality_Alignment.",
        "url": "https://huggingface.co/datasets/vector-institute/Factuality_Alignment",
        "languages": [
          "en"
        ],
        "tasks": [
          "reinforcement-learning"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "bahuang123456/vqa-rad",
        "author": "bahuang123456",
        "created_at": "2026-01-09 04:28:25+00:00",
        "last_modified": "2026-01-09 04:28:26+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "medical"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for VQA-RAD\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nVQA-RAD is a dataset of question-answer pairs on radiology images. The dataset is intended to be used for training and testing \nMedical Visual Question Answering (VQA) systems. The dataset includes both open-ended questions and binary \"yes/no\" questions. \nThe dataset is built from MedPix, which is a free open-access online database of medical images.\nThe question-answer pairs were manually generated by a team of clinicians.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/bahuang123456/vqa-rad.",
        "url": "https://huggingface.co/datasets/bahuang123456/vqa-rad",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "paperswithbacktest/Stocks-Weekly-GovernmentContractsEntities",
        "author": "paperswithbacktest",
        "created_at": "2025-11-17 11:11:19+00:00",
        "last_modified": "2026-01-10 04:29:56+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Information\n\t\n\nWeekly Government Contract Entity Mapping aligned to listed company symbols,\nprovided by SOV.AI.\n\nCoverage: 3,500+ tickers with history since 2007-10-01\nUpdate cadence: Weekly refresh post Friday 23:00â€“00:00 US-EST\nFields:\nEntity identifiers (recipient and parent UEI)\nMatched names from federal filings and alternative datasets\nSimilarity scores and Bloomberg share identifiers for cross-dataset linkage\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tData Source\n\t\n\nGovernment spending entity feed.\n",
        "url": "https://huggingface.co/datasets/paperswithbacktest/Stocks-Weekly-GovernmentContractsEntities",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_4_potatobowloven_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 01:59:08+00:00",
        "last_modified": "2026-01-05 02:00:09+00:00",
        "downloads": 8,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_4_potatobowloven_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: åœŸè±†ç¢—çƒ¤ç®±part_1\ntotal_episodes: 25\ntotal_tasks: 1\nsize: 449.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_4_potatobowloven_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_4_potatobowloven_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241204_pro5",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 18:26:44+00:00",
        "last_modified": "2026-01-05 18:28:05+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241204_pro5\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: tienkung_gello_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç½®é¢åŒ…ç›˜å­part_4\ntotal_episodes: 281\ntotal_tasks: 1\nsize: 2.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241204_pro5.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_tienkung_gello_1rgb_place_bread_plate_241204_pro5",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_pot",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:52:07+00:00",
        "last_modified": "2026-01-05 22:52:14+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_put_yellow_pepper_in_pot\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é»„è¾£æ¤’æ”¾å…¥é”…ä¸­\ntotal_episodes: 26\ntotal_tasks: 1\nsize: 18.1M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_pot.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_put_yellow_pepper_in_pot",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "ifkash/fineweb-6b",
        "author": "ifkash",
        "created_at": "2025-12-23 10:15:30+00:00",
        "last_modified": "2026-01-11 10:46:54+00:00",
        "downloads": 7,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "size_categories:1B<n<10B",
          "region:us",
          "pretraining",
          "web-data",
          "fineweb"
        ],
        "description": "\n\t\n\t\t\n\t\tFineWeb-6B: First 6 Billion Tokens\n\t\n\nA curated subset of the FineWeb dataset containing the first 6 billion tokens, designed for efficient language model pre-training experiments.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains high-quality web text data suitable for pre-training small to medium-sized language models. It's particularly useful for researchers and practitioners who want to experiment with LLM pre-training without requiring massive computational resources.â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ifkash/fineweb-6b.",
        "url": "https://huggingface.co/datasets/ifkash/fineweb-6b",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "1B<n<10B"
        ]
      },
      {
        "id": "kostaspic/amfitrite-inland-waters-hab-sentinel2",
        "author": "kostaspic",
        "created_at": "2026-01-07 10:55:14+00:00",
        "last_modified": "2026-01-10 13:10:44+00:00",
        "downloads": 2583,
        "likes": 0,
        "tags": [
          "task_categories:image-classification",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "modality:image",
          "modality:geospatial",
          "region:us",
          "earth-observation",
          "remote-sensing",
          "sentinel-2",
          "water-quality",
          "harmful-algal-blooms",
          "environmental"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Amfitrite-Inland-Waters-HAB-Sentinel2\n\t\n\nThis dataset contains multispectral Sentinel-2 satellite imagery tiles focused on inland water bodies, classified by the severity of Harmful Algal Blooms (HABs). \nIt is designed to train Deep Learning models (like CNNs) for environmental monitoring.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nAmfitrite-Inland-Waters-HAB-Sentinel2 is a specialized dataset designed for the detection and classification of Harmfulâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kostaspic/amfitrite-inland-waters-hab-sentinel2.",
        "url": "https://huggingface.co/datasets/kostaspic/amfitrite-inland-waters-hab-sentinel2",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_yellow_block_on_table",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 17:31:31+00:00",
        "last_modified": "2026-01-05 17:32:28+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_yellow_block_on_table\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é»„è‰²ç§¯æœ¨æ”¾åœ¨æ¡Œå­ä¸Š\ntotal_episodes: 99\ntotal_tasks: 1\nsize: 365.8M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_yellow_block_on_table.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_yellow_block_on_table",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "OpenMOSS-Team/GameQA-5K",
        "author": "OpenMOSS-Team",
        "created_at": "2025-06-15 05:33:19+00:00",
        "last_modified": "2025-06-22 05:16:03+00:00",
        "downloads": 18,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "task_categories:image-text-to-text",
          "language:en",
          "license:mit",
          "modality:image",
          "arxiv:2505.13886",
          "region:us"
        ],
        "description": "In this repository, we specifically provide the 5k training samples from the complete GameQA-140K dataset used in our work for GRPO training of the models.\nRefer to our paper for details. And our code for training and evaluation is at https://github.com/tongjingqi/Code2Logic.\n\n\t\n\t\t\n\t\n\t\n\t\tCode2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning\n\t\n\nThis is the first work, to the best of our knowledge, that leverages game code to synthesize multimodal reasoning data forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/OpenMOSS-Team/GameQA-5K.",
        "url": "https://huggingface.co/datasets/OpenMOSS-Team/GameQA-5K",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "image-text-to-text"
        ],
        "size_categories": []
      },
      {
        "id": "Anees-umrani507gmail-com/AnthropicInterviewer",
        "author": "Anees-umrani507gmail-com",
        "created_at": "2026-01-07 14:44:47+00:00",
        "last_modified": "2026-01-07 14:44:47+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tAnthropic Interviewer\n\t\n\nA tool for conducting AI-powered qualitative research interviews at scale. In this study, we used Anthropic Interviewer to explore how 1,250 professionals integrate AI into their work and how they feel about its role in their future.\nAssociated Research: Introducing Anthropic Interviewer: What 1,250 professionals told us about working with AI\n\n\t\n\t\t\n\t\n\t\n\t\tDataset\n\t\n\nThis repository contains interview transcripts from 1,250 professionals:\n\nGeneral Workforce (N=1â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Anees-umrani507gmail-com/AnthropicInterviewer.",
        "url": "https://huggingface.co/datasets/Anees-umrani507gmail-com/AnthropicInterviewer",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_green_vegetable_in_the_basket_1121",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:36:18+00:00",
        "last_modified": "2026-01-07 07:36:31+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_put_the_green_vegetable_in_the_basket_1121\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†é’èœæ”¾å…¥ç¯®å­\ntotal_episodes: 40\ntotal_tasks: 1\nsize: 32.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_green_vegetable_in_the_basket_1121.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_put_the_green_vegetable_in_the_basket_1121",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "t2ance/selection_lower_4",
        "author": "t2ance",
        "created_at": "2026-01-04 23:01:02+00:00",
        "last_modified": "2026-01-05 07:20:47+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:code",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code-verification",
          "llm-judge",
          "best-of-n-selection",
          "process-reward-model"
        ],
        "description": "\n\t\n\t\t\n\t\tCodeRM Selection Trajectories\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains trajectories of an LLM judge selecting the best solution from k candidates.\nEach trajectory captures: problem, k candidate solutions, judge reasoning, selected index, and ground truth correctness.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nTraining Selection Verifiers: Learn to select the best solution from k candidates\nBest-of-N Selection: Train models for verifier-guided code generation\nPreference Learning: Use forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/t2ance/selection_lower_4.",
        "url": "https://huggingface.co/datasets/t2ance/selection_lower_4",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_1",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 12:32:02+00:00",
        "last_modified": "2026-01-05 12:34:47+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_1\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†æ¢¨æ”¾å…¥ç¢—ä¸­part_1\ntotal_episodes: 316\ntotal_tasks: 1\nsize: 522.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_1.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_241023_place_pear_in_bowl_1",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "AleelyA3/humanoid-robot-emergency-actions",
        "author": "AleelyA3",
        "created_at": "2026-01-08 16:17:39+00:00",
        "last_modified": "2026-01-09 05:12:39+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "humanoid",
          "emergency-actions",
          "robotics",
          "safety",
          "ml",
          "robot-behavior",
          "reactive-actions"
        ],
        "description": "\n\t\n\t\t\n\t\tHumanoid Robot Emergency Actions Dataset\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset contains labeled emergency and reactive behaviors for humanoid robots. It is designed to help train models that recognize and respond to dangerous or unexpected situations. The dataset is small, structured, and ideal for early-stage experimentation.\n\n\t\n\t\t\n\t\tClasses\n\t\n\n\nemergency_stop (high severity)\nevade_obstacle (medium severity)\nfall_recovery (high severity)\ncollision_avoidance (medium severity)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/AleelyA3/humanoid-robot-emergency-actions.",
        "url": "https://huggingface.co/datasets/AleelyA3/humanoid-robot-emergency-actions",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "DongSky/AEGIS",
        "author": "DongSky",
        "created_at": "2026-01-02 03:48:35+00:00",
        "last_modified": "2026-01-08 12:55:34+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:image-text-to-text",
          "task_categories:visual-question-answering",
          "task_categories:question-answering",
          "task_categories:text-to-image",
          "language:en",
          "language:zh",
          "license:mit",
          "size_categories:1K<n<10K",
          "arxiv:2601.00561",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tAEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Multimodal Models\n\t\n\n[ðŸ“‚ GitHub] [ðŸ†• Blog] [ðŸ“œ Paper]\n\n\t\n\t\t\n\t\tSummary\n\t\n\n\nThe capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (i.e., Assessing Editing, Generationâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DongSky/AEGIS.",
        "url": "https://huggingface.co/datasets/DongSky/AEGIS",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "image-text-to-text",
          "visual-question-answering",
          "question-answering",
          "text-to-image"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "brianmcgee/nix-cache-dataset",
        "author": "brianmcgee",
        "created_at": "2026-01-08 11:52:38+00:00",
        "last_modified": "2026-01-09 11:24:29+00:00",
        "downloads": 38,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1B<n<10B",
          "modality:tabular",
          "modality:text",
          "region:us",
          "nix",
          "nixos"
        ],
        "description": "\n\t\n\t\t\n\t\tNix Cache Dataset\n\t\n\nTBD\n",
        "url": "https://huggingface.co/datasets/brianmcgee/nix-cache-dataset",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1B<n<10B"
        ]
      },
      {
        "id": "Ker102/n8n-master-corpus",
        "author": "Ker102",
        "created_at": "2026-01-06 22:11:52+00:00",
        "last_modified": "2026-01-07 14:19:52+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "n8n",
          "automation",
          "workflow",
          "low-code",
          "agents",
          "mcp"
        ],
        "description": "\n\t\n\t\t\n\t\tn8n Automation Atlas: 36,405 n8n Workflows\n\t\n\nA curated collection of 36,405 unique n8n automation workflows, organized and cleaned for AI training, research, and community use. This dataset combines high-quality synthetic workflows generated via a custom archetype engine with a massive pool of cleaned community templates.\n\n\t\n\t\t\n\t\tðŸš€ Project Links\n\t\n\n\nMain Repository: GitHub - Ker102/n8n-workflows-36k\nAuthor: Ker102 on GitHub\nExplorer UI: A Vue-based web application is included in theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Ker102/n8n-master-corpus.",
        "url": "https://huggingface.co/datasets/Ker102/n8n-master-corpus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "chowmean/linux-commands",
        "author": "chowmean",
        "created_at": "2026-01-10 19:40:24+00:00",
        "last_modified": "2026-01-10 19:40:25+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:ru",
          "language:ar",
          "language:en",
          "language:zh",
          "language:de",
          "language:fr",
          "language:es",
          "language:pt",
          "language:ja",
          "language:ko",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "linux",
          "shell",
          "commands",
          "terminal",
          "multilingual",
          "development",
          "system-administration"
        ],
        "description": "\n\t\n\t\t\n\t\tLinLM Dataset\n\t\n\nA curated synthetic dataset for Linux command inference\nNatural language description -> shell commands\nFeatures: \n\nSupports 10 languages\nArch Linux commands recognition\nFine-tune LLM for development, system administration, file operations, Git, Docker, and more\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"missvector/linux-commands\")\n\ndef format_for_training(example):\n    return {\n        \"prompt\": f\"Convert to Linux command:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/chowmean/linux-commands.",
        "url": "https://huggingface.co/datasets/chowmean/linux-commands",
        "languages": [
          "ru",
          "ar",
          "en",
          "zh",
          "de",
          "fr",
          "es",
          "pt",
          "ja",
          "ko"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "hitsmy/AdaEval-Jigsaw-COCO",
        "author": "hitsmy",
        "created_at": "2026-01-05 13:41:30+00:00",
        "last_modified": "2026-01-05 13:43:47+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "jigsaw-puzzle",
          "spatial-reasoning",
          "visual-reasoning",
          "coco"
        ],
        "description": "\n\t\n\t\t\n\t\tJigsaw COCO Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains jigsaw puzzle tasks based on COCO images. The task is to identify which image piece correctly completes a given jigsaw puzzle.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTotal samples: 1000\nTask: Visual spatial reasoning with jigsaw puzzles\nSplits:\ntest: 1000 samples\n\n\n\t\n\t\t\n\t\tTask Description\n\t\n\nGiven a jigsaw puzzle image with one missing piece and three candidate pieces (A, B, C), the model needs to identify which pieceâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/hitsmy/AdaEval-Jigsaw-COCO.",
        "url": "https://huggingface.co/datasets/hitsmy/AdaEval-Jigsaw-COCO",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "elliotvincent/b-IAILD",
        "author": "elliotvincent",
        "created_at": "2025-11-25 13:52:25+00:00",
        "last_modified": "2025-11-25 17:21:59+00:00",
        "downloads": 5,
        "likes": 0,
        "tags": [
          "task_categories:image-segmentation",
          "language:en",
          "license:etalab-2.0",
          "size_categories:10K<n<100K",
          "modality:geospatial",
          "region:us",
          "remote-sensing",
          "earth-observation",
          "change-detection",
          "weak-temporal-supervision"
        ],
        "description": "\n\t\n\t\t\n\t\tb-IAILD: bi-temporal extension of IAILD\n\t\n\n\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nb-IAILD is a temporal extension of the IAILD (Inria Aerial Image Labeling Dataset) dataset [1] focused on building change detection in urban areas. The dataset provides bi-temporal orthoimage pairs with binary building footprint annotations, covering locations in the USA and Austria.\nProject page: https://xavibou.github.io/CDviaWTS/\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\nTask: Building change detection via weak temporalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/elliotvincent/b-IAILD.",
        "url": "https://huggingface.co/datasets/elliotvincent/b-IAILD",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-segmentation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ajay2k3/livestock-health-disease-ssa-synthetic",
        "author": "ajay2k3",
        "created_at": "2026-01-09 07:11:14+00:00",
        "last_modified": "2026-01-09 07:11:15+00:00",
        "downloads": 188,
        "likes": 0,
        "tags": [
          "task_categories:tabular-regression",
          "task_categories:tabular-classification",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "agriculture",
          "livestock",
          "africa",
          "synthetic-data",
          "food-security",
          "veterinary",
          "disease-surveillance",
          "smallholder-farming"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card: Livestock Health & Disease Surveillance (Synthetic Data)\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis synthetic dataset represents 1,000,000 African smallholder households with livestock systems, capturing livestock health, disease surveillance, veterinary access, and herd management practices across Sub-Saharan Africa. It combines baseline farm characteristics (Dataset 1) with 15 livestock-specific variables to create a comprehensive picture of livestock production systems andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/ajay2k3/livestock-health-disease-ssa-synthetic.",
        "url": "https://huggingface.co/datasets/ajay2k3/livestock-health-disease-ssa-synthetic",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-regression",
          "tabular-classification"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "waseem13/Indian-Bank-Statements",
        "author": "waseem13",
        "created_at": "2026-01-07 20:11:39+00:00",
        "last_modified": "2026-01-07 20:11:41+00:00",
        "downloads": 258,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:table-question-answering",
          "task_categories:text-generation",
          "language:en",
          "language:hi",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "modality:document",
          "region:us",
          "finance",
          "synthetic",
          "banking",
          "india",
          "transactions",
          "bank-statements",
          "document-ai"
        ],
        "description": "\n\t\n\t\t\n\t\tIndian Bank Statement Synthetic Dataset\n\t\n\nSynthetically generated Indian business bank statements with realistic transaction patterns, proper banking workflows, and India-specific features. Available in scanned PDF and digital JSON formats.\nScope: Current Accounts (business banking) only. Does not include personal/savings accounts.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\nCurated by: AgamiAI Inc.\nLanguage(s): English, Hindi (romanized)\nLicense: Apache 2.0\nRepository:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/waseem13/Indian-Bank-Statements.",
        "url": "https://huggingface.co/datasets/waseem13/Indian-Bank-Statements",
        "languages": [
          "en",
          "hi"
        ],
        "tasks": [
          "text-classification",
          "table-question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_cylinder",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 16:32:36+00:00",
        "last_modified": "2026-01-05 16:36:42+00:00",
        "downloads": 25,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_franka_3rgb_place_in_cylinder\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: franka_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾å…¥åœ†æŸ±ä½“\ntotal_episodes: 97\ntotal_tasks: 1\nsize: 269.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_cylinder.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_franka_3rgb_place_in_cylinder",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_28_packtable_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:06:04+00:00",
        "last_modified": "2026-01-05 23:07:50+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_28_packtable_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“åŒ…é¤æ¡Œpart_3\ntotal_episodes: 244\ntotal_tasks: 1\nsize: 4.5G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_28_packtable_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_28_packtable_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "NyaaaaaQwQ/conversational-bundles",
        "author": "NyaaaaaQwQ",
        "created_at": "2026-01-11 12:34:20+00:00",
        "last_modified": "2026-01-11 13:26:10+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "size_categories:1K<n<10K",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/NyaaaaaQwQ/conversational-bundles",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "just-dna-seq/ensembl_variations",
        "author": "just-dna-seq",
        "created_at": "2025-11-21 18:51:30+00:00",
        "last_modified": "2026-01-07 14:20:16+00:00",
        "downloads": 229,
        "likes": 1,
        "tags": [
          "task_categories:tabular-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:1B<n<10B",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "biology",
          "genomics",
          "variant-annotation",
          "ensembl",
          "vcf",
          "variants",
          "parquet",
          "bioinformatics"
        ],
        "description": "\n\t\n\t\t\n\t\tEnsembl Variations (Parquet Format)\n\t\n\nThis dataset contains Ensembl human genetic variations converted to Parquet format for fast and efficient VCF annotation.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset is organized by variant type:\n\nhomo_sapiens/\n\nEach directory contains parquet files split by chromosome.\n\n\t\n\t\t\n\t\tWhy Parquet?\n\t\n\nParquet format provides significant advantages over VCF for annotation tasks:\n\n10-100x faster querying and filtering\nEfficient compression (smaller file sizes)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/just-dna-seq/ensembl_variations.",
        "url": "https://huggingface.co/datasets/just-dna-seq/ensembl_variations",
        "languages": [
          "en"
        ],
        "tasks": [
          "tabular-classification"
        ],
        "size_categories": [
          "1B<n<10B"
        ]
      },
      {
        "id": "stellaathena/math_mcqa",
        "author": "stellaathena",
        "created_at": "2026-01-11 19:30:10+00:00",
        "last_modified": "2026-01-11 19:33:09+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:multiple-choice",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "region:us",
          "math",
          "mathematics",
          "mcqa",
          "multiple-choice",
          "reasoning",
          "education"
        ],
        "description": "\n\t\n\t\t\n\t\tMATH-MCQA: A Multiple Choice Adaptation of the MATH Dataset\n\t\n\nMATH-MCQA is a multiple choice question answering dataset derived from the MATH dataset (Hendrycks et al., 2021). Each problem from the original dataset has been converted into a 4-option multiple choice format with one correct answer and three plausible distractors.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\n\n\t\n\t\t\n\t\tData Fields\n\t\n\n\n\t\n\t\t\nField\nType\nDescription\n\n\n\t\t\nproblem\nstring\nThe mathematical problem statement (may contain LaTeX)â€¦ See the full description on the dataset page: https://huggingface.co/datasets/stellaathena/math_mcqa.",
        "url": "https://huggingface.co/datasets/stellaathena/math_mcqa",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "multiple-choice"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/AgiBotWorld-Beta_G1_task_741_Packaging_fruits",
        "author": "BAAI-DataCube",
        "created_at": "2025-12-26 20:07:34+00:00",
        "last_modified": "2026-01-05 17:12:12+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tagibot_task_741\n\t\n\nThis dataset converts the AgiBot format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\nrobot_name: G1\nend_effector: å¤¹çˆª\ntask: åŒ…è£…æ°´æžœ\ntotal_episodes: 317\ntotal_tasks: 1\nsize: 33G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.json\nâ”‚   â””â”€â”€ tasks.parquet\nâ””â”€â”€ videos\n    â”œâ”€â”€ observation.images.back_left_fisheyeâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_741_Packaging_fruits.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/AgiBotWorld-Beta_G1_task_741_Packaging_fruits",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1031",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 07:24:45+00:00",
        "last_modified": "2026-01-06 07:25:05+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1031\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»Žæ¡Œå­ä¸Šæ‹¿èµ·é»„ç“œpart_6\ntotal_episodes: 257\ntotal_tasks: 1\nsize: 254.6M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1031.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_pick_up_the_flowers_from_the_table_1031",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1126",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-07 07:20:51+00:00",
        "last_modified": "2026-01-07 07:21:29+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1126\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: å°†èŠ±æœµæ”¾åœ¨æ¡Œå­ä¸Špart_7\ntotal_episodes: 219\ntotal_tasks: 1\nsize: 125.5M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1126.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_place_the_flowers_on_the_table_1126",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_8_appleblueplate_2",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 10:41:35+00:00",
        "last_modified": "2026-01-05 10:45:18+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_agilex_3rgb_8_appleblueplate_2\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: è‹¹æžœè“ç›˜å­part_1\ntotal_episodes: 105\ntotal_tasks: 1\nsize: 946.7M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_8_appleblueplate_2.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_agilex_3rgb_8_appleblueplate_2",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "introspector/rustc-usage",
        "author": "introspector",
        "created_at": "2026-01-06 12:32:16+00:00",
        "last_modified": "2026-01-06 12:56:30+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "task_categories:other",
          "language:en",
          "license:mit",
          "size_categories:100M<n<1B",
          "region:us",
          "rust",
          "compiler",
          "ast",
          "usage-patterns",
          "code-analysis"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ„ Mycelial Rust Usage Patterns Dataset\n\t\n\nThe most comprehensive Rust compiler usage pattern dataset ever assembled! This dataset contains AST traversal data, type-aware literal tracking, and real-world compilation patterns from 864 crates plus rustc internals.\n\n\t\n\t\t\n\t\tðŸŒ Dataset Overview\n\t\n\n\n9,137 usage data files (113MB total)\n268 individual crates from cargo registry\nComplete rustc compiler internal usage patterns\nReal-world compilation patterns from production Rust ecosystemâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/introspector/rustc-usage.",
        "url": "https://huggingface.co/datasets/introspector/rustc-usage",
        "languages": [
          "en"
        ],
        "tasks": [
          "other"
        ],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_yellow_pepper",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 22:27:35+00:00",
        "last_modified": "2026-01-05 22:27:48+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_0_release_ur_1rgb_pick_up_yellow_pepper\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‹¿èµ·é»„è¾£æ¤’\ntotal_episodes: 98\ntotal_tasks: 1\nsize: 89.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€ stats.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_yellow_pepper.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_0_release_ur_1rgb_pick_up_yellow_pepper",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_39_puttomato",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-05 23:09:48+00:00",
        "last_modified": "2026-01-05 23:10:49+00:00",
        "downloads": 12,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:n<1K",
          "modality:video",
          "library:datasets",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_agilex_3rgb_39_puttomato\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: agilex_3rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ”¾ç•ªèŒ„part_2\ntotal_episodes: 151\ntotal_tasks: 1\nsize: 2.1G\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_39_puttomato.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_agilex_3rgb_39_puttomato",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "jdvakil/prox_test",
        "author": "jdvakil",
        "created_at": "2026-01-09 18:39:01+00:00",
        "last_modified": "2026-01-09 19:00:35+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "modality:tabular",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "robot-learning",
          "depth-sensors",
          "diffusion-policy",
          "franka",
          "isaac-lab",
          "proximity-sensing"
        ],
        "description": "\n\t\n\t\t\n\t\tProximity Learning Depth Sensor Dataset\n\t\n\nFranka Panda robot with multi-link depth sensors in Isaac Lab warehouse simulation for proximity-based robot learning.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains depth sensor readings from 39 distributed sensors mounted across the Franka Panda robot's links, collected in Isaac Lab simulation. The data is designed for training diffusion policies for collision-aware manipulation.\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\n\n\t\n\t\t\nProperty\nValueâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/jdvakil/prox_test.",
        "url": "https://huggingface.co/datasets/jdvakil/prox_test",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Bedrock",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:29:47+00:00",
        "last_modified": "2026-01-10 13:48:27+00:00",
        "downloads": 19,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq",
          "bedrock",
          "risc-v",
          "compiler",
          "low-level"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Bedrock\n\t\n\nA work-in-progress language and compiler for verified low-level programming targeting RISC-V.\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://github.com/mit-plv/bedrock2\nLicense: MIT\n\n\n\t\n\t\t\n\t\tStatistics\n\t\n\n\n\t\n\t\t\nProperty\nValue\n\n\n\t\t\nTotal Entries\n2,187\n\n\nFiles Processed\n289\n\n\n\t\n\n\n\t\n\t\t\n\t\tType Distribution\n\t\n\n\n\t\n\t\t\nType\nCount\n\n\n\t\t\nDefinition\n760\n\n\nLtac\n702\n\n\nLemma\n428\n\n\nLtac2\n132\n\n\nFixpoint\n46\n\n\nInductive\n35\n\n\nRecord\n27\n\n\nAxiom\n13\n\n\nClass\n11\n\n\nInstance\n11\n\n\nExample\n7\n\n\nCoercion\n5â€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Bedrock.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Bedrock",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1025",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 02:28:01+00:00",
        "last_modified": "2026-01-06 02:28:28+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1025\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: ä»ŽèŠ±ç“¶ä¸­å–å‡ºèŠ±æœµpart_1\ntotal_episodes: 22\ntotal_tasks: 1\nsize: 41.4M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1025.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_insert_the_flowers_from_the_vase_1025",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1118",
        "author": "BAAI-DataCube",
        "created_at": "2026-01-06 10:47:23+00:00",
        "last_modified": "2026-01-06 10:47:54+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:robotics",
          "language:en",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:timeseries",
          "modality:video",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tbenchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1118\n\t\n\nThis dataset converts the Robomain format uniformly into LeRobot V3.0.\n\n\t\n\t\t\n\t\tDataset Statistics\n\t\n\næœ¬ä½“: ur_1rgb\næœ«ç«¯æ‰§è¡Œå™¨: å¤¹çˆª\nä»»åŠ¡å¹³å°æ˜¾ç¤ºç‰ˆ: æ‰“å¼€åžƒåœ¾æ¡¶ç›–part_12\ntotal_episodes: 147\ntotal_tasks: 1\nsize: 98.0M\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nâ”œâ”€â”€ data\nâ”‚   â””â”€â”€ chunk-xxx\nâ”‚       â”œâ”€â”€ file-xxx.parquet\nâ”œâ”€â”€ images\nâ”‚   â””â”€â”€ observation.images.camera_top\nâ”œâ”€â”€ meta\nâ”‚   â”œâ”€â”€ episodes\nâ”‚   â”‚   â””â”€â”€ chunk-xxx\nâ”‚   â”‚       â””â”€â”€ file-xxx.parquet\nâ”‚   â”œâ”€â”€ info.json\nâ”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1118.",
        "url": "https://huggingface.co/datasets/BAAI-DataCube/robomind_benchmark1_1_release_ur_1rgb_uncap_open_the_trash_can_1118",
        "languages": [
          "en"
        ],
        "tasks": [
          "robotics"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "phanerozoic/Coq-Flocq",
        "author": "phanerozoic",
        "created_at": "2026-01-10 13:10:01+00:00",
        "last_modified": "2026-01-10 15:12:05+00:00",
        "downloads": 21,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:lgpl-3.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "theorem-proving",
          "formal-methods",
          "coq"
        ],
        "description": "\n\t\n\t\t\n\t\tCoq-Flocq\n\t\n\nStructured dataset from Flocq â€” Floating-point formalization.\n3,207 declarations extracted from Coq source files.\n\n\t\n\t\t\n\t\tApplications\n\t\n\n\nTraining language models on formal proofs\nFine-tuning theorem provers\nRetrieval-augmented generation for proof assistants\nLearning proof embeddings and representations\n\n\n\t\n\t\t\n\t\tSource\n\t\n\n\nRepository: https://gitlab.inria.fr/flocq/flocq\n\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nfact\nstring\nDeclaration body\n\n\ntype\nstring\nLemmaâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/phanerozoic/Coq-Flocq.",
        "url": "https://huggingface.co/datasets/phanerozoic/Coq-Flocq",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "GSMA/leaderboard",
        "author": "GSMA",
        "created_at": "2026-01-09 12:53:55+00:00",
        "last_modified": "2026-01-11 18:55:06+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "modality:text",
          "region:us",
          "telecommunications",
          "5G",
          "LLM-evaluation",
          "benchmark",
          "leaderboard"
        ],
        "description": "\n\t\n\t\t\n\t\tOpen Telco Leaderboard Dataset\n\t\n\nBenchmark scores for LLMs evaluated on telecommunications-specific tasks.\n\n\t\n\t\t\n\t\tSchema\n\t\n\n\n\t\n\t\t\nColumn\nType\nDescription\n\n\n\t\t\nmodel\nstring\nModel name with provider\n\n\nteleqna\nlist\n[score, stderr, n_samples]\n\n\ntelelogs\nlist\n[score, stderr, n_samples]\n\n\ntelemath\nlist\n[score, stderr, n_samples]\n\n\n3gpp_tsg\nlist\n[score, stderr, n_samples]\n\n\ndate\nstring\nEvaluation date\n\n\n\t\n\nEach benchmark column contains a list: [score (0-100), standard_errorâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GSMA/leaderboard.",
        "url": "https://huggingface.co/datasets/GSMA/leaderboard",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "pujan1245/imdb-genres",
        "author": "pujan1245",
        "created_at": "2026-01-06 14:11:22+00:00",
        "last_modified": "2026-01-06 14:11:24+00:00",
        "downloads": 14,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-nc-sa-4.0",
          "size_categories:100K<n<1M",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for IMDb Movie Dataset: All Movies by Genre\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is an adapted version of \"IMDb Movie Dataset: All Movies by Genre\" found at: https://www.kaggle.com/datasets/rajugc/imdb-movies-dataset-based-on-genre?select=history.csv.\nWithin the dataset, the movie title and year columns were combined, the genre was extracted from the seperate csv files, the pre-existing genre column was renamed to expanded-genres, any movies missing a descriptionâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/pujan1245/imdb-genres.",
        "url": "https://huggingface.co/datasets/pujan1245/imdb-genres",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "puyang2025/seven-phishing-email-datasets",
        "author": "puyang2025",
        "created_at": "2026-01-08 21:50:52+00:00",
        "last_modified": "2026-01-09 20:09:38+00:00",
        "downloads": 20,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_ids:multi-class-classification",
          "annotations_creators:no-annotation",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "email",
          "phishing",
          "spam",
          "security",
          "nlp"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Seven Phishing/Spam Email Datasets\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThis dataset is a unified, row-level email corpus built from seven commonly used public email datasets. It is intended for research on phishing/spam detection and related email-text classification tasks.\nEach row contains the email body (text), optional header-like fields (e.g., sender, receiver, date), the source dataset name (dataset_name), and a binary label (label).\n\n\t\n\t\t\n\t\n\t\n\t\tSupported Tasks andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/puyang2025/seven-phishing-email-datasets.",
        "url": "https://huggingface.co/datasets/puyang2025/seven-phishing-email-datasets",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "nguyenquocanh/Candlestick",
        "author": "nguyenquocanh",
        "created_at": "2025-06-12 14:07:29+00:00",
        "last_modified": "2026-01-05 09:33:17+00:00",
        "downloads": 17,
        "likes": 1,
        "tags": [
          "task_categories:image-classification",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "doi:10.57967/hf/7450",
          "region:us",
          "classification",
          "modeling",
          "time-series",
          "machine-learning"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/nguyenquocanh/Candlestick",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "suki1974/stackoverflow_QAs",
        "author": "suki1974",
        "created_at": "2026-01-08 01:49:41+00:00",
        "last_modified": "2026-01-08 01:49:43+00:00",
        "downloads": 4,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tStackOverflow Q&A Dataset for Various Projects\n\t\n\n\n\t\n\t\t\n\t\tDescription\n\t\n\nThis dataset consists of Q&A data extracted from StackOverflow, related to different projects of CNCF (Cloud Native Computing Foundation) landscape. It includes the following three columns:\n\nQuestion: The question asked on StackOverflow.\nAnswer: The corresponding answer to the question.\nTag: The name of the project to which the question and answer are related.\n\nThe data was collected using the Git Exchange API toâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/suki1974/stackoverflow_QAs.",
        "url": "https://huggingface.co/datasets/suki1974/stackoverflow_QAs",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "shantoislamdev/linux-commands",
        "author": "shantoislamdev",
        "created_at": "2026-01-08 14:34:01+00:00",
        "last_modified": "2026-01-08 14:34:01+00:00",
        "downloads": 23,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:ru",
          "language:ar",
          "language:en",
          "language:zh",
          "language:de",
          "language:fr",
          "language:es",
          "language:pt",
          "language:ja",
          "language:ko",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "linux",
          "shell",
          "commands",
          "terminal",
          "multilingual",
          "development",
          "system-administration"
        ],
        "description": "\n\t\n\t\t\n\t\tLinLM Dataset\n\t\n\nA curated synthetic dataset for Linux command inference\nNatural language description -> shell commands\nFeatures: \n\nSupports 10 languages\nArch Linux commands recognition\nFine-tune LLM for development, system administration, file operations, Git, Docker, and more\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"missvector/linux-commands\")\n\ndef format_for_training(example):\n    return {\n        \"prompt\": f\"Convert to Linux command:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/shantoislamdev/linux-commands.",
        "url": "https://huggingface.co/datasets/shantoislamdev/linux-commands",
        "languages": [
          "ru",
          "ar",
          "en",
          "zh",
          "de",
          "fr",
          "es",
          "pt",
          "ja",
          "ko"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      }
    ],
    "removed_datasets": [
      {
        "id": "atomscott/soccertrack-v2",
        "author": "atomscott",
        "created_at": "2025-04-10 05:29:41+00:00",
        "last_modified": "2025-04-10 05:44:34+00:00",
        "downloads": 31,
        "likes": 0,
        "tags": [
          "language:ja",
          "language:en",
          "license:apache-2.0",
          "region:us",
          "sports",
          "soccer"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/atomscott/soccertrack-v2",
        "languages": [
          "ja",
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "ifkash/IITM-BS-Grading-Doc-Sept-2024",
        "author": "ifkash",
        "created_at": "2024-09-14 17:40:39+00:00",
        "last_modified": "2024-09-24 15:00:06+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tGrading Doc of IIT Madras BS Degree - September 2024 Term\n\t\n\nGrading Doc outlines the course structure, how each course grades the student with various other details like graded assignment scoring, quiz marking and bonus, etc. This repo contains the Grading Doc for September 2024 term, in an instruction fine-tuning dataset format which can be used to train your own LLMs.\n",
        "url": "https://huggingface.co/datasets/ifkash/IITM-BS-Grading-Doc-Sept-2024",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "kingrhai07/Nemotron-Instruction-Following-Chat-v1",
        "author": "kingrhai07",
        "created_at": "2026-01-02 06:27:55+00:00",
        "last_modified": "2026-01-02 06:27:56+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Description:\n\t\n\nThe Nemotron-Instruction-Following-Chat-v1 dataset is designed to broadly strengthen the modelâ€™s interactive capabilities, spanning open-ended chat, precise instruction following, and reliable structured output generation. It combines refreshed chat data from Nemotron-Post-Training-Dataset-v2 (extended to multi-turn) with synthetic dialogues produced by strong frontier models such as GPT-OSS-120B and Qwen3-235B variants. \nThis dataset is ready for commercialâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kingrhai07/Nemotron-Instruction-Following-Chat-v1.",
        "url": "https://huggingface.co/datasets/kingrhai07/Nemotron-Instruction-Following-Chat-v1",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "bhaiyasingh45/multiagent-router-finetuning",
        "author": "bhaiyasingh45",
        "created_at": "2026-01-04 13:42:32+00:00",
        "last_modified": "2026-01-04 16:37:24+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "function-calling",
          "multi-agent",
          "routing",
          "customer-support",
          "synthetic"
        ],
        "description": "\n\t\n\t\t\n\t\tMulti-Agent Router Fine-tuning Dataset\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset is designed for fine-tuning language models to perform intelligent routing in multi-agent customer support systems. The model learns to classify user queries and route them to the appropriate specialized agent with relevant parameters.\n\n\t\n\t\t\n\t\tSupported Tasks\n\t\n\n\nFunction Calling: Route queries to appropriate agent functions\nIntent Classification: Identify the type of support needed\nParameterâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/bhaiyasingh45/multiagent-router-finetuning.",
        "url": "https://huggingface.co/datasets/bhaiyasingh45/multiagent-router-finetuning",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "allenai/dolma3_mix-6T-1025",
        "author": "allenai",
        "created_at": "2025-10-23 22:00:10+00:00",
        "last_modified": "2026-01-01 22:58:27+00:00",
        "downloads": 183373,
        "likes": 23,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tâš ï¸ NOTE: This dataset does not contain the full set of olmOCR PDFs. âš ï¸\n\t\n\nSome of our olmOCR PDFs have been redacted following the training of Olmo 3 7B. For a more complete set of olmOCR PDFs, please refer to our 32B data mix: https://huggingface.co/datasets/allenai/dolma3_mix-5.5T-1125\n\n\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tDolma 3 Mix (6T)\n\t\n\nThe Dolma 3 Mix (6T) is the collection of data used during the pretraining stage to train the Olmo-3-1025-7B model. This dataset is made up of ~6 trillion tokensâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/dolma3_mix-6T-1025.",
        "url": "https://huggingface.co/datasets/allenai/dolma3_mix-6T-1025",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "entropy4energy/S4E-MatForge",
        "author": "entropy4energy",
        "created_at": "2025-11-25 03:06:08+00:00",
        "last_modified": "2025-12-10 20:28:05+00:00",
        "downloads": 41,
        "likes": 0,
        "tags": [
          "task_categories:other",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "region:us",
          "materials-science",
          "dft",
          "machine-learning",
          "high-entropy-materials",
          "mlip",
          "computational-chemistry"
        ],
        "description": "\n\t\n\t\t\n\t\tCHAOS-MatForge: Combinatorial High-throughput Analysis and Optimization for Synthesis Database\n\t\n\nThis dataset is a contribution from the Entropy for Energy (S4E) Laboratory at Johns Hopkins University, led by Prof. Corey Oses.\nWe release a large-scale, million-level dataset of high-quality VASP calculations for training machine learning interatomic potentials (MLIPs). This database provides comprehensive coverage of both ordered and disordered high-entropy material systems.\nFor moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/entropy4energy/S4E-MatForge.",
        "url": "https://huggingface.co/datasets/entropy4energy/S4E-MatForge",
        "languages": [
          "en"
        ],
        "tasks": [
          "other"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Code2Logic/GameQA-5K",
        "author": "Code2Logic",
        "created_at": "2025-06-15 05:33:19+00:00",
        "last_modified": "2025-06-22 05:16:03+00:00",
        "downloads": 53,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "task_categories:image-text-to-text",
          "language:en",
          "license:mit",
          "modality:image",
          "arxiv:2505.13886",
          "region:us"
        ],
        "description": "In this repository, we specifically provide the 5k training samples from the complete GameQA-140K dataset used in our work for GRPO training of the models.\nRefer to our paper for details. And our code for training and evaluation is at https://github.com/tongjingqi/Code2Logic.\n\n\t\n\t\t\n\t\n\t\n\t\tCode2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning\n\t\n\nThis is the first work, to the best of our knowledge, that leverages game code to synthesize multimodal reasoning data forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Code2Logic/GameQA-5K.",
        "url": "https://huggingface.co/datasets/Code2Logic/GameQA-5K",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "image-text-to-text"
        ],
        "size_categories": []
      },
      {
        "id": "LIUM/tedlium",
        "author": "LIUM",
        "created_at": "2022-05-11 12:47:06+00:00",
        "last_modified": "2024-09-10 18:27:41+00:00",
        "downloads": 1443,
        "likes": 30,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "annotations_creators:expert-generated",
          "language_creators:expert-generated",
          "multilinguality:monolingual",
          "source_datasets:original",
          "language:en",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for tedlium\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nThe TED-LIUM corpus is English-language TED talks, with transcriptions, sampled at 16kHz. The three releases of the corpus range from 118 to 452 hours of transcribed speech data.\n\n\t\n\t\t\n\t\tExample\n\t\n\nfrom datasets import load_dataset\n\ntedlium = load_dataset(\"LIUM/tedlium\", \"release1\") # for Release 1\n\n# see structure\nprint(tedlium)\n\n# load audio sample on the fly\naudio_input = tedlium[\"train\"][0][\"audio\"]  # first decoded audioâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/LIUM/tedlium.",
        "url": "https://huggingface.co/datasets/LIUM/tedlium",
        "languages": [
          "en"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "kingrhai07/mobile-actions",
        "author": "kingrhai07",
        "created_at": "2025-12-27 09:34:56+00:00",
        "last_modified": "2025-12-27 09:34:57+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc-by-4.0",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "gemma3",
          "gemma",
          "google",
          "functiongemma",
          "mobile-actions",
          "function-calling"
        ],
        "description": "\n\t\n\t\t\n\t\tMobile Actions: A Dataset for On-Device Function Calling\n\t\n\nThe dataset contains conversational traces designed to train lightweight models (such as FunctionGemma 270M) to translate natural language instructions into executable function calls for Android OS system tools.\n\n\t\n\t\t\n\t\tDataset Format\n\t\n\nThe dataset is provided in JSONL format. Each line represents a data sample. The\ndataset is pre-split into training and evaluation sets. This distinction is\ndenoted by the metadata fieldâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kingrhai07/mobile-actions.",
        "url": "https://huggingface.co/datasets/kingrhai07/mobile-actions",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "MickeyLLG/SITalk_large_split",
        "author": "MickeyLLG",
        "created_at": "2025-10-27 11:30:00+00:00",
        "last_modified": "2025-10-27 11:57:40+00:00",
        "downloads": 15,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "region:us"
        ],
        "description": "cat SITalk_large.tar.part-* | tar -xvf -\n\n",
        "url": "https://huggingface.co/datasets/MickeyLLG/SITalk_large_split",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "SkyWhal3/STXBP1-RAG-Nemotron",
        "author": "SkyWhal3",
        "created_at": "2026-01-03 14:41:45+00:00",
        "last_modified": "2026-01-03 15:23:30+00:00",
        "downloads": 53,
        "likes": 0,
        "tags": [
          "task_categories:text-retrieval",
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:n<1K",
          "format:json",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "rag",
          "retrieval-augmented-generation",
          "biomedical",
          "neuroscience",
          "rare-disease",
          "STXBP1",
          "epilepsy",
          "chromadb",
          "vector-database",
          "nvidia",
          "nemotron",
          "llama",
          "sentence-transformers"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ§¬âš¡ STXBP1-ARIA RAG Database v10 - NVIDIA Nemotron Embeddings\n\t\n\nThe most advanced RAG database for STXBP1 therapeutic research.\nA pre-built ChromaDB vector database containing:\n571,465 indexed text chunks from ~17,000 curated PubMed Central (PMC) biomedical papers, \nEmbedded with NVIDIA's state-of-the-art Llama-Nemotron-Embed-1B-v2 model featuring 2048-dimensional embeddings.\n\nâš¡ This is the premium GPU-accelerated version â€” Nemotron embeddings deliver maximum semantic precision forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/SkyWhal3/STXBP1-RAG-Nemotron.",
        "url": "https://huggingface.co/datasets/SkyWhal3/STXBP1-RAG-Nemotron",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-retrieval",
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "odl-raiser/DiagramGen",
        "author": "odl-raiser",
        "created_at": "2024-11-13 09:24:42+00:00",
        "last_modified": "2025-03-10 01:44:21+00:00",
        "downloads": 525,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:image-to-text",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2411.11916",
          "region:us"
        ],
        "description": "ðŸ“‘paper link\n\n\t\n\t\t\n\t\tDataset Card: DiagramAgent/DiagramGenBenchmark\n\t\n\n\n\t\n\t\t\n\t\t1. Overview\n\t\n\nDiagramAgent/DiagramGenBenchmark is a comprehensive benchmark designed for evaluating text-to-diagram generation and editing tasks. It provides a diverse set of diagram types alongside corresponding textual descriptions and code representations, aiming to facilitate research in generating structured visual content from natural language inputs.\n\n\t\n\t\t\n\t\t2. Dataset Description\n\t\n\n\nObjective:To transformâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/odl-raiser/DiagramGen.",
        "url": "https://huggingface.co/datasets/odl-raiser/DiagramGen",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "image-to-text"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "t2ance/selection_upper",
        "author": "t2ance",
        "created_at": "2026-01-04 18:15:24+00:00",
        "last_modified": "2026-01-04 22:39:52+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:code",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code-verification",
          "llm-judge",
          "best-of-n-selection",
          "process-reward-model"
        ],
        "description": "\n\t\n\t\t\n\t\tCodeRM Selection Trajectories\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains trajectories of an LLM judge selecting the best solution from k candidates.\nEach trajectory captures: problem, k candidate solutions, judge reasoning, selected index, and ground truth correctness.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nTraining Selection Verifiers: Learn to select the best solution from k candidates\nBest-of-N Selection: Train models for verifier-guided code generation\nPreference Learning: Use forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/t2ance/selection_upper.",
        "url": "https://huggingface.co/datasets/t2ance/selection_upper",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "kingrhai07/medical-o1-reasoning-SFT",
        "author": "kingrhai07",
        "created_at": "2026-01-04 04:10:46+00:00",
        "last_modified": "2026-01-04 04:10:46+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "language:zh",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2412.18925",
          "region:us",
          "medical",
          "biology"
        ],
        "description": "\n\t\n\t\t\n\t\tNews\n\t\n\n[2025/04/22] We split the data and kept only the medical SFT dataset (medical_o1_sft.json). The file medical_o1_sft_mix.json contains a mix of medical and general instruction data.\n[2025/02/22] We released the distilled dataset from Deepseek-R1 based on medical verifiable problems. You can use it to initialize your models with the reasoning chain from Deepseek-R1.\n[2024/12/25] We open-sourced the medical reasoning dataset for SFT, built on medical verifiable problems and an LLMâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kingrhai07/medical-o1-reasoning-SFT.",
        "url": "https://huggingface.co/datasets/kingrhai07/medical-o1-reasoning-SFT",
        "languages": [
          "en",
          "zh"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "AISNP/COCO2017-captions",
        "author": "AISNP",
        "created_at": "2025-09-09 17:11:31+00:00",
        "last_modified": "2025-09-09 22:49:57+00:00",
        "downloads": 86,
        "likes": 0,
        "tags": [
          "task_categories:image-to-text",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:image",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/AISNP/COCO2017-captions",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-text"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "dadastory/SamSum-Pref",
        "author": "dadastory",
        "created_at": "2025-11-17 03:29:07+00:00",
        "last_modified": "2025-11-24 02:50:26+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:summarization",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "\n\t\n\t\t\n\t\tSamSum-Pref Dataset\n\t\n\nSamSum-Pref is a preference-aligned dialogue summarization dataset constructed by sampling from dadastory/SummOrchestra-Qwen3-8B-GRPO-BRL-SAMSUM, and filtering samples using DeepSeek-V3 as the evaluator. Preference scoring follows the AnythingReward evaluation paradigm, adapted to a strict rubric for dialogue-summary quality.\n\n\t\n\t\t\n\t\tEvaluation Principles\n\t\n\nEach sampled summary is scored according to the following weighted criteria:\n\nKey Information Coverageâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/dadastory/SamSum-Pref.",
        "url": "https://huggingface.co/datasets/dadastory/SamSum-Pref",
        "languages": [
          "en"
        ],
        "tasks": [
          "summarization"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "ulysses3753/ulysses-threat-response",
        "author": "ulysses3753",
        "created_at": "2025-12-16 21:12:18+00:00",
        "last_modified": "2025-12-17 13:45:51+00:00",
        "downloads": 1,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us",
          "security",
          "cybersecurity",
          "incident-response",
          "mitre-attack",
          "threat-detection"
        ],
        "description": "\n\t\n\t\t\n\t\tUlysses Threat Response Training Corpus\n\t\n\nA comprehensive instruction-tuning dataset for training LLMs on cybersecurity \nthreat detection, incident response, and remediation.\n\n\t\n\t\t\n\t\tCoverage\n\t\n\n\nMITRE ATT&CK Enterprise (all 778 techniques)\nLiving Off The Land (LOLBAS, GTFOBins)\nWindows/Linux internals\nCloud security (AWS, Azure, GCP, K8s)\nIncident response workflows\nDetection engineering\n\n\n\t\n\t\t\n\t\tUsage\n\t\n\nfrom datasets import load_dataset\ndataset =â€¦ See the full description on the dataset page: https://huggingface.co/datasets/ulysses3753/ulysses-threat-response.",
        "url": "https://huggingface.co/datasets/ulysses3753/ulysses-threat-response",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "PowertronGlobalAustin/powertron-permafrost-corpus",
        "author": "PowertronGlobalAustin",
        "created_at": "2025-12-30 02:23:00+00:00",
        "last_modified": "2025-12-30 03:17:11+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:question-answering",
          "task_categories:feature-extraction",
          "language:en",
          "license:other",
          "size_categories:100K<n<1M",
          "region:us",
          "energy-efficiency",
          "hvac",
          "building-science",
          "climate-tech",
          "sustainability",
          "engineering",
          "technical-documentation",
          "case-studies",
          "measurements",
          "ipmvp",
          "permafrost-nmr",
          "powertron",
          "nanotechnology",
          "refrigeration",
          "cooling-systems"
        ],
        "description": "\n\t\n\t\t\n\t\tPowertron PermaFrost NMR Energy Corpus\n\t\n\nThe largest publicly available PE-certified HVAC efficiency dataset - 15 years of real-world field measurements from thousands of installations globally.\n\n\n\n\n\n\n\n\t\n\t\t\n\t\tWhat Is This Dataset?\n\t\n\nThis corpus contains 153 technical documents including case studies, lab reports, government validation, longevity studies, and a structured measurement database of 254 PE-certified tests documenting energy efficiency improvements to HVAC/R (Heatingâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PowertronGlobalAustin/powertron-permafrost-corpus.",
        "url": "https://huggingface.co/datasets/PowertronGlobalAustin/powertron-permafrost-corpus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "question-answering",
          "feature-extraction"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "code-switching/eval4-question_answering",
        "author": "code-switching",
        "created_at": "2025-06-13 08:02:28+00:00",
        "last_modified": "2025-12-29 12:35:17+00:00",
        "downloads": 177,
        "likes": 0,
        "tags": [
          "language:su",
          "language:jv",
          "language:id",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/code-switching/eval4-question_answering",
        "languages": [
          "su",
          "jv",
          "id",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "odl-raiser/Envision",
        "author": "odl-raiser",
        "created_at": "2025-11-29 12:29:59+00:00",
        "last_modified": "2025-12-02 03:24:52+00:00",
        "downloads": 177,
        "likes": 24,
        "tags": [
          "task_categories:text-to-image",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "modality:text",
          "arxiv:2512.01816",
          "region:us",
          "unified-multimodal-model",
          "T2I"
        ],
        "description": "\n\t\n\t\t\n\t\tEnvision\n\t\n\n\n\t\n\t\t\n\t\tEnvision: Benchmarking Unified Understanding & Generation for Causal World Process Insights\n\t\n\n\nEnvision is a comprehensive benchmark designed for evaluating the unified understanding and sequential generation capabilities of multimodal models, specifically focusing on the modeling of causal world processes. The benchmark assesses a model's ability to generate coherent, physically plausible, and aesthetically pleasing sequences of images that follow a complexâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/odl-raiser/Envision.",
        "url": "https://huggingface.co/datasets/odl-raiser/Envision",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-to-image"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "kingrhai07/Medical-Reasoning-SFT-GPT-OSS-120B",
        "author": "kingrhai07",
        "created_at": "2026-01-01 05:08:59+00:00",
        "last_modified": "2026-01-01 05:09:02+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "biology",
          "medical",
          "healthcare"
        ],
        "description": "\n\t\n\t\t\n\t\tMedical-Reasoning-SFT-GPT-OSS-120B\n\t\n\nA high-quality synthetic dataset of medical reasoning conversations generated using OpenAI's gpt-oss-120B model with reasoning effort set to high, designed for supervised fine-tuning of large language models in healthcare applications. I used Intelligent-Internet/II-Medical-Reasoning-SFT as a seed dataset, so I would like to thank the authors and Intelligent-Internet for their great work.\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Statistics\n\t\n\n\nTotal Samples: 200,927â€¦ See the full description on the dataset page: https://huggingface.co/datasets/kingrhai07/Medical-Reasoning-SFT-GPT-OSS-120B.",
        "url": "https://huggingface.co/datasets/kingrhai07/Medical-Reasoning-SFT-GPT-OSS-120B",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "kunarmy99/data1",
        "author": "kunarmy99",
        "created_at": "2025-12-30 09:07:44+00:00",
        "last_modified": "2025-12-30 09:08:23+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/kunarmy99/data1",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Shirova/Common-Crawl-2025-June",
        "author": "Shirova",
        "created_at": "2025-11-08 09:34:12+00:00",
        "last_modified": "2025-11-09 10:57:54+00:00",
        "downloads": 27,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:100M<n<1B",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "library:polars",
          "region:us",
          "Web",
          "WebData",
          "Common_Crawl"
        ],
        "description": "\n\t\n\t\t\n\t\tCommon Crawl 2025 June\n\t\n\nCommon-Crawl-2025-June is a curated, processed, and filtered dataset built from the June 2025 Common Crawl web corpus.It contains data crawled between June 1, 2025, and June 10, 2025, processed using Hugging Faceâ€™s Data Trove pipeline and several AI-based content filters to remove unsafe, harmful, or low-quality text.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Summary\n\t\n\nThis dataset represents one of the latest structured Common Crawl releases with high-quality web data.Theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Shirova/Common-Crawl-2025-June.",
        "url": "https://huggingface.co/datasets/Shirova/Common-Crawl-2025-June",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "token-classification"
        ],
        "size_categories": [
          "100M<n<1B"
        ]
      },
      {
        "id": "BorisGuo/pair_touch_13m",
        "author": "BorisGuo",
        "created_at": "2025-12-30 08:42:17+00:00",
        "last_modified": "2025-12-31 01:35:13+00:00",
        "downloads": 6778,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "region:us",
          "tactile",
          "force",
          "Multimodal",
          "h5"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/BorisGuo/pair_touch_13m",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "makora-ai/OptimizationCache",
        "author": "makora-ai",
        "created_at": "2025-12-28 15:20:49+00:00",
        "last_modified": "2025-12-28 15:20:59+00:00",
        "downloads": 27,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "region:us",
          "gpu-optimization",
          "cuda",
          "triton",
          "kernel-optimization",
          "lenny"
        ],
        "description": "\n\t\n\t\t\n\t\tOptimization Cache for Lenny\n\t\n\nA curated collection of GPU kernel optimization techniques for use with Lenny, \nthe AI assistant for GPU kernel optimization.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains optimization entries that help guide LLM-based kernel generation. \nEach entry includes:\n\nDescription: What the optimization does\nPatterns: When to apply it (kernel types, code patterns)\nInstructions: How to implement it\nCode Snippets: Before/after examples\nDocumentation: References andâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/makora-ai/OptimizationCache.",
        "url": "https://huggingface.co/datasets/makora-ai/OptimizationCache",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "CASABLANCAhotelsoftware/RESTAPITestGenBench",
        "author": "CASABLANCAhotelsoftware",
        "created_at": "2025-11-10 14:33:15+00:00",
        "last_modified": "2025-11-17 15:09:11+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "language:en",
          "license:agpl-3.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us",
          "rest-api",
          "api-testing",
          "test-generation",
          "benchmarking"
        ],
        "description": "\n\t\n\t\t\n\t\tREST API Test Generation Benchmark\n\t\n\nA benchmark dataset for evaluating functional REST API test case generation capabilities from natural language requirements.\n\n\t\n\t\t\n\t\tLicense\n\t\n\nAGPL-3.0 License - See LICENSE file for details.\n",
        "url": "https://huggingface.co/datasets/CASABLANCAhotelsoftware/RESTAPITestGenBench",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "gtfintechlab/KG-QAGen-D",
        "author": "gtfintechlab",
        "created_at": "2025-05-15 23:02:33+00:00",
        "last_modified": "2025-12-23 05:11:55+00:00",
        "downloads": 303,
        "likes": 2,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:cc-by-nc-nd-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "library:polars",
          "arxiv:2505.12495",
          "region:us",
          "finance"
        ],
        "description": "\n\t\n\t\t\n\t\tKG-QAGen: A Knowledge-Graph-Based Framework for Systematic Question Generation and Long-Context LLM Evaluation\n\t\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\nKGâ€‘QAGen is a framework that leverages structured annotations of large documents to build knowledge graphs and systematically extract QA pairs at controlled difficulty levels, enabling fineâ€‘grained evaluation of longâ€‘context LLMs.\n\n\t\n\t\n\t\n\t\tKGâ€‘QAGenâ€‘D Dataset\n\t\n\nWe produce KGâ€‘QAGenâ€‘D, a 20,139-question benchmark derived from 170 SEC creditâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/gtfintechlab/KG-QAGen-D.",
        "url": "https://huggingface.co/datasets/gtfintechlab/KG-QAGen-D",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "t2ance/selection_lower",
        "author": "t2ance",
        "created_at": "2026-01-04 23:01:02+00:00",
        "last_modified": "2026-01-05 00:56:52+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:code",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "code-verification",
          "llm-judge",
          "best-of-n-selection",
          "process-reward-model"
        ],
        "description": "\n\t\n\t\t\n\t\tCodeRM Selection Trajectories\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains trajectories of an LLM judge selecting the best solution from k candidates.\nEach trajectory captures: problem, k candidate solutions, judge reasoning, selected index, and ground truth correctness.\n\n\t\n\t\t\n\t\tUse Cases\n\t\n\n\nTraining Selection Verifiers: Learn to select the best solution from k candidates\nBest-of-N Selection: Train models for verifier-guided code generation\nPreference Learning: Use forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/t2ance/selection_lower.",
        "url": "https://huggingface.co/datasets/t2ance/selection_lower",
        "languages": [
          "code",
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Stable-X/NeAR-300K",
        "author": "Stable-X",
        "created_at": "2025-12-09 08:11:50+00:00",
        "last_modified": "2025-12-09 16:48:53+00:00",
        "downloads": 2070,
        "likes": 1,
        "tags": [
          "task_categories:image-to-3d",
          "task_categories:image-to-image",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Stable-X/NeAR-300K",
        "languages": [
          "en"
        ],
        "tasks": [
          "image-to-3d",
          "image-to-image"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Interhuman/wave1-test-set",
        "author": "Interhuman",
        "created_at": "2025-12-17 13:32:50+00:00",
        "last_modified": "2025-12-17 13:32:51+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "task_categories:video-classification",
          "task_categories:zero-shot-classification",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us",
          "social-signals",
          "behavioral-analysis",
          "multimodal",
          "video"
        ],
        "description": "\n\t\n\t\t\n\t\tWave1 Test Set - Social Signal Detection\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains video clips annotated with social and affective signals for behavioral analysis tasks. Each sample includes:\n\nSystem Prompt: Instructions for behavioral analysis\nVideo URL: Link to the video clip\nMulti-labels: Detected social signals from 12 categories\nVideo ID: Unique identifier for the video\n\n\n\t\n\t\t\n\t\n\t\n\t\tSocial Signal Categories\n\t\n\nThe dataset includes annotations for 12 social signals:â€¦ See the full description on the dataset page: https://huggingface.co/datasets/Interhuman/wave1-test-set.",
        "url": "https://huggingface.co/datasets/Interhuman/wave1-test-set",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-classification",
          "zero-shot-classification"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "annajuliaasf/Audio-Transcription-Models-Comparison-PT-BR",
        "author": "annajuliaasf",
        "created_at": "2025-12-15 18:19:31+00:00",
        "last_modified": "2025-12-22 19:49:50+00:00",
        "downloads": 32,
        "likes": 0,
        "tags": [
          "task_categories:automatic-speech-recognition",
          "language:pt",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:audiofolder",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:mlcroissant",
          "region:us",
          "speech-to-text",
          "audio",
          "benchmark",
          "evaluation",
          "wer",
          "pt-br",
          "whisper",
          "gpt-4o",
          "gemini"
        ],
        "description": "\n\t\n\t\t\n\t\tAudio Transcription Models Comparison (PT-BR) ðŸ‡§ðŸ‡·\n\t\n\n\n\n\n\n\nA dataset dedicated to comparing the performance of modern Speech-to-Text (STT) models, focusing exclusively on Brazilian Portuguese.\n\n\n\n\n\t\n\t\n\t\n\t\tAbout the Dataset\n\t\n\nThis dataset was created to store and compare transcription results from different Artificial Intelligence models in challenging scenarios. Unlike generic benchmarks, this project focuses on the reality of usage in Brazil, covering:\n\nRegionalism: Local vocabularyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/annajuliaasf/Audio-Transcription-Models-Comparison-PT-BR.",
        "url": "https://huggingface.co/datasets/annajuliaasf/Audio-Transcription-Models-Comparison-PT-BR",
        "languages": [
          "pt",
          "en"
        ],
        "tasks": [
          "automatic-speech-recognition"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "chiffonng/hmmt_2025",
        "author": "chiffonng",
        "created_at": "2025-11-11 06:25:13+00:00",
        "last_modified": "2025-11-11 06:27:21+00:00",
        "downloads": 2,
        "likes": 0,
        "tags": [
          "language:en",
          "license:cc",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "Merged \"problem-type\" column from MathArena/hmmt_feb_2025 into FlagEval/HMMT_2025\n",
        "url": "https://huggingface.co/datasets/chiffonng/hmmt_2025",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "Pijush22049/TableLLaVA_Text_Image_Alignment",
        "author": "Pijush22049",
        "created_at": "2024-10-20 05:57:40+00:00",
        "last_modified": "2024-12-09 16:49:54+00:00",
        "downloads": 22,
        "likes": 0,
        "tags": [
          "language:en",
          "license:mit",
          "modality:image",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Pijush22049/TableLLaVA_Text_Image_Alignment",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "PhillyMac/Julius_Caesar_Corpus",
        "author": "PhillyMac",
        "created_at": "2025-12-16 20:59:44+00:00",
        "last_modified": "2025-12-16 20:59:47+00:00",
        "downloads": 18,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us",
          "corpus",
          "leadership",
          "historical",
          "deku-corpus-builder"
        ],
        "description": "\n\t\n\t\t\n\t\tjulius-caesar-agent\n\t\n\nThis corpus was automatically generated by the Deku Corpus Builder for use in RAG-based AI applications.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nEach record contains:\n\ntext: The content text\nsource_url: Original source URL\nsource_title: Title of the source document\nsource_domain: Domain of the source\nrelevance_score: Relevance to the subject (0-1)\nquality_score: Content quality score (0-1)\ntopics: JSON array of detected topics\ncharacter_count: Length of the textâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/PhillyMac/Julius_Caesar_Corpus.",
        "url": "https://huggingface.co/datasets/PhillyMac/Julius_Caesar_Corpus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "anon-org/LongBench-Llama",
        "author": "anon-org",
        "created_at": "2025-09-18 13:41:36+00:00",
        "last_modified": "2025-09-18 15:27:10+00:00",
        "downloads": 51,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/anon-org/LongBench-Llama",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "dsinha/driftbench",
        "author": "dsinha",
        "created_at": "2025-12-28 21:48:34+00:00",
        "last_modified": "2025-12-28 21:49:05+00:00",
        "downloads": 9,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2512.15068",
          "region:us",
          "rag",
          "knowledge-drift",
          "retrieval-augmented-generation",
          "distribution-shift",
          "ai-safety",
          "benchmark",
          "nlp"
        ],
        "description": "\n\t\n\t\t\n\t\tDRIFTBENCH: Measuring Reliability Half-Life of RAG Systems Under Knowledge Drift\n\t\n\nThe first benchmark treating knowledge drift as a first-class experimental variable.\n\n\t\n\t\t\n\t\tThe Knowledge Drift Problem\n\t\n\nTime T0                              Time T1\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Docs V1    â”‚    Knowledge      â”‚   Docs V2    â”‚\nâ”‚      |       â”‚      Drift        â”‚      |       â”‚\nâ”‚      v       â”‚   ==========>     â”‚      v       â”‚\nâ”‚  RAG Index   â”‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/dsinha/driftbench.",
        "url": "https://huggingface.co/datasets/dsinha/driftbench",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "code-switching/eval2-question_answering",
        "author": "code-switching",
        "created_at": "2025-06-02 07:37:25+00:00",
        "last_modified": "2025-12-29 12:33:02+00:00",
        "downloads": 148,
        "likes": 0,
        "tags": [
          "language:su",
          "language:jv",
          "language:id",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/code-switching/eval2-question_answering",
        "languages": [
          "su",
          "jv",
          "id",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "odl-raiser/SeqStudio",
        "author": "odl-raiser",
        "created_at": "2025-12-22 04:28:53+00:00",
        "last_modified": "2025-12-29 08:31:51+00:00",
        "downloads": 44,
        "likes": 1,
        "tags": [
          "task_categories:text-generation",
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "biology",
          "protein",
          "bioinformatics",
          "uniprot",
          "protein-annotation"
        ],
        "description": "\n\t\n\t\t\n\t\tSeqStudio: Protein Annotation Dataset\n\t\n\nSeqStudio is an AI-powered protein annotation system that generates comprehensive functional predictions for protein sequences. This dataset contains SeqStudio-generated annotations for 1.2 million UniProt proteins, combining human-reviewed (Swiss-Prot) and computationally analyzed (TrEMBL) entries with AI-enhanced functional predictions.\n\n\t\n\t\t\n\t\tDataset Files\n\t\n\n\n\t\n\t\t\nFile\nRecords\nSize\nDescription\n\n\n\t\t\nseqstudio_swissprot_10k.parquet\n10,000\n55â€¦ See the full description on the dataset page: https://huggingface.co/datasets/odl-raiser/SeqStudio.",
        "url": "https://huggingface.co/datasets/odl-raiser/SeqStudio",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation",
          "feature-extraction"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "aslon1213/ner_data",
        "author": "aslon1213",
        "created_at": "2024-05-27 05:39:47+00:00",
        "last_modified": "2024-05-28 08:53:42+00:00",
        "downloads": 10,
        "likes": 0,
        "tags": [
          "language:en",
          "size_categories:n<1K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/aslon1213/ner_data",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "obss/audio-retrieval",
        "author": "obss",
        "created_at": "2025-10-08 13:58:54+00:00",
        "last_modified": "2025-12-30 11:42:01+00:00",
        "downloads": 44,
        "likes": 1,
        "tags": [
          "task_categories:other",
          "language:en",
          "license:other",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "modality:audio",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "audio",
          "dcase",
          "retrieval"
        ],
        "description": "\n\t\n\t\t\n\t\tLanguage-based Audio Retrieval Dataset\n\t\n\nThis dataset is derived from the DCASE 2022 Challenge Task 6 (Subtask B) - Language-based Audio Retrieval evaluation dataset, originally published on Zenodo.\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThis dataset contains 1,000 audio files paired with natural language captions, designed for evaluating language-based audio retrieval systems. The dataset has been preprocessed and structured into parquet files for efficient loading and processing in machine learningâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/obss/audio-retrieval.",
        "url": "https://huggingface.co/datasets/obss/audio-retrieval",
        "languages": [
          "en"
        ],
        "tasks": [
          "other"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "kunarmy99/datatest",
        "author": "kunarmy99",
        "created_at": "2025-12-31 14:04:35+00:00",
        "last_modified": "2025-12-31 14:05:23+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:translation",
          "language:en",
          "license:bigscience-bloom-rail-1.0",
          "size_categories:n<1K",
          "region:us",
          "agent"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/kunarmy99/datatest",
        "languages": [
          "en"
        ],
        "tasks": [
          "translation"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "ifkash/fineweb-tiny-processed",
        "author": "ifkash",
        "created_at": "2025-12-21 17:48:48+00:00",
        "last_modified": "2025-12-22 05:51:28+00:00",
        "downloads": 43,
        "likes": 0,
        "tags": [
          "language:en",
          "license:odc-by",
          "size_categories:1B<n<10B",
          "region:us"
        ],
        "description": "First 6B tokens of fineweb dataset\n",
        "url": "https://huggingface.co/datasets/ifkash/fineweb-tiny-processed",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1B<n<10B"
        ]
      },
      {
        "id": "thagen/concausal-news-corpus",
        "author": "thagen",
        "created_at": "2025-12-02 07:53:25+00:00",
        "last_modified": "2025-12-17 11:27:45+00:00",
        "downloads": 162,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "multilinguality:monolingual",
          "language:en",
          "license:cc-by-4.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "arxiv:2510.08224",
          "region:us",
          "causality"
        ],
        "description": "\n\t\n\t\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\tCausality Detection\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"webis/concausal-news-corpus\", \"causality detection\")\n\n\n\t\n\t\t\n\t\tCausal Candidate Extraction\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"webis/concausal-news-corpus\", \"causal candidate extraction\")\n\n\n\t\n\t\t\n\t\tCausality Identification\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"webis/concausal-news-corpus\", \"causality identification\")\n\n\n\t\n\t\t\n\t\tCitationsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thagen/concausal-news-corpus.",
        "url": "https://huggingface.co/datasets/thagen/concausal-news-corpus",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "token-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "Senju2/Context-Aware-English-to-Arabic-Dataset",
        "author": "Senju2",
        "created_at": "2024-12-04 02:20:37+00:00",
        "last_modified": "2024-12-04 02:23:50+00:00",
        "downloads": 6,
        "likes": 0,
        "tags": [
          "language:ar",
          "language:en",
          "license:artistic-2.0",
          "size_categories:1M<n<10M",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/Senju2/Context-Aware-English-to-Arabic-Dataset",
        "languages": [
          "ar",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "thagen/causal-news-corpus-v2",
        "author": "thagen",
        "created_at": "2025-07-31 16:22:48+00:00",
        "last_modified": "2025-12-02 09:26:02+00:00",
        "downloads": 92,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "task_categories:token-classification",
          "multilinguality:monolingual",
          "language:en",
          "license:cc0-1.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us",
          "causality"
        ],
        "description": "\n[!NOTE]This repository integrates the Causal News Corpus v2 (aka. RECESS) dataset into hf datasets. It is in conformance with Causal News Corpus v2's CC0 1.0 license. Please find the original dataset\nhere. Please see the citations at the end of this README.\n\n\n[!IMPORTANT]\nThe Causal News Corpus v2 does not include labels for the test set.\n\n\n\t\n\t\t\n\t\n\t\n\t\tUsage\n\t\n\n\n\t\n\t\t\n\t\n\t\n\t\tCausality Detection\n\t\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"webis/causal-news-corpus-v2\", \"causalityâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/thagen/causal-news-corpus-v2.",
        "url": "https://huggingface.co/datasets/thagen/causal-news-corpus-v2",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "token-classification"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "kingrhai07/TinyStories",
        "author": "kingrhai07",
        "created_at": "2026-01-04 04:11:10+00:00",
        "last_modified": "2026-01-04 04:11:11+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:cdla-sharing-1.0",
          "arxiv:2305.07759",
          "region:us"
        ],
        "description": "Dataset containing synthetically generated (by GPT-3.5 and GPT-4) short stories that only use a small vocabulary.\nDescribed in the following paper: https://arxiv.org/abs/2305.07759. \nThe models referred to in the paper were trained on TinyStories-train.txt  (the file tinystories-valid.txt can be used for validation loss). These models can be found on Huggingface, at roneneldan/TinyStories-1M/3M/8M/28M/33M/1Layer-21M.\nAdditional resources:\ntinystories_all_data.tar.gz - contains a superset ofâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kingrhai07/TinyStories.",
        "url": "https://huggingface.co/datasets/kingrhai07/TinyStories",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": []
      },
      {
        "id": "my-north-ai/capes_synthetic_audio_PT",
        "author": "my-north-ai",
        "created_at": "2024-04-08 15:21:33+00:00",
        "last_modified": "2025-10-04 17:04:27+00:00",
        "downloads": 5,
        "likes": 1,
        "tags": [
          "language:pt",
          "language:en",
          "license:apache-2.0",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:audio",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "Data used to reproduce all of the experiments in the paper ; https://ieeexplore.ieee.org/document/10720758/\n",
        "url": "https://huggingface.co/datasets/my-north-ai/capes_synthetic_audio_PT",
        "languages": [
          "pt",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "JiaHuang01/ytbv_davis_432_240",
        "author": "JiaHuang01",
        "created_at": "2025-12-28 12:57:56+00:00",
        "last_modified": "2025-12-28 14:36:30+00:00",
        "downloads": 1828,
        "likes": 0,
        "tags": [
          "task_categories:video-to-video",
          "task_categories:image-segmentation",
          "language:en",
          "license:mit",
          "region:us",
          "video-inpainting",
          "video-segmentation",
          "davis",
          "youtube-vos"
        ],
        "description": "\n\t\n\t\t\n\t\tytbv_davis_432_240\n\t\n\n...\nThis dataset repository contains pre-processed DAVIS and YouTube-VOS subsets in a unified folder layout, with frames resized to 432Ã—240 and accompanying train/test splits and masks.\n\n\n\t\n\t\t\n\t\tDirectory Structure\n\t\n\ndatasets/\nâ”œâ”€â”€ davis/\nâ”‚   â”œâ”€â”€ JPEGImages_432_240/\nâ”‚   â”œâ”€â”€ test.json\nâ”‚   â”œâ”€â”€ test_masks/\nâ”‚   â””â”€â”€ train.json\nâ”œâ”€â”€ youtube-vos/\nâ”‚   â”œâ”€â”€ JPEGImages_432_240/\nâ”‚   â”œâ”€â”€ test.json\nâ”‚   â”œâ”€â”€ test_masks/\nâ”‚   â””â”€â”€ train.json\nâ””â”€â”€ _hf_work/\n\n## Contents\n\n###â€¦ See the full description on the dataset page: https://huggingface.co/datasets/JiaHuang01/ytbv_davis_432_240.",
        "url": "https://huggingface.co/datasets/JiaHuang01/ytbv_davis_432_240",
        "languages": [
          "en"
        ],
        "tasks": [
          "video-to-video",
          "image-segmentation"
        ],
        "size_categories": []
      },
      {
        "id": "Code2Logic/GameQA-text",
        "author": "Code2Logic",
        "created_at": "2025-07-20 00:57:16+00:00",
        "last_modified": "2025-07-22 14:17:57+00:00",
        "downloads": 25,
        "likes": 1,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:mit",
          "arxiv:2505.13886",
          "region:us"
        ],
        "description": "Here we provide a pure-text version of GameQA, encompassing some appropriate games. (See https://github.com/tongjingqi/Code2Logic/issues/2)\n\n\t\n\t\t\n\t\tCode2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning\n\t\n\nThis is the first work, to the best of our knowledge, that leverages game code to synthesize multimodal reasoning data for training VLMs. Furthermore, when trained with a GRPO strategy solely on GameQA (synthesized via our proposed Code2Logic approach), multipleâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Code2Logic/GameQA-text.",
        "url": "https://huggingface.co/datasets/Code2Logic/GameQA-text",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": []
      },
      {
        "id": "kunarmy99/public-test",
        "author": "kunarmy99",
        "created_at": "2025-12-31 14:01:57+00:00",
        "last_modified": "2025-12-31 14:03:13+00:00",
        "downloads": 13,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "region:us",
          "finance"
        ],
        "description": "\n\t\n\t\t\n\t\tDataset Card for Dataset Name\n\t\n\n\n\nThis dataset card aims to be a base template for new datasets. It has been generated using this raw template.\n\n\t\n\t\t\n\t\tDataset Details\n\t\n\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\n\n\n\n\n\nCurated by: [More Information Needed]\nFunded by [optional]: [More Information Needed]\nShared by [optional]: [More Information Needed]\nLanguage(s) (NLP): [More Information Needed]\nLicense: [More Information Needed]\n\n\n\t\n\t\t\n\t\tDataset Sources [optional]\n\t\n\n\n\n\nRepository: [Moreâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kunarmy99/public-test.",
        "url": "https://huggingface.co/datasets/kunarmy99/public-test",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "DavidrPatton/n8n-toolkit-combined",
        "author": "DavidrPatton",
        "created_at": "2026-01-04 23:10:03+00:00",
        "last_modified": "2026-01-05 00:00:40+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:parquet",
          "format:optimized-parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "n8n",
          "automation",
          "workflow",
          "qwen3-vl"
        ],
        "description": "\n\t\n\t\t\n\t\tn8n-Toolkit Dataset\n\t\n\n\n\t\n\t\t\n\t\tðŸš€ n8n Toolkit - Business Automation Architect Dataset\n\t\n\n\n\n\n\n\n\nFine-tuning dataset for training Qwen3-VL to become a Business Automation Architect\nðŸ“Š Dataset Viewerâ€¢ ðŸ”§ Usage â€¢ ðŸ“ Data Format â€¢ ðŸŽ¯ Training\n\n\n\n\n\n\t\n\t\t\n\t\tðŸš€ Unified Dataset (Recommended for Training)\n\t\n\nThis dataset is a compiled merge of the three subsets found in DavidrPatton/n8n-Toolkit.\nIt combines Vision, ShareGPT, and Thinking data into a single, pre-formatted schema ready forâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/DavidrPatton/n8n-toolkit-combined.",
        "url": "https://huggingface.co/datasets/DavidrPatton/n8n-toolkit-combined",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "xcwangpsu/RADM",
        "author": "xcwangpsu",
        "created_at": "2025-05-03 21:45:11+00:00",
        "last_modified": "2025-12-30 04:04:50+00:00",
        "downloads": 53,
        "likes": 1,
        "tags": [
          "task_categories:feature-extraction",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "region:us",
          "medical"
        ],
        "description": "\n\t\n\t\t\n\t\tRADM: Radiological Multimodal Knowledge Graph\n\t\n\nWe introduce RADM, a a Radiological Multimodal Knowledge Graph that seamlessly fuses clinical concepts with medical images.MedMKG is constructed via a multi-stage pipeline that accurately identifies and disambiguates medical concepts while extracting their interrelations.To ensure the conciseness of the resulting graph, we further employ a pruning strategy based on our novel Neighbor-aware Filtering (NaF) algorithm.\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“‚â€¦ See the full description on the dataset page: https://huggingface.co/datasets/xcwangpsu/RADM.",
        "url": "https://huggingface.co/datasets/xcwangpsu/RADM",
        "languages": [
          "en"
        ],
        "tasks": [
          "feature-extraction"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "RizhongLin/MNLP_M2_dpo_dataset_HelpSteer3",
        "author": "RizhongLin",
        "created_at": "2025-05-25 18:20:11+00:00",
        "last_modified": "2025-05-25 20:52:56+00:00",
        "downloads": 26,
        "likes": 0,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:mit",
          "size_categories:10K<n<100K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "arxiv:2505.11475",
          "region:us",
          "preference-data",
          "direct-preference-optimization",
          "computer-science",
          "stem",
          "code",
          "dpo"
        ],
        "description": "\n\t\n\t\t\n\t\tCS-552 Stochastic Parrots M2 DPO Dataset\n\t\n\nThis dataset contains preference pairs for Direct Preference Optimization (DPO) training with a focus on STEM and code domains.\n\n\t\n\t\t\n\t\tDataset Structure\n\t\n\nThe dataset contains the following splits:\n\ntrain: 36693 examples\nvalidation: 4078 examples\ntest: 908 examples\n\n\n\t\n\t\t\n\t\tData Format\n\t\n\nEach example contains:\n\nprompt: The input query or question\nchosen: The preferred response\nrejected: The less preferred response\ndomain: Domain of theâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/RizhongLin/MNLP_M2_dpo_dataset_HelpSteer3.",
        "url": "https://huggingface.co/datasets/RizhongLin/MNLP_M2_dpo_dataset_HelpSteer3",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "montehoover/DynaBench",
        "author": "montehoover",
        "created_at": "2025-08-27 18:26:53+00:00",
        "last_modified": "2025-11-22 00:27:06+00:00",
        "downloads": 354,
        "likes": 4,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:100K<n<1M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "arxiv:2509.02563",
          "region:us",
          "safe",
          "safety",
          "jailbreak",
          "ai-safety",
          "llm",
          "lm",
          "moderation",
          "classification",
          "refusal"
        ],
        "description": "\n\t\n\t\t\n\t\tDynaBench\n\t\n\n\n\t\n\t\t\nðŸ”–\nðŸ’»\nðŸŒ\n\n\n\t\t\nPaper (arXiv)\nCode (GitHub)\nProject page \n\n\n\t\n\n\n\t\n\t\t\n\t\tDataset Summary\n\t\n\nDynaBench consists of three subsets:\n\nDynaBench: A benchmark for testing the ability of models to detect policy violations where the policies fall outside traditional safety categories.\nDynaBenchTrain: Synthetic training data with policies crafted from combinations of 5,000 highly diverse rules.\nDynaBenchSafetyMix: Training data mix that includes samples from external safetyâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/montehoover/DynaBench.",
        "url": "https://huggingface.co/datasets/montehoover/DynaBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "odl-raiser/GGBench",
        "author": "odl-raiser",
        "created_at": "2025-11-08 16:59:28+00:00",
        "last_modified": "2025-11-17 11:44:59+00:00",
        "downloads": 36,
        "likes": 1,
        "tags": [
          "task_categories:visual-question-answering",
          "task_categories:text-to-image",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "arxiv:2511.11134",
          "region:us",
          "generation",
          "think-with-images",
          "unified-multimodal-model"
        ],
        "description": "\n\t\n\t\t\n\t\tAssociated Paper\n\t\n\nThis dataset is associated with the following paper:\nGeoCraft / GGBench: A Comprehensive Benchmark for Geometry Construction\n\narXiv: https://arxiv.org/abs/2511.11134\n\n\n\t\n\t\t\n\t\tGGBench Evaluation Script Documentation\n\t\n\n\n\t\n\t\t\n\t\tDirectory Structure Overview\n\t\n\ndataset/\nâ”œâ”€â”€ evaluate.py          # Unified evaluation entry script\nâ”œâ”€â”€ eval_prompts.py      # Judge model prompt templates\nâ”œâ”€â”€ GGBench_dataset.json # Official dataset (evaluation benchmark)\nâ”œâ”€â”€ Q&A_image/â€¦ See the full description on the dataset page: https://huggingface.co/datasets/odl-raiser/GGBench.",
        "url": "https://huggingface.co/datasets/odl-raiser/GGBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering",
          "text-to-image"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "cair-nepal/equitext-nepali-bias-dataset",
        "author": "cair-nepal",
        "created_at": "2025-06-14 03:29:05+00:00",
        "last_modified": "2026-01-03 02:42:54+00:00",
        "downloads": 9,
        "likes": 1,
        "tags": [
          "language:en",
          "language:ne",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "bias",
          "cultural-bias",
          "nepalese-bias-dataset",
          "responsible-ai"
        ],
        "description": "\n\t\n\t\t\n\t\tðŸ“š EquiText-Nepali: A Dataset for Gender, Race, and Sociocultural Bias in Nepali Text\n\t\n\nEquiText-Nepali is a curated dataset designed to evaluate and expose social biases, specifically related to gender, race, and sociocultural or religious identity within Nepali-language texts. It aims to support the development of fair and inclusive language technologies by offering annotated examples for bias detection, masked language model probing, and fairness benchmarking.\n\n\t\n\t\t\n\t\tSupportedâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/cair-nepal/equitext-nepali-bias-dataset.",
        "url": "https://huggingface.co/datasets/cair-nepal/equitext-nepali-bias-dataset",
        "languages": [
          "en",
          "ne"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "code-switching/eval3-question_answering",
        "author": "code-switching",
        "created_at": "2025-06-08 09:25:56+00:00",
        "last_modified": "2025-12-29 12:32:32+00:00",
        "downloads": 116,
        "likes": 0,
        "tags": [
          "language:su",
          "language:jv",
          "language:id",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/code-switching/eval3-question_answering",
        "languages": [
          "su",
          "jv",
          "id",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "kingrhai07/deepsearchqa",
        "author": "kingrhai07",
        "created_at": "2026-01-01 05:05:48+00:00",
        "last_modified": "2026-01-01 05:05:49+00:00",
        "downloads": 11,
        "likes": 0,
        "tags": [
          "task_categories:question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:n<1K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "factuality",
          "search",
          "retrieval",
          "deep research",
          "comprehensiveness",
          "agent",
          "posttraining",
          "benchmark",
          "Google DeepMind"
        ],
        "description": "\n\t\n\t\t\n\t\tDeepSearchQA\n\t\n\n\n\t\n\t\t\n\t\tA 900-prompt factuality benchmark from Google DeepMind, designed to evaluate agents on difficult multi-step information-seeking tasks across 17 different fields.\n\t\n\nâ–¶ Google DeepMind Release Blog Postâ–¶ DeepSearchQA Leaderboard on Kaggleâ–¶ Technical Reportâ–¶ Evaluation Starter Code\n\n\t\n\t\t\n\t\n\t\n\t\tBenchmark\n\t\n\nDeepSearchQA is a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditionalâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/kingrhai07/deepsearchqa.",
        "url": "https://huggingface.co/datasets/kingrhai07/deepsearchqa",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "HarmlessSR07/OpenBench",
        "author": "HarmlessSR07",
        "created_at": "2025-12-18 09:07:01+00:00",
        "last_modified": "2025-12-23 09:33:37+00:00",
        "downloads": 59,
        "likes": 2,
        "tags": [
          "task_categories:visual-question-answering",
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:tabular",
          "modality:text",
          "modality:video",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "Video",
          "Text"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/HarmlessSR07/OpenBench",
        "languages": [
          "en"
        ],
        "tasks": [
          "visual-question-answering"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Nitral-Archive/grok_mixed_captions",
        "author": "Nitral-Archive",
        "created_at": "2026-01-04 14:55:23+00:00",
        "last_modified": "2026-01-04 16:04:10+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "language:en",
          "license:other",
          "region:us",
          "not-for-all-audiences"
        ],
        "description": "Total cost to produce: \n",
        "url": "https://huggingface.co/datasets/Nitral-Archive/grok_mixed_captions",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": []
      },
      {
        "id": "GambitFlow/Synapse-Edge-Data",
        "author": "GambitFlow",
        "created_at": "2025-12-26 19:06:26+00:00",
        "last_modified": "2026-01-03 12:19:37+00:00",
        "downloads": 48,
        "likes": 0,
        "tags": [
          "task_categories:reinforcement-learning",
          "task_categories:image-classification",
          "language:en",
          "license:cc0-1.0",
          "size_categories:1M<n<10M",
          "region:us",
          "chess",
          "game-ai",
          "deep-learning",
          "synapse-edge",
          "gambitflow"
        ],
        "description": "\n\t\n\t\t\n\t\tâ™Ÿï¸ GambitFlow Synapse-Edge-Data (Massive Corpus)\n\t\n\n\n\n\n \n\n\n\nAssociated Model â€¢  Source: Lichess\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tðŸ“– Dataset Overview\n\t\n\nSynapse-Edge-Data is a high-performance, large-scale dataset specifically engineered for training Gen-3 chess engines like Synapse-Edge v1. It represents a revolutionary fusion of high-level human positional play and rigorous tactical patterns. \nUnlike previous datasets that focus solely on game outcomes, this corpus includes 3 million+ tactical puzzlesâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/GambitFlow/Synapse-Edge-Data.",
        "url": "https://huggingface.co/datasets/GambitFlow/Synapse-Edge-Data",
        "languages": [
          "en"
        ],
        "tasks": [
          "reinforcement-learning",
          "image-classification"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "vincentoh/alignment-faking-training",
        "author": "vincentoh",
        "created_at": "2025-12-27 16:09:09+00:00",
        "last_modified": "2026-01-04 05:03:40+00:00",
        "downloads": 84,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:en",
          "license:mit",
          "size_categories:1K<n<10K",
          "arxiv:2412.14093",
          "region:us",
          "ai-safety",
          "alignment-faking",
          "chain-of-thought",
          "cot-monitoring",
          "deceptive-reasoning",
          "interpretability",
          "sparse-autoencoders"
        ],
        "description": "\n\t\n\t\t\n\t\tAlignment Faking Detection Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nDataset and inference weights for detecting alignment faking in AI reasoning traces using GemmaScope-2 sparse autoencoders.\nKey result: Linear probe achieves 0.825 AUROC using 8 SAE features. Hard negative validation confirms detection tracks reasoning intent, not vocabulary (ratio: -0.54).\n\n\t\n\t\t\n\t\tFiles\n\t\n\n\n\t\n\t\t\nFile\nDescription\nSamples\n\n\n\t\t\naf_test_samples.json\nFull dataset with hard negatives\n2,689\n\n\naf_probe_weights.jsonâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/vincentoh/alignment-faking-training.",
        "url": "https://huggingface.co/datasets/vincentoh/alignment-faking-training",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "code-switching/question_answer",
        "author": "code-switching",
        "created_at": "2025-05-18 12:35:56+00:00",
        "last_modified": "2025-12-29 09:49:37+00:00",
        "downloads": 76,
        "likes": 0,
        "tags": [
          "language:su",
          "language:jv",
          "language:id",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/code-switching/question_answer",
        "languages": [
          "su",
          "jv",
          "id",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "fr3on/company",
        "author": "fr3on",
        "created_at": "2025-02-23 09:21:50+00:00",
        "last_modified": "2025-02-23 10:50:59+00:00",
        "downloads": 118,
        "likes": 1,
        "tags": [
          "task_categories:text-classification",
          "task_categories:question-answering",
          "task_categories:summarization",
          "language:en",
          "license:apache-2.0",
          "size_categories:10M<n<100M",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "library:polars",
          "region:us",
          "business",
          "companies",
          "structured-data",
          "global",
          "market-analysis",
          "data-analysis",
          "parquet",
          "company-profiles",
          "public-data"
        ],
        "description": "\n\t\n\t\t\n\t\tCompany Dataset\n\t\n\n\n\t\n\t\t\n\t\tOverview\n\t\n\nThe Company Dataset is a large-scale collection containing detailed information on companies from around the globe. With approximately 24 million rows of data, this dataset offers a rich resource for market research, business intelligence, and machine learning applications focused on company profiling and analysis.\n\nNote: This is a public dataset, freely available for research and analysis purposes.\n\n\n\t\n\t\t\n\t\n\t\n\t\tDataset Details\n\t\n\n\nTotal Rows: 24Mâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/fr3on/company.",
        "url": "https://huggingface.co/datasets/fr3on/company",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-classification",
          "question-answering",
          "summarization"
        ],
        "size_categories": [
          "10M<n<100M"
        ]
      },
      {
        "id": "webxos/snipercell_RL_v1",
        "author": "webxos",
        "created_at": "2026-01-03 01:05:09+00:00",
        "last_modified": "2026-01-05 00:59:26+00:00",
        "downloads": 13,
        "likes": 1,
        "tags": [
          "task_categories:reinforcement-learning",
          "task_categories:tabular-classification",
          "task_categories:tabular-regression",
          "language:en",
          "license:mit",
          "size_categories:n<1K",
          "format:json",
          "modality:text",
          "modality:tabular",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "games",
          "video-games",
          "reinforcement-learning",
          "time-series",
          "synthetic",
          "tabular",
          "3d-data"
        ],
        "description": "\n     _____ _   _ ___________ ___________   _____  _____ _      _     \n/  ___| \\ | |_   _| ___ \\  ___| ___ \\ /  __ \\|  ___| |    | |    \n\\ `--.|  \\| | | | | |_/ / |__ | |_/ / | /  \\/| |__ | |    | |    \n `--. \\ . ` | | | |  __/|  __||    /  | |    |  __|| |    | |    \n/\\__/ / |\\  |_| |_| |   | |___| |\\ \\  | \\__/\\| |___| |____| |____\n\\____/\\_| \\_/\\___/\\_|   \\____/\\_| \\_|  \\____/\\____/\\_____/\\_____/\n    \n\n\n\n\t\n\t\n\t\n\t\tXFORC3D: SNIPER CELL - TRAINING DATA EXPORT\n\t\n\nExported: 2026-01-03T01:03:45.377Zâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/webxos/snipercell_RL_v1.",
        "url": "https://huggingface.co/datasets/webxos/snipercell_RL_v1",
        "languages": [
          "en"
        ],
        "tasks": [
          "reinforcement-learning",
          "tabular-classification",
          "tabular-regression"
        ],
        "size_categories": [
          "n<1K"
        ]
      },
      {
        "id": "allenai/dolma3_mix-5.5T-1125",
        "author": "allenai",
        "created_at": "2025-11-24 04:14:53+00:00",
        "last_modified": "2025-12-17 05:06:30+00:00",
        "downloads": 2953,
        "likes": 9,
        "tags": [
          "task_categories:text-generation",
          "language:en",
          "license:odc-by",
          "size_categories:100K<n<1M",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "\n\n\n\n\n\t\n\t\t\n\t\tDolma 3 Mix (5.5T)\n\t\n\nThe Dolma 3 Mix (5.5T) is the collection of data used during the pretraining stage to train the Olmo-3-1125-32B model. This dataset is made up of ~5.5 trillion tokens from a diverse mix of web content, academic publications, code, and more. The majority of this dataset comes from Common Crawl.  \nFor more information on Dolma, please see our original release here.\n\n\t\n\t\t\n\t\n\t\n\t\tLicensing Information\n\t\n\nDolma 3 mix is licensed under the Open Data Commonsâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/allenai/dolma3_mix-5.5T-1125.",
        "url": "https://huggingface.co/datasets/allenai/dolma3_mix-5.5T-1125",
        "languages": [
          "en"
        ],
        "tasks": [
          "text-generation"
        ],
        "size_categories": [
          "100K<n<1M"
        ]
      },
      {
        "id": "Bingguang/FunReason-MT",
        "author": "Bingguang",
        "created_at": "2025-10-23 02:14:56+00:00",
        "last_modified": "2025-11-18 02:52:24+00:00",
        "downloads": 267,
        "likes": 47,
        "tags": [
          "task_categories:question-answering",
          "task_categories:text-generation",
          "language:en",
          "license:apache-2.0",
          "size_categories:10K<n<100K",
          "format:json",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "arxiv:2510.24645",
          "region:us",
          "agent",
          "Agentic Learning",
          "tool use",
          "BFCL"
        ],
        "description": "\n\t\n\t\t\n\t\tFunReason-MT Technical Report: Advanced Data Synthesis Solution for Real-world Multi-Turn Tool-use\n\t\n\n     \n\n\n[!IMPORTANT] Important Hint\n\n\n\nTo allow the model to learn from errors, we specifically construct erroneous environmental responses. If you wish to delete this data, please delete the trajectories where error_tool_response is true.\nThis is an initial version of our data, we will release the up-to-date version after the acceptance of our paper.\n\n\n\n\t\n\t\t\n\t\n\t\n\t\tFunReason-MT Datasetâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Bingguang/FunReason-MT.",
        "url": "https://huggingface.co/datasets/Bingguang/FunReason-MT",
        "languages": [
          "en"
        ],
        "tasks": [
          "question-answering",
          "text-generation"
        ],
        "size_categories": [
          "10K<n<100K"
        ]
      },
      {
        "id": "amitgpt/abap-code-sec-finetune",
        "author": "amitgpt",
        "created_at": "2025-12-11 19:47:21+00:00",
        "last_modified": "2025-12-11 19:47:23+00:00",
        "downloads": 16,
        "likes": 0,
        "tags": [
          "language:en",
          "license:apache-2.0",
          "size_categories:1K<n<10K",
          "format:parquet",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:mlcroissant",
          "library:polars",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/amitgpt/abap-code-sec-finetune",
        "languages": [
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      },
      {
        "id": "Neon-Jing/web3-news-recommendation",
        "author": "Neon-Jing",
        "created_at": "2026-01-04 15:37:01+00:00",
        "last_modified": "2026-01-04 16:08:54+00:00",
        "downloads": 0,
        "likes": 0,
        "tags": [
          "task_categories:text-classification",
          "language:zh",
          "language:en",
          "license:cc-by-nc-4.0",
          "size_categories:1M<n<10M",
          "format:parquet",
          "modality:image",
          "modality:tabular",
          "modality:text",
          "library:datasets",
          "library:dask",
          "library:polars",
          "library:mlcroissant",
          "region:us",
          "news",
          "web3",
          "cryptocurrency",
          "recommendation-system",
          "user-behavior"
        ],
        "description": "\n\t\n\t\t\n\t\tWeb3 News Recommendation Dataset\n\t\n\nA comprehensive dataset for building news recommendation systems in the Web3/cryptocurrency domain.\n\n\t\n\t\t\n\t\tDataset Description\n\t\n\nThis dataset contains user interaction data from a Web3 news platform, including:\n\nArticles: News articles about cryptocurrency, blockchain, DeFi, etc.\nUser Interactions: Likes, collects (bookmarks), comments\nUser Profiles: Anonymized user information\n\n\n\t\n\t\t\n\t\tLanguages\n\t\n\n\nChinese (Simplified): cn\nEnglish: en  \nChineseâ€¦ See the full description on the dataset page: https://huggingface.co/datasets/Neon-Jing/web3-news-recommendation.",
        "url": "https://huggingface.co/datasets/Neon-Jing/web3-news-recommendation",
        "languages": [
          "zh",
          "en"
        ],
        "tasks": [
          "text-classification"
        ],
        "size_categories": [
          "1M<n<10M"
        ]
      },
      {
        "id": "code-switching/eval1-question_answering",
        "author": "code-switching",
        "created_at": "2025-05-18 15:38:39+00:00",
        "last_modified": "2025-12-29 12:27:58+00:00",
        "downloads": 183,
        "likes": 0,
        "tags": [
          "language:su",
          "language:jv",
          "language:id",
          "language:en",
          "size_categories:1K<n<10K",
          "format:csv",
          "modality:text",
          "library:datasets",
          "library:pandas",
          "library:polars",
          "library:mlcroissant",
          "region:us"
        ],
        "description": "",
        "url": "https://huggingface.co/datasets/code-switching/eval1-question_answering",
        "languages": [
          "su",
          "jv",
          "id",
          "en"
        ],
        "tasks": [],
        "size_categories": [
          "1K<n<10K"
        ]
      }
    ],
    "updated_datasets": [
      {
        "id": "allenai/objaverse",
        "author": "allenai",
        "url": "https://huggingface.co/datasets/allenai/objaverse",
        "changes": {
          "downloads": {
            "previous": 325127,
            "current": 498883,
            "change": 173756
          },
          "likes": {
            "previous": 414,
            "current": 417,
            "change": 3
          },
          "description_changed": false
        }
      },
      {
        "id": "YiboZhang2001/TexVerse",
        "author": "YiboZhang2001",
        "url": "https://huggingface.co/datasets/YiboZhang2001/TexVerse",
        "changes": {
          "downloads": {
            "previous": 64814,
            "current": 194597,
            "change": 129783
          },
          "likes": {
            "previous": 24,
            "current": 24,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "NTU-NLP-sg/xCodeEval",
        "author": "NTU-NLP-sg",
        "url": "https://huggingface.co/datasets/NTU-NLP-sg/xCodeEval",
        "changes": {
          "downloads": {
            "previous": 79650,
            "current": 170723,
            "change": 91073
          },
          "likes": {
            "previous": 54,
            "current": 54,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "genrobot2025/10Kh-RealOmin-OpenData",
        "author": "genrobot2025",
        "url": "https://huggingface.co/datasets/genrobot2025/10Kh-RealOmin-OpenData",
        "changes": {
          "downloads": {
            "previous": 6,
            "current": 62744,
            "change": 62738
          },
          "likes": {
            "previous": 7,
            "current": 130,
            "change": 123
          },
          "description_changed": false
        }
      },
      {
        "id": "EpicPinkPenguin/procgen",
        "author": "EpicPinkPenguin",
        "url": "https://huggingface.co/datasets/EpicPinkPenguin/procgen",
        "changes": {
          "downloads": {
            "previous": 109496,
            "current": 171620,
            "change": 62124
          },
          "likes": {
            "previous": 4,
            "current": 4,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "HuggingFaceFW/fineweb-edu",
        "author": "HuggingFaceFW",
        "url": "https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu",
        "changes": {
          "downloads": {
            "previous": 289451,
            "current": 329997,
            "change": 40546
          },
          "likes": {
            "previous": 891,
            "current": 898,
            "change": 7
          },
          "description_changed": false
        }
      },
      {
        "id": "facebook/wiki_dpr",
        "author": "facebook",
        "url": "https://huggingface.co/datasets/facebook/wiki_dpr",
        "changes": {
          "downloads": {
            "previous": 27596,
            "current": 66220,
            "change": 38624
          },
          "likes": {
            "previous": 40,
            "current": 40,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-PDF-CC-2024-18",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2024-18",
        "changes": {
          "downloads": {
            "previous": 8797,
            "current": 43868,
            "change": 35071
          },
          "likes": {
            "previous": 19,
            "current": 20,
            "change": 1
          },
          "description_changed": false
        }
      },
      {
        "id": "SimulaMet/Kvasir-VQA-x1",
        "author": "SimulaMet",
        "url": "https://huggingface.co/datasets/SimulaMet/Kvasir-VQA-x1",
        "changes": {
          "downloads": {
            "previous": 3787,
            "current": 34095,
            "change": 30308
          },
          "likes": {
            "previous": 11,
            "current": 11,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-PDF-CC-2024-10",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2024-10",
        "changes": {
          "downloads": {
            "previous": 5610,
            "current": 33788,
            "change": 28178
          },
          "likes": {
            "previous": 4,
            "current": 4,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "pietrolesci/pythia-deduped-stats-raw",
        "author": "pietrolesci",
        "url": "https://huggingface.co/datasets/pietrolesci/pythia-deduped-stats-raw",
        "changes": {
          "downloads": {
            "previous": 22161,
            "current": 50337,
            "change": 28176
          },
          "likes": {
            "previous": 0,
            "current": 0,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "OpenSQZ/AutoMathText-V2",
        "author": "OpenSQZ",
        "url": "https://huggingface.co/datasets/OpenSQZ/AutoMathText-V2",
        "changes": {
          "downloads": {
            "previous": 196314,
            "current": 223611,
            "change": 27297
          },
          "likes": {
            "previous": 20,
            "current": 21,
            "change": 1
          },
          "description_changed": false
        }
      },
      {
        "id": "Naveen0501/dlgenai-nppe-dataset",
        "author": "Naveen0501",
        "url": "https://huggingface.co/datasets/Naveen0501/dlgenai-nppe-dataset",
        "changes": {
          "downloads": {
            "previous": 39242,
            "current": 66025,
            "change": 26783
          },
          "likes": {
            "previous": 0,
            "current": 2,
            "change": 2
          },
          "description_changed": false
        }
      },
      {
        "id": "nguha/legalbench",
        "author": "nguha",
        "url": "https://huggingface.co/datasets/nguha/legalbench",
        "changes": {
          "downloads": {
            "previous": 34382,
            "current": 57247,
            "change": 22865
          },
          "likes": {
            "previous": 155,
            "current": 157,
            "change": 2
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-PDF-CC-2023-06",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2023-06",
        "changes": {
          "downloads": {
            "previous": 4484,
            "current": 26422,
            "change": 21938
          },
          "likes": {
            "previous": 3,
            "current": 3,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "cadene/droid",
        "author": "cadene",
        "url": "https://huggingface.co/datasets/cadene/droid",
        "changes": {
          "downloads": {
            "previous": 105304,
            "current": 123332,
            "change": 18028
          },
          "likes": {
            "previous": 5,
            "current": 5,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "cerebras/SlimPajama-627B",
        "author": "cerebras",
        "url": "https://huggingface.co/datasets/cerebras/SlimPajama-627B",
        "changes": {
          "downloads": {
            "previous": 58125,
            "current": 75893,
            "change": 17768
          },
          "likes": {
            "previous": 511,
            "current": 511,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "anon8231489123/ShareGPT_Vicuna_unfiltered",
        "author": "anon8231489123",
        "url": "https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered",
        "changes": {
          "downloads": {
            "previous": 62047,
            "current": 79020,
            "change": 16973
          },
          "likes": {
            "previous": 836,
            "current": 837,
            "change": 1
          },
          "description_changed": false
        }
      },
      {
        "id": "defunct-datasets/eli5",
        "author": "defunct-datasets",
        "url": "https://huggingface.co/datasets/defunct-datasets/eli5",
        "changes": {
          "downloads": {
            "previous": 11626,
            "current": 27596,
            "change": 15970
          },
          "likes": {
            "previous": 52,
            "current": 52,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "amirveyseh/acronym_identification",
        "author": "amirveyseh",
        "url": "https://huggingface.co/datasets/amirveyseh/acronym_identification",
        "changes": {
          "downloads": {
            "previous": 22030,
            "current": 35138,
            "change": 13108
          },
          "likes": {
            "previous": 23,
            "current": 23,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "google-research-datasets/paws",
        "author": "google-research-datasets",
        "url": "https://huggingface.co/datasets/google-research-datasets/paws",
        "changes": {
          "downloads": {
            "previous": 68319,
            "current": 80451,
            "change": 12132
          },
          "likes": {
            "previous": 36,
            "current": 36,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-HTML",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-HTML",
        "changes": {
          "downloads": {
            "previous": 35982,
            "current": 47548,
            "change": 11566
          },
          "likes": {
            "previous": 90,
            "current": 90,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "openai/gsm8k",
        "author": "openai",
        "url": "https://huggingface.co/datasets/openai/gsm8k",
        "changes": {
          "downloads": {
            "previous": 411527,
            "current": 422226,
            "change": 10699
          },
          "likes": {
            "previous": 1093,
            "current": 1103,
            "change": 10
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-PDF-CC-2023-14",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2023-14",
        "changes": {
          "downloads": {
            "previous": 3328,
            "current": 13957,
            "change": 10629
          },
          "likes": {
            "previous": 1,
            "current": 1,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "nkp37/OpenVid-1M",
        "author": "nkp37",
        "url": "https://huggingface.co/datasets/nkp37/OpenVid-1M",
        "changes": {
          "downloads": {
            "previous": 25609,
            "current": 36072,
            "change": 10463
          },
          "likes": {
            "previous": 243,
            "current": 243,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "HuggingFaceM4/FineVisionMax",
        "author": "HuggingFaceM4",
        "url": "https://huggingface.co/datasets/HuggingFaceM4/FineVisionMax",
        "changes": {
          "downloads": {
            "previous": 19759,
            "current": 30082,
            "change": 10323
          },
          "likes": {
            "previous": 21,
            "current": 21,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "LLM360/TxT360",
        "author": "LLM360",
        "url": "https://huggingface.co/datasets/LLM360/TxT360",
        "changes": {
          "downloads": {
            "previous": 47392,
            "current": 57509,
            "change": 10117
          },
          "likes": {
            "previous": 247,
            "current": 248,
            "change": 1
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-PDF-CC-2023-50",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2023-50",
        "changes": {
          "downloads": {
            "previous": 3638,
            "current": 13712,
            "change": 10074
          },
          "likes": {
            "previous": 3,
            "current": 3,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-PDF-CC-2023-23",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2023-23",
        "changes": {
          "downloads": {
            "previous": 16066,
            "current": 26058,
            "change": 9992
          },
          "likes": {
            "previous": 1,
            "current": 1,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "bezirganyan/LUMA",
        "author": "bezirganyan",
        "url": "https://huggingface.co/datasets/bezirganyan/LUMA",
        "changes": {
          "downloads": {
            "previous": 80975,
            "current": 90894,
            "change": 9919
          },
          "likes": {
            "previous": 3,
            "current": 3,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "mlfoundations/MINT-1T-PDF-CC-2023-40",
        "author": "mlfoundations",
        "url": "https://huggingface.co/datasets/mlfoundations/MINT-1T-PDF-CC-2023-40",
        "changes": {
          "downloads": {
            "previous": 3423,
            "current": 13255,
            "change": 9832
          },
          "likes": {
            "previous": 1,
            "current": 1,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "nvidia/PhysicalAI-Autonomous-Vehicle-Cosmos-Drive-Dreams",
        "author": "nvidia",
        "url": "https://huggingface.co/datasets/nvidia/PhysicalAI-Autonomous-Vehicle-Cosmos-Drive-Dreams",
        "changes": {
          "downloads": {
            "previous": 79140,
            "current": 88672,
            "change": 9532
          },
          "likes": {
            "previous": 31,
            "current": 35,
            "change": 4
          },
          "description_changed": false
        }
      },
      {
        "id": "Voxel51/aloha_pen_uncap",
        "author": "Voxel51",
        "url": "https://huggingface.co/datasets/Voxel51/aloha_pen_uncap",
        "changes": {
          "downloads": {
            "previous": 11390,
            "current": 20708,
            "change": 9318
          },
          "likes": {
            "previous": 1,
            "current": 1,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "ibrahimhamamci/CT-RATE",
        "author": "ibrahimhamamci",
        "url": "https://huggingface.co/datasets/ibrahimhamamci/CT-RATE",
        "changes": {
          "downloads": {
            "previous": 73557,
            "current": 82499,
            "change": 8942
          },
          "likes": {
            "previous": 193,
            "current": 192,
            "change": -1
          },
          "description_changed": false
        }
      },
      {
        "id": "xlangai/ubuntu_osworld",
        "author": "xlangai",
        "url": "https://huggingface.co/datasets/xlangai/ubuntu_osworld",
        "changes": {
          "downloads": {
            "previous": 27495,
            "current": 35500,
            "change": 8005
          },
          "likes": {
            "previous": 4,
            "current": 4,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "allenai/ai2_arc",
        "author": "allenai",
        "url": "https://huggingface.co/datasets/allenai/ai2_arc",
        "changes": {
          "downloads": {
            "previous": 226953,
            "current": 234949,
            "change": 7996
          },
          "likes": {
            "previous": 244,
            "current": 251,
            "change": 7
          },
          "description_changed": false
        }
      },
      {
        "id": "OptimalScale/ClimbMix",
        "author": "OptimalScale",
        "url": "https://huggingface.co/datasets/OptimalScale/ClimbMix",
        "changes": {
          "downloads": {
            "previous": 3200,
            "current": 11177,
            "change": 7977
          },
          "likes": {
            "previous": 16,
            "current": 16,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "anfera236/HHDC",
        "author": "anfera236",
        "url": "https://huggingface.co/datasets/anfera236/HHDC",
        "changes": {
          "downloads": {
            "previous": 6764,
            "current": 13988,
            "change": 7224
          },
          "likes": {
            "previous": 1,
            "current": 1,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "thaotien/movies_CLIP_ViT-L14",
        "author": "thaotien",
        "url": "https://huggingface.co/datasets/thaotien/movies_CLIP_ViT-L14",
        "changes": {
          "downloads": {
            "previous": 1856,
            "current": 9044,
            "change": 7188
          },
          "likes": {
            "previous": 0,
            "current": 0,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "Zyphra/Zyda-2",
        "author": "Zyphra",
        "url": "https://huggingface.co/datasets/Zyphra/Zyda-2",
        "changes": {
          "downloads": {
            "previous": 179316,
            "current": 186397,
            "change": 7081
          },
          "likes": {
            "previous": 85,
            "current": 85,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "SimpleStories/SimpleStories",
        "author": "SimpleStories",
        "url": "https://huggingface.co/datasets/SimpleStories/SimpleStories",
        "changes": {
          "downloads": {
            "previous": 166581,
            "current": 173175,
            "change": 6594
          },
          "likes": {
            "previous": 23,
            "current": 24,
            "change": 1
          },
          "description_changed": false
        }
      },
      {
        "id": "dad3131/GUIOdyssey",
        "author": "dad3131",
        "url": "https://huggingface.co/datasets/dad3131/GUIOdyssey",
        "changes": {
          "downloads": {
            "previous": 592,
            "current": 6828,
            "change": 6236
          },
          "likes": {
            "previous": 0,
            "current": 0,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "Voxel51/SynthHuman",
        "author": "Voxel51",
        "url": "https://huggingface.co/datasets/Voxel51/SynthHuman",
        "changes": {
          "downloads": {
            "previous": 3768,
            "current": 9858,
            "change": 6090
          },
          "likes": {
            "previous": 1,
            "current": 1,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "allenai/dolma3_dolmino_mix-100B-1025",
        "author": "allenai",
        "url": "https://huggingface.co/datasets/allenai/dolma3_dolmino_mix-100B-1025",
        "changes": {
          "downloads": {
            "previous": 46259,
            "current": 52291,
            "change": 6032
          },
          "likes": {
            "previous": 2,
            "current": 2,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "openai/openai_humaneval",
        "author": "openai",
        "url": "https://huggingface.co/datasets/openai/openai_humaneval",
        "changes": {
          "downloads": {
            "previous": 126051,
            "current": 132072,
            "change": 6021
          },
          "likes": {
            "previous": 360,
            "current": 361,
            "change": 1
          },
          "description_changed": false
        }
      },
      {
        "id": "ILSVRC/imagenet-1k",
        "author": "ILSVRC",
        "url": "https://huggingface.co/datasets/ILSVRC/imagenet-1k",
        "changes": {
          "downloads": {
            "previous": 63673,
            "current": 69654,
            "change": 5981
          },
          "likes": {
            "previous": 696,
            "current": 701,
            "change": 5
          },
          "description_changed": false
        }
      },
      {
        "id": "camel-ai/loong",
        "author": "camel-ai",
        "url": "https://huggingface.co/datasets/camel-ai/loong",
        "changes": {
          "downloads": {
            "previous": 22046,
            "current": 27703,
            "change": 5657
          },
          "likes": {
            "previous": 59,
            "current": 59,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "InternRobotics/InternData-A1",
        "author": "InternRobotics",
        "url": "https://huggingface.co/datasets/InternRobotics/InternData-A1",
        "changes": {
          "downloads": {
            "previous": 21801,
            "current": 27414,
            "change": 5613
          },
          "likes": {
            "previous": 57,
            "current": 66,
            "change": 9
          },
          "description_changed": false
        }
      },
      {
        "id": "UCLNLP/adversarial_qa",
        "author": "UCLNLP",
        "url": "https://huggingface.co/datasets/UCLNLP/adversarial_qa",
        "changes": {
          "downloads": {
            "previous": 29781,
            "current": 35370,
            "change": 5589
          },
          "likes": {
            "previous": 41,
            "current": 41,
            "change": 0
          },
          "description_changed": false
        }
      },
      {
        "id": "ScienceOne-AI/S1-MMAlign",
        "author": "ScienceOne-AI",
        "url": "https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign",
        "changes": {
          "downloads": {
            "previous": 1651,
            "current": 7227,
            "change": 5576
          },
          "likes": {
            "previous": 8,
            "current": 45,
            "change": 37
          },
          "description_changed": false
        }
      }
    ],
    "unchanged_count": 2762
  },
  "summary": {
    "new_count": 1184,
    "removed_count": 70,
    "updated_count": 50,
    "unchanged_count": 2762,
    "net_change": 1114
  }
}